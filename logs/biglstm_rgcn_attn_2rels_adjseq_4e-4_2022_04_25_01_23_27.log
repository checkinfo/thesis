Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='RGCNSeqTimeDataset', dout=0.3, epochs=60, glstm_layers=1, gnn_layers=1, gpu=0, graph_attn=True, hidden_dim=128, inner_prod=False, input_dim=9, input_graph=True, label_cnt=3, lr=0.0004, lstm_layers=1, market=None, mask_adj=True, mask_type='soft', model_type='BiGLSTM', normalize_adj=True, num_days=8, num_heads=1, print_inteval=500, rank_loss=False, relation_num=2, rsr_data_path=None, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_250_0.8/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
load 2305 train graphs successful!
load 126 test graphs successful!
2517
BiGLSTM(
  (input_to_hidden): Linear(in_features=9, out_features=128, bias=True)
  (forward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (attention): ModuleList(
            (0): GraphAttentionLayer (128 -> 128)
            (1): GraphAttentionLayer (128 -> 128)
          )
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
            (1): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
  )
  (backward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (attention): ModuleList(
            (0): GraphAttentionLayer (128 -> 128)
            (1): GraphAttentionLayer (128 -> 128)
          )
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
            (1): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
  )
  (fc0): ModuleList(
    (0): Linear(in_features=256, out_features=128, bias=True)
  )
  (w_out): Linear(in_features=128, out_features=1, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
)
train 0, step: 0, loss: 4.931181358116692, grad_norm: 4.941579925469582, ic: -0.03934702255174804
train 0, step: 500, loss: 0.8647283397407216, grad_norm: 0.026175876613327684, ic: 0.03614061190865891
train 0, step: 1000, loss: 1.9479735792337236, grad_norm: 0.5075208383850753, ic: 0.0366094044807793
train 0, step: 1500, loss: 0.9573278856842885, grad_norm: 0.053536183296322565, ic: 0.027250224528147255
train 0, step: 2000, loss: 1.0013043683067855, grad_norm: 0.15401850781445628, ic: 0.007092585491823299
Epoch 0: 2022-04-25 13:31:55.914665: train loss: 1.6486740136407043
Eval step 0: eval loss: 0.8361741800579556
Eval: 2022-04-25 13:32:26.784327: total loss: 1.0792990730044212, mse:4.822932138507077, ic :0.008104010530046134, sharpe5:8.279790868163108, irr5:235.18467712402344, ndcg5:0.8630661462734066, pnl5:2.84899640083313 
train 1, step: 0, loss: 2.772035857169859, grad_norm: 0.8635760214679601, ic: 0.05749831848762091
train 1, step: 500, loss: 1.754440009931561, grad_norm: 0.7542049935481133, ic: 0.12037187686334132
train 1, step: 1000, loss: 0.8775988408534707, grad_norm: 0.17398103648110153, ic: 0.06760831568292697
train 1, step: 1500, loss: 1.712982388200431, grad_norm: 0.20786453774955066, ic: -0.014772672378500553
train 1, step: 2000, loss: 2.1784666015625, grad_norm: 0.8865598672944269, ic: -0.03763179698844819
Epoch 1: 2022-04-25 13:40:44.663585: train loss: 1.6467048719490733
Eval step 0: eval loss: 0.834353351492525
Eval: 2022-04-25 13:41:14.768613: total loss: 1.0789934659485438, mse:4.823833719052189, ic :0.006895584125472916, sharpe5:8.12517363488674, irr5:233.8961944580078, ndcg5:0.8529958498971929, pnl5:2.710139513015747 
train 2, step: 0, loss: 2.1424462002840907, grad_norm: 0.009785572656051433, ic: 0.1074050700724108
train 2, step: 500, loss: 3.2989064486746873, grad_norm: 0.27930445423693573, ic: 0.08972457412063711
train 2, step: 1000, loss: 2.0727529708453067, grad_norm: 0.00017259599055287605, ic: 0.16948279904403868
train 2, step: 1500, loss: 1.484721362863788, grad_norm: 0.059239253206209125, ic: -0.04581480084440239
train 2, step: 2000, loss: 3.2341939603365386, grad_norm: 0.7806012525801553, ic: 0.14555141126648594
Epoch 2: 2022-04-25 13:49:37.320392: train loss: 1.6464979057906528
Eval step 0: eval loss: 0.8358211537432494
Eval: 2022-04-25 13:50:08.357502: total loss: 1.0795006881389884, mse:4.820970555446193, ic :0.021625603501548546, sharpe5:10.703543888926506, irr5:335.2259826660156, ndcg5:0.8420657203255691, pnl5:2.562544345855713 
train 3, step: 0, loss: 1.5226878096417682, grad_norm: 0.5196772960203832, ic: -0.026908967384443788
train 3, step: 500, loss: 1.4992552468248337, grad_norm: 0.3399752977179775, ic: 0.1084134332149517
train 3, step: 1000, loss: 3.680119841141336, grad_norm: 0.703358640244804, ic: -0.03495157186370396
train 3, step: 1500, loss: 1.9725291849938626, grad_norm: 1.4125230108486164, ic: -0.05831589755701837
train 3, step: 2000, loss: 0.8959959617820946, grad_norm: 0.0013306993196437154, ic: 0.05351961705271816
Epoch 3: 2022-04-25 13:58:20.806729: train loss: 1.6458046592535953
Eval step 0: eval loss: 0.8338359997571456
Eval: 2022-04-25 13:58:51.272075: total loss: 1.0788438365945552, mse:4.817224619701617, ic :0.0422161672181, sharpe5:10.01909569144249, irr5:236.83767700195312, ndcg5:0.8536916856645772, pnl5:2.3554859161376953 
train 4, step: 0, loss: 1.4347040417729593, grad_norm: 0.04779406228536, ic: 0.05676906673799471
train 4, step: 500, loss: 1.6290458138533463, grad_norm: 0.5540245551526469, ic: -0.08688127102642752
train 4, step: 1000, loss: 2.9489861465081937, grad_norm: 0.7865144038241176, ic: -0.016198636804364223
train 4, step: 1500, loss: 2.1496658260812236, grad_norm: 0.5107899926798081, ic: -0.04076819620300005
train 4, step: 2000, loss: 1.0687899433806376, grad_norm: 0.4373119683705611, ic: 0.2215414563471872
Epoch 4: 2022-04-25 14:07:03.798052: train loss: 1.6393996322742472
Eval step 0: eval loss: 0.8473962878276474
Eval: 2022-04-25 14:07:34.799105: total loss: 1.0813814130864197, mse:4.781206889993759, ic :0.1098674786700002, sharpe5:16.050739917755127, irr5:500.7591247558594, ndcg5:0.8336035569543896, pnl5:4.787568092346191 
train 5, step: 0, loss: 1.3054629332267198, grad_norm: 0.3590295070921907, ic: 0.34596052028865193
train 5, step: 500, loss: 0.8849917600118953, grad_norm: 0.013023299155458266, ic: 0.8567769094501224
train 5, step: 1000, loss: 0.9873382685284962, grad_norm: 0.18316744593521303, ic: -0.028989082279585177
train 5, step: 1500, loss: 1.5246082907613898, grad_norm: 0.17095404761463656, ic: 0.11737689883211137
train 5, step: 2000, loss: 1.0974579919518561, grad_norm: 0.03819334620051251, ic: 0.19878526453622175
Epoch 5: 2022-04-25 14:16:05.566777: train loss: 1.6309384571121677
Eval step 0: eval loss: 0.832804061841412
Eval: 2022-04-25 14:16:37.366354: total loss: 1.0738236435686555, mse:4.742412481076814, ic :0.13290522770316168, sharpe5:18.032677524089813, irr5:558.7373657226562, ndcg5:0.8524170940659868, pnl5:7.775022029876709 
train 6, step: 0, loss: 1.333364191618072, grad_norm: 0.4572383457031456, ic: 0.17300907127812204
train 6, step: 500, loss: 1.0073369305130169, grad_norm: 0.04306780869358076, ic: 0.02180839081679468
train 6, step: 1000, loss: 1.1170059262119771, grad_norm: 0.11374670830779021, ic: 0.27215685498663594
train 6, step: 1500, loss: 1.5703032186208676, grad_norm: 0.7176534988850136, ic: 0.11629999844551846
train 6, step: 2000, loss: 0.8061615307871296, grad_norm: 0.2142573394722575, ic: 0.3523519262569287
Epoch 6: 2022-04-25 14:24:48.802205: train loss: 1.6285856934929919
Eval step 0: eval loss: 0.8247088320765279
Eval: 2022-04-25 14:25:19.824727: total loss: 1.070594567679173, mse:4.687036368110173, ic :0.16608843467325515, sharpe5:17.735255777835846, irr5:580.4619140625, ndcg5:0.8615891704573495, pnl5:4.29428768157959 
train 7, step: 0, loss: 0.9765707015991212, grad_norm: 0.09836084378278626, ic: 0.21206032173872247
train 7, step: 500, loss: 0.6471150406950513, grad_norm: 0.020035283682339804, ic: 0.08402248330207068
train 7, step: 1000, loss: 1.0267401852865574, grad_norm: 0.23844959179439568, ic: 0.10459832977712441
train 7, step: 1500, loss: 2.256533967209271, grad_norm: 0.6998567034054916, ic: 0.4432837504707909
train 7, step: 2000, loss: 0.9144720961858845, grad_norm: 0.059134010553557964, ic: -0.04156938604390041
Epoch 7: 2022-04-25 14:33:37.775956: train loss: 1.6283895776884976
Eval step 0: eval loss: 0.8363596651903319
Eval: 2022-04-25 14:34:07.569434: total loss: 1.0762538692016208, mse:4.6935061651846794, ic :0.15877436121766855, sharpe5:16.617097803354262, irr5:540.599365234375, ndcg5:0.8595556453595377, pnl5:6.203294277191162 
train 8, step: 0, loss: 3.549069435009058, grad_norm: 2.1890017259794625, ic: 0.1698261745514057
train 8, step: 500, loss: 2.7574333028590425, grad_norm: 1.4935654057472973, ic: 0.038853860269464954
train 8, step: 1000, loss: 3.0357605865036232, grad_norm: 1.0313337620233574, ic: 0.11750180567187647
train 8, step: 1500, loss: 0.7125456371377928, grad_norm: 0.047628235316331646, ic: 0.4599182248007341
train 8, step: 2000, loss: 1.0807922969089252, grad_norm: 0.3990697733558184, ic: 0.5603940170636053
Epoch 8: 2022-04-25 14:42:30.247453: train loss: 1.6276856823738457
Eval step 0: eval loss: 0.8278865191155163
Eval: 2022-04-25 14:42:59.767475: total loss: 1.0692651198700016, mse:4.670710020088874, ic :0.17193071857107922, sharpe5:17.269487632513044, irr5:567.94091796875, ndcg5:0.8328246757681139, pnl5:5.082550525665283 
train 9, step: 0, loss: 5.397508441736443, grad_norm: 0.7817389105380016, ic: 0.17411835993994787
train 9, step: 500, loss: 1.3219297021851504, grad_norm: 1.318354333538554, ic: 0.3498937676173632
train 9, step: 1000, loss: 0.9202369727524631, grad_norm: 0.01584149523066454, ic: 0.1655170530606347
train 9, step: 1500, loss: 1.0793359051396816, grad_norm: 0.05982245567509883, ic: 0.4809521505118253
train 9, step: 2000, loss: 1.0559933799759127, grad_norm: 0.42508803482636426, ic: 0.272022029058416
Epoch 9: 2022-04-25 14:51:15.173271: train loss: 1.6257287267519966
Eval step 0: eval loss: 0.8278605357613277
Eval: 2022-04-25 14:51:42.853919: total loss: 1.0712840634757779, mse:4.642882258691834, ic :0.1693374776630873, sharpe5:17.011720983982084, irr5:553.004150390625, ndcg5:0.8496957209829449, pnl5:6.703734397888184 
train 10, step: 0, loss: 7.099482678115889, grad_norm: 3.112350775918438, ic: 0.22522630648628394
train 10, step: 500, loss: 1.1335275790755004, grad_norm: 0.18128992442090758, ic: 0.06889092136012158
train 10, step: 1000, loss: 2.3697897320144747, grad_norm: 0.9287661003672721, ic: 0.13868241150941213
train 10, step: 1500, loss: 1.117246355329241, grad_norm: 0.71164156067016, ic: 0.0027125777703179976
train 10, step: 2000, loss: 2.664236700643522, grad_norm: 0.4448211568284357, ic: 0.5429414349751736
Epoch 10: 2022-04-25 15:00:00.903087: train loss: 1.623692904563338
Eval step 0: eval loss: 0.825734081208015
Eval: 2022-04-25 15:00:30.940770: total loss: 1.0671650290911798, mse:4.612143502554394, ic :0.1819219628977622, sharpe5:17.487181084156035, irr5:570.1494140625, ndcg5:0.8523272195405952, pnl5:7.720648288726807 
train 11, step: 0, loss: 1.247690765782096, grad_norm: 0.03422469471834232, ic: 0.21038010875067825
train 11, step: 500, loss: 0.6441898173875563, grad_norm: 0.035130675481661336, ic: 0.6426862528451575
train 11, step: 1000, loss: 0.9407857342977123, grad_norm: 0.23663406192016004, ic: 0.025268996471720803
train 11, step: 1500, loss: 1.054071593702885, grad_norm: 0.17481379939489383, ic: 0.16527129518467149
train 11, step: 2000, loss: 0.7857850181736276, grad_norm: 0.005856947236061193, ic: 0.129438701799394
Epoch 11: 2022-04-25 15:08:55.133410: train loss: 1.6215813505591756
Eval step 0: eval loss: 0.8296149266909246
Eval: 2022-04-25 15:09:26.127192: total loss: 1.0684229445933235, mse:4.586008394489576, ic :0.18654246478772776, sharpe5:17.76099252462387, irr5:580.2832641601562, ndcg5:0.8613276650639785, pnl5:6.645025253295898 
train 12, step: 0, loss: 0.9667539596557617, grad_norm: 0.1829263745992019, ic: 0.3928839525247607
train 12, step: 500, loss: 0.9276597931383088, grad_norm: 0.09953416252259607, ic: 0.1710459499990023
train 12, step: 1000, loss: 2.9419322408688298, grad_norm: 0.3974466166380577, ic: 0.430084539135877
train 12, step: 1500, loss: 0.9492842942271992, grad_norm: 0.49522607817091335, ic: -0.06069812912832647
train 12, step: 2000, loss: 0.873237817309054, grad_norm: 0.006272794280529539, ic: 0.21879658358570386
Epoch 12: 2022-04-25 15:17:32.293710: train loss: 1.6209418325885623
Eval step 0: eval loss: 0.8279624110906216
Eval: 2022-04-25 15:18:03.475901: total loss: 1.0666149785188541, mse:4.589562683541183, ic :0.18424319530124889, sharpe5:17.49877624154091, irr5:572.7807006835938, ndcg5:0.8571655745758142, pnl5:6.317315578460693 
train 13, step: 0, loss: 2.061133250767225, grad_norm: 1.3062183789271808, ic: 0.4392226819005262
train 13, step: 500, loss: 0.8069581243871504, grad_norm: 0.07861132942555966, ic: 0.599963552175074
train 13, step: 1000, loss: 0.9473107664377097, grad_norm: 0.4976424744784334, ic: 0.6022748357405276
train 13, step: 1500, loss: 2.417365354825332, grad_norm: 0.8819256388688075, ic: -0.01575492053980192
train 13, step: 2000, loss: 1.4572266188835161, grad_norm: 0.12300106450957815, ic: 0.21366162759952498
Epoch 13: 2022-04-25 15:26:51.714053: train loss: 1.621018789513014
Eval step 0: eval loss: 0.8232869509022654
Eval: 2022-04-25 15:27:24.606974: total loss: 1.0678287704896114, mse:4.616497427334007, ic :0.179615684110119, sharpe5:17.289573419094086, irr5:565.3167114257812, ndcg5:0.8461965136630163, pnl5:5.167167663574219 
train 14, step: 0, loss: 4.4857156786271455, grad_norm: 1.692290516043921, ic: 0.17775530573826484
train 14, step: 500, loss: 0.8278229973002675, grad_norm: 0.02095209251112627, ic: 0.10842130935118673
train 14, step: 1000, loss: 1.8089952751281322, grad_norm: 0.43527307499256496, ic: 0.4675021536715875
train 14, step: 1500, loss: 1.1278390450230573, grad_norm: 0.19185091842500263, ic: -0.05492091988040587
train 14, step: 2000, loss: 1.1401323287503624, grad_norm: 0.8491023666504851, ic: 0.05724898891687967
Epoch 14: 2022-04-25 15:36:14.378819: train loss: 1.6203530732842557
Eval step 0: eval loss: 0.8342992623814541
Eval: 2022-04-25 15:36:47.238328: total loss: 1.0684777680705229, mse:4.596443952688367, ic :0.17811663612075537, sharpe5:16.18637431383133, irr5:522.3021850585938, ndcg5:0.8400637572716972, pnl5:3.4009757041931152 
train 15, step: 0, loss: 3.401494482611868, grad_norm: 1.0235436370980482, ic: 0.07547240591855275
train 15, step: 500, loss: 1.2524527710671238, grad_norm: 0.0539310218891976, ic: 0.07648104838883231
train 15, step: 1000, loss: 1.316580721227134, grad_norm: 0.14868242667529302, ic: 0.043535373369837746
train 15, step: 1500, loss: 0.8498399629367618, grad_norm: 0.63785618552952, ic: 0.07179426079561203
train 15, step: 2000, loss: 1.4720417704559179, grad_norm: 1.9704925070325374, ic: 0.07204747236944789
Epoch 15: 2022-04-25 15:47:21.743932: train loss: 1.619119461006998
Eval step 0: eval loss: 0.83653228727608
Eval: 2022-04-25 15:48:07.007587: total loss: 1.0701100288162981, mse:4.584947428742748, ic :0.18931501174316756, sharpe5:17.15107286810875, irr5:570.353515625, ndcg5:0.842334951576524, pnl5:5.29219388961792 
train 16, step: 0, loss: 0.6937958512717736, grad_norm: 2.044650038040091, ic: 0.047241828530688375
train 16, step: 500, loss: 1.592656343055188, grad_norm: 1.0766097664822627, ic: 0.18438461998480069
train 16, step: 1000, loss: 0.8815302993312026, grad_norm: 0.015844105526471534, ic: -0.074946851194963
train 16, step: 1500, loss: 0.8424685022039993, grad_norm: 0.5338786206775659, ic: 0.1336815197684791
train 16, step: 2000, loss: 3.2969417304268167, grad_norm: 1.6775708729673042, ic: 0.007176342018922031
Epoch 16: 2022-04-25 15:58:43.241579: train loss: 1.6193235689768193
Eval step 0: eval loss: 0.8300862287193757
Eval: 2022-04-25 15:59:13.491510: total loss: 1.0673246418707798, mse:4.593760172715239, ic :0.18401705136319702, sharpe5:16.644217493534086, irr5:557.3967895507812, ndcg5:0.8446426182460831, pnl5:8.416232109069824 
train 17, step: 0, loss: 1.260902400737732, grad_norm: 0.9520764726014048, ic: -0.07344381256192944
train 17, step: 500, loss: 1.7920035674966124, grad_norm: 2.389870181580756, ic: 0.1870352420648305
train 17, step: 1000, loss: 1.277531709802492, grad_norm: 0.129011665789188, ic: 0.15104482461240348
train 17, step: 1500, loss: 4.5202182879087065, grad_norm: 1.5046221450962196, ic: 0.20281432189381304
train 17, step: 2000, loss: 1.2736779503530231, grad_norm: 2.2081655399935682, ic: 0.10880629399556008
Epoch 17: 2022-04-25 16:07:31.203613: train loss: 1.6188884201813574
Eval step 0: eval loss: 0.833116119352608
Eval: 2022-04-25 16:08:02.247463: total loss: 1.0683087779225298, mse:4.603617828904464, ic :0.1876133315609826, sharpe5:17.523039236068726, irr5:588.5174560546875, ndcg5:0.8528464835937388, pnl5:6.2262396812438965 
train 18, step: 0, loss: 1.4037984132203973, grad_norm: 2.031925938219988, ic: 0.2501240993009374
train 18, step: 500, loss: 1.5239990825514527, grad_norm: 2.203263864124331, ic: 0.07524099023510655
train 18, step: 1000, loss: 0.6541068466395548, grad_norm: 0.033572929683992, ic: 0.5735920891948046
train 18, step: 1500, loss: 1.4430460512003482, grad_norm: 19.75949204672035, ic: 0.019898524315384032
train 18, step: 2000, loss: 0.9102514959444666, grad_norm: 0.024037617078087166, ic: 0.011014345106202432
Epoch 18: 2022-04-25 16:16:14.532521: train loss: 1.618031054183338
Eval step 0: eval loss: 0.8235253031562829
Eval: 2022-04-25 16:16:45.317928: total loss: 1.0648696516384089, mse:4.59518993535224, ic :0.18980916877599746, sharpe5:17.18736803770065, irr5:596.8355712890625, ndcg5:0.8569436083869106, pnl5:6.2103705406188965 
train 19, step: 0, loss: 1.481072998046875, grad_norm: 2.122486133696202, ic: 0.011917774524012908
train 19, step: 500, loss: 0.8601257182933666, grad_norm: 0.12520669705954948, ic: 0.23306966230908896
train 19, step: 1000, loss: 0.9553707415349754, grad_norm: 0.07910255930424753, ic: 0.2208214827297028
train 19, step: 1500, loss: 3.938841315113317, grad_norm: 1.692650601847995, ic: 0.15230437838522085
train 19, step: 2000, loss: 1.0046619591346153, grad_norm: 0.417748520799209, ic: 0.18912897145982985
Epoch 19: 2022-04-25 16:24:49.621991: train loss: 1.6187356319167838
Eval step 0: eval loss: 0.827056723977542
Eval: 2022-04-25 16:25:20.172141: total loss: 1.0668085363128492, mse:4.592116166252303, ic :0.1911600289982889, sharpe5:16.97851331591606, irr5:586.0857543945312, ndcg5:0.8532283955206675, pnl5:6.037851333618164 
train 20, step: 0, loss: 2.339492303297925, grad_norm: 5.546885214405035, ic: 0.048982065129149974
train 20, step: 500, loss: 3.2376495028409087, grad_norm: 0.8245179132230608, ic: 0.09264794248265018
train 20, step: 1000, loss: 0.9713193893432618, grad_norm: 0.15473845537431055, ic: 0.13684497554417108
train 20, step: 1500, loss: 1.7916680375430705, grad_norm: 3.1451608852797315, ic: 0.26412253864647683
train 20, step: 2000, loss: 1.036596002625408, grad_norm: 0.15031694338311669, ic: 0.0011005490793458
Epoch 20: 2022-04-25 16:33:37.116193: train loss: 1.6175716409719847
Eval step 0: eval loss: 0.8380366205792281
Eval: 2022-04-25 16:34:08.070172: total loss: 1.06928226856323, mse:4.587040466232591, ic :0.19119494380393462, sharpe5:16.917584348917007, irr5:584.8267822265625, ndcg5:0.8398037380308021, pnl5:4.761237621307373 
train 21, step: 0, loss: 1.001334951998713, grad_norm: 0.426051669283116, ic: 0.05459631975352637
train 21, step: 500, loss: 0.7695430654340085, grad_norm: 0.018719711128955215, ic: 0.20095553284350443
train 21, step: 1000, loss: 0.9270463910019188, grad_norm: 2.472315467199458, ic: 0.1739978976517192
train 21, step: 1500, loss: 0.981525462338013, grad_norm: 0.3680972330752744, ic: 0.3092270783999411
train 21, step: 2000, loss: 0.9375532621297065, grad_norm: 0.19412461584483492, ic: 0.07102167336043763
Epoch 21: 2022-04-25 16:42:22.142497: train loss: 1.6180238542137553
Eval step 0: eval loss: 0.8246966121822312
Eval: 2022-04-25 16:42:54.011629: total loss: 1.066375696659505, mse:4.609772602242304, ic :0.18598354375737652, sharpe5:17.37501132130623, irr5:597.2850341796875, ndcg5:0.837488688884509, pnl5:7.635955810546875 
train 22, step: 0, loss: 1.038566891082936, grad_norm: 0.025814816191603175, ic: 0.21861755541951655
train 22, step: 500, loss: 3.267599561737805, grad_norm: 2.721216304926119, ic: -0.2261781334346754
train 22, step: 1000, loss: 1.1942271326318643, grad_norm: 0.01775787873990632, ic: 0.4605554800668346
train 22, step: 1500, loss: 0.9757020801183127, grad_norm: 0.20629403182483075, ic: 0.10344302694513596
train 22, step: 2000, loss: 1.8097972913123583, grad_norm: 28.32480633369362, ic: 0.11853004868280416
Epoch 22: 2022-04-25 16:51:15.089864: train loss: 1.6182055695211455
Eval step 0: eval loss: 0.8253528848211933
Eval: 2022-04-25 16:51:46.423597: total loss: 1.0659984004307965, mse:4.584096217535275, ic :0.19082871863310719, sharpe5:16.68204884648323, irr5:569.0519409179688, ndcg5:0.8488579886589082, pnl5:7.677234649658203 
train 23, step: 0, loss: 0.9777124234510087, grad_norm: 0.0861335489176938, ic: 0.19374900425393796
train 23, step: 500, loss: 1.412121735337765, grad_norm: 0.3161685056335336, ic: 0.06945276441471197
train 23, step: 1000, loss: 1.650910135904948, grad_norm: 0.14398478870900822, ic: 0.257243170129731
train 23, step: 1500, loss: 1.1216822731796814, grad_norm: 3.1749728607125336, ic: 0.0911553915169472
train 23, step: 2000, loss: 1.8937328594110854, grad_norm: 2.355889443625707, ic: 0.45170083639378594
Epoch 23: 2022-04-25 16:59:48.869610: train loss: 1.6166416273484217
Eval step 0: eval loss: 0.82863990775652
Eval: 2022-04-25 17:00:20.105055: total loss: 1.067575097584839, mse:4.614109623081881, ic :0.18465840451739737, sharpe5:17.41151081085205, irr5:584.2896728515625, ndcg5:0.8502246557580901, pnl5:6.506228923797607 
train 24, step: 0, loss: 2.196744584250843, grad_norm: 0.042373223320280956, ic: 0.14943330012204353
train 24, step: 500, loss: 1.2192566155459632, grad_norm: 0.3935112209580039, ic: 0.20917410141044723
train 24, step: 1000, loss: 0.9036872652557394, grad_norm: 0.0385192443595136, ic: 0.5267408685134836
train 24, step: 1500, loss: 2.630160565230833, grad_norm: 3.9710334412397312, ic: -0.020432292036204273
train 24, step: 2000, loss: 0.9278456012505093, grad_norm: 0.022918231745953754, ic: 0.09660566660355024
Epoch 24: 2022-04-25 17:08:28.545478: train loss: 1.6131855908737325
Eval step 0: eval loss: 0.8237120745933219
Eval: 2022-04-25 17:08:59.888459: total loss: 1.0671356227906594, mse:4.641388776702919, ic :0.18416031701208171, sharpe5:16.892137055397033, irr5:576.0878295898438, ndcg5:0.8471830750828255, pnl5:4.311625957489014 
train 25, step: 0, loss: 0.8219244879645271, grad_norm: 0.09021836818944534, ic: 0.6263129879606201
train 25, step: 500, loss: 0.8669774726798527, grad_norm: 0.007938196593882752, ic: 0.23012653744302985
train 25, step: 1000, loss: 2.083072891874524, grad_norm: 0.08812313492583984, ic: 0.27601926433722035
train 25, step: 1500, loss: 1.131098477540384, grad_norm: 0.8235347682514373, ic: 0.5388876877201206
train 25, step: 2000, loss: 1.000474642582191, grad_norm: 0.6688928369981739, ic: 0.6062620685278867
Epoch 25: 2022-04-25 17:17:14.311306: train loss: 1.6141246650945256
Eval step 0: eval loss: 0.8237168339205743
Eval: 2022-04-25 17:17:45.219544: total loss: 1.0644742407670866, mse:4.584476148272165, ic :0.19364452708239507, sharpe5:17.23543052315712, irr5:587.8209228515625, ndcg5:0.8462954733255305, pnl5:5.0152997970581055 
train 26, step: 0, loss: 6.781677441094249, grad_norm: 2.0030807987635466, ic: 0.15112289397611206
train 26, step: 500, loss: 3.909269021207975, grad_norm: 8.163253443552227, ic: 0.3755619964089928
train 26, step: 1000, loss: 1.2716955547242936, grad_norm: 1.6289487912523777, ic: -0.004732195572240569
train 26, step: 1500, loss: 0.8382305330068239, grad_norm: 0.178159638129678, ic: 0.30741897638075605
train 26, step: 2000, loss: 0.9603801640256195, grad_norm: 0.7379927727489715, ic: 0.15216443244317154
Epoch 26: 2022-04-25 17:26:15.793971: train loss: 1.6165635421027118
Eval step 0: eval loss: 0.8267225420261459
Eval: 2022-04-25 17:26:46.669413: total loss: 1.0658659649176287, mse:4.6114273667777645, ic :0.1866555472192399, sharpe5:16.90824427843094, irr5:592.2694091796875, ndcg5:0.8487263360862085, pnl5:4.59744930267334 
train 27, step: 0, loss: 0.8271602136948529, grad_norm: 0.01743529076787201, ic: 0.11326383681979707
train 27, step: 500, loss: 0.9407357299061866, grad_norm: 5.992097640456532, ic: 0.27894621494656674
train 27, step: 1000, loss: 0.75344355347907, grad_norm: 1.2251368462772732, ic: 0.197468673474328
train 27, step: 1500, loss: 0.6347419813486126, grad_norm: 0.07623893297974892, ic: 0.5206032822201001
train 27, step: 2000, loss: 1.3812323521735004, grad_norm: 0.09164824492479416, ic: 0.04280490958611321
Epoch 27: 2022-04-25 17:35:00.179095: train loss: 1.6153932282147985
Eval step 0: eval loss: 0.8259955226307296
Eval: 2022-04-25 17:35:31.042682: total loss: 1.065729956397318, mse:4.596545071687635, ic :0.18943663859136464, sharpe5:16.353797489404677, irr5:580.7109985351562, ndcg5:0.843643046707465, pnl5:3.5617191791534424 
train 28, step: 0, loss: 1.555395036498552, grad_norm: 5.433010775053356, ic: 0.23594358255425693
train 28, step: 500, loss: 1.4037826648965903, grad_norm: 5.411916854348161, ic: 0.18972960088072965
train 28, step: 1000, loss: 0.9060037090849424, grad_norm: 0.2617583804497728, ic: 0.5737304101560107
train 28, step: 1500, loss: 1.0345095713748058, grad_norm: 0.19044889274186239, ic: 0.029962245644263485
train 28, step: 2000, loss: 1.0426353033334932, grad_norm: 0.9018623404970125, ic: 0.14243663546345164
Epoch 28: 2022-04-25 17:43:46.608143: train loss: 1.611934793791362
Eval step 0: eval loss: 0.8213522843741767
Eval: 2022-04-25 17:44:16.602796: total loss: 1.0743008012514577, mse:4.666812804683346, ic :0.18279107451250476, sharpe5:17.34138555407524, irr5:602.8712158203125, ndcg5:0.8417015402142378, pnl5:3.953263282775879 
train 29, step: 0, loss: 0.9047231493437263, grad_norm: 0.23135139224542584, ic: 0.10817987078375513
train 29, step: 500, loss: 1.1116294659241044, grad_norm: 0.299491267068607, ic: 0.6088252998792456
train 29, step: 1000, loss: 1.0626838080990981, grad_norm: 0.7720380375422307, ic: 0.08963535430380182
train 29, step: 1500, loss: 2.3780608106459797, grad_norm: 0.37114311743854655, ic: -0.12097016784784001
train 29, step: 2000, loss: 4.318060980902778, grad_norm: 18.910376200562546, ic: 0.21250465886972922
Epoch 29: 2022-04-25 17:52:28.859056: train loss: 1.6144842372752364
Eval step 0: eval loss: 0.827348972396931
Eval: 2022-04-25 17:52:59.467160: total loss: 1.0673293195223494, mse:4.641558951708353, ic :0.18556878029105112, sharpe5:17.427239663600922, irr5:605.46728515625, ndcg5:0.8548516621963229, pnl5:7.2380242347717285 
train 30, step: 0, loss: 1.0069377010750158, grad_norm: 0.14912719301340363, ic: 0.5175949279350682
train 30, step: 500, loss: 1.4435378239720058, grad_norm: 3.6956643716023683, ic: 0.048385749496406935
train 30, step: 1000, loss: 0.9793437610973011, grad_norm: 0.37351941878524275, ic: -0.024127907588817332
train 30, step: 1500, loss: 1.5151775178260578, grad_norm: 9.731139900552197, ic: 0.1248748158918574
train 30, step: 2000, loss: 1.8480608472408186, grad_norm: 2.3191880944137533, ic: 0.08164897870590218
Epoch 30: 2022-04-25 18:01:13.519924: train loss: 1.6136292064344282
Eval step 0: eval loss: 0.8382911802719968
Eval: 2022-04-25 18:01:44.602011: total loss: 1.0757938962388203, mse:4.725235331696898, ic :0.18474871544419072, sharpe5:16.609422562122344, irr5:590.2498168945312, ndcg5:0.8432749851513271, pnl5:5.173910617828369 
train 31, step: 0, loss: 1.0348812391124234, grad_norm: 0.32700663822295045, ic: 0.38392940412499393
train 31, step: 500, loss: 1.4794070899241254, grad_norm: 3.1028519356162354, ic: 0.02261794431205599
train 31, step: 1000, loss: 4.403818885392272, grad_norm: 7.625622775807461, ic: 0.48407285873416617
train 31, step: 1500, loss: 0.7640746582681426, grad_norm: 0.057654455895017845, ic: 0.7132473218196005
train 31, step: 2000, loss: 1.2605699347869965, grad_norm: 15.471916679512935, ic: 0.11519517791201259
Epoch 31: 2022-04-25 18:09:56.586773: train loss: 1.611587294596951
Eval step 0: eval loss: 0.8307196051353398
Eval: 2022-04-25 18:10:27.662262: total loss: 1.0682957875169157, mse:4.590974852923837, ic :0.18747776433920468, sharpe5:16.386307064294815, irr5:579.75048828125, ndcg5:0.8464370089677512, pnl5:5.258448123931885 
train 32, step: 0, loss: 1.1197826596599767, grad_norm: 0.0340032810052109, ic: 0.2643559828614229
train 32, step: 500, loss: 1.4877854715182086, grad_norm: 1.7295362519889266, ic: 0.11123416727059378
train 32, step: 1000, loss: 1.038919757706273, grad_norm: 0.26173618854178404, ic: 0.5123831867726872
train 32, step: 1500, loss: 0.9782978351747236, grad_norm: 3.66218908669984, ic: 0.06938118131818757
train 32, step: 2000, loss: 0.9412482589354565, grad_norm: 0.09070032306417924, ic: 0.5597695390921509
Epoch 32: 2022-04-25 18:18:45.589032: train loss: 1.6119354897819238
Eval step 0: eval loss: 0.8217135430387249
Eval: 2022-04-25 18:19:15.466409: total loss: 1.0644350589672522, mse:4.605002619259755, ic :0.19312397724303343, sharpe5:17.184534044265746, irr5:603.27734375, ndcg5:0.861162980329564, pnl5:6.1810455322265625 
train 33, step: 0, loss: 1.2708012558214092, grad_norm: 1.0474828299891792, ic: 0.220136440597632
train 33, step: 500, loss: 0.9822588659043162, grad_norm: 0.021824867419765314, ic: 0.19303070461701827
train 33, step: 1000, loss: 1.0255480865445807, grad_norm: 4.997155642602821, ic: 0.24722020154095045
train 33, step: 1500, loss: 0.9247458244133675, grad_norm: 0.40447381662415466, ic: 0.5490720486310142
train 33, step: 2000, loss: 0.8046874032723356, grad_norm: 0.06300723063864432, ic: 0.2885329435953118
Epoch 33: 2022-04-25 18:27:38.830704: train loss: 1.613706314300134
Eval step 0: eval loss: 0.8245272058581401
Eval: 2022-04-25 18:28:06.220503: total loss: 1.0648808195717574, mse:4.584891483425511, ic :0.19753834933607045, sharpe5:17.569643104076384, irr5:617.4905395507812, ndcg5:0.8449862928997266, pnl5:6.493786811828613 
train 34, step: 0, loss: 1.016634430842297, grad_norm: 0.7535382524248571, ic: 0.5995353634143246
train 34, step: 500, loss: 0.7909919202145451, grad_norm: 0.35249493132008897, ic: 0.25899307988250525
train 34, step: 1000, loss: 3.198805473550307, grad_norm: 3.637151419648431, ic: 0.3283822017026944
train 34, step: 1500, loss: 0.8055958253408074, grad_norm: 0.7393677376068772, ic: 0.6891423203606943
train 34, step: 2000, loss: 6.0540952084140205, grad_norm: 17.541179891525868, ic: 0.4571804490103242
Epoch 34: 2022-04-25 18:36:13.202658: train loss: 1.6136440095736542
Eval step 0: eval loss: 0.823105453314344
Eval: 2022-04-25 18:36:41.966824: total loss: 1.064899262945349, mse:4.5909628683126025, ic :0.19743041526275393, sharpe5:16.600843015909195, irr5:584.9644165039062, ndcg5:0.8550386119916944, pnl5:4.321516036987305 
train 35, step: 0, loss: 1.1834627039292278, grad_norm: 0.8930833589637001, ic: 0.5522209364086423
train 35, step: 500, loss: 1.1808816530815618, grad_norm: 1.2388877337276314, ic: 0.12574781508830546
train 35, step: 1000, loss: 1.85974769025345, grad_norm: 8.868347818438895, ic: 0.03269764361315318
train 35, step: 1500, loss: 1.6153703962053572, grad_norm: 2.169294860516862, ic: 0.07984762719379943
train 35, step: 2000, loss: 0.7847864487591911, grad_norm: 0.1743325756289364, ic: 0.5689128185983385
Epoch 35: 2022-04-25 18:44:48.009391: train loss: 1.6123988314400195
Eval step 0: eval loss: 0.8313311786872695
Eval: 2022-04-25 18:45:15.850736: total loss: 1.0660151268163087, mse:4.590995825163605, ic :0.19232708459720946, sharpe5:16.48075017929077, irr5:577.6777954101562, ndcg5:0.8502825268100337, pnl5:6.121984481811523 
train 36, step: 0, loss: 1.847965737526982, grad_norm: 8.265795658756566, ic: 0.06688815793975648
train 36, step: 500, loss: 0.8357539616578015, grad_norm: 0.0477070942008154, ic: 0.16928527762864715
train 36, step: 1000, loss: 1.6221914062499998, grad_norm: 1.0742855428297369, ic: 0.23845088723593735
train 36, step: 1500, loss: 0.7685619847506497, grad_norm: 0.10154477628642797, ic: 0.3814226389510893
train 36, step: 2000, loss: 1.1279347293238682, grad_norm: 3.1417236943506754, ic: 0.7773910021300864
Epoch 36: 2022-04-25 18:53:32.308353: train loss: 1.6112548596822376
Eval step 0: eval loss: 0.8252533248402923
Eval: 2022-04-25 18:54:02.716302: total loss: 1.0642353577869703, mse:4.586062331964429, ic :0.19510770515882214, sharpe5:17.767799406051633, irr5:598.7836303710938, ndcg5:0.8432827978891055, pnl5:5.786818981170654 
train 37, step: 0, loss: 2.031464604469755, grad_norm: 4.384534143006919, ic: 0.18641001061965512
train 37, step: 500, loss: 2.3320842201519167, grad_norm: 2.9843504361471984, ic: -0.07053551278138015
train 37, step: 1000, loss: 1.0793272160685408, grad_norm: 0.22507079829373178, ic: 0.01592578456619039
train 37, step: 1500, loss: 2.0263491739844977, grad_norm: 3.1678555670981163, ic: 0.5977777884408837
train 37, step: 2000, loss: 1.313326712066549, grad_norm: 0.42778277262481823, ic: 0.13205774735431353
Epoch 37: 2022-04-25 19:02:16.225269: train loss: 1.6050759225924875
Eval step 0: eval loss: 0.8279820915519626
Eval: 2022-04-25 19:02:47.666504: total loss: 1.0667508734322273, mse:4.627915972656764, ic :0.18745758529338163, sharpe5:17.72233632445335, irr5:604.1897583007812, ndcg5:0.8696708729193934, pnl5:6.814432621002197 
train 38, step: 0, loss: 1.3247458295124332, grad_norm: 3.230712930305716, ic: -0.07439246721550395
train 38, step: 500, loss: 0.9141233844521605, grad_norm: 0.07223183745020167, ic: 0.25930802143052034
train 38, step: 1000, loss: 0.89562216295084, grad_norm: 0.2990614677340324, ic: 0.12336348603526223
train 38, step: 1500, loss: 0.9472083437144078, grad_norm: 0.013317951288022416, ic: 0.21905605890699625
train 38, step: 2000, loss: 2.290628208494619, grad_norm: 10.824896030752278, ic: -0.013842232042919494
Epoch 38: 2022-04-25 19:10:54.670235: train loss: 1.6130493736051925
Eval step 0: eval loss: 0.8254828015921364
Eval: 2022-04-25 19:11:16.855559: total loss: 1.06531426164095, mse:4.623566858215263, ic :0.18650250837607735, sharpe5:17.931508877277373, irr5:598.4041137695312, ndcg5:0.8708348033879336, pnl5:5.168187618255615 
train 39, step: 0, loss: 0.9658333781297783, grad_norm: 0.010743911137757384, ic: 0.09965306220631469
train 39, step: 500, loss: 0.87226763292059, grad_norm: 0.13202749256103136, ic: 0.2141244370215652
train 39, step: 1000, loss: 0.9311690784463061, grad_norm: 0.37891068835356506, ic: 0.23482012484272624
train 39, step: 1500, loss: 2.106957195300119, grad_norm: 0.4892943832062733, ic: 0.1887927013397302
train 39, step: 2000, loss: 0.6066857408761601, grad_norm: 0.061723336002223975, ic: 0.17316756830899444
Epoch 39: 2022-04-25 19:16:55.306068: train loss: 1.6067690595647568
Eval step 0: eval loss: 0.8272603460056638
Eval: 2022-04-25 19:17:17.374362: total loss: 1.066262291931673, mse:4.644548434377594, ic :0.18862768473823696, sharpe5:17.295014383792875, irr5:595.287109375, ndcg5:0.853982043950623, pnl5:3.7084834575653076 
train 40, step: 0, loss: 0.8742908500091374, grad_norm: 0.04033983733025536, ic: 0.25827691784859097
train 40, step: 500, loss: 1.0831222728311865, grad_norm: 0.011194955398572473, ic: 0.4752864206688926
train 40, step: 1000, loss: 1.3010606719226372, grad_norm: 1.5128649418295455, ic: 0.11271567999213766
train 40, step: 1500, loss: 2.605786897008855, grad_norm: 4.0731991084703125, ic: 0.07194775497497374
train 40, step: 2000, loss: 1.025886970120302, grad_norm: 6.275153070233703, ic: 0.08910629046349589
Epoch 40: 2022-04-25 19:22:57.406128: train loss: 1.6092201521731135
Eval step 0: eval loss: 0.8262466736161419
Eval: 2022-04-25 19:23:19.521596: total loss: 1.0691354134882338, mse:4.646951253493394, ic :0.1856736832449614, sharpe5:18.267923573255537, irr5:627.3298950195312, ndcg5:0.8492298021596003, pnl5:7.518632888793945 
train 41, step: 0, loss: 1.638603964619253, grad_norm: 0.40305081837610107, ic: 0.41143899248681176
train 41, step: 500, loss: 1.23933984660336, grad_norm: 1.7914905712883782, ic: 0.23630321150629385
train 41, step: 1000, loss: 1.0774442017533397, grad_norm: 10.788270963742713, ic: 0.22070892478606968
train 41, step: 1500, loss: 3.2288600837825467, grad_norm: 3.4884631737401675, ic: 0.05372658429035031
train 41, step: 2000, loss: 1.0382360858255562, grad_norm: 1.469900489106652, ic: 0.11727784507685159
Epoch 41: 2022-04-25 19:29:01.073473: train loss: 1.6023713979563754
Eval step 0: eval loss: 0.8291534005779109
Eval: 2022-04-25 19:29:23.052262: total loss: 1.0675852323652137, mse:4.667536703131617, ic :0.18298370094231184, sharpe5:17.3901839697361, irr5:589.0237426757812, ndcg5:0.8522656035041949, pnl5:5.384167194366455 
train 42, step: 0, loss: 2.1550751317049808, grad_norm: 6.720148101332306, ic: 0.08784643431712226
train 42, step: 500, loss: 1.399948992389389, grad_norm: 1.964561580410544, ic: 0.2125366717443485
train 42, step: 1000, loss: 3.249454005880638, grad_norm: 4.354921232958206, ic: 0.112344879196256
train 42, step: 1500, loss: 1.2052702246170706, grad_norm: 0.12136168402061423, ic: 0.5541394901055963
train 42, step: 2000, loss: 1.179036152569545, grad_norm: 0.07920233568765168, ic: 0.4760881722561407
Epoch 42: 2022-04-25 19:35:05.974344: train loss: 1.6072138563504503
Eval step 0: eval loss: 0.8235738611573037
Eval: 2022-04-25 19:35:28.119030: total loss: 1.0643732170427596, mse:4.579985564769017, ic :0.19606406773947058, sharpe5:17.342762821912764, irr5:606.9991455078125, ndcg5:0.8563529240338359, pnl5:6.8968048095703125 
train 43, step: 0, loss: 0.8412300785885581, grad_norm: 1.3610546956873277, ic: 0.0698265314701218
train 43, step: 500, loss: 0.9618874254930339, grad_norm: 0.5212082851042834, ic: 0.26309053929814313
train 43, step: 1000, loss: 1.6625256316700125, grad_norm: 6.723029960268327, ic: -0.08330010870385014
train 43, step: 1500, loss: 1.3955346627296807, grad_norm: 0.10300347743384872, ic: 0.15029081035618735
train 43, step: 2000, loss: 1.6926936592642716, grad_norm: 2.2940059696665176, ic: -0.011434960378291963
Epoch 43: 2022-04-25 19:41:07.887577: train loss: 1.6051813313537804
Eval step 0: eval loss: 0.8200140773182296
Eval: 2022-04-25 19:41:29.672754: total loss: 1.0680985784127357, mse:4.678567051211789, ic :0.192996005417293, sharpe5:18.134517778158187, irr5:618.3641357421875, ndcg5:0.8515677390888494, pnl5:8.823780059814453 
train 44, step: 0, loss: 1.035404660765209, grad_norm: 0.5921237949406373, ic: 0.06741855346296449
train 44, step: 500, loss: 2.0724397645816968, grad_norm: 4.471191037329583, ic: 0.13529153039060823
train 44, step: 1000, loss: 1.8150363210904397, grad_norm: 4.6133718137484685, ic: 0.1234579768588483
train 44, step: 1500, loss: 1.0414605909778225, grad_norm: 0.2955228342392619, ic: 0.08207949371782398
train 44, step: 2000, loss: 0.9292500813802084, grad_norm: 0.22518314048153337, ic: 0.6973457588658113
Epoch 44: 2022-04-25 19:47:02.732719: train loss: 1.614832280916555
Eval step 0: eval loss: 0.8196771298118084
Eval: 2022-04-25 19:47:24.530339: total loss: 1.0651370273392027, mse:4.606047732506845, ic :0.19686486501385664, sharpe5:17.67418303012848, irr5:612.6433715820312, ndcg5:0.8706838762154624, pnl5:5.82440185546875 
train 45, step: 0, loss: 1.623783702420113, grad_norm: 3.6745338690749403, ic: 0.06324070890610235
train 45, step: 500, loss: 0.9656855778323127, grad_norm: 0.6822759898431817, ic: 0.46766532247371667
train 45, step: 1000, loss: 1.5351565401829934, grad_norm: 1.2435726529509965, ic: 0.8929522961273115
train 45, step: 1500, loss: 0.9880911077716169, grad_norm: 0.8478099473894458, ic: 0.20838519521963306
train 45, step: 2000, loss: 1.6951642922794117, grad_norm: 0.34518885239715336, ic: 0.44652347879294835
Epoch 45: 2022-04-25 19:53:02.985159: train loss: 1.607233802045012
Eval step 0: eval loss: 0.8210158513896206
Eval: 2022-04-25 19:53:25.170196: total loss: 1.0681019021109335, mse:4.747531427344499, ic :0.18066678322629262, sharpe5:17.595695790052414, irr5:607.7332153320312, ndcg5:0.8501222427914474, pnl5:4.955415725708008 
train 46, step: 0, loss: 2.165005302531033, grad_norm: 8.139326695568847, ic: 0.011010232218975284
train 46, step: 500, loss: 1.9332041666666668, grad_norm: 5.469721150942945, ic: 0.09131260591478241
train 46, step: 1000, loss: 0.8878552635088677, grad_norm: 4.323536816794301, ic: 0.07345800631763807
train 46, step: 1500, loss: 1.2767194194178428, grad_norm: 2.105037293015719, ic: 0.8657277026744314
train 46, step: 2000, loss: 2.765918196033747, grad_norm: 1.1524911603477663, ic: 0.3166508448986013
Epoch 46: 2022-04-25 19:59:05.134125: train loss: 1.6026750687885556
Eval step 0: eval loss: 0.8251500345758693
Eval: 2022-04-25 19:59:27.194395: total loss: 1.0669689803698459, mse:4.670996179894117, ic :0.18955175322044937, sharpe5:17.10741082906723, irr5:605.978759765625, ndcg5:0.8654425244306801, pnl5:5.361253261566162 
train 47, step: 0, loss: 1.070621924167996, grad_norm: 0.03807794191697851, ic: 0.21379719755410773
train 47, step: 500, loss: 1.4384326198426454, grad_norm: 1.4419487830334123, ic: 0.14455765208649532
train 47, step: 1000, loss: 3.299771404192487, grad_norm: 120.55302267592312, ic: 0.507621631524466
train 47, step: 1500, loss: 1.6536976884051067, grad_norm: 3.328396276385692, ic: -0.05397283042467263
train 47, step: 2000, loss: 1.2727602128937203, grad_norm: 3.211719915746346, ic: 0.1119480628108091
Epoch 47: 2022-04-25 20:05:07.101533: train loss: 1.5998676302056434
Eval step 0: eval loss: 0.8253989345281216
Eval: 2022-04-25 20:05:29.090944: total loss: 1.064654125628753, mse:4.591867767487635, ic :0.19588422356056337, sharpe5:17.271576236486435, irr5:593.71923828125, ndcg5:0.840553507957185, pnl5:5.255160331726074 
train 48, step: 0, loss: 1.0962201286764706, grad_norm: 2.1276088807375158, ic: 0.20410757587203127
train 48, step: 500, loss: 1.2756268353030744, grad_norm: 0.16249546271877793, ic: 0.20022217639998094
train 48, step: 1000, loss: 1.5820131106662243, grad_norm: 2.525191941259462, ic: 0.11518880760096385
train 48, step: 1500, loss: 1.1387317652998608, grad_norm: 0.2375497234068203, ic: 0.5192846569001086
train 48, step: 2000, loss: 2.381436563979425, grad_norm: 3.5478382677129074, ic: 0.5326071184324518
Epoch 48: 2022-04-25 20:11:12.020648: train loss: 1.6097336052454645
Eval step 0: eval loss: 0.8425483984992426
Eval: 2022-04-25 20:11:34.016252: total loss: 1.0749824362087854, mse:4.740211157236776, ic :0.18159812764201744, sharpe5:18.274698293209074, irr5:611.05810546875, ndcg5:0.8743489009606364, pnl5:5.223445892333984 
train 49, step: 0, loss: 0.9161603435780268, grad_norm: 0.34482403705035114, ic: 0.08433110265278694
train 49, step: 500, loss: 1.51919038977794, grad_norm: 0.06196350291971765, ic: -0.01146749327515421
train 49, step: 1000, loss: 1.784389877319336, grad_norm: 0.854576811976236, ic: 0.09303064327397084
train 49, step: 1500, loss: 1.5893354051184907, grad_norm: 0.29367926708954667, ic: 0.45742879912623424
train 49, step: 2000, loss: 0.9446284146916946, grad_norm: 0.6676694378552175, ic: 0.5913897551420533
Epoch 49: 2022-04-25 20:17:17.606015: train loss: 1.6108523559822847
Eval step 0: eval loss: 0.8261824226982349
Eval: 2022-04-25 20:17:39.586147: total loss: 1.0737200876930644, mse:4.669084144462003, ic :0.18812371309875223, sharpe5:17.61514023900032, irr5:612.97314453125, ndcg5:0.8436518544986102, pnl5:4.494218826293945 
train 50, step: 0, loss: 1.4970774052704512, grad_norm: 4.018845677621976, ic: 0.20031029004626977
train 50, step: 500, loss: 2.790131314846838, grad_norm: 1.811153453211516, ic: 0.26496637348882535
train 50, step: 1000, loss: 0.8534378005378515, grad_norm: 0.03495006438598334, ic: 0.16229674411854866
train 50, step: 1500, loss: 1.44361150328979, grad_norm: 1.6808817948294177, ic: 0.37808096963303073
train 50, step: 2000, loss: 9.476191206794972, grad_norm: 2.474705703310286, ic: 0.04016888389340497
Epoch 50: 2022-04-25 20:23:24.625041: train loss: 1.6059182098958709
Eval step 0: eval loss: 0.823733684511657
Eval: 2022-04-25 20:23:46.907979: total loss: 1.0654578636962488, mse:4.621577893378675, ic :0.18983272196629078, sharpe5:17.255378204584122, irr5:590.4312133789062, ndcg5:0.8340065731677806, pnl5:4.218219757080078 
train 51, step: 0, loss: 3.3690664352807596, grad_norm: 2.742285985078392, ic: -0.004524670767452912
train 51, step: 500, loss: 1.4377654913260456, grad_norm: 1.5931727053030913, ic: 0.0604525582901312
train 51, step: 1000, loss: 1.5247098556978012, grad_norm: 0.42502483182719053, ic: 0.902397749818354
train 51, step: 1500, loss: 1.0208780572322482, grad_norm: 0.09901894759496027, ic: 0.18116709319681723
train 51, step: 2000, loss: 2.351692573262448, grad_norm: 0.46003529652427616, ic: 0.2063231272300569
Epoch 51: 2022-04-25 20:29:25.221326: train loss: 1.5994768351762951
Eval step 0: eval loss: 0.8197161691583245
Eval: 2022-04-25 20:29:47.199662: total loss: 1.0678247715501585, mse:4.666136527879206, ic :0.1883784757439443, sharpe5:18.004857848882676, irr5:618.9109497070312, ndcg5:0.8517409885863135, pnl5:6.5242743492126465 
train 52, step: 0, loss: 1.1896476099046611, grad_norm: 2.27919926655303, ic: 0.15921832641669253
train 52, step: 500, loss: 1.68193935268481, grad_norm: 4.629511288286059, ic: 0.17565431573032253
train 52, step: 1000, loss: 1.1595314020927967, grad_norm: 0.6119127783968543, ic: 0.5817072908340704
train 52, step: 1500, loss: 1.0544438277952322, grad_norm: 0.7635525152855964, ic: -0.0693297888414359
train 52, step: 2000, loss: 1.3721727179901215, grad_norm: 2.583701032086739, ic: 0.20811059616894134
Epoch 52: 2022-04-25 20:35:29.526119: train loss: 1.6111972075839962
Eval step 0: eval loss: 0.8265162830734655
Eval: 2022-04-25 20:35:51.759233: total loss: 1.0671516912245762, mse:4.662291494901477, ic :0.18636212964068985, sharpe5:17.745123674869536, irr5:604.9055786132812, ndcg5:0.846467442628322, pnl5:5.260415554046631 
train 53, step: 0, loss: 3.1614934546976827, grad_norm: 4.815232030552079, ic: 0.08201544390642779
train 53, step: 500, loss: 1.0625848559462445, grad_norm: 0.03423920672932691, ic: 0.49218675218050656
train 53, step: 1000, loss: 1.253390593045441, grad_norm: 0.37496368653253603, ic: 0.17764333193498846
train 53, step: 1500, loss: 1.3400033604934387, grad_norm: 4.66229996873368, ic: 0.12371042096358806
train 53, step: 2000, loss: 3.0259640001106414, grad_norm: 6.589166278929177, ic: 0.24626339701834243
Epoch 53: 2022-04-25 20:41:32.808110: train loss: 1.5971925279841694
Eval step 0: eval loss: 0.8174478352007046
Eval: 2022-04-25 20:41:54.412795: total loss: 1.0666186289814719, mse:4.678411161232383, ic :0.18997826932082704, sharpe5:18.147599930763242, irr5:620.6322021484375, ndcg5:0.8417719746700066, pnl5:3.9466848373413086 
train 54, step: 0, loss: 2.025818839905754, grad_norm: 9.595333542435663, ic: -0.007700320022877134
train 54, step: 500, loss: 0.8738069517422566, grad_norm: 0.1303199641526097, ic: 0.5327848760032156
train 54, step: 1000, loss: 2.227876927164777, grad_norm: 0.3109025967267862, ic: 0.1694108788379725
train 54, step: 1500, loss: 1.682618139686525, grad_norm: 34.08953282788636, ic: 0.2370543953739356
train 54, step: 2000, loss: 2.144914729420732, grad_norm: 1.0923327732984927, ic: 0.026567912200249746
Epoch 54: 2022-04-25 20:47:36.562541: train loss: 1.595061896461517
Eval step 0: eval loss: 0.8274487896387644
Eval: 2022-04-25 20:47:58.675519: total loss: 1.065724572966037, mse:4.624299773482102, ic :0.19278913950171778, sharpe5:16.833094264268873, irr5:589.6622924804688, ndcg5:0.859980010762605, pnl5:6.302309989929199 
train 55, step: 0, loss: 1.8221617598361461, grad_norm: 2.878540858377587, ic: 0.09355059386902474
train 55, step: 500, loss: 0.8833930783155488, grad_norm: 0.038585578827077915, ic: 0.3219732729600582
train 55, step: 1000, loss: 1.0452321789410008, grad_norm: 1.5446748097976508, ic: 0.10208434259108556
train 55, step: 1500, loss: 1.0722405932714714, grad_norm: 0.4020859497185196, ic: 0.5836362366438641
train 55, step: 2000, loss: 2.2346299830111027, grad_norm: 4.0034168189834585, ic: 0.022030458512499084
Epoch 55: 2022-04-25 20:53:34.291969: train loss: 1.5960220982844995
Eval step 0: eval loss: 0.8252556401886854
Eval: 2022-04-25 20:53:56.350081: total loss: 1.0649224210682504, mse:4.6130415761441315, ic :0.1939545191925308, sharpe5:17.897234205007553, irr5:605.867431640625, ndcg5:0.8451299563933363, pnl5:4.696645259857178 
train 56, step: 0, loss: 1.0128460289119992, grad_norm: 0.0638766586711725, ic: 0.09804011366427681
train 56, step: 500, loss: 0.8986026307139968, grad_norm: 0.12218038846123955, ic: 0.04632687588661907
train 56, step: 1000, loss: 5.259271148270222, grad_norm: 56.34676937222835, ic: -0.02953100015105472
train 56, step: 1500, loss: 1.149920969736977, grad_norm: 0.10385463381023445, ic: 0.13985277558714765
train 56, step: 2000, loss: 1.0178218103814265, grad_norm: 2.2104200756656573, ic: 0.4539456572654678
Epoch 56: 2022-04-25 20:59:35.712665: train loss: 1.6011283238354568
Eval step 0: eval loss: 0.8293944540717202
Eval: 2022-04-25 20:59:57.665678: total loss: 1.0643431984422267, mse:4.582732341293485, ic :0.19445637159444043, sharpe5:16.898510702848434, irr5:592.1166381835938, ndcg5:0.8494754271330307, pnl5:3.9814000129699707 
train 57, step: 0, loss: 1.0509089565221361, grad_norm: 0.12275091744033163, ic: 0.09056397529696089
train 57, step: 500, loss: 0.8801334114498286, grad_norm: 0.15447766924028344, ic: 0.5746401391517143
train 57, step: 1000, loss: 2.2117685901068653, grad_norm: 3.2138202990552065, ic: 0.10286587285465341
train 57, step: 1500, loss: 1.132917075533414, grad_norm: 0.7381779011148837, ic: 0.13526967407802473
train 57, step: 2000, loss: 1.0774277270970951, grad_norm: 3.7328114052528325, ic: 0.6086545962264892
Epoch 57: 2022-04-25 21:05:41.799552: train loss: 1.5998564538346605
Eval step 0: eval loss: 0.8285579701494994
Eval: 2022-04-25 21:06:03.719260: total loss: 1.0637002705552383, mse:4.587718225290812, ic :0.19783890828499476, sharpe5:17.207875707149505, irr5:599.9489135742188, ndcg5:0.8433019918218716, pnl5:5.8541975021362305 
train 58, step: 0, loss: 1.4087236205767912, grad_norm: 1.3515563624831068, ic: 0.18612900969951404
train 58, step: 500, loss: 1.4695957943028257, grad_norm: 9.231390905904286, ic: 0.12063680423014893
train 58, step: 1000, loss: 1.5241214923469388, grad_norm: 1.6998820781588273, ic: 0.09489713369397025
train 58, step: 1500, loss: 2.2230334335498596, grad_norm: 1.3093874481509449, ic: 0.41489177977482805
train 58, step: 2000, loss: 0.9660671106789731, grad_norm: 0.5420727490321424, ic: 0.28396717227227675
Epoch 58: 2022-04-25 21:11:47.979699: train loss: 1.5942743251494582
Eval step 0: eval loss: 0.820757175521931
Eval: 2022-04-25 21:12:10.053325: total loss: 1.0652074623218626, mse:4.6248545698139365, ic :0.19276624249661733, sharpe5:18.36895789861679, irr5:629.6990356445312, ndcg5:0.8439325702688255, pnl5:4.940435409545898 
train 59, step: 0, loss: 1.1658246274567234, grad_norm: 1.0441213051262674, ic: 0.020582102519582788
train 59, step: 500, loss: 0.7273925684522335, grad_norm: 1.0400465810758595, ic: 0.1797327307883355
train 59, step: 1000, loss: 5.021392363173001, grad_norm: 83.42526004586851, ic: -0.11496695844888971
train 59, step: 1500, loss: 1.3611073471142345, grad_norm: 1.443204568586587, ic: 0.16402310910356904
train 59, step: 2000, loss: 0.9807925235523897, grad_norm: 0.2183366456510675, ic: 0.13254544902149482
Epoch 59: 2022-04-25 21:17:45.173536: train loss: 1.601797523789354
Eval step 0: eval loss: 0.8192550289367097
Eval: 2022-04-25 21:18:07.099993: total loss: 1.0670619052258492, mse:4.708799612458718, ic :0.18722957634670612, sharpe5:17.920430195331573, irr5:619.62109375, ndcg5:0.8477948087974889, pnl5:6.3795857429504395 

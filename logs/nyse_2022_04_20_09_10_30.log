Namespace(adj_path='./data/graphs/NYSE_1737_1737.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='AdjSeqTimeDataset', dout=0.3, epochs=60, glstm_layers=1, gnn_layers=1, gpu=0, graph_attn=True, hidden_dim=128, inner_prod=False, input_dim=5, input_graph=True, label_cnt=1, lr=0.001, lstm_layers=1, mask_adj=True, mask_type='soft', model_type='BiGLSTM', normalize_adj=True, num_days=8, num_heads=1, print_inteval=500, relation_num=1, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_250_0.8/', stock_num=1931, test_mask_path='./data/NYSE/test_mask_237_1737.npy', test_path='./data/NYSE/test_237_1737_6.npy', top_stocks=5, train_mask_path='./data/NYSE/train_mask_756_1737.npy', train_path='./data/NYSE/train_756_1737_6.npy', use_adj=True)
42899
BiGLSTM(
  (input_to_hidden): Linear(in_features=5, out_features=128, bias=True)
  (forward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (attention): ModuleList(
            (0): GraphAttentionLayer (128 -> 128)
          )
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
  )
  (backward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (attention): ModuleList(
            (0): GraphAttentionLayer (128 -> 128)
          )
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
  )
  (fc0): ModuleList(
    (0): Linear(in_features=256, out_features=128, bias=True)
  )
  (w_out): Linear(in_features=128, out_features=1, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
)
train 0, step: 0, loss: 0.0034099833574146032, grad_norm: 0.001784654564889598, ic: 0.059098470922807914
train 0, step: 500, loss: 0.00013838920858688653, grad_norm: 6.503782361106582e-05, ic: -0.01707553671423953
Epoch 0: 2022-04-20 21:11:49.138531: train loss: 0.0005829807786514687
Eval step 0: eval loss: 7.076819019857794e-05
Eval: 2022-04-20 21:12:06.281319: total loss: 0.00012285140061146153, mse:0.00024570279848699775, ic :0.023804491100654995, sharpe5:0.38338132649660106, irr5:-0.8802180290222168, ndcg5:0.8561662628210143, pnl5:1.0298278331756592 
train 1, step: 0, loss: 0.0002971615467686206, grad_norm: 0.00019793665147482383, ic: 0.04867633987430658
train 1, step: 500, loss: 0.00017924050916917622, grad_norm: 3.258192230268891e-05, ic: -0.01761773459894617
Epoch 1: 2022-04-20 21:13:20.797563: train loss: 0.00015211875348936926
Eval step 0: eval loss: 7.767432543914765e-05
Eval: 2022-04-20 21:13:38.431132: total loss: 0.00011663645946891452, mse:0.0002332729166945217, ic :0.048472013007042326, sharpe5:1.4041417052596807, irr5:-0.5463008880615234, ndcg5:0.8424536745100313, pnl5:1.1004142761230469 

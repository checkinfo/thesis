Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='RGCNSeqTimeDataset', dout=0.3, epochs=40, glstm_layers=1, gnn_layers=2, gpu=0, graph_attn=False, hidden_dim=128, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=3, mask_adj=True, mask_type='soft', model_type='RGCNModel', normalize_adj=True, num_days=1, num_heads=1, print_inteval=500, relation_num=2, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_250_0.8/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
load 2305 train graphs successful!
load 126 test graphs successful!
8945
RGCNModel(
  (fc1): Linear(in_features=9, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
  (fc4): Linear(in_features=128, out_features=1, bias=True)
  (gnns): ModuleList(
    (0): RGCN(
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
        (1): Linear(in_features=128, out_features=128, bias=False)
      )
    )
    (1): RGCN(
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
        (1): Linear(in_features=128, out_features=128, bias=False)
      )
    )
  )
  (dropout): Dropout(p=0.3, inplace=False)
  (relu): LeakyReLU(negative_slope=0.01)
)
train 0, step: 0, loss: 2.0793296844120555, grad_norm: 0.6271507184925209, ic: -0.010495029972923276
train 0, step: 500, loss: 1.3544677549279758, grad_norm: 0.8545752020938582, ic: -0.0073150647929204095
train 0, step: 1000, loss: 1.507930674451463, grad_norm: 0.03221458698218399, ic: 0.1019432995908614
train 0, step: 1500, loss: 1.1955275539248655, grad_norm: 0.10742907417210237, ic: 0.0506636291817414
train 0, step: 2000, loss: 1.558266802531917, grad_norm: 0.04743089153003647, ic: -0.01179982834894408
Epoch 0: 2022-04-19 00:22:51.482532: train loss: 1.6487174445881865
Eval step 0: eval loss: 1.0129109764802198
Eval: 2022-04-19 00:22:57.764995: total loss: 1.0916628862064084, mse:4.8885403756770485, ic :0.015253910469840887, sharpe5:0.3131387749314308, irr5:3.396195411682129, ndcg5:0.8497910210754148, pnl5:0.9270744919776917 
train 1, step: 0, loss: 0.6400373100054146, grad_norm: 0.051414490318803664, ic: 0.06371978869362739
train 1, step: 500, loss: 1.2771070710455765, grad_norm: 0.3403514615453383, ic: 0.21518985075122796
train 1, step: 1000, loss: 0.8788395065197842, grad_norm: 0.06557440255324559, ic: 0.11208450060534215
train 1, step: 1500, loss: 1.8487303198837652, grad_norm: 0.5396798490212008, ic: 0.08188249156773694
train 1, step: 2000, loss: 1.3789144752584228, grad_norm: 0.22450454369893794, ic: 0.019918669469212707
Epoch 1: 2022-04-19 00:23:50.501370: train loss: 1.6463305606874667
Eval step 0: eval loss: 1.0082992384972354
Eval: 2022-04-19 00:23:56.918730: total loss: 1.0897877964267682, mse:4.880517577481964, ic :0.04748223582376677, sharpe5:6.654486646950245, irr5:178.67982482910156, ndcg5:0.8478033126927855, pnl5:2.5407259464263916 
train 2, step: 0, loss: 1.3254403553446046, grad_norm: 0.4832513007453339, ic: 0.006019850978022989
train 2, step: 500, loss: 0.9428264519513467, grad_norm: 0.24691017641918814, ic: 0.04661767171233603
train 2, step: 1000, loss: 3.017433606501632, grad_norm: 1.125647875020172, ic: 0.0953866390325684
train 2, step: 1500, loss: 2.2823098142595164, grad_norm: 0.8510996251285675, ic: 0.08853065808294969
train 2, step: 2000, loss: 1.4571724842536284, grad_norm: 0.2808312312658917, ic: -0.0941386221595015
Epoch 2: 2022-04-19 00:24:52.485692: train loss: 1.645399318292122
Eval step 0: eval loss: 0.9991525144813058
Eval: 2022-04-19 00:24:58.770040: total loss: 1.0896121638757428, mse:4.880945056913246, ic :0.04784653449354134, sharpe5:6.8327094563841815, irr5:202.09756469726562, ndcg5:0.8582253510553227, pnl5:2.731950044631958 
train 3, step: 0, loss: 1.8302783688791124, grad_norm: 0.06531809604723789, ic: -0.13742018362484693
train 3, step: 500, loss: 0.7822204826720166, grad_norm: 0.02462060524954388, ic: 0.12101959851717041
train 3, step: 1000, loss: 1.3512730242817732, grad_norm: 0.7091941253590951, ic: 0.24046132368978712
train 3, step: 1500, loss: 2.611825091840681, grad_norm: 0.5039906321141584, ic: -0.05911537831043133
train 3, step: 2000, loss: 1.3561810117779356, grad_norm: 0.16755831982179448, ic: 0.0689429531613767
Epoch 3: 2022-04-19 00:25:53.418677: train loss: 1.6448741193176377
Eval step 0: eval loss: 1.0019613530147444
Eval: 2022-04-19 00:25:59.665656: total loss: 1.091023521986295, mse:4.876584521132783, ic :0.0575318999941447, sharpe5:6.5719347640871995, irr5:197.2527313232422, ndcg5:0.8548799065374874, pnl5:2.7772412300109863 
train 4, step: 0, loss: 1.153191367603691, grad_norm: 0.162967533566323, ic: 0.09188191093617469
train 4, step: 500, loss: 0.9898878674339054, grad_norm: 0.0070192767075779585, ic: 0.17300796320480588
train 4, step: 1000, loss: 1.3348754603475401, grad_norm: 0.07192381822427184, ic: 0.06697870972396783
train 4, step: 1500, loss: 1.048998553936298, grad_norm: 0.1311660857297261, ic: 0.6096964949096689
train 4, step: 2000, loss: 4.179065527266916, grad_norm: 0.9203144512410576, ic: -0.021864268817628624
Epoch 4: 2022-04-19 00:26:54.180601: train loss: 1.6415223876244687
Eval step 0: eval loss: 1.006173132343503
Eval: 2022-04-19 00:27:00.528628: total loss: 1.0888641519250135, mse:4.721158188362349, ic :0.12229658236034939, sharpe5:7.624429413378238, irr5:218.62823486328125, ndcg5:0.8504779480744851, pnl5:3.474289894104004 
train 5, step: 0, loss: 0.989458628855674, grad_norm: 0.1679910812381884, ic: -0.09644580786691222
train 5, step: 500, loss: 0.788221217633047, grad_norm: 0.026824754175176505, ic: 0.15512118080253895
train 5, step: 1000, loss: 1.092448741291957, grad_norm: 0.058041873307459246, ic: 0.40074313373543125
train 5, step: 1500, loss: 1.7807920874618903, grad_norm: 0.41406112197127176, ic: -0.05875636099167618
train 5, step: 2000, loss: 2.183281540427509, grad_norm: 0.8297416809900748, ic: 0.031054806557832874
Epoch 5: 2022-04-19 00:27:55.019935: train loss: 1.638514083806498
Eval step 0: eval loss: 1.0027934110057923
Eval: 2022-04-19 00:28:01.230509: total loss: 1.0864099324047571, mse:4.714940773301535, ic :0.11983047005568165, sharpe5:7.66649898648262, irr5:216.1864013671875, ndcg5:0.8498281377890196, pnl5:3.6242189407348633 
train 6, step: 0, loss: 0.7807121720728525, grad_norm: 0.011096305306590865, ic: -0.07954951942164921
train 6, step: 500, loss: 1.409476653874269, grad_norm: 0.31987057111122835, ic: 0.05111516356737211
train 6, step: 1000, loss: 1.2255969833055396, grad_norm: 0.1877379436327362, ic: 0.20907438770069925
train 6, step: 1500, loss: 1.0696414357311321, grad_norm: 0.33890490062753503, ic: 0.0803557412331965
train 6, step: 2000, loss: 2.3051374220028644, grad_norm: 1.421884274902412, ic: 0.11166514698125417
Epoch 6: 2022-04-19 00:28:55.142479: train loss: 1.6380019159883321
Eval step 0: eval loss: 1.001198976023565
Eval: 2022-04-19 00:29:01.397316: total loss: 1.086167298713041, mse:4.7188437059857495, ic :0.1195241832945209, sharpe5:7.876950430870056, irr5:223.15357971191406, ndcg5:0.845639380658938, pnl5:3.315812826156616 
train 7, step: 0, loss: 1.4569212459457372, grad_norm: 0.5750883811777197, ic: 0.20517870154527817
train 7, step: 500, loss: 1.3481790228616402, grad_norm: 0.07387053417702345, ic: 0.1810659744869877
train 7, step: 1000, loss: 0.6386601603246697, grad_norm: 0.03211503056607393, ic: 0.2883559165917955
train 7, step: 1500, loss: 0.9998216255755947, grad_norm: 0.12929101616595226, ic: 0.1045630309136451
train 7, step: 2000, loss: 1.5827097623233624, grad_norm: 0.6077962377927741, ic: 0.42681196174906094
Epoch 7: 2022-04-19 00:29:54.012353: train loss: 1.638667871551293
Eval step 0: eval loss: 0.9942115916271721
Eval: 2022-04-19 00:30:00.260399: total loss: 1.0854765368582107, mse:4.720966987795008, ic :0.12258961090760426, sharpe5:8.245014855265618, irr5:227.35577392578125, ndcg5:0.8459379998097869, pnl5:2.9654314517974854 
train 8, step: 0, loss: 1.210727492779917, grad_norm: 0.08328894357683625, ic: 0.059635278661128575
train 8, step: 500, loss: 5.543734846443965, grad_norm: 1.13004136980344, ic: 0.13841511973316314
train 8, step: 1000, loss: 1.89470078677337, grad_norm: 0.6258764912261727, ic: 0.17578551289676508
train 8, step: 1500, loss: 1.0798432986730382, grad_norm: 0.3542234112562022, ic: 0.6413417842070922
train 8, step: 2000, loss: 1.1268795698116987, grad_norm: 0.5296304185489035, ic: 0.008753009751156872
Epoch 8: 2022-04-19 00:30:54.257276: train loss: 1.637745378818716
Eval step 0: eval loss: 1.0033345315379805
Eval: 2022-04-19 00:31:00.673347: total loss: 1.087864153361997, mse:4.716952314497998, ic :0.12171801939380719, sharpe5:7.776720615327358, irr5:219.2045135498047, ndcg5:0.8370695659213243, pnl5:3.365488290786743 
train 9, step: 0, loss: 1.12064366466389, grad_norm: 0.021262729247135834, ic: 0.43954694931120364
train 9, step: 500, loss: 3.2054865124381657, grad_norm: 1.198579223541221, ic: 0.09449173908806938
train 9, step: 1000, loss: 0.8724610904463587, grad_norm: 0.1379696659868013, ic: 0.2481370271970056
train 9, step: 1500, loss: 2.1624536251519446, grad_norm: 1.1791768478996385, ic: -0.01130579204064279
train 9, step: 2000, loss: 0.6037662485094168, grad_norm: 0.004333238207064062, ic: 0.06711619214290249
Epoch 9: 2022-04-19 00:31:54.052856: train loss: 1.637395500085792
Eval step 0: eval loss: 0.9916987044990784
Eval: 2022-04-19 00:32:00.423480: total loss: 1.0841602382323952, mse:4.7260313744893026, ic :0.12238243603383182, sharpe5:8.791140335798262, irr5:243.4180450439453, ndcg5:0.8517138688313557, pnl5:3.2160067558288574 
train 10, step: 0, loss: 1.298888345485184, grad_norm: 0.046945263289653205, ic: 0.3928438019654075
train 10, step: 500, loss: 0.8965888612644523, grad_norm: 0.008676996378391845, ic: 0.11205719454173317
train 10, step: 1000, loss: 1.5321848898704205, grad_norm: 0.54101044736714, ic: 0.04524487873613287
train 10, step: 1500, loss: 3.0775283825481905, grad_norm: 1.1170192427723133, ic: 0.007679872979949383
train 10, step: 2000, loss: 1.3854041751757218, grad_norm: 0.14706518157665227, ic: 0.048097984965456766
Epoch 10: 2022-04-19 00:32:54.722148: train loss: 1.6376546269420071
Eval step 0: eval loss: 1.0029201095765863
Eval: 2022-04-19 00:33:01.143918: total loss: 1.0854672916633012, mse:4.714076141676318, ic :0.12241494481629749, sharpe5:8.255094639658928, irr5:231.57542419433594, ndcg5:0.8631163079822277, pnl5:3.189775228500366 
train 11, step: 0, loss: 4.839917812988663, grad_norm: 1.1294822505502753, ic: 0.13450481403180908
train 11, step: 500, loss: 0.996591313094038, grad_norm: 0.06456360413282637, ic: 0.0264290491875434
train 11, step: 1000, loss: 1.0350089462361747, grad_norm: 0.31852308202664403, ic: 0.023433029479108285
train 11, step: 1500, loss: 0.6921549224256069, grad_norm: 0.0012353877490121512, ic: 0.11047698229391224
train 11, step: 2000, loss: 1.1331889247816815, grad_norm: 0.052632926631301785, ic: -0.18496009925649406
Epoch 11: 2022-04-19 00:33:53.973694: train loss: 1.6366356232001462
Eval step 0: eval loss: 0.994149367265666
Eval: 2022-04-19 00:34:00.266542: total loss: 1.083378263418197, mse:4.71484058883882, ic :0.13123966860716121, sharpe5:12.792259481549262, irr5:379.5557556152344, ndcg5:0.8457935212468344, pnl5:4.548079490661621 
train 12, step: 0, loss: 1.389145489246673, grad_norm: 0.2541407544748092, ic: 0.04434430671451926
train 12, step: 500, loss: 0.8256972748742107, grad_norm: 0.3987400318648816, ic: 0.030110760629223753
train 12, step: 1000, loss: 1.2239106110343831, grad_norm: 0.30783463903949826, ic: 0.5717408883823019
train 12, step: 1500, loss: 1.087883718881403, grad_norm: 0.2186213340800493, ic: -0.0013971735210611888
train 12, step: 2000, loss: 1.1126554207903039, grad_norm: 0.05903118546418899, ic: 0.10944103645210507
Epoch 12: 2022-04-19 00:34:55.778350: train loss: 1.6371473866478634
Eval step 0: eval loss: 0.9998796010029949
Eval: 2022-04-19 00:35:02.104225: total loss: 1.0855689095941843, mse:4.719617695631975, ic :0.12422125606105824, sharpe5:7.713353051841259, irr5:214.7532501220703, ndcg5:0.8507217709885637, pnl5:2.729907751083374 
train 13, step: 0, loss: 1.0857614772412016, grad_norm: 0.05898966118727923, ic: 0.421192097893928
train 13, step: 500, loss: 1.1498920003876432, grad_norm: 0.01077320065160705, ic: -0.17184108417259764
train 13, step: 1000, loss: 1.3900001459849527, grad_norm: 0.4196142733946001, ic: 0.07732330505574514
train 13, step: 1500, loss: 0.7764747654466324, grad_norm: 0.003172919591552246, ic: -0.054519455139118336
train 13, step: 2000, loss: 1.0402350125408026, grad_norm: 0.025467414454386154, ic: 0.04483732770817783
Epoch 13: 2022-04-19 00:35:55.660701: train loss: 1.6367986751729515
Eval step 0: eval loss: 0.9906865301227619
Eval: 2022-04-19 00:36:01.957574: total loss: 1.084575611423041, mse:4.737460077641991, ic :0.1198934854466638, sharpe5:8.07452971816063, irr5:224.07424926757812, ndcg5:0.8616963951820406, pnl5:3.3461015224456787 
train 14, step: 0, loss: 1.757410340389963, grad_norm: 0.5713895498123476, ic: 0.16700122771292514
train 14, step: 500, loss: 1.2775837648098824, grad_norm: 0.17280801702571602, ic: 0.18265030981620106
train 14, step: 1000, loss: 1.0675675321216425, grad_norm: 0.13173176439581444, ic: 0.16394741283308997
train 14, step: 1500, loss: 0.9694652249025693, grad_norm: 0.09567216272663276, ic: 0.2072468381303289
train 14, step: 2000, loss: 2.309415384762439, grad_norm: 0.5100677618519707, ic: -0.0735607285215696
Epoch 14: 2022-04-19 00:36:55.741738: train loss: 1.6364780507828725
Eval step 0: eval loss: 1.004694210974526
Eval: 2022-04-19 00:37:02.110672: total loss: 1.0876154009380685, mse:4.719750619208902, ic :0.12024955833228677, sharpe5:7.0846104195713995, irr5:203.34780883789062, ndcg5:0.8575751287749701, pnl5:3.1635818481445312 
train 15, step: 0, loss: 0.9760681785589586, grad_norm: 0.15990500907442937, ic: 0.12972720724636833
train 15, step: 500, loss: 1.2245230212113254, grad_norm: 0.0076694619151599, ic: 0.06606766802600796
train 15, step: 1000, loss: 1.763253515625, grad_norm: 0.14292696042445402, ic: -0.025241914001377562
train 15, step: 1500, loss: 5.406893488979118, grad_norm: 1.2448137829506765, ic: 0.07980450077251822
train 15, step: 2000, loss: 0.9298778377630121, grad_norm: 0.01589367219801051, ic: -0.09616104910072192
Epoch 15: 2022-04-19 00:37:56.216807: train loss: 1.6334330107167307
Eval step 0: eval loss: 1.00502333156431
Eval: 2022-04-19 00:38:02.393509: total loss: 1.0844285042809112, mse:4.685929831171123, ic :0.15756929443550857, sharpe5:16.09974832892418, irr5:517.0843505859375, ndcg5:0.8334631345778056, pnl5:6.766747951507568 
train 16, step: 0, loss: 6.383678766488046, grad_norm: 5.539955083874335, ic: 0.1479164859771935
train 16, step: 500, loss: 1.3515280102926588, grad_norm: 0.9255098092500221, ic: -0.02136729825367749
train 16, step: 1000, loss: 0.8390304725271958, grad_norm: 0.34080759899095103, ic: -0.05996973869074442
train 16, step: 1500, loss: 1.2279647675377774, grad_norm: 0.31969167747804594, ic: 0.14086647176260073
train 16, step: 2000, loss: 0.9524695500323341, grad_norm: 0.5608663361045726, ic: 0.5541335759997845
Epoch 16: 2022-04-19 00:38:56.056790: train loss: 1.6279500699707508
Eval step 0: eval loss: 0.9958957633952079
Eval: 2022-04-19 00:39:02.309773: total loss: 1.0811381131041868, mse:4.714745722298244, ic :0.15407102534387346, sharpe5:15.680062846541404, irr5:520.2428588867188, ndcg5:0.8559466303530326, pnl5:7.720729827880859 
train 17, step: 0, loss: 1.1812141278038728, grad_norm: 0.018083611422485577, ic: 0.1229387492998749
train 17, step: 500, loss: 1.0458949526215844, grad_norm: 0.03218001004461686, ic: -0.026030818383468414
train 17, step: 1000, loss: 3.395241111025165, grad_norm: 1.2242638879565064, ic: -0.01657485715757581
train 17, step: 1500, loss: 0.887021160434365, grad_norm: 0.0037613624524778823, ic: 0.023496023503853797
train 17, step: 2000, loss: 1.0075164180473992, grad_norm: 0.8822459701049702, ic: 0.5883894579684411
Epoch 17: 2022-04-19 00:39:56.862552: train loss: 1.6300050745008805
Eval step 0: eval loss: 1.000659912495063
Eval: 2022-04-19 00:40:03.139052: total loss: 1.0828098233877235, mse:4.708411837756821, ic :0.15338115837776803, sharpe5:14.731112063527107, irr5:468.4963073730469, ndcg5:0.8443906273346871, pnl5:5.639679908752441 
train 18, step: 0, loss: 0.8561498768920409, grad_norm: 0.4342260159489322, ic: 0.015515723121320928
train 18, step: 500, loss: 2.5183292034716516, grad_norm: 1.0957717340250421, ic: 0.005483240889099542
train 18, step: 1000, loss: 1.3536810785746403, grad_norm: 0.379463718475159, ic: 0.5356446449380246
train 18, step: 1500, loss: 1.732125954815085, grad_norm: 2.0578138942523436, ic: 0.32729065564899773
train 18, step: 2000, loss: 1.2424399619981223, grad_norm: 0.43301749577419113, ic: 0.25878652559450505
Epoch 18: 2022-04-19 00:40:57.709025: train loss: 1.6272150657560778
Eval step 0: eval loss: 0.9965987444049499
Eval: 2022-04-19 00:41:04.088498: total loss: 1.0841776227557796, mse:4.7178084943141645, ic :0.12821389609942183, sharpe5:9.287182833552361, irr5:271.50341796875, ndcg5:0.8513037218639083, pnl5:3.809882402420044 
train 19, step: 0, loss: 2.2937047209736035, grad_norm: 0.9785412780568692, ic: 0.05785661685758729
train 19, step: 500, loss: 1.016137624341388, grad_norm: 0.06375651885678695, ic: 0.06461828605848459
train 19, step: 1000, loss: 0.9906090351021752, grad_norm: 0.47278169946968335, ic: 0.5473513752228576
train 19, step: 1500, loss: 1.5834938331886572, grad_norm: 0.18867871072793613, ic: 0.13391213374250518
train 19, step: 2000, loss: 1.7964996314288477, grad_norm: 1.6015261783585468, ic: 0.6435871834991287
Epoch 19: 2022-04-19 00:41:58.667359: train loss: 1.626439577203868
Eval step 0: eval loss: 1.001758866714389
Eval: 2022-04-19 00:42:04.378597: total loss: 1.0799819196317948, mse:4.685704250944104, ic :0.16170404875046146, sharpe5:15.44367222726345, irr5:491.8454895019531, ndcg5:0.8430480891018548, pnl5:3.9802310466766357 
train 20, step: 0, loss: 1.237549665265547, grad_norm: 0.3739956945429594, ic: 0.47025117012823325
train 20, step: 500, loss: 1.2149507168083824, grad_norm: 0.5079775984278789, ic: 0.052091158613714494
train 20, step: 1000, loss: 1.557174529140749, grad_norm: 0.6165832127235862, ic: 0.1678907427749816
train 20, step: 1500, loss: 0.8565750972932156, grad_norm: 0.5330398191287062, ic: 0.5921073243364523
train 20, step: 2000, loss: 1.3604356400313258, grad_norm: 0.24400896667807975, ic: -0.038384647553067405
Epoch 20: 2022-04-19 00:42:54.523842: train loss: 1.6246350340004478
Eval step 0: eval loss: 0.9960011205527579
Eval: 2022-04-19 00:43:00.311150: total loss: 1.0814104825962394, mse:4.690391247498326, ic :0.15659046413480213, sharpe5:15.184935058951377, irr5:483.44268798828125, ndcg5:0.8524439388367646, pnl5:4.221558094024658 
train 21, step: 0, loss: 1.3899680268312682, grad_norm: 0.37804684058754306, ic: 0.3431318925498713
train 21, step: 500, loss: 1.1136051519462509, grad_norm: 0.09728133993789614, ic: -0.004595693718548559
train 21, step: 1000, loss: 0.9057089586971034, grad_norm: 0.4146495781379748, ic: 0.05619232946146948
train 21, step: 1500, loss: 0.7359022389063555, grad_norm: 0.15320067885261762, ic: 0.6261582941676757
train 21, step: 2000, loss: 1.1257657626651982, grad_norm: 0.2445144925025347, ic: 0.29580983035933717
Epoch 21: 2022-04-19 00:43:49.928016: train loss: 1.6248616724390263
Eval step 0: eval loss: 1.0087337805259347
Eval: 2022-04-19 00:43:55.658346: total loss: 1.0847668820847576, mse:4.7108413461814935, ic :0.1341588196063625, sharpe5:10.084061869382857, irr5:304.2231140136719, ndcg5:0.8688607005775688, pnl5:4.012930870056152 
train 22, step: 0, loss: 1.0462066879354233, grad_norm: 0.35378076924043883, ic: 0.09216033097868279
train 22, step: 500, loss: 1.0271568959153543, grad_norm: 0.001882904885834172, ic: 0.008886025279415385
train 22, step: 1000, loss: 0.9094229875490148, grad_norm: 0.02713555513850071, ic: 0.15051040690573436
train 22, step: 1500, loss: 1.0055357555734035, grad_norm: 0.20085150615425468, ic: 0.25021378171185094
train 22, step: 2000, loss: 1.044546863644622, grad_norm: 0.1296577839090186, ic: 0.1304007326520354
Epoch 22: 2022-04-19 00:44:45.515985: train loss: 1.6239856089558615
Eval step 0: eval loss: 1.0044798969029751
Eval: 2022-04-19 00:44:51.253907: total loss: 1.0828589033815048, mse:4.6950865025368325, ic :0.14446534046676923, sharpe5:11.880656683444975, irr5:355.8194885253906, ndcg5:0.8586831706629083, pnl5:3.135089159011841 
train 23, step: 0, loss: 1.285870466726354, grad_norm: 1.235865520983978, ic: 0.023602561557799537
train 23, step: 500, loss: 0.898772187285371, grad_norm: 0.1750665673342746, ic: 0.6001232047973512
train 23, step: 1000, loss: 2.2737835915833005, grad_norm: 1.0613718802648104, ic: 0.026303808749191894
train 23, step: 1500, loss: 0.7692053573249837, grad_norm: 0.48799487094317817, ic: 0.727321137345035
train 23, step: 2000, loss: 1.4912282377143566, grad_norm: 0.37392722109804183, ic: 0.4128371032887875
Epoch 23: 2022-04-19 00:45:40.671593: train loss: 1.623537797573022
Eval step 0: eval loss: 1.0102279365784623
Eval: 2022-04-19 00:45:46.408190: total loss: 1.0868451229002751, mse:4.698802606517784, ic :0.14690602221200644, sharpe5:13.172874448299407, irr5:400.87640380859375, ndcg5:0.8523294673736214, pnl5:4.365135669708252 
train 24, step: 0, loss: 1.1930896958552888, grad_norm: 0.7789954108955184, ic: 0.31773571356469255
train 24, step: 500, loss: 1.261533828840103, grad_norm: 0.6708070650750503, ic: 0.010843315428316003
train 24, step: 1000, loss: 1.0238917280987996, grad_norm: 0.42039309564243155, ic: 0.10179333248083967
train 24, step: 1500, loss: 1.1990870678518701, grad_norm: 0.08353718320458797, ic: 0.13064609856531798
train 24, step: 2000, loss: 1.3486245844852554, grad_norm: 0.4621053839527737, ic: 0.4454412891811796
Epoch 24: 2022-04-19 00:46:32.203249: train loss: 1.6253469061454395
Eval step 0: eval loss: 1.0150857436274026
Eval: 2022-04-19 00:46:38.047386: total loss: 1.0817991909613254, mse:4.682049825602087, ic :0.16249782995305287, sharpe5:15.523597274422645, irr5:516.6255493164062, ndcg5:0.8566646741733717, pnl5:6.6261138916015625 
train 25, step: 0, loss: 1.3166324350146095, grad_norm: 0.5965080712478509, ic: 0.2242240044443003
train 25, step: 500, loss: 1.483162223518669, grad_norm: 1.5371812499486155, ic: 0.09643647270303804
train 25, step: 1000, loss: 1.3556426949306355, grad_norm: 0.3100856154418707, ic: 0.27515171560797735
train 25, step: 1500, loss: 2.862129516158315, grad_norm: 1.5307102178938334, ic: 0.2703761803268538
train 25, step: 2000, loss: 1.1984015356136273, grad_norm: 0.26318273539676484, ic: 0.13725059011825416
Epoch 25: 2022-04-19 00:47:26.842893: train loss: 1.6240066039815289
Eval step 0: eval loss: 1.007203176939343
Eval: 2022-04-19 00:47:32.554065: total loss: 1.079818279802772, mse:4.671302550778879, ic :0.17042124055424362, sharpe5:14.32921755194664, irr5:482.7608642578125, ndcg5:0.8549433382277596, pnl5:4.3664937019348145 
train 26, step: 0, loss: 1.6249543678977272, grad_norm: 0.34190476245057044, ic: 0.18578674984331506
train 26, step: 500, loss: 1.0222585234567583, grad_norm: 0.295139353630106, ic: -0.034079029419522344
train 26, step: 1000, loss: 1.8159517134159036, grad_norm: 0.8957365753166079, ic: 0.18061390573248295
train 26, step: 1500, loss: 0.9191649358317918, grad_norm: 0.025829912323363992, ic: 0.04230478005021218
train 26, step: 2000, loss: 0.999060731422244, grad_norm: 0.3305750765444769, ic: 0.14926689651307928
Epoch 26: 2022-04-19 00:48:23.079568: train loss: 1.6245025070689416
Eval step 0: eval loss: 1.0066137811018956
Eval: 2022-04-19 00:48:28.784144: total loss: 1.0800684519675052, mse:4.67497031821911, ic :0.17123336921187277, sharpe5:16.055951968431472, irr5:519.889404296875, ndcg5:0.8407706645517649, pnl5:5.6835432052612305 
train 27, step: 0, loss: 1.6289821762636485, grad_norm: 0.4818078509165875, ic: 0.6479130832751236
train 27, step: 500, loss: 1.509231021578538, grad_norm: 0.38133914658051743, ic: 0.05207444210221744
train 27, step: 1000, loss: 2.564336081670066, grad_norm: 1.2155647516659613, ic: 0.4085606479527861
train 27, step: 1500, loss: 0.8282553721102967, grad_norm: 0.4891785540784786, ic: 0.5655558004444646
train 27, step: 2000, loss: 1.3347566431751632, grad_norm: 1.4192101747868442, ic: -0.0019500869514796882
Epoch 27: 2022-04-19 00:49:17.785105: train loss: 1.6221910100762924
Eval step 0: eval loss: 1.0148920638740784
Eval: 2022-04-19 00:49:23.590332: total loss: 1.078750400611889, mse:4.676198757320229, ic :0.17055383627954493, sharpe5:14.412103346586226, irr5:490.0, ndcg5:0.8512060858371525, pnl5:4.744241714477539 
train 28, step: 0, loss: 1.1581460366898817, grad_norm: 0.14610270658299657, ic: 0.17673790052225236
train 28, step: 500, loss: 2.9410245540310958, grad_norm: 0.7478135599211305, ic: 0.09512428964698996
train 28, step: 1000, loss: 2.7842647317461493, grad_norm: 3.0852409681815054, ic: -0.03468896396545832
train 28, step: 1500, loss: 1.0316110991153686, grad_norm: 0.8457381678838292, ic: 0.1776357461197308
train 28, step: 2000, loss: 1.7529708507449127, grad_norm: 0.4595502281386252, ic: 0.09457772312148627
Epoch 28: 2022-04-19 00:50:12.718584: train loss: 1.621340399849827
Eval step 0: eval loss: 1.0059300845017114
Eval: 2022-04-19 00:50:18.493674: total loss: 1.0802240083886452, mse:4.693066523907999, ic :0.16213425533155418, sharpe5:14.16826261639595, irr5:463.0995178222656, ndcg5:0.8576449602991439, pnl5:3.2889254093170166 
train 29, step: 0, loss: 1.5113712336820033, grad_norm: 0.1674877320368478, ic: 0.07146770685095079
train 29, step: 500, loss: 2.5376921752728583, grad_norm: 3.0326071611163092, ic: -0.14159445847901625
train 29, step: 1000, loss: 1.6990835856401383, grad_norm: 1.3758939477131393, ic: 0.4884133554844807
train 29, step: 1500, loss: 3.9391891962728125, grad_norm: 1.4958521951762216, ic: 0.1662590900593403
train 29, step: 2000, loss: 0.9326502251764783, grad_norm: 0.22666087841829297, ic: 0.472816622470791
Epoch 29: 2022-04-19 00:51:06.079719: train loss: 1.6228799995061927
Eval step 0: eval loss: 1.0097180567897577
Eval: 2022-04-19 00:51:11.723739: total loss: 1.0792324303941543, mse:4.672424865496228, ic :0.1739228331346922, sharpe5:16.20011293888092, irr5:542.4796142578125, ndcg5:0.8454607646479521, pnl5:3.8973934650421143 
train 30, step: 0, loss: 1.2465308374929032, grad_norm: 0.12476082890507473, ic: 0.9869978582206331
train 30, step: 500, loss: 1.9502957500988924, grad_norm: 0.531618239600381, ic: 0.16649454840431777
train 30, step: 1000, loss: 3.412170692539656, grad_norm: 1.1118162418540145, ic: 0.4370498369425887
train 30, step: 1500, loss: 1.0763727252896518, grad_norm: 0.30130958952689807, ic: 0.1412753067295136
train 30, step: 2000, loss: 1.0929836776181445, grad_norm: 0.13327914141296274, ic: 0.4333740477009219
Epoch 30: 2022-04-19 00:52:00.224896: train loss: 1.6227454605540992
Eval step 0: eval loss: 1.0134927228352093
Eval: 2022-04-19 00:52:06.010986: total loss: 1.0798934558076836, mse:4.671040536436018, ic :0.17145851132054957, sharpe5:14.296002316474913, irr5:503.3370361328125, ndcg5:0.8531408398620507, pnl5:4.216557025909424 
train 31, step: 0, loss: 1.1588020754705113, grad_norm: 0.366338908873902, ic: 0.16273522394813628
train 31, step: 500, loss: 0.8220165136183438, grad_norm: 0.10555437628827892, ic: 0.2252378067921228
train 31, step: 1000, loss: 5.239097078672179, grad_norm: 3.6575341096957774, ic: -0.07650903863330924
train 31, step: 1500, loss: 1.6914837938924845, grad_norm: 0.3336296536961351, ic: 0.26898296023462814
train 31, step: 2000, loss: 0.9478910365780652, grad_norm: 0.7206500080173311, ic: 0.2263642360568197
Epoch 31: 2022-04-19 00:52:54.136487: train loss: 1.6225425161878597
Eval step 0: eval loss: 1.0141503854824907
Eval: 2022-04-19 00:52:59.887659: total loss: 1.0811150062447374, mse:4.673128438625579, ic :0.16901207573402252, sharpe5:14.72925804913044, irr5:480.7073059082031, ndcg5:0.8402029433532956, pnl5:4.709941387176514 
train 32, step: 0, loss: 0.8959742525113722, grad_norm: 0.6317749567332488, ic: 0.11287203545532615
train 32, step: 500, loss: 1.0954926653606136, grad_norm: 0.37831805770905463, ic: 0.12398926967978477
train 32, step: 1000, loss: 1.3787111199863187, grad_norm: 0.06780073060333912, ic: 0.07574550239850901
train 32, step: 1500, loss: 2.052031431404799, grad_norm: 0.7009776901619, ic: 0.44459732305157346
train 32, step: 2000, loss: 1.070114627384483, grad_norm: 0.5170497474399913, ic: 0.46234013627506126
Epoch 32: 2022-04-19 00:53:48.587166: train loss: 1.6201421244872052
Eval step 0: eval loss: 1.0103731481824314
Eval: 2022-04-19 00:53:54.360908: total loss: 1.078924474821855, mse:4.667434667440774, ic :0.1783016375015018, sharpe5:16.252727218866347, irr5:544.947265625, ndcg5:0.8419918760599862, pnl5:5.166011810302734 
train 33, step: 0, loss: 1.1625778862681435, grad_norm: 0.02727387547901837, ic: 0.024303142439407212
train 33, step: 500, loss: 3.1732561491160647, grad_norm: 0.6839573796775555, ic: 0.5144525944080106
train 33, step: 1000, loss: 5.243863232884196, grad_norm: 2.9137728571299517, ic: 0.027997073246859648
train 33, step: 1500, loss: 1.3384640577362805, grad_norm: 1.4660344028294865, ic: 0.05303814530057219
train 33, step: 2000, loss: 1.8535648316375968, grad_norm: 0.3637983292642843, ic: 0.09495415542909715
Epoch 33: 2022-04-19 00:54:42.918292: train loss: 1.6232703498811694
Eval step 0: eval loss: 1.0183608149025802
Eval: 2022-04-19 00:54:48.678900: total loss: 1.0855452079684769, mse:4.684847044056898, ic :0.16715084490983168, sharpe5:15.09006343960762, irr5:486.5066833496094, ndcg5:0.8484566084223726, pnl5:5.2349958419799805 
train 34, step: 0, loss: 0.7203140379698644, grad_norm: 0.5610097135294898, ic: 0.1702244769225781
train 34, step: 500, loss: 1.8263095578954749, grad_norm: 0.5044801840178059, ic: 0.8427137476524363
train 34, step: 1000, loss: 0.6791203360721982, grad_norm: 0.04567283685386814, ic: 0.4988140498765723
train 34, step: 1500, loss: 1.6260347806490385, grad_norm: 1.3868559543152144, ic: 0.6601845222447368
train 34, step: 2000, loss: 3.006530460062294, grad_norm: 0.5977988982297672, ic: 0.08578452218555932
Epoch 34: 2022-04-19 00:55:36.920328: train loss: 1.6220058341935164
Eval step 0: eval loss: 1.0057649456745326
Eval: 2022-04-19 00:55:42.758592: total loss: 1.080477700026029, mse:4.679874690514722, ic :0.1693996800423298, sharpe5:14.800333961248397, irr5:497.84521484375, ndcg5:0.8598461401798496, pnl5:5.323520183563232 
train 35, step: 0, loss: 1.0432898605926126, grad_norm: 0.6305986214563397, ic: -0.01214419335095104
train 35, step: 500, loss: 3.283454663825758, grad_norm: 1.8071545175205022, ic: -0.07905639438583671
train 35, step: 1000, loss: 1.3454136385065634, grad_norm: 0.1429449291958499, ic: 0.5083835809624475
train 35, step: 1500, loss: 1.6355089442247646, grad_norm: 0.4509589639715591, ic: 0.05850856482523595
train 35, step: 2000, loss: 1.2932454051193225, grad_norm: 0.08312007408116288, ic: -0.09362551652137448
Epoch 35: 2022-04-19 00:56:30.021201: train loss: 1.621649615067054
Eval step 0: eval loss: 1.003917306394813
Eval: 2022-04-19 00:56:35.806605: total loss: 1.081024127308267, mse:4.680065194664756, ic :0.16697271150691648, sharpe5:14.757214883565902, irr5:476.2013244628906, ndcg5:0.8451240797792768, pnl5:3.1109511852264404 
train 36, step: 0, loss: 8.96763547010655, grad_norm: 1.2643129837751725, ic: -0.09081849812143364
train 36, step: 500, loss: 0.8608225635467922, grad_norm: 0.012193651193118587, ic: 0.09763761768934459
train 36, step: 1000, loss: 1.9889606139580167, grad_norm: 2.0530386462776855, ic: 0.06693229524056578
train 36, step: 1500, loss: 1.048131560395242, grad_norm: 0.1449433236737297, ic: 0.08885377445767031
train 36, step: 2000, loss: 2.168143197744997, grad_norm: 2.0774763882774825, ic: 0.37052777374340995
Epoch 36: 2022-04-19 00:57:23.493469: train loss: 1.6210672943176196
Eval step 0: eval loss: 1.0210544612295944
Eval: 2022-04-19 00:57:29.206377: total loss: 1.0833561882842517, mse:4.677702392996702, ic :0.166687669840793, sharpe5:14.181507468223572, irr5:467.7036437988281, ndcg5:0.845319940484014, pnl5:3.971015453338623 
train 37, step: 0, loss: 1.196017375653279, grad_norm: 0.2822559265605547, ic: 0.12018530622921364
train 37, step: 500, loss: 2.3375380899896263, grad_norm: 0.04801188550811182, ic: 0.15208227962698628
train 37, step: 1000, loss: 0.7602361083597464, grad_norm: 0.5971322502093808, ic: 0.16695482389885555
train 37, step: 1500, loss: 3.0816950919059325, grad_norm: 1.2535899736109266, ic: 0.22467516373547833
train 37, step: 2000, loss: 3.1516144843155893, grad_norm: 2.368532412292917, ic: 0.014334023388092552
Epoch 37: 2022-04-19 00:58:18.317051: train loss: 1.6202975861497209
Eval step 0: eval loss: 1.0072812787980516
Eval: 2022-04-19 00:58:24.048343: total loss: 1.0783911937129336, mse:4.669902410901298, ic :0.17407656645673975, sharpe5:15.557669518589973, irr5:529.9201049804688, ndcg5:0.8268835041603592, pnl5:4.503814220428467 
train 38, step: 0, loss: 1.3509116432883523, grad_norm: 0.49333480367243043, ic: -0.2691855320421272
train 38, step: 500, loss: 1.7423396620639535, grad_norm: 1.0916939892659108, ic: 0.19553087243813994
train 38, step: 1000, loss: 1.824759196411037, grad_norm: 0.6429465574771993, ic: 0.15276563384344075
train 38, step: 1500, loss: 1.0641069824822311, grad_norm: 0.19963690088758806, ic: 0.49911495544753176
train 38, step: 2000, loss: 0.7476341969682355, grad_norm: 0.24659269238979753, ic: 0.5820495432078958
Epoch 38: 2022-04-19 00:59:13.100271: train loss: 1.6204601991169993
Eval step 0: eval loss: 1.0029098888395207
Eval: 2022-04-19 00:59:18.810182: total loss: 1.0785348190101394, mse:4.693696720470331, ic :0.17734796772128758, sharpe5:16.7938175368309, irr5:581.7811889648438, ndcg5:0.8609457418432105, pnl5:4.874118328094482 
train 39, step: 0, loss: 0.8684778198435031, grad_norm: 0.07255069452104976, ic: 0.5358600529119891
train 39, step: 500, loss: 1.2414862075230553, grad_norm: 0.42637978369122265, ic: 0.016943627608254998
train 39, step: 1000, loss: 1.4081274783972537, grad_norm: 0.40218101290917996, ic: 0.09207863487453208
train 39, step: 1500, loss: 2.463898009240033, grad_norm: 0.9869448736589084, ic: -0.04611105739920611
train 39, step: 2000, loss: 2.870876707298858, grad_norm: 1.9341685567865072, ic: 0.20233347785998404
Epoch 39: 2022-04-19 01:00:07.724927: train loss: 1.617737275264126
Eval step 0: eval loss: 0.9988242938306344
Eval: 2022-04-19 01:00:13.448043: total loss: 1.0781365744901077, mse:4.669110264617966, ic :0.17953363654217408, sharpe5:16.033376505374907, irr5:566.874267578125, ndcg5:0.8448045760012693, pnl5:5.993978023529053 

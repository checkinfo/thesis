Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='SparseAdjSeqTimeDataset', dout=0.3, epochs=40, gnn_layers=2, gpu=0, hidden_dim=128, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=3, mask_adj=True, mask_type='soft', model_type='GNNModel', normalize_adj=False, num_days=1, num_heads=1, print_inteval=500, relation_num=1, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_750_0.8/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=False)
load 2305 train graphs successful!
load 126 test graphs successful!
13672
GNNModel(
  (fc1): Linear(in_features=9, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
  (fc4): Linear(in_features=128, out_features=1, bias=True)
  (gnns): ModuleList(
    (0): GraphConv(128, 128)
    (1): GraphConv(128, 128)
  )
  (dropout): Dropout(p=0.3, inplace=False)
  (relu): LeakyReLU(negative_slope=0.01)
)
train 0, step: 0, loss: 2.0732205718873518, grad_norm: 0.4700866820099027, ic: 0.004701117901220072
train 0, step: 500, loss: 1.3673909196716263, grad_norm: 0.8521327322605555, ic: -0.002587106960191635
train 0, step: 1000, loss: 1.5060494730398426, grad_norm: 0.03239028132673454, ic: 0.19624426572444398
train 0, step: 1500, loss: 1.1836697507326095, grad_norm: 0.09309079575605084, ic: 0.029469067653905605
train 0, step: 2000, loss: 1.5608774510825554, grad_norm: 0.050537365653473935, ic: 0.0479413726205894
Epoch 0: 2022-04-04 02:38:55.089243: train loss: 1.6472295680787525
Eval step 0: eval loss: 1.008111536910874
Eval: 2022-04-04 02:38:59.078421: total loss: 1.0913222169658294, mse:4.887858122432876, ic :0.02875075476530122, sharpe5:6.938867388367653, irr5:208.58551025390625, ndcg5:0.8519082702418077, pnl5:2.3608920574188232 
train 1, step: 0, loss: 0.643763249463374, grad_norm: 0.06812222600581642, ic: 0.04922647098242977
train 1, step: 500, loss: 1.2575677048424934, grad_norm: 0.3030464247492862, ic: 0.23235321465181413
train 1, step: 1000, loss: 0.8761270731011345, grad_norm: 0.06208327643173786, ic: 0.07581884731170102
train 1, step: 1500, loss: 1.858481988674257, grad_norm: 0.559237148634022, ic: 0.09092773978693669
train 1, step: 2000, loss: 1.36877245121674, grad_norm: 0.24207343386113367, ic: 0.15486529395592558
Epoch 1: 2022-04-04 02:39:26.507575: train loss: 1.645372081846272
Eval step 0: eval loss: 1.0031938839109398
Eval: 2022-04-04 02:39:30.549150: total loss: 1.0885413687968541, mse:4.876870612459816, ic :0.0547342859216054, sharpe5:5.898227080106735, irr5:174.80496215820312, ndcg5:0.8509067228170129, pnl5:2.625739812850952 
train 2, step: 0, loss: 1.329286066409137, grad_norm: 0.5108851255434164, ic: 0.07853353197362313
train 2, step: 500, loss: 0.9567604354372156, grad_norm: 0.3038625181781985, ic: 0.08066039165600719
train 2, step: 1000, loss: 3.0427551601605005, grad_norm: 1.2099560740419055, ic: 0.17485281059980132
train 2, step: 1500, loss: 2.2889575640612607, grad_norm: 0.8987946701504856, ic: 0.08013789631653251
train 2, step: 2000, loss: 1.4571392467932338, grad_norm: 0.28012379409141824, ic: -0.10777916148241351
Epoch 2: 2022-04-04 02:39:58.527602: train loss: 1.6443455364732187
Eval step 0: eval loss: 0.9957448950311019
Eval: 2022-04-04 02:40:02.506055: total loss: 1.0881854012945502, mse:4.870634776133866, ic :0.06537373382915186, sharpe5:6.775603921115398, irr5:204.4003143310547, ndcg5:0.8640882081889024, pnl5:2.781221866607666 
train 3, step: 0, loss: 1.8325561430040167, grad_norm: 0.07150833574195063, ic: -0.15322561720572306
train 3, step: 500, loss: 0.7813760972115541, grad_norm: 0.02180471695834812, ic: 0.16743024779355145
train 3, step: 1000, loss: 1.3854378478167808, grad_norm: 0.44214250974228747, ic: 0.2332991598285381
train 3, step: 1500, loss: 2.6013219469015856, grad_norm: 0.4715807092432002, ic: -0.047138355120960825
train 3, step: 2000, loss: 1.3500508626302083, grad_norm: 0.16365956415288424, ic: 0.08203927587854412
Epoch 3: 2022-04-04 02:40:29.986721: train loss: 1.6417291092598236
Eval step 0: eval loss: 0.9987272932505594
Eval: 2022-04-04 02:40:34.048905: total loss: 1.0876397839623133, mse:4.71790619751177, ic :0.12263217736223418, sharpe5:7.101196753978729, irr5:214.39637756347656, ndcg5:0.8367569685721827, pnl5:3.514988422393799 
train 4, step: 0, loss: 1.1466245607698344, grad_norm: 0.1680169200741956, ic: 0.08257032864358743
train 4, step: 500, loss: 0.9904822902172233, grad_norm: 0.006483670004292372, ic: 0.13418705029137973
train 4, step: 1000, loss: 1.3274211636215199, grad_norm: 0.06244013498860229, ic: 0.0768148147974645
train 4, step: 1500, loss: 1.0463526799128606, grad_norm: 0.1321898372067872, ic: 0.6059216555451297
train 4, step: 2000, loss: 4.149807453530684, grad_norm: 0.949500948198114, ic: -0.016997134014582027
Epoch 4: 2022-04-04 02:41:01.365406: train loss: 1.6381428470559234
Eval step 0: eval loss: 1.00334443086822
Eval: 2022-04-04 02:41:05.431072: total loss: 1.0893848866360927, mse:4.718711786191499, ic :0.1236107829908504, sharpe5:6.991293429136276, irr5:211.92955017089844, ndcg5:0.8341253164570015, pnl5:3.2776687145233154 
train 5, step: 0, loss: 0.9902605926908797, grad_norm: 0.15526294524581963, ic: -0.15908078058510722
train 5, step: 500, loss: 0.7953147948447373, grad_norm: 0.04449070079098138, ic: 0.13354954395752006
train 5, step: 1000, loss: 1.1010959424724904, grad_norm: 0.06326693524450036, ic: 0.39902865616221395
train 5, step: 1500, loss: 1.777658353976118, grad_norm: 0.4257149254730196, ic: -0.04024246369132567
train 5, step: 2000, loss: 2.1763621050185873, grad_norm: 0.8697624986192701, ic: 0.03543438301491644
Epoch 5: 2022-04-04 02:41:32.696798: train loss: 1.6382481028100957
Eval step 0: eval loss: 1.0050217888115454
Eval: 2022-04-04 02:41:36.784442: total loss: 1.0863442711779472, mse:4.7135502047793745, ic :0.12367627584007929, sharpe5:7.284230541586876, irr5:215.0268096923828, ndcg5:0.8679000025167746, pnl5:3.3374228477478027 
train 6, step: 0, loss: 0.7767881253743155, grad_norm: 0.007563716389193956, ic: -0.04149025448397873
train 6, step: 500, loss: 1.378806487858644, grad_norm: 0.47300238225176644, ic: 0.034085749314738914
train 6, step: 1000, loss: 1.2271714354335848, grad_norm: 0.18939990164986914, ic: 0.1972261895301203
train 6, step: 1500, loss: 1.0577564858490565, grad_norm: 0.33376404478761335, ic: 0.08567956089696604
train 6, step: 2000, loss: 2.3098240429367842, grad_norm: 1.2011516412926362, ic: 0.08242406970805422
Epoch 6: 2022-04-04 02:42:04.424913: train loss: 1.6378705398546098
Eval step 0: eval loss: 0.9991267376538638
Eval: 2022-04-04 02:42:08.516081: total loss: 1.0852115070562314, mse:4.713999151839722, ic :0.1250912677672479, sharpe5:6.711526440382004, irr5:202.29489135742188, ndcg5:0.8592582640120336, pnl5:2.9620115756988525 
train 7, step: 0, loss: 1.456333820273888, grad_norm: 0.5471039948581742, ic: 0.20672370504651405
train 7, step: 500, loss: 1.337593597237152, grad_norm: 0.0774011330196133, ic: 0.18859041034443946
train 7, step: 1000, loss: 0.6393808250798635, grad_norm: 0.01934442535914292, ic: 0.29418975903587213
train 7, step: 1500, loss: 1.003605430526909, grad_norm: 0.13317121611335145, ic: 0.11620278523987396
train 7, step: 2000, loss: 1.5731121855190175, grad_norm: 0.5904837638877822, ic: 0.41993451235828416
Epoch 7: 2022-04-04 02:42:35.505204: train loss: 1.6375485908777765
Eval step 0: eval loss: 0.9928213785421602
Eval: 2022-04-04 02:42:39.445448: total loss: 1.083666184762513, mse:4.719854050411916, ic :0.12420031309284484, sharpe5:7.265729180574417, irr5:217.13890075683594, ndcg5:0.8436782122171405, pnl5:2.659231185913086 
train 8, step: 0, loss: 1.2053735621544233, grad_norm: 0.0835018349993918, ic: 0.05324637509887453
train 8, step: 500, loss: 5.532947504408307, grad_norm: 1.2629209538497128, ic: 0.15513775283379444
train 8, step: 1000, loss: 1.89675555712392, grad_norm: 0.611245094917835, ic: 0.05527623143804605
train 8, step: 1500, loss: 1.0611834277586074, grad_norm: 0.3628575395158838, ic: 0.6437373905469084
train 8, step: 2000, loss: 1.124075669508714, grad_norm: 0.5173565308128502, ic: 0.019640220197346528
Epoch 8: 2022-04-04 02:43:06.126975: train loss: 1.63728354184214
Eval step 0: eval loss: 1.0000677525589126
Eval: 2022-04-04 02:43:10.226362: total loss: 1.0871831725937795, mse:4.714126163791561, ic :0.1273400559692003, sharpe5:6.607616973817348, irr5:198.6434783935547, ndcg5:0.8583541109668852, pnl5:2.965333938598633 
train 9, step: 0, loss: 1.1216867872416252, grad_norm: 0.02554445599690035, ic: 0.4377603355835132
train 9, step: 500, loss: 3.2115261130136985, grad_norm: 1.8446554101161863, ic: 0.0786791722702448
train 9, step: 1000, loss: 0.880438772513704, grad_norm: 0.1389385402236381, ic: 0.22025072713936605
train 9, step: 1500, loss: 2.156518277704619, grad_norm: 0.9535247151819929, ic: -0.05176735758372898
train 9, step: 2000, loss: 0.6059889174370574, grad_norm: 0.007306528940346454, ic: 0.042528621609786314
Epoch 9: 2022-04-04 02:43:37.701702: train loss: 1.6373366115466539
Eval step 0: eval loss: 0.9953119600365323
Eval: 2022-04-04 02:43:41.788861: total loss: 1.095908666387374, mse:4.803731915011342, ic :0.12598998105521525, sharpe5:7.952001122832298, irr5:252.8920135498047, ndcg5:0.846650422313237, pnl5:3.6715667247772217 
train 10, step: 0, loss: 1.3168663762179658, grad_norm: 0.03830606228199654, ic: 0.36108883698817335
train 10, step: 500, loss: 0.8986192635282411, grad_norm: 0.006493782615402417, ic: 0.07972545596167299
train 10, step: 1000, loss: 1.52591996903622, grad_norm: 0.5320562013805528, ic: 0.058359103472037765
train 10, step: 1500, loss: 3.039367531717152, grad_norm: 1.5363503148524136, ic: 0.04032194875248417
train 10, step: 2000, loss: 1.3806733940147702, grad_norm: 0.14227490923944114, ic: 0.04640782416416434
Epoch 10: 2022-04-04 02:44:09.191380: train loss: 1.6376186221778348
Eval step 0: eval loss: 1.000995332658636
Eval: 2022-04-04 02:44:13.263279: total loss: 1.0854875083416082, mse:4.712183953978515, ic :0.1261951156253262, sharpe5:6.424149952232837, irr5:194.67958068847656, ndcg5:0.8514064102225306, pnl5:2.8747811317443848 
train 11, step: 0, loss: 4.8014714865129005, grad_norm: 1.3952017654890125, ic: 0.10439773886558265
train 11, step: 500, loss: 0.9917679418982814, grad_norm: 0.06193148348654748, ic: 0.04683022769088104
train 11, step: 1000, loss: 1.033999142621329, grad_norm: 0.32915059810796715, ic: 0.042730353392626014
train 11, step: 1500, loss: 0.6938835508485464, grad_norm: 0.0014639468784145243, ic: 0.0760294299599336
train 11, step: 2000, loss: 1.1370453946867383, grad_norm: 0.06311746641771565, ic: -0.18593265179563748
Epoch 11: 2022-04-04 02:44:40.890941: train loss: 1.6393848799780661
Eval step 0: eval loss: 0.986935841026527
Eval: 2022-04-04 02:44:44.975860: total loss: 1.0836697689856423, mse:4.723147470895088, ic :0.12880127781907735, sharpe5:8.389812433719635, irr5:274.4327087402344, ndcg5:0.8503757190505512, pnl5:4.181851863861084 
train 12, step: 0, loss: 1.387700418102424, grad_norm: 0.24772551888189223, ic: 0.05911088178471959
train 12, step: 500, loss: 0.8165769750147988, grad_norm: 0.3380213351152734, ic: 0.0253186441801388
train 12, step: 1000, loss: 1.2198916311943435, grad_norm: 0.29434599630571934, ic: 0.5753683081075843
train 12, step: 1500, loss: 1.0928857085901662, grad_norm: 0.19279700283719975, ic: -0.10887086446327177
train 12, step: 2000, loss: 1.1146200314651462, grad_norm: 0.0616644449125354, ic: 0.11403470327549763
Epoch 12: 2022-04-04 02:45:12.497830: train loss: 1.637074740468311
Eval step 0: eval loss: 1.0003729604808451
Eval: 2022-04-04 02:45:16.567053: total loss: 1.0861771950936687, mse:4.718970330919864, ic :0.12962761965098785, sharpe5:6.748742941617965, irr5:205.5158233642578, ndcg5:0.8345673607674777, pnl5:3.1666154861450195 
train 13, step: 0, loss: 1.0844669281567059, grad_norm: 0.05005300880429933, ic: 0.4239171777888644
train 13, step: 500, loss: 1.1473067188990935, grad_norm: 0.008142977364446708, ic: -0.16685130962225045
train 13, step: 1000, loss: 1.3869120840197187, grad_norm: 0.3959419143644677, ic: 0.0602913876039976
train 13, step: 1500, loss: 0.7766589857127568, grad_norm: 0.0026421783792017063, ic: -0.0636279466131445
train 13, step: 2000, loss: 1.0344005766369047, grad_norm: 0.02363151264059381, ic: 0.058932773710907535
Epoch 13: 2022-04-04 02:45:43.712227: train loss: 1.6370493423943626
Eval step 0: eval loss: 0.9892644977619799
Eval: 2022-04-04 02:45:47.665412: total loss: 1.0837168339707208, mse:4.725063135433898, ic :0.12657516970884286, sharpe5:7.390347325801849, irr5:222.47901916503906, ndcg5:0.8519369173939474, pnl5:2.643693685531616 
train 14, step: 0, loss: 1.7728879249702065, grad_norm: 0.5018135093881441, ic: 0.14643261362941284
train 14, step: 500, loss: 1.2767281066311535, grad_norm: 0.15398451487501524, ic: 0.1841966217692934
train 14, step: 1000, loss: 1.0741935288610538, grad_norm: 0.12806642916319272, ic: 0.12393978952326334
train 14, step: 1500, loss: 0.9785885476809083, grad_norm: 0.08366911166413402, ic: 0.20598346564986808
train 14, step: 2000, loss: 2.290659171722064, grad_norm: 0.4652895927523313, ic: -0.06867411046914025
Epoch 14: 2022-04-04 02:46:15.137192: train loss: 1.6368240568821673
Eval step 0: eval loss: 1.0006759828363612
Eval: 2022-04-04 02:46:19.247823: total loss: 1.0890176032699908, mse:4.723407952310873, ic :0.12546018567536332, sharpe5:6.948372522890567, irr5:200.2847137451172, ndcg5:0.8432544468717534, pnl5:3.4727678298950195 
train 15, step: 0, loss: 0.973386723426277, grad_norm: 0.15260589759008342, ic: 0.1394347045328855
train 15, step: 500, loss: 1.2238238912397346, grad_norm: 0.005635521780603895, ic: 0.057972848147665554
train 15, step: 1000, loss: 1.7588529947916667, grad_norm: 0.03945859500538972, ic: -0.10587063865773115
train 15, step: 1500, loss: 5.413324980060905, grad_norm: 0.8592871997344294, ic: -0.005760333676417581
train 15, step: 2000, loss: 0.9278502268912652, grad_norm: 0.014788819342481996, ic: -0.04379667978358535
Epoch 15: 2022-04-04 02:46:46.347546: train loss: 1.6379066671873392
Eval step 0: eval loss: 0.9979820793838862
Eval: 2022-04-04 02:46:50.386461: total loss: 1.0856462325757037, mse:4.712582319488363, ic :0.12536714103404667, sharpe5:7.042149706184864, irr5:205.88265991210938, ndcg5:0.8420939114869231, pnl5:3.468959093093872 
train 16, step: 0, loss: 6.348400949350784, grad_norm: 0.9809239693083502, ic: -0.05032150198099901
train 16, step: 500, loss: 1.3878562321738592, grad_norm: 0.6894899039141384, ic: -0.02609511421391298
train 16, step: 1000, loss: 0.8280996219656527, grad_norm: 0.10528610196816518, ic: -0.014271194389384375
train 16, step: 1500, loss: 1.2186212984769509, grad_norm: 0.2750713763816331, ic: 0.14504176314792688
train 16, step: 2000, loss: 0.97254420981056, grad_norm: 0.2242156772607074, ic: 0.5200926867168326
Epoch 16: 2022-04-04 02:47:17.567622: train loss: 1.6367551741915027
Eval step 0: eval loss: 0.9891262928268166
Eval: 2022-04-04 02:47:21.502112: total loss: 1.0824969721745121, mse:4.72785282640298, ic :0.12414518989118842, sharpe5:6.504910251796245, irr5:196.93067932128906, ndcg5:0.8403710351439787, pnl5:2.6317520141601562 
train 17, step: 0, loss: 1.180572509765625, grad_norm: 0.011421681567504085, ic: 0.13452065609362487
train 17, step: 500, loss: 1.044080027942751, grad_norm: 0.032105878389816336, ic: -0.024071504991152445
train 17, step: 1000, loss: 3.3634184280244432, grad_norm: 0.7188144201500664, ic: -0.02456586713067691
train 17, step: 1500, loss: 0.8877901243932039, grad_norm: 0.0030635936153085588, ic: -6.467176850799561e-05
train 17, step: 2000, loss: 1.046350834993708, grad_norm: 0.6262729933051714, ic: 0.5152656132652406
Epoch 17: 2022-04-04 02:47:48.546911: train loss: 1.6367186762988513
Eval step 0: eval loss: 0.9956741855293904
Eval: 2022-04-04 02:47:52.490755: total loss: 1.085754861112218, mse:4.735735624734425, ic :0.12025927163216771, sharpe5:7.085547358989715, irr5:209.0180206298828, ndcg5:0.8428545962751397, pnl5:3.362661123275757 
train 18, step: 0, loss: 0.8499052021727145, grad_norm: 0.004084507639723844, ic: 0.04223970553219869
train 18, step: 500, loss: 2.5226992604765814, grad_norm: 1.026906706126161, ic: 0.10317283004583697
train 18, step: 1000, loss: 1.3746276416366907, grad_norm: 0.3089435849931357, ic: 0.5049227493780828
train 18, step: 1500, loss: 1.7281006118272801, grad_norm: 0.8074859030655228, ic: 0.3268131498372085
train 18, step: 2000, loss: 1.2650767766554736, grad_norm: 0.32120282925243604, ic: 0.11517592562213509
Epoch 18: 2022-04-04 02:48:19.762960: train loss: 1.6370316409484194
Eval step 0: eval loss: 0.9941272544760399
Eval: 2022-04-04 02:48:23.855239: total loss: 1.0846549774223793, mse:4.717074551546523, ic :0.1266266580755139, sharpe5:6.9494404730200765, irr5:198.60816955566406, ndcg5:0.8476452741444683, pnl5:3.602708339691162 
train 19, step: 0, loss: 2.2891999808722265, grad_norm: 0.8599081718728301, ic: 0.06463648211535236
train 19, step: 500, loss: 1.0263816656068314, grad_norm: 0.05921592881876496, ic: -0.1001358651825281
train 19, step: 1000, loss: 1.0332690284844677, grad_norm: 0.03649615943384757, ic: 0.4655905021239333
train 19, step: 1500, loss: 1.5906763900945216, grad_norm: 0.0071974564352625834, ic: 0.052326643605294584
train 19, step: 2000, loss: 1.7865153561243234, grad_norm: 1.346351099450848, ic: 0.6168294313359397
Epoch 19: 2022-04-04 02:48:51.350869: train loss: 1.635486102395623
Eval step 0: eval loss: 1.003311261683781
Eval: 2022-04-04 02:48:55.392415: total loss: 1.08271425650049, mse:4.696935225438488, ic :0.14905432146373024, sharpe5:14.218111009597777, irr5:481.5276184082031, ndcg5:0.8485342370022066, pnl5:4.530633449554443 
train 20, step: 0, loss: 1.2494034993083696, grad_norm: 0.3550204605733834, ic: 0.46152462835002206
train 20, step: 500, loss: 1.2420057348855116, grad_norm: 0.5419763160572628, ic: -0.0066504376669510165
train 20, step: 1000, loss: 1.5628590379334304, grad_norm: 0.26922738178957517, ic: 0.1637577380753759
train 20, step: 1500, loss: 0.8622125675243959, grad_norm: 0.35026389484916237, ic: 0.5628976711287987
train 20, step: 2000, loss: 1.3558317044133992, grad_norm: 0.0935932118181682, ic: -0.05808419015388025
Epoch 20: 2022-04-04 02:49:22.591894: train loss: 1.6305363041862748
Eval step 0: eval loss: 0.9956507228310952
Eval: 2022-04-04 02:49:26.641025: total loss: 1.0835719370249246, mse:4.700480128343898, ic :0.1538366978412505, sharpe5:12.389585527181625, irr5:403.276611328125, ndcg5:0.8503527263810166, pnl5:3.9217498302459717 
train 21, step: 0, loss: 1.4028855571246355, grad_norm: 0.27415973585152253, ic: 0.2949502710605917
train 21, step: 500, loss: 1.1102224873876243, grad_norm: 0.07925841305013588, ic: -0.011328707007057001
train 21, step: 1000, loss: 0.9217935529221446, grad_norm: 0.17167394921237944, ic: 0.10528069729303172
train 21, step: 1500, loss: 0.7365410268346979, grad_norm: 0.1420528805571516, ic: 0.6260499785845798
train 21, step: 2000, loss: 1.1660613341478523, grad_norm: 0.023542669969250318, ic: 0.12739785454761382
Epoch 21: 2022-04-04 02:49:53.924971: train loss: 1.6283352598754337
Eval step 0: eval loss: 0.9989367862197208
Eval: 2022-04-04 02:49:57.998780: total loss: 1.0812741236161678, mse:4.6872261906828445, ic :0.1582997247254435, sharpe5:12.635645399093628, irr5:430.843017578125, ndcg5:0.8575402925405465, pnl5:4.056332588195801 
train 22, step: 0, loss: 1.0610558283929528, grad_norm: 0.2351802074451821, ic: 0.09443847245910902
train 22, step: 500, loss: 1.0269096795029526, grad_norm: 0.011765779630004247, ic: 0.0320197358627602
train 22, step: 1000, loss: 0.9146862073809295, grad_norm: 0.01469049526880707, ic: 0.11962464491101873
train 22, step: 1500, loss: 1.0117866302205023, grad_norm: 0.029034357232912412, ic: 0.20632154106989592
train 22, step: 2000, loss: 1.0524820017260175, grad_norm: 0.12200964006430697, ic: 0.11612869836180559
Epoch 22: 2022-04-04 02:50:25.177208: train loss: 1.6280465764329848
Eval step 0: eval loss: 1.0078378268578856
Eval: 2022-04-04 02:50:29.238696: total loss: 1.0833828668676648, mse:4.690159179600866, ic :0.15137036240733298, sharpe5:11.248083052039146, irr5:353.38922119140625, ndcg5:0.8457104877524801, pnl5:3.556163787841797 
train 23, step: 0, loss: 1.2880004691179356, grad_norm: 0.8210592787705552, ic: -0.02221594822748342
train 23, step: 500, loss: 0.901660625751202, grad_norm: 0.19517404772701907, ic: 0.5785667797625758
train 23, step: 1000, loss: 2.2886918395899367, grad_norm: 0.828842425660269, ic: 0.1004888169826129
train 23, step: 1500, loss: 0.7834141982753345, grad_norm: 0.41549488006305213, ic: 0.7120148223935352
train 23, step: 2000, loss: 1.4352181709272251, grad_norm: 0.41469770278719115, ic: 0.4273133978996069
Epoch 23: 2022-04-04 02:50:56.951450: train loss: 1.6268475396976454
Eval step 0: eval loss: 1.0043352638312928
Eval: 2022-04-04 02:51:01.024201: total loss: 1.0876171261437833, mse:4.697099508481508, ic :0.1558046724354194, sharpe5:11.688929838538169, irr5:371.555908203125, ndcg5:0.8394009300612886, pnl5:3.703566312789917 
train 24, step: 0, loss: 1.1818174887782982, grad_norm: 0.41734755890186165, ic: 0.2635912884705484
train 24, step: 500, loss: 1.2489666389564265, grad_norm: 0.24132970342127608, ic: -0.003305822477667291
train 24, step: 1000, loss: 1.0663952711151867, grad_norm: 2.2149680539125662, ic: 0.13853308169336287
train 24, step: 1500, loss: 1.2008622777743603, grad_norm: 0.0863804456701964, ic: 0.09956959992043832
train 24, step: 2000, loss: 1.3616072346876644, grad_norm: 0.371436159800204, ic: 0.4521461439886055
Epoch 24: 2022-04-04 02:51:28.172699: train loss: 1.6263574018095406
Eval step 0: eval loss: 1.0081711900177723
Eval: 2022-04-04 02:51:32.282909: total loss: 1.0848641026186652, mse:4.690376699518133, ic :0.1594129675251676, sharpe5:12.90714783489704, irr5:446.22235107421875, ndcg5:0.8404913574675968, pnl5:3.737269163131714 
train 25, step: 0, loss: 1.342835655777865, grad_norm: 0.36900353167893357, ic: 0.20949281957806343
train 25, step: 500, loss: 1.5186338548536427, grad_norm: 0.29699135682006067, ic: 0.11754922519366695
train 25, step: 1000, loss: 1.369460436583525, grad_norm: 0.21067102589566275, ic: 0.2757353904027625
train 25, step: 1500, loss: 2.8857460880764343, grad_norm: 0.9937897405377105, ic: 0.18942761486839502
train 25, step: 2000, loss: 1.20181486878214, grad_norm: 0.14546020130910908, ic: 0.1864421707154516
Epoch 25: 2022-04-04 02:52:00.659969: train loss: 1.6276459386032573
Eval step 0: eval loss: 1.0000352261881253
Eval: 2022-04-04 02:52:04.653805: total loss: 1.0818045902992528, mse:4.683804139163911, ic :0.16098626683334633, sharpe5:12.510086057782173, irr5:422.1092834472656, ndcg5:0.8601209618171892, pnl5:3.891880512237549 
train 26, step: 0, loss: 1.6230687144886362, grad_norm: 0.22521705501161698, ic: 0.1619797994602596
train 26, step: 500, loss: 1.0107588380109902, grad_norm: 0.3182037198096603, ic: -0.06112146236617305
train 26, step: 1000, loss: 1.80743423449209, grad_norm: 0.5152625363055936, ic: 0.18251901401870035
train 26, step: 1500, loss: 0.9221596586779863, grad_norm: 0.01831157953625232, ic: 0.015782949065570373
train 26, step: 2000, loss: 0.9862437330831693, grad_norm: 0.08757488377633484, ic: 0.1370350306971222
Epoch 26: 2022-04-04 02:52:32.558589: train loss: 1.6267391124689567
Eval step 0: eval loss: 1.0026850326240784
Eval: 2022-04-04 02:52:36.608389: total loss: 1.0839381316173975, mse:4.685719998487329, ic :0.16748627424326668, sharpe5:15.290105917453765, irr5:521.7625732421875, ndcg5:0.8579386024596168, pnl5:5.5767412185668945 
train 27, step: 0, loss: 1.6564647260918675, grad_norm: 2.1461694056173486, ic: 0.6283244495665146
train 27, step: 500, loss: 1.4950784591271384, grad_norm: 0.2167050612823559, ic: 0.09417144789291088
train 27, step: 1000, loss: 2.6364213043900544, grad_norm: 1.4529362763932505, ic: 0.39616736777907025
train 27, step: 1500, loss: 0.8621897330141828, grad_norm: 0.4889350974421073, ic: 0.5400505342057921
train 27, step: 2000, loss: 1.351101783014113, grad_norm: 0.7542220516843515, ic: -0.007939430340567856
Epoch 27: 2022-04-04 02:53:03.841151: train loss: 1.6251126433820438
Eval step 0: eval loss: 0.9989551706901658
Eval: 2022-04-04 02:53:07.984667: total loss: 1.0798385034171736, mse:4.676990632013193, ic :0.17376605774203213, sharpe5:14.766573872566223, irr5:526.3424682617188, ndcg5:0.8519251483961773, pnl5:4.637241840362549 
train 28, step: 0, loss: 1.1615518829839058, grad_norm: 0.5157308141491487, ic: 0.1760902418419887
train 28, step: 500, loss: 2.936091867663715, grad_norm: 0.4780342242795499, ic: 0.1152813414950819
train 28, step: 1000, loss: 2.7910964266760465, grad_norm: 1.9711089572841334, ic: -0.054840128224071714
train 28, step: 1500, loss: 1.023209103787165, grad_norm: 0.02834710512874536, ic: 0.20075714821614907
train 28, step: 2000, loss: 1.7716618027797966, grad_norm: 0.37590137157604514, ic: 0.08297429240888822
Epoch 28: 2022-04-04 02:53:35.060916: train loss: 1.6254957967901713
Eval step 0: eval loss: 1.0031198317782384
Eval: 2022-04-04 02:53:39.056671: total loss: 1.0815503123033194, mse:4.688126601242603, ic :0.15849323777851795, sharpe5:12.534786069989204, irr5:410.42437744140625, ndcg5:0.8612471864093166, pnl5:3.5783019065856934 
train 29, step: 0, loss: 1.5172736433259097, grad_norm: 0.1318490552414928, ic: 0.07132536528481889
train 29, step: 500, loss: 2.5461594708865323, grad_norm: 1.283660964249505, ic: 0.004157318827775716
train 29, step: 1000, loss: 1.7124290387110725, grad_norm: 0.8272409613349128, ic: 0.48217936530123284
train 29, step: 1500, loss: 3.9935797436929685, grad_norm: 1.1012372872406635, ic: 0.11930315310961283
train 29, step: 2000, loss: 0.9393162917887586, grad_norm: 0.5018186669877488, ic: 0.46132113294093036
Epoch 29: 2022-04-04 02:54:06.666153: train loss: 1.6260707498935505
Eval step 0: eval loss: 1.0051421235271853
Eval: 2022-04-04 02:54:10.705716: total loss: 1.0820274014015123, mse:4.6791127079538954, ic :0.1678998384567779, sharpe5:14.508368314504622, irr5:524.0609130859375, ndcg5:0.8416570925986109, pnl5:4.614807605743408 
train 30, step: 0, loss: 1.2621800482588947, grad_norm: 2.3612789432453436, ic: 0.9617867252705845
train 30, step: 500, loss: 1.9768108899080301, grad_norm: 6.396056596990284, ic: 0.15929076513091278
train 30, step: 1000, loss: 3.4209349052999007, grad_norm: 1.50578036486044, ic: 0.40003754730464997
train 30, step: 1500, loss: 1.0893442245070524, grad_norm: 0.22893782174277394, ic: 0.1445714412131887
train 30, step: 2000, loss: 1.097172598020894, grad_norm: 0.293550161651818, ic: 0.44187563097485577
Epoch 30: 2022-04-04 02:54:37.740999: train loss: 1.6257172147426884
Eval step 0: eval loss: 1.076434785783636
Eval: 2022-04-04 02:54:41.737292: total loss: 1.1073009979576558, mse:4.804456037028607, ic :0.13860824819814918, sharpe5:13.222865676283837, irr5:468.6235046386719, ndcg5:0.856051654806771, pnl5:3.6294407844543457 
train 31, step: 0, loss: 1.1788640659596417, grad_norm: 1.4676883678959731, ic: 0.10699326426890977
train 31, step: 500, loss: 0.8275287003842012, grad_norm: 0.07526061935879542, ic: 0.22283215833583742
train 31, step: 1000, loss: 5.1264538241731525, grad_norm: 1.672910190122085, ic: -0.03314953374685169
train 31, step: 1500, loss: 1.682030042503864, grad_norm: 0.29315122019617207, ic: 0.25689652977599176
train 31, step: 2000, loss: 0.9934553475215517, grad_norm: 0.46744643808587183, ic: 0.19924491008285194
Epoch 31: 2022-04-04 02:55:08.915161: train loss: 1.6263963966448138
Eval step 0: eval loss: 1.0100176079515533
Eval: 2022-04-04 02:55:12.856584: total loss: 1.085004836533826, mse:4.686423740415896, ic :0.15846512981918562, sharpe5:12.37701322853565, irr5:414.8415222167969, ndcg5:0.8485458501309546, pnl5:3.9117767810821533 
train 32, step: 0, loss: 0.8878895699571171, grad_norm: 0.9622348640339704, ic: 0.11279773597493184
train 32, step: 500, loss: 1.1043003361399581, grad_norm: 0.36570645184145156, ic: 0.17278816089424048
train 32, step: 1000, loss: 1.3749152742091564, grad_norm: 0.020408983894392337, ic: 0.07756404207271611
train 32, step: 1500, loss: 2.0925090777984714, grad_norm: 0.9163183080910852, ic: 0.418834281034387
train 32, step: 2000, loss: 1.0659647373407293, grad_norm: 0.3587169394813254, ic: 0.46874873403422385
Epoch 32: 2022-04-04 02:55:40.114199: train loss: 1.6227775240953843
Eval step 0: eval loss: 1.0089855063520272
Eval: 2022-04-04 02:55:44.179687: total loss: 1.0839205213301966, mse:4.6855807727275876, ic :0.16372340049186887, sharpe5:14.5840830463171, irr5:514.9097900390625, ndcg5:0.8404390695970261, pnl5:4.305194854736328 
train 33, step: 0, loss: 1.166444409795168, grad_norm: 0.025764582864782216, ic: 0.007781864211979343
train 33, step: 500, loss: 3.1639960697300156, grad_norm: 0.43706062350836145, ic: 0.5178244334563333
train 33, step: 1000, loss: 5.2780073572924255, grad_norm: 2.0899658266268673, ic: 0.012286706053920429
train 33, step: 1500, loss: 1.2839397151295733, grad_norm: 0.7854071456493509, ic: 0.056940821361997206
train 33, step: 2000, loss: 1.8667461543120154, grad_norm: 0.2535851028878788, ic: 0.1058113681110259
Epoch 33: 2022-04-04 02:56:11.949505: train loss: 1.6259986928495618
Eval step 0: eval loss: 1.0190232343708858
Eval: 2022-04-04 02:56:15.990935: total loss: 1.0917332321504318, mse:4.703918391815797, ic :0.1628157154842754, sharpe5:13.4368293428421, irr5:476.62969970703125, ndcg5:0.8445228916598323, pnl5:4.329338073730469 
train 34, step: 0, loss: 0.7159893440935767, grad_norm: 0.6763974235820114, ic: 0.14935980875164023
train 34, step: 500, loss: 1.8046465968586387, grad_norm: 0.45993329374823955, ic: 0.8837221112816257
train 34, step: 1000, loss: 0.6952514227505388, grad_norm: 0.343551379562941, ic: 0.4655376025334722
train 34, step: 1500, loss: 1.6610872708834135, grad_norm: 0.8057287497401918, ic: 0.6337519234865573
train 34, step: 2000, loss: 2.973350059848641, grad_norm: 0.4012843788957344, ic: 0.08539758385846251
Epoch 34: 2022-04-04 02:56:43.293456: train loss: 1.6250332051009053
Eval step 0: eval loss: 1.0098016225645075
Eval: 2022-04-04 02:56:47.351003: total loss: 1.0840872296749766, mse:4.691696343110648, ic :0.15710680436270685, sharpe5:12.556262367367744, irr5:414.1445617675781, ndcg5:0.8526119001563318, pnl5:3.386262893676758 
train 35, step: 0, loss: 1.0594277683692643, grad_norm: 0.6672326214276223, ic: -0.02103387168124965
train 35, step: 500, loss: 3.315120812618371, grad_norm: 2.9446199195582814, ic: -0.10979752526261508
train 35, step: 1000, loss: 1.3537907615350704, grad_norm: 0.13921508453383877, ic: 0.4939078052317453
train 35, step: 1500, loss: 1.6116794395602991, grad_norm: 0.39668886177427115, ic: 0.07682255986181605
train 35, step: 2000, loss: 1.3108112197182928, grad_norm: 0.11828296078671885, ic: -0.11447199001109401
Epoch 35: 2022-04-04 02:57:14.883772: train loss: 1.6236911034792827
Eval step 0: eval loss: 1.0056736018545944
Eval: 2022-04-04 02:57:18.823871: total loss: 1.082150202812861, mse:4.68143661837245, ic :0.16089221243184534, sharpe5:13.249192680716513, irr5:425.88702392578125, ndcg5:0.8370755520890225, pnl5:4.382481575012207 
train 36, step: 0, loss: 8.942947014354775, grad_norm: 1.0426766859863765, ic: -0.22509652006929265
train 36, step: 500, loss: 0.8556181729336204, grad_norm: 0.002775567923015091, ic: 0.10539950953004289
train 36, step: 1000, loss: 1.9906612500593655, grad_norm: 1.9869933448170158, ic: 0.08082715008014427
train 36, step: 1500, loss: 1.051765380010682, grad_norm: 0.0978733983707582, ic: 0.08946612888708738
train 36, step: 2000, loss: 2.155866904704973, grad_norm: 1.082591463376894, ic: 0.382683255090306
Epoch 36: 2022-04-04 02:57:46.241349: train loss: 1.6260138916609908
Eval step 0: eval loss: 1.0159666554559965
Eval: 2022-04-04 02:57:50.327977: total loss: 1.0893564792497643, mse:4.70117187192561, ic :0.1553665994407828, sharpe5:12.319431892633437, irr5:391.87237548828125, ndcg5:0.8388926168305829, pnl5:3.754103899002075 
train 37, step: 0, loss: 1.184299884110109, grad_norm: 0.13907993074184116, ic: 0.1893661136823686
train 37, step: 500, loss: 2.3337369926737552, grad_norm: 0.043528340484863925, ic: 0.17933392576451102
train 37, step: 1000, loss: 0.7685837057993264, grad_norm: 0.603598609087016, ic: 0.1446203011890122
train 37, step: 1500, loss: 3.1277208667116114, grad_norm: 0.7680805055443087, ic: 0.23157608823281747
train 37, step: 2000, loss: 3.121693797528517, grad_norm: 2.6580672565851606, ic: 0.027076110813189988
Epoch 37: 2022-04-04 02:58:18.137140: train loss: 1.62408558001542
Eval step 0: eval loss: 1.002873184179996
Eval: 2022-04-04 02:58:22.208181: total loss: 1.081205939626042, mse:4.6778770756515495, ic :0.1677655379053598, sharpe5:14.424307680130005, irr5:506.0102233886719, ndcg5:0.8453959382530944, pnl5:4.334306240081787 
train 38, step: 0, loss: 1.361249149206913, grad_norm: 2.937298082017453, ic: -0.1845287250841357
train 38, step: 500, loss: 1.6767827943313953, grad_norm: 0.9173901190084541, ic: 0.19193085324178155
train 38, step: 1000, loss: 1.8287797494844855, grad_norm: 0.6007191333449677, ic: 0.12242711398364098
train 38, step: 1500, loss: 1.090150283794615, grad_norm: 0.22448495241027655, ic: 0.4754928245202893
train 38, step: 2000, loss: 0.7530897687328532, grad_norm: 0.08907426625002321, ic: 0.5800253362487304
Epoch 38: 2022-04-04 02:58:50.015125: train loss: 1.621744688336806
Eval step 0: eval loss: 0.9989618559521458
Eval: 2022-04-04 02:58:54.108677: total loss: 1.0794042995002182, mse:4.679608069788437, ic :0.17222708277495619, sharpe5:14.301067748665808, irr5:517.6722412109375, ndcg5:0.8580290585587893, pnl5:3.8092968463897705 
train 39, step: 0, loss: 0.8674229626406991, grad_norm: 0.3281329624206961, ic: 0.5394142065092373
train 39, step: 500, loss: 1.249098030585906, grad_norm: 1.62439591136286, ic: 0.019000461667541206
train 39, step: 1000, loss: 1.396405029296875, grad_norm: 0.2945992845359949, ic: 0.06942173977707038
train 39, step: 1500, loss: 2.441002120211275, grad_norm: 0.44716230924808215, ic: -0.06367514002931146
train 39, step: 2000, loss: 2.8845174650657195, grad_norm: 1.229237430239499, ic: 0.23957252772555301
Epoch 39: 2022-04-04 02:59:21.422198: train loss: 1.6239702239736982
Eval step 0: eval loss: 0.9989264369199249
Eval: 2022-04-04 02:59:25.475075: total loss: 1.0797272103947015, mse:4.6815880669775005, ic :0.16617188075023434, sharpe5:13.369645915031432, irr5:476.49517822265625, ndcg5:0.843312152000853, pnl5:2.7982804775238037 

Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='RGCNSeqTimeDataset', dout=0.3, epochs=40, glstm_layers=1, gnn_layers=2, gpu=0, graph_attn=False, hidden_dim=128, inner_prod=False, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=3, market=None, mask_adj=True, mask_type='soft', model_type='RGCNModel', normalize_adj=True, num_days=1, num_heads=1, print_inteval=500, rank_loss=False, relation_num=2, rsr_data_path=None, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_750_0.6/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
load 2305 train graphs successful!
load 126 test graphs successful!
13156
RGCNModel(
  (fc1): Linear(in_features=9, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
  (fc4): Linear(in_features=128, out_features=1, bias=True)
  (gnns): ModuleList(
    (0): RGCN(
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
        (1): Linear(in_features=128, out_features=128, bias=False)
      )
      (lin_gate): Linear(in_features=256, out_features=256, bias=True)
    )
    (1): RGCN(
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
        (1): Linear(in_features=128, out_features=128, bias=False)
      )
      (lin_gate): Linear(in_features=256, out_features=256, bias=True)
    )
  )
  (dropout): Dropout(p=0.3, inplace=False)
  (relu): LeakyReLU(negative_slope=0.01)
)
train 0, step: 0, loss: 2.0710565016674902, grad_norm: 0.4457589980858457, ic: -0.18610312489380443
train 0, step: 500, loss: 1.368717497275398, grad_norm: 0.851635703501506, ic: 0.06073082055288456
train 0, step: 1000, loss: 1.5071773747570583, grad_norm: 0.032780680153454984, ic: 0.1968097239372134
train 0, step: 1500, loss: 1.1953850290942063, grad_norm: 0.10792762901236254, ic: 0.03798531881258279
train 0, step: 2000, loss: 1.5594940185546875, grad_norm: 0.0486640989235262, ic: 0.08015732402529357
Epoch 0: 2022-05-08 18:01:17.198827: train loss: 1.6472675196816895
Eval step 0: eval loss: 1.0013511300149749
Eval: 2022-05-08 18:01:29.397261: total loss: 1.090909400547732, mse:4.894499148687906, ic :0.03534363384065935, sharpe5:1.64185910359025, irr5:16.57484245300293, ndcg5:0.8562922245738083, pnl5:1.0856866836547852 
train 1, step: 0, loss: 0.655466891751431, grad_norm: 0.14675739193509016, ic: 0.03848446601450702
train 1, step: 500, loss: 1.2619357929792225, grad_norm: 0.2999974259213805, ic: 0.25718472928940883
train 1, step: 1000, loss: 0.8754265367753873, grad_norm: 0.06065570084607902, ic: 0.09747973533931936
train 1, step: 1500, loss: 1.8599834907345656, grad_norm: 0.5508302639941658, ic: 0.0853238153919918
train 1, step: 2000, loss: 1.363952917125287, grad_norm: 0.23469133569206616, ic: 0.18171604660767976
Epoch 1: 2022-05-08 18:03:20.004114: train loss: 1.6452869896300533
Eval step 0: eval loss: 1.0039967581621905
Eval: 2022-05-08 18:03:32.334517: total loss: 1.089292180920704, mse:4.878014885534763, ic :0.05350019929425856, sharpe5:4.200884467363357, irr5:69.66376495361328, ndcg5:0.8430191984014886, pnl5:1.4206109046936035 
train 2, step: 0, loss: 1.3165349065156136, grad_norm: 0.5038494314651257, ic: 0.05211740819064241
train 2, step: 500, loss: 0.9500452715999621, grad_norm: 0.2747071553538194, ic: 0.09205483038090895
train 2, step: 1000, loss: 3.0283274852931177, grad_norm: 1.0072477249804777, ic: 0.128076178441191
train 2, step: 1500, loss: 2.3068475927463323, grad_norm: 0.9399221489510952, ic: 0.10117073140364924
train 2, step: 2000, loss: 1.4621791636856092, grad_norm: 0.2765508397959885, ic: -0.11770836740640321
Epoch 2: 2022-05-08 18:05:24.242433: train loss: 1.6443876866498004
Eval step 0: eval loss: 0.9962819015559176
Eval: 2022-05-08 18:05:36.953329: total loss: 1.0886312048692197, mse:4.876184017639719, ic :0.055650869549048444, sharpe5:3.0062214401364327, irr5:32.63602828979492, ndcg5:0.8443824850201628, pnl5:1.1761906147003174 
train 3, step: 0, loss: 1.830235592901205, grad_norm: 0.06426752839035825, ic: -0.14286427945394437
train 3, step: 500, loss: 0.7831975978836514, grad_norm: 0.025053452996728315, ic: 0.07454512743537975
train 3, step: 1000, loss: 1.4067880755327244, grad_norm: 0.38271165492124026, ic: 0.23155007808926914
train 3, step: 1500, loss: 2.640880469656323, grad_norm: 0.3740496702126632, ic: -0.06438404329303092
train 3, step: 2000, loss: 1.3467058586351799, grad_norm: 0.16883016060480655, ic: 0.0625871717548722
Epoch 3: 2022-05-08 18:07:22.633028: train loss: 1.6447357168866128
Eval step 0: eval loss: 1.001820769669069
Eval: 2022-05-08 18:07:33.412861: total loss: 1.0902503962364842, mse:4.873478485188597, ic :0.065944757002392, sharpe5:8.477646365761757, irr5:254.65904235839844, ndcg5:0.8454839937941527, pnl5:3.284031391143799 
train 4, step: 0, loss: 1.1575737289823533, grad_norm: 0.1547281444321084, ic: 0.0969773442909088
train 4, step: 500, loss: 0.9779327524688853, grad_norm: 0.020405168877600684, ic: 0.2125729649640018
train 4, step: 1000, loss: 1.331324340913425, grad_norm: 0.06643096957464138, ic: 0.08704604318800363
train 4, step: 1500, loss: 1.055421408628806, grad_norm: 0.12865482538678175, ic: 0.6120222643561812
train 4, step: 2000, loss: 4.180739744172896, grad_norm: 0.9192100414567372, ic: 0.009996468107026653
Epoch 4: 2022-05-08 18:09:19.561135: train loss: 1.6393268143839532
Eval step 0: eval loss: 1.0172176993853672
Eval: 2022-05-08 18:09:32.829899: total loss: 1.1012324125715325, mse:4.7965635490192495, ic :0.11403850824658868, sharpe5:9.336003951430321, irr5:278.8484802246094, ndcg5:0.8574944435083102, pnl5:4.7391438484191895 
train 5, step: 0, loss: 1.0093219696068165, grad_norm: 0.24142663719126944, ic: -0.10128192403796957
train 5, step: 500, loss: 0.7853175640859499, grad_norm: 0.021597115928805748, ic: 0.16182490351169004
train 5, step: 1000, loss: 1.093061102878602, grad_norm: 0.04740302315881892, ic: 0.4065231223269222
train 5, step: 1500, loss: 1.7714770309324186, grad_norm: 0.3877687875201033, ic: -0.04968365256478904
train 5, step: 2000, loss: 2.1861002431293146, grad_norm: 0.8952305487256617, ic: -0.016348807829313243
Epoch 5: 2022-05-08 18:11:22.000234: train loss: 1.6385815418982328
Eval step 0: eval loss: 0.9883830716824644
Eval: 2022-05-08 18:11:35.008493: total loss: 1.0846004611603555, mse:4.751077612975681, ic :0.12704556035631007, sharpe5:8.71396320283413, irr5:252.62974548339844, ndcg5:0.8379728980810849, pnl5:2.9199750423431396 
train 6, step: 0, loss: 0.7884111241230322, grad_norm: 0.06470999304878416, ic: -0.09179633969682666
train 6, step: 500, loss: 1.3960226850900035, grad_norm: 0.32487320199668873, ic: 0.12115632854865854
train 6, step: 1000, loss: 1.2299523349888826, grad_norm: 0.180235543921078, ic: 0.15728968938185903
train 6, step: 1500, loss: 1.0583191148290094, grad_norm: 0.33325819832514963, ic: 0.0878733895520384
train 6, step: 2000, loss: 2.28587848269998, grad_norm: 1.048381327423038, ic: 0.08254466715739825
Epoch 6: 2022-05-08 18:13:31.704566: train loss: 1.6322147096501172
Eval step 0: eval loss: 1.0065117022939705
Eval: 2022-05-08 18:13:43.645105: total loss: 1.0857297565505282, mse:4.710676360665422, ic :0.13471177865101747, sharpe5:11.113547821640967, irr5:336.232666015625, ndcg5:0.8541197804544011, pnl5:5.272885322570801 
train 7, step: 0, loss: 1.4691656825962727, grad_norm: 0.5166688227995277, ic: 0.210493937570167
train 7, step: 500, loss: 1.3468032574477888, grad_norm: 0.1589072925576978, ic: 0.1844937638320283
train 7, step: 1000, loss: 0.6125046009811804, grad_norm: 0.27792823665224803, ic: 0.3849630874389487
train 7, step: 1500, loss: 1.0045847098642555, grad_norm: 0.1374292238563431, ic: 0.10299343435880676
train 7, step: 2000, loss: 1.5867602010284603, grad_norm: 0.6723820353487627, ic: 0.4092098024291541
Epoch 7: 2022-05-08 18:15:35.371493: train loss: 1.627424070702506
Eval step 0: eval loss: 0.9960771654077804
Eval: 2022-05-08 18:15:47.778990: total loss: 1.0815533308394987, mse:4.693604541532974, ic :0.1508292983387091, sharpe5:14.123653705716132, irr5:410.65179443359375, ndcg5:0.8423597381874409, pnl5:5.370410442352295 
train 8, step: 0, loss: 1.2019973441511158, grad_norm: 0.0955565500470423, ic: 0.07207533845209264
train 8, step: 500, loss: 5.5223488164919665, grad_norm: 1.1451026210583963, ic: 0.0760543418977637
train 8, step: 1000, loss: 1.8850874380155147, grad_norm: 0.5762847722069957, ic: 0.05882518289376651
train 8, step: 1500, loss: 1.1031741007386011, grad_norm: 0.38638717859267596, ic: 0.6353677321763773
train 8, step: 2000, loss: 1.1278721736027644, grad_norm: 0.5210366006164486, ic: -0.005288610160673217
Epoch 8: 2022-05-08 18:17:36.210069: train loss: 1.6275528793436091
Eval step 0: eval loss: 1.0104778625263295
Eval: 2022-05-08 18:17:47.725123: total loss: 1.0861231684840038, mse:4.686191236639305, ic :0.16397551834090615, sharpe5:14.117177898287773, irr5:464.0980224609375, ndcg5:0.8471078331030029, pnl5:5.351931571960449 
train 9, step: 0, loss: 1.0889651569738952, grad_norm: 0.03796845826842638, ic: 0.48799054346272164
train 9, step: 500, loss: 3.0932736099219937, grad_norm: 0.8941721832093193, ic: 0.21337832702049708
train 9, step: 1000, loss: 0.8626105802173062, grad_norm: 0.07948863534280097, ic: 0.2746035762450013
train 9, step: 1500, loss: 2.1587695549913897, grad_norm: 1.0803641807344082, ic: -0.006590291325323211
train 9, step: 2000, loss: 0.6073076801915323, grad_norm: 0.009470587278349242, ic: 0.06474670496852591
Epoch 9: 2022-05-08 18:19:32.768784: train loss: 1.6261766838947895
Eval step 0: eval loss: 0.9929585549754805
Eval: 2022-05-08 18:19:44.001927: total loss: 1.0812751533702347, mse:4.694349531484016, ic :0.15676300746319438, sharpe5:13.442513410449028, irr5:419.2879638671875, ndcg5:0.8284446691370871, pnl5:7.523690223693848 
train 10, step: 0, loss: 1.2944948570141483, grad_norm: 0.051576189779744236, ic: 0.39607349225808536
train 10, step: 500, loss: 0.8986101938613533, grad_norm: 0.008266752558480268, ic: 0.09574999374635128
train 10, step: 1000, loss: 1.525060903023522, grad_norm: 0.49674783100372044, ic: 0.05553240426475228
train 10, step: 1500, loss: 3.0680140053353657, grad_norm: 1.034387252884845, ic: 0.10265997735013446
train 10, step: 2000, loss: 1.383553084631459, grad_norm: 0.1547945294984489, ic: 0.09649554322944068
Epoch 10: 2022-05-08 18:21:35.677591: train loss: 1.625805242035491
Eval step 0: eval loss: 1.0033392883590047
Eval: 2022-05-08 18:21:47.896800: total loss: 1.082648332411285, mse:4.681274414071859, ic :0.16331374629060055, sharpe5:13.562537194490432, irr5:449.0176086425781, ndcg5:0.8469937399516431, pnl5:6.472917079925537 
train 11, step: 0, loss: 4.705829444390148, grad_norm: 1.3108332038825776, ic: 0.40890166083583945
train 11, step: 500, loss: 0.9880892377112135, grad_norm: 0.05944581599750547, ic: 0.039464227622379514
train 11, step: 1000, loss: 1.038233706825658, grad_norm: 0.3632464275602021, ic: 0.06578469458639456
train 11, step: 1500, loss: 0.6929742847463538, grad_norm: 0.0018213314316923405, ic: 0.08062639874187932
train 11, step: 2000, loss: 1.1341450595933185, grad_norm: 0.05649883029457031, ic: -0.18329086025661578
Epoch 11: 2022-05-08 18:23:30.881021: train loss: 1.6246443745658228
Eval step 0: eval loss: 0.9947687825006581
Eval: 2022-05-08 18:23:42.742033: total loss: 1.0811022132678885, mse:4.6893569365134935, ic :0.15915902862045986, sharpe5:14.42363985657692, irr5:475.7803955078125, ndcg5:0.8435414109965951, pnl5:6.143827438354492 
train 12, step: 0, loss: 1.380281977780418, grad_norm: 0.29162270138192137, ic: 0.17378215920629336
train 12, step: 500, loss: 0.8212796205973757, grad_norm: 0.39323135748930793, ic: 0.008776242699777137
train 12, step: 1000, loss: 1.1628773067746123, grad_norm: 0.27919956764433934, ic: 0.6341198046710055
train 12, step: 1500, loss: 1.083489374283257, grad_norm: 0.23376282188458064, ic: 0.06615721459926216
train 12, step: 2000, loss: 1.109943120697074, grad_norm: 0.05553315337302164, ic: 0.10688904082976834
Epoch 12: 2022-05-08 18:25:38.525415: train loss: 1.6241594263529104
Eval step 0: eval loss: 1.004970492282122
Eval: 2022-05-08 18:25:51.616530: total loss: 1.0816326022187848, mse:4.679718956257439, ic :0.17380254599899, sharpe5:14.452053573131561, irr5:478.6488952636719, ndcg5:0.8521561950003916, pnl5:7.663913726806641 
train 13, step: 0, loss: 1.0818709407944278, grad_norm: 0.07387343804044302, ic: 0.43025711016876383
train 13, step: 500, loss: 1.1513629010615458, grad_norm: 0.012694706730660194, ic: -0.14899513523210078
train 13, step: 1000, loss: 1.3917292032909618, grad_norm: 0.6057547411220412, ic: 0.11311435642204885
train 13, step: 1500, loss: 0.7760225293117389, grad_norm: 0.007096844925221111, ic: -0.03268972103531292
train 13, step: 2000, loss: 1.0370476835517473, grad_norm: 0.029743849597328186, ic: 0.06874438635750257
Epoch 13: 2022-05-08 18:27:40.316353: train loss: 1.6246998263864008
Eval step 0: eval loss: 0.9931985815931081
Eval: 2022-05-08 18:27:52.498718: total loss: 1.0799226899753023, mse:4.693329805196239, ic :0.16210945699207965, sharpe5:13.941339767575263, irr5:460.2483215332031, ndcg5:0.8523437133898168, pnl5:6.7188496589660645 
train 14, step: 0, loss: 1.7478640281547935, grad_norm: 0.5394939576483505, ic: 0.19240607107403107
train 14, step: 500, loss: 1.2593478413735304, grad_norm: 0.1652413047107678, ic: 0.26852448324547795
train 14, step: 1000, loss: 1.0639680720557851, grad_norm: 0.13551401756613618, ic: 0.2074724219025903
train 14, step: 1500, loss: 0.982829715766936, grad_norm: 0.1813334482751922, ic: 0.12125031549245036
train 14, step: 2000, loss: 2.3093644059696166, grad_norm: 0.5915860066611521, ic: -0.051154292545331534
Epoch 14: 2022-05-08 18:29:43.204985: train loss: 1.6273649592905248
Eval step 0: eval loss: 1.0132004354676802
Eval: 2022-05-08 18:29:55.075645: total loss: 1.0826880306695168, mse:4.66885283311832, ic :0.17517134331190515, sharpe5:15.247785201072691, irr5:528.6760864257812, ndcg5:0.8353427902210535, pnl5:6.721372127532959 
train 15, step: 0, loss: 0.9767851102666102, grad_norm: 0.263738548600111, ic: 0.028377613147048113
train 15, step: 500, loss: 1.2265624067453686, grad_norm: 0.017767863667050483, ic: 0.06966949919750487
train 15, step: 1000, loss: 1.7543526041666668, grad_norm: 0.08412994866149456, ic: 0.029192600027318175
train 15, step: 1500, loss: 5.392352677276682, grad_norm: 0.8832836398599354, ic: 0.014077478876226089
train 15, step: 2000, loss: 0.925803960755814, grad_norm: 0.30807102799741054, ic: 0.0757581379052723
Epoch 15: 2022-05-08 18:31:49.723243: train loss: 1.6239108693691213
Eval step 0: eval loss: 1.0095036141554765
Eval: 2022-05-08 18:32:02.495768: total loss: 1.0826952813747064, mse:4.670474546053754, ic :0.17495598205230348, sharpe5:15.171846284866332, irr5:524.1973876953125, ndcg5:0.868081199499278, pnl5:7.275546073913574 
train 16, step: 0, loss: 6.36683447225371, grad_norm: 1.7632521467773716, ic: 0.16794770374881127
train 16, step: 500, loss: 1.3713768368675596, grad_norm: 0.8184864629032669, ic: -0.03083877168176774
train 16, step: 1000, loss: 0.8367569744346797, grad_norm: 0.44678678964066754, ic: 0.026553888540304778
train 16, step: 1500, loss: 1.2357077799230107, grad_norm: 0.36435378769816884, ic: 0.13778758321631165
train 16, step: 2000, loss: 0.9563246835533323, grad_norm: 0.5949126073300265, ic: 0.5572152535981453
Epoch 16: 2022-05-08 18:33:49.167407: train loss: 1.6234302103740268
Eval step 0: eval loss: 0.99748839849921
Eval: 2022-05-08 18:34:01.768793: total loss: 1.078724119997484, mse:4.691291895512983, ic :0.16820910138505446, sharpe5:14.155191814899444, irr5:474.5578918457031, ndcg5:0.8490288379254917, pnl5:5.645427227020264 
train 17, step: 0, loss: 1.1802425267506231, grad_norm: 0.013482591910866523, ic: 0.12872276856132892
train 17, step: 500, loss: 1.0442887223758668, grad_norm: 0.030086660286474033, ic: -0.02484263578699698
train 17, step: 1000, loss: 3.389660926541873, grad_norm: 0.8732753052360652, ic: -0.019052293061765688
train 17, step: 1500, loss: 0.8804262031629247, grad_norm: 0.03389618378322382, ic: 0.10312231651687878
train 17, step: 2000, loss: 0.9892976287227349, grad_norm: 0.9079240895993216, ic: 0.6019464439329429
Epoch 17: 2022-05-08 18:35:49.094410: train loss: 1.6238609930910108
Eval step 0: eval loss: 1.0013564010869207
Eval: 2022-05-08 18:36:02.164722: total loss: 1.0801721527658819, mse:4.683431616483707, ic :0.17472839530558928, sharpe5:14.414594914913177, irr5:500.056884765625, ndcg5:0.8546519631666322, pnl5:5.926595687866211 
train 18, step: 0, loss: 0.851616535936247, grad_norm: 0.030088981399247296, ic: 0.026535114303891646
train 18, step: 500, loss: 2.5183604984079704, grad_norm: 1.0676619496241104, ic: 0.06843435919678402
train 18, step: 1000, loss: 1.3663547872639388, grad_norm: 0.4296013342953074, ic: 0.5345981590165053
train 18, step: 1500, loss: 1.7715097469843586, grad_norm: 0.9954996880689779, ic: 0.31816416752962584
train 18, step: 2000, loss: 1.2351786471873194, grad_norm: 0.40749919069090723, ic: 0.24692004230733616
Epoch 18: 2022-05-08 18:37:49.955747: train loss: 1.6242707183354064
Eval step 0: eval loss: 0.995969686965179
Eval: 2022-05-08 18:38:02.445603: total loss: 1.0842136761117527, mse:4.688498163054556, ic :0.16769220084727002, sharpe5:14.222000656127928, irr5:469.9280700683594, ndcg5:0.8643671386400197, pnl5:6.00369930267334 
train 19, step: 0, loss: 2.19280366087653, grad_norm: 0.8256083318938537, ic: 0.24770564543057197
train 19, step: 500, loss: 1.016927674759266, grad_norm: 0.09372124881566361, ic: 0.08973343776189711
train 19, step: 1000, loss: 0.9692466499464403, grad_norm: 0.0396927113486577, ic: 0.5628531024193444
train 19, step: 1500, loss: 1.584551022376543, grad_norm: 0.2553536917784632, ic: 0.12626585341485172
train 19, step: 2000, loss: 1.697075297273782, grad_norm: 1.614362954533859, ic: 0.649183949796222
Epoch 19: 2022-05-08 18:39:52.214936: train loss: 1.6227535435985896
Eval step 0: eval loss: 0.9979080915325499
Eval: 2022-05-08 18:40:03.808904: total loss: 1.0799595168813225, mse:4.676345059581202, ic :0.17004572375554686, sharpe5:14.208227031826972, irr5:480.7890319824219, ndcg5:0.8627591637875944, pnl5:8.245911598205566 
train 20, step: 0, loss: 1.247649309343828, grad_norm: 0.3620488586712198, ic: 0.4640019004606171
train 20, step: 500, loss: 1.2110720584912291, grad_norm: 0.4133206253960733, ic: -0.013288610745926032
train 20, step: 1000, loss: 1.5495286237758075, grad_norm: 0.33425870929909407, ic: 0.18740888574480496
train 20, step: 1500, loss: 0.8616171911303439, grad_norm: 1.0953256010676433, ic: 0.5909409303947281
train 20, step: 2000, loss: 1.3506648835388035, grad_norm: 0.18113438422727904, ic: -0.047088053518534165
Epoch 20: 2022-05-08 18:41:56.883750: train loss: 1.6255532418433278
Eval step 0: eval loss: 1.0013297243203658
Eval: 2022-05-08 18:42:08.135088: total loss: 1.0784618074300527, mse:4.668677778767928, ic :0.17361345513294504, sharpe5:15.694276326298713, irr5:546.346923828125, ndcg5:0.8360257755933201, pnl5:5.646735668182373 
train 21, step: 0, loss: 1.389496116526968, grad_norm: 0.708125091657503, ic: 0.28449756315083163
train 21, step: 500, loss: 1.1060820902771136, grad_norm: 0.08794394496862416, ic: 0.058735928355585124
train 21, step: 1000, loss: 0.9070457138776191, grad_norm: 0.19278445567611283, ic: 0.13505067766534196
train 21, step: 1500, loss: 0.7303226942310939, grad_norm: 0.17290294758067926, ic: 0.6345625745555056
train 21, step: 2000, loss: 1.117397582828561, grad_norm: 0.08980622731820766, ic: 0.30636901999684435
Epoch 21: 2022-05-08 18:43:55.269216: train loss: 1.6218962505725285
Eval step 0: eval loss: 0.9983041290234991
Eval: 2022-05-08 18:44:06.562341: total loss: 1.0796098523115125, mse:4.686826398703752, ic :0.16327102218303624, sharpe5:13.942670685052871, irr5:446.734130859375, ndcg5:0.8474428747117276, pnl5:4.187695503234863 
train 22, step: 0, loss: 1.0691025254555198, grad_norm: 0.35779391441505126, ic: 0.10614709763332386
train 22, step: 500, loss: 1.0274264117864174, grad_norm: 0.0012957126678388537, ic: -0.009063760314003352
train 22, step: 1000, loss: 0.9108321664893363, grad_norm: 0.01657979654029843, ic: 0.1256999024963502
train 22, step: 1500, loss: 0.9970873300902939, grad_norm: 0.04535254867238426, ic: 0.2618973445322148
train 22, step: 2000, loss: 1.043641769054324, grad_norm: 0.12911638834279685, ic: 0.16074814417434918
Epoch 22: 2022-05-08 18:45:49.791603: train loss: 1.6219956615540272
Eval step 0: eval loss: 1.0066214948657186
Eval: 2022-05-08 18:46:02.678783: total loss: 1.0822961361173107, mse:4.675580358835765, ic :0.17018219419575087, sharpe5:14.030888662934302, irr5:469.97454833984375, ndcg5:0.85154395857992, pnl5:4.514016628265381 
train 23, step: 0, loss: 1.285763343799058, grad_norm: 0.9026924753465655, ic: -0.03557361533447249
train 23, step: 500, loss: 0.9072626134851477, grad_norm: 0.1788850550914366, ic: 0.6038998468721957
train 23, step: 1000, loss: 2.2859080174078845, grad_norm: 0.9464494317541574, ic: 0.07146792568759724
train 23, step: 1500, loss: 0.7620977097952023, grad_norm: 0.3890463888147729, ic: 0.7331272968028536
train 23, step: 2000, loss: 1.473776473480017, grad_norm: 0.3562752376944233, ic: 0.398198974581851
Epoch 23: 2022-05-08 18:47:54.868785: train loss: 1.621736289125743
Eval step 0: eval loss: 1.0051242533076619
Eval: 2022-05-08 18:48:06.966710: total loss: 1.0842978944214723, mse:4.68543282642206, ic :0.16207546963611996, sharpe5:13.540191591382026, irr5:433.4201965332031, ndcg5:0.8451450906731441, pnl5:4.224110126495361 
train 24, step: 0, loss: 1.1762641948428962, grad_norm: 0.3850397840364297, ic: 0.3481232273848869
train 24, step: 500, loss: 1.252486845084859, grad_norm: 0.3522019879873373, ic: 0.004322197786062054
train 24, step: 1000, loss: 1.0312673056997905, grad_norm: 0.4649990769948557, ic: 0.11193683981566062
train 24, step: 1500, loss: 1.2017174427903543, grad_norm: 0.06883185606234347, ic: 0.04408328889860566
train 24, step: 2000, loss: 1.3477015040810951, grad_norm: 0.3620360474535813, ic: 0.4449485598158608
Epoch 24: 2022-05-08 18:49:48.304347: train loss: 1.6221753897468023
Eval step 0: eval loss: 1.0022907950113547
Eval: 2022-05-08 18:50:00.802701: total loss: 1.0791391188050652, mse:4.669459895980976, ic :0.17571055784046702, sharpe5:16.28994750380516, irr5:564.2314453125, ndcg5:0.8431491491706483, pnl5:7.7556071281433105 
train 25, step: 0, loss: 1.3044130157853477, grad_norm: 0.5875048863404745, ic: 0.23426582078678665
train 25, step: 500, loss: 1.4607457743062602, grad_norm: 0.3216872364051054, ic: 0.12990316064419105
train 25, step: 1000, loss: 1.3524921717761644, grad_norm: 0.2783292847711979, ic: 0.2798789526479975
train 25, step: 1500, loss: 2.8817118282498186, grad_norm: 1.4032213270540583, ic: 0.2589558719234492
train 25, step: 2000, loss: 1.1990219309360166, grad_norm: 0.18612768356291845, ic: 0.13165400250513704
Epoch 25: 2022-05-08 18:51:51.734547: train loss: 1.6210976508072539
Eval step 0: eval loss: 1.0044539272314374
Eval: 2022-05-08 18:52:03.517440: total loss: 1.0788237166900065, mse:4.664146275998465, ic :0.17986601483008186, sharpe5:15.731957277059553, irr5:545.6348266601562, ndcg5:0.8654235370023646, pnl5:5.886516571044922 
train 26, step: 0, loss: 1.6153826349431817, grad_norm: 0.33727774516261083, ic: 0.19390101689689998
train 26, step: 500, loss: 1.0243028250500719, grad_norm: 0.2426169487354027, ic: -0.024639645308706867
train 26, step: 1000, loss: 1.8041256309845963, grad_norm: 0.6160609186620044, ic: 0.20629019001318483
train 26, step: 1500, loss: 0.9213326516665566, grad_norm: 0.027110219294427265, ic: 0.0625650832313773
train 26, step: 2000, loss: 1.0052680548720472, grad_norm: 0.1426074406640141, ic: 0.12959370090311467
Epoch 26: 2022-05-08 18:53:52.005393: train loss: 1.6217087667211076
Eval step 0: eval loss: 0.9975906058698656
Eval: 2022-05-08 18:54:04.175474: total loss: 1.0827918096208686, mse:4.69055669137041, ic :0.16788524769799032, sharpe5:14.342023494243621, irr5:494.99664306640625, ndcg5:0.8463831206915005, pnl5:5.4827446937561035 
train 27, step: 0, loss: 1.6011177890272026, grad_norm: 0.3998966543870914, ic: 0.6474278632503716
train 27, step: 500, loss: 1.4960642291079413, grad_norm: 0.3537787518327668, ic: 0.09780282509751674
train 27, step: 1000, loss: 2.4864897472319347, grad_norm: 0.8223219402964279, ic: 0.4305195602012708
train 27, step: 1500, loss: 0.8345082353834142, grad_norm: 0.5380844640467173, ic: 0.5647330091762714
train 27, step: 2000, loss: 1.3698079802107335, grad_norm: 1.8524795620863075, ic: -0.014481737081580657
Epoch 27: 2022-05-08 18:55:54.843517: train loss: 1.6200682562944773
Eval step 0: eval loss: 1.0011293593050619
Eval: 2022-05-08 18:56:07.082941: total loss: 1.078146462249022, mse:4.6731931323248475, ic :0.17750264920413214, sharpe5:14.679509924054145, irr5:508.1266174316406, ndcg5:0.8440041684132361, pnl5:5.0866265296936035 
train 28, step: 0, loss: 1.1597579004582852, grad_norm: 0.15272077391321093, ic: 0.1325439639738652
train 28, step: 500, loss: 2.960522219612335, grad_norm: 1.2318555915787737, ic: 0.1001594239403681
train 28, step: 1000, loss: 2.795059951372433, grad_norm: 3.2014192704796383, ic: -0.04793009665711509
train 28, step: 1500, loss: 1.027768235709799, grad_norm: 0.17849909703181452, ic: 0.19395298315204368
train 28, step: 2000, loss: 1.7550203190293423, grad_norm: 0.4757126752210021, ic: 0.049095156790315425
Epoch 28: 2022-05-08 18:57:51.205735: train loss: 1.6220797972310947
Eval step 0: eval loss: 1.0042483554255528
Eval: 2022-05-08 18:58:01.492912: total loss: 1.0796414088615849, mse:4.680892572723121, ic :0.17835452390769901, sharpe5:15.476451390981673, irr5:534.9331665039062, ndcg5:0.8487198168497023, pnl5:6.0749006271362305 
train 29, step: 0, loss: 1.5193987218062925, grad_norm: 0.16207948573357056, ic: 0.07482902742732106
train 29, step: 500, loss: 2.53538309565486, grad_norm: 1.6654062598687946, ic: -0.18709321170691973
train 29, step: 1000, loss: 1.7061974548551038, grad_norm: 1.1357717594736743, ic: 0.49056965434512084
train 29, step: 1500, loss: 3.9371362134326353, grad_norm: 1.8437399421598828, ic: 0.17784196221676157
train 29, step: 2000, loss: 0.912421151813066, grad_norm: 0.23108483864519158, ic: 0.47575969639723903
Epoch 29: 2022-05-08 19:00:00.117598: train loss: 1.619869274097952
Eval step 0: eval loss: 1.0044912747046142
Eval: 2022-05-08 19:00:12.331441: total loss: 1.0785824007375626, mse:4.6719507690433755, ic :0.17737943854264096, sharpe5:16.330925005674363, irr5:562.7898559570312, ndcg5:0.8598944106135173, pnl5:6.85714054107666 
train 30, step: 0, loss: 1.2427646772686411, grad_norm: 0.04855082102498655, ic: 0.9773140279974484
train 30, step: 500, loss: 1.9526799841772151, grad_norm: 0.24276586899738314, ic: 0.15954856892733757
train 30, step: 1000, loss: 3.3951334527842034, grad_norm: 0.7619648279269581, ic: 0.4416023725513675
train 30, step: 1500, loss: 1.0704298617857657, grad_norm: 0.30929854120463796, ic: 0.1923064985742416
train 30, step: 2000, loss: 1.083629986508168, grad_norm: 0.12840180302158222, ic: 0.43347189331202013
Epoch 30: 2022-05-08 19:02:03.753979: train loss: 1.6195759046120344
Eval step 0: eval loss: 1.001178213142608
Eval: 2022-05-08 19:02:16.500471: total loss: 1.0832287625633277, mse:4.7086609393009216, ic :0.1519903120975315, sharpe5:12.228561539053917, irr5:404.48583984375, ndcg5:0.8486633043966127, pnl5:2.730419635772705 
train 31, step: 0, loss: 1.1815467625616445, grad_norm: 0.3755562263835957, ic: 0.146951465115735
train 31, step: 500, loss: 0.8346277056210846, grad_norm: 0.09742951135748322, ic: 0.2223151437427635
train 31, step: 1000, loss: 5.098590254134241, grad_norm: 0.6909684462851993, ic: 0.01476427695804143
train 31, step: 1500, loss: 1.6865358898039027, grad_norm: 0.2605642241325541, ic: 0.2691850596053036
train 31, step: 2000, loss: 0.9603307965158047, grad_norm: 0.46876651731063856, ic: 0.24148527358700209
Epoch 31: 2022-05-08 19:04:06.684855: train loss: 1.6199636898900527
Eval step 0: eval loss: 1.0073351465820826
Eval: 2022-05-08 19:04:19.019679: total loss: 1.0802153372264545, mse:4.6645464412349815, ic :0.17808554836625606, sharpe5:15.97097189426422, irr5:546.8829345703125, ndcg5:0.8569716452580882, pnl5:6.180655002593994 
train 32, step: 0, loss: 0.8710577489753127, grad_norm: 0.4378614428048107, ic: 0.11373294296842743
train 32, step: 500, loss: 1.110093279582698, grad_norm: 0.4505484021344037, ic: 0.17562726482273436
train 32, step: 1000, loss: 1.3784667186665776, grad_norm: 0.11887647588479111, ic: 0.11113350119111429
train 32, step: 1500, loss: 2.068165498621324, grad_norm: 0.9567379316168311, ic: 0.44433312320740215
train 32, step: 2000, loss: 1.1028268252050382, grad_norm: 0.6151212121336587, ic: 0.459335093230137
Epoch 32: 2022-05-08 19:06:06.820046: train loss: 1.6161052807986398
Eval step 0: eval loss: 1.0064856683410677
Eval: 2022-05-08 19:06:20.581365: total loss: 1.0792686345033689, mse:4.666582718331307, ic :0.1751183624149892, sharpe5:16.47117173552513, irr5:568.0033569335938, ndcg5:0.8368216729396154, pnl5:6.448767185211182 
train 33, step: 0, loss: 1.1649890780175707, grad_norm: 0.027028004118872146, ic: 0.028896708553722176
train 33, step: 500, loss: 3.1768456355687933, grad_norm: 0.8162989897972952, ic: 0.5130006331032748
train 33, step: 1000, loss: 5.214105815845776, grad_norm: 7.0432861442923, ic: 0.06998156216778101
train 33, step: 1500, loss: 1.3070913919588414, grad_norm: 1.0720289979116524, ic: 0.06944374865578329
train 33, step: 2000, loss: 1.860860472686531, grad_norm: 0.36737831165043594, ic: 0.0788276880000328
Epoch 33: 2022-05-08 19:08:10.391198: train loss: 1.6162529989356718
Eval step 0: eval loss: 1.0068743134750198
Eval: 2022-05-08 19:08:22.946764: total loss: 1.0802900655428214, mse:4.661467171935776, ic :0.1816657225160497, sharpe5:16.027712302207945, irr5:554.811767578125, ndcg5:0.8639168685540252, pnl5:3.9309043884277344 
train 34, step: 0, loss: 0.7137944966601872, grad_norm: 0.21823890196689608, ic: 0.1786864978927839
train 34, step: 500, loss: 1.9058661678431188, grad_norm: 3.583665192584491, ic: 0.8257670875044998
train 34, step: 1000, loss: 0.6783183762122844, grad_norm: 0.027259284375435573, ic: 0.5009962576311796
train 34, step: 1500, loss: 1.6257518279246794, grad_norm: 1.6014238570279697, ic: 0.6581923270119745
train 34, step: 2000, loss: 3.0066477038714994, grad_norm: 0.5727444014685957, ic: 0.05596897828790599
Epoch 34: 2022-05-08 19:10:23.166799: train loss: 1.6211826858920682
Eval step 0: eval loss: 1.0064256938273433
Eval: 2022-05-08 19:10:34.975776: total loss: 1.0794506195909452, mse:4.668135576398635, ic :0.17686177796113906, sharpe5:16.58717249751091, irr5:577.8203735351562, ndcg5:0.8493158395887727, pnl5:5.355503559112549 
train 35, step: 0, loss: 1.038662777671331, grad_norm: 0.5344046133333692, ic: -8.351839178574044e-05
train 35, step: 500, loss: 3.2975756096117426, grad_norm: 1.2328571847209666, ic: -0.0697874605871367
train 35, step: 1000, loss: 1.3412653525421239, grad_norm: 0.0627955139128979, ic: 0.503882754913024
train 35, step: 1500, loss: 1.6426465083691648, grad_norm: 0.42860636227785526, ic: 0.05194638937401273
train 35, step: 2000, loss: 1.273410811802348, grad_norm: 0.16881230648112797, ic: 0.04884700468826818
Epoch 35: 2022-05-08 19:12:24.829770: train loss: 1.6183894452297258
Eval step 0: eval loss: 1.0019952292942007
Eval: 2022-05-08 19:12:35.578865: total loss: 1.0792080367360741, mse:4.669194518075524, ic :0.17530192981318518, sharpe5:17.108339728116988, irr5:556.2371215820312, ndcg5:0.8443819130026259, pnl5:5.258219242095947 
train 36, step: 0, loss: 9.09067463743094, grad_norm: 3.107587537913587, ic: -0.13659889516430684
train 36, step: 500, loss: 0.8567986787944739, grad_norm: 0.059050942268230044, ic: 0.1441357329813345
train 36, step: 1000, loss: 1.9638760923252279, grad_norm: 2.1830660990858344, ic: 0.04427371218022378
train 36, step: 1500, loss: 1.0431070869242467, grad_norm: 0.4662898045633125, ic: 0.049012401209937995
train 36, step: 2000, loss: 2.1584364883755147, grad_norm: 1.3931927997732478, ic: 0.39443133016775866
Epoch 36: 2022-05-08 19:14:26.600242: train loss: 1.6177521808593047
Eval step 0: eval loss: 1.0150235835472616
Eval: 2022-05-08 19:14:38.658462: total loss: 1.0807525815225671, mse:4.659361631032389, ic :0.178723415886407, sharpe5:16.879181656837464, irr5:582.4443969726562, ndcg5:0.8404846875372455, pnl5:4.973606109619141 
train 37, step: 0, loss: 1.2224663628472223, grad_norm: 0.21558668884529494, ic: 0.1576043399752476
train 37, step: 500, loss: 2.3344698197614107, grad_norm: 0.06708716552057405, ic: 0.15658820566860568
train 37, step: 1000, loss: 0.7466768243611331, grad_norm: 0.2541033537219313, ic: 0.16760209299416506
train 37, step: 1500, loss: 3.100586866969384, grad_norm: 1.3338276567208236, ic: 0.23045005450049066
train 37, step: 2000, loss: 3.146786626663498, grad_norm: 1.3710235823506531, ic: 0.006799873046902362
Epoch 37: 2022-05-08 19:16:24.695651: train loss: 1.617546864832053
Eval step 0: eval loss: 1.0109667865899814
Eval: 2022-05-08 19:16:36.929922: total loss: 1.0782125637827218, mse:4.661195178686074, ic :0.18197728701123325, sharpe5:17.34163338661194, irr5:591.1310424804688, ndcg5:0.8470258075088312, pnl5:4.717670917510986 
train 38, step: 0, loss: 1.3366618763316762, grad_norm: 0.38764698281125753, ic: -0.25760537794579114
train 38, step: 500, loss: 1.742750726744186, grad_norm: 0.8453619097459877, ic: 0.21516012063225642
train 38, step: 1000, loss: 1.8219217568612531, grad_norm: 0.5954326158941826, ic: 0.14691855424964897
train 38, step: 1500, loss: 1.058146058260584, grad_norm: 0.2838121826542118, ic: 0.504367368129635
train 38, step: 2000, loss: 0.737604002566658, grad_norm: 0.47525911008545424, ic: 0.59186339241891
Epoch 38: 2022-05-08 19:18:29.067922: train loss: 1.6163944103642813
Eval step 0: eval loss: 0.9993035756895076
Eval: 2022-05-08 19:18:41.397843: total loss: 1.0775661569929516, mse:4.677755992616808, ic :0.1800735798854793, sharpe5:15.67028954207897, irr5:557.8146362304688, ndcg5:0.8550831596578105, pnl5:4.392362117767334 
train 39, step: 0, loss: 0.8627621136947077, grad_norm: 0.02230576063281688, ic: 0.5373049952220006
train 39, step: 500, loss: 1.2539259261289595, grad_norm: 0.3920329017070335, ic: -0.002048255335908921
train 39, step: 1000, loss: 1.410461055871212, grad_norm: 0.3745508695902814, ic: 0.09513928342875105
train 39, step: 1500, loss: 2.450772814576412, grad_norm: 0.4651856865369009, ic: -0.0472096841201531
train 39, step: 2000, loss: 2.9087977234632234, grad_norm: 1.2289657478855402, ic: 0.21596855444011392
Epoch 39: 2022-05-08 19:20:40.379621: train loss: 1.6172350342612876
Eval step 0: eval loss: 1.0001989508252698
Eval: 2022-05-08 19:20:53.320005: total loss: 1.0804086337290841, mse:4.6799195477108055, ic :0.17189138533656914, sharpe5:15.56528232872486, irr5:503.0747985839844, ndcg5:0.8377450050405063, pnl5:7.94775390625 

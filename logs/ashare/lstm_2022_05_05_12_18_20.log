Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='AdjTimeDataset', dout=0.3, epochs=40, glstm_layers=1, gnn_layers=2, gpu=0, graph_attn=False, hidden_dim=128, inner_prod=False, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=1, market=None, mask_adj=False, mask_type='soft', model_type='BaseLSTM', normalize_adj=False, num_days=8, num_heads=1, print_inteval=500, rank_loss=False, relation_num=1, rsr_data_path=None, seed=10086, shuffle=True, side_info=False, sparse_adj_path=None, stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=False)
80724
BaseLSTM(
  (rnn1): LSTM(9, 128, batch_first=True, dropout=0.3, bidirectional=True)
  (fc0): Linear(in_features=256, out_features=128, bias=True)
  (predict): Linear(in_features=128, out_features=1, bias=True)
  (relu): PReLU(num_parameters=1)
  (dropout): Dropout(p=0.3, inplace=False)
)
train 0, step: 0, loss: 4.879133020181783, grad_norm: 0.7237482948028695, ic: -0.011436347590720687
train 0, step: 500, loss: 0.8659503307213169, grad_norm: 0.023505360605380447, ic: 0.06666984584366878
train 0, step: 1000, loss: 1.9353561345555963, grad_norm: 0.40690740022651173, ic: 0.025277925197590367
train 0, step: 1500, loss: 0.9566257642663043, grad_norm: 0.04755863544864593, ic: -0.04821823690269837
train 0, step: 2000, loss: 0.9984435815447263, grad_norm: 0.12828013323387774, ic: 0.12083569668536626
Epoch 0: 2022-05-05 12:18:47.285154: train loss: 1.6474680394659305
Eval step 0: eval loss: 0.8357161269675315
Eval: 2022-05-05 12:18:49.759990: total loss: 1.0791276575211861, mse:4.8231909848985755, ic :0.006427540843209306, sharpe5:7.05539266616106, irr5:201.41317749023438, ndcg5:0.8690426927999173, pnl5:2.827601671218872 
train 1, step: 0, loss: 2.7671999039188506, grad_norm: 0.745013744169601, ic: 0.10300375899351077
train 1, step: 500, loss: 1.7557466001612652, grad_norm: 0.6688145652403452, ic: 0.07416578621363307
train 1, step: 1000, loss: 0.8746855319003286, grad_norm: 0.1508739727621679, ic: 0.06640520841207956
train 1, step: 1500, loss: 1.7114319549209769, grad_norm: 0.1862616767106463, ic: -0.019139770527764104
train 1, step: 2000, loss: 2.1793443359375, grad_norm: 0.8502111730713902, ic: -0.0072276783437650125
Epoch 1: 2022-05-05 12:19:09.097006: train loss: 1.6466369406989987
Eval step 0: eval loss: 0.8347220707241174
Eval: 2022-05-05 12:19:11.424965: total loss: 1.0788206784186296, mse:4.823068932526123, ic :0.0113500507561383, sharpe5:7.118438141942024, irr5:201.52342224121094, ndcg5:0.8447764474242454, pnl5:2.5845792293548584 
train 2, step: 0, loss: 2.140663174715909, grad_norm: 0.008260250327440117, ic: 0.21425006436157326
train 2, step: 500, loss: 3.30450869278169, grad_norm: 0.2935714295881915, ic: -0.0037233503442607417
train 2, step: 1000, loss: 2.0718630268199236, grad_norm: 0.00042017105350321596, ic: 0.25350898244282416
train 2, step: 1500, loss: 1.4871941719346373, grad_norm: 0.05828191570087594, ic: -0.06515628913417738
train 2, step: 2000, loss: 3.2316800631009617, grad_norm: 0.7809633520037159, ic: 0.3015823738779497
Epoch 2: 2022-05-05 12:19:30.879754: train loss: 1.6465183259332339
Eval step 0: eval loss: 0.8361375203750658
Eval: 2022-05-05 12:19:33.234757: total loss: 1.07921887908034, mse:4.822162080819253, ic :0.014377758141982758, sharpe5:6.9998559486866, irr5:198.2421875, ndcg5:0.8536986122994706, pnl5:2.6242897510528564 
train 3, step: 0, loss: 1.5265517816310976, grad_norm: 0.5143980428590401, ic: 0.030666286866209803
train 3, step: 500, loss: 1.5044729162588097, grad_norm: 0.33114723247387157, ic: 0.09202618493665946
train 3, step: 1000, loss: 3.6799438687392056, grad_norm: 0.693584696022967, ic: -0.03858320810064539
train 3, step: 1500, loss: 1.9954550285776391, grad_norm: 1.1234582285388406, ic: -0.05023594260637322
train 3, step: 2000, loss: 0.8961398067989865, grad_norm: 0.00045998022297589656, ic: 0.026019219730938282
Epoch 3: 2022-05-05 12:19:52.578052: train loss: 1.646310034867324
Eval step 0: eval loss: 0.8326548505005268
Eval: 2022-05-05 12:19:54.824601: total loss: 1.0787347571188197, mse:4.82751867609335, ic :0.01659593158576364, sharpe5:7.067509028613567, irr5:198.643310546875, ndcg5:0.8510973111408273, pnl5:2.4508697986602783 
train 4, step: 0, loss: 1.4372084263392857, grad_norm: 0.045995743931820696, ic: 0.11649395626344959
train 4, step: 500, loss: 1.6597340981791338, grad_norm: 0.5892475120547553, ic: 0.056873571457852906
train 4, step: 1000, loss: 2.974760288145484, grad_norm: 0.6701311899336728, ic: -0.005092613146415105
train 4, step: 1500, loss: 2.1396725425237344, grad_norm: 0.47874357365778897, ic: -0.006996302811353442
train 4, step: 2000, loss: 1.0841013194984448, grad_norm: 0.37641399581060503, ic: 0.25367086828830665
Epoch 4: 2022-05-05 12:20:14.649612: train loss: 1.6459557314615396
Eval step 0: eval loss: 0.8455052913428609
Eval: 2022-05-05 12:20:16.887914: total loss: 1.082890115617731, mse:4.825459693761814, ic :0.029296226336153076, sharpe5:6.818481314778327, irr5:192.32679748535156, ndcg5:0.8577267244036755, pnl5:2.7107045650482178 
train 5, step: 0, loss: 1.3452693247955116, grad_norm: 0.1029300353120469, ic: 0.026460054328889447
train 5, step: 500, loss: 0.8896526968923474, grad_norm: 0.007033504569718083, ic: 0.0113415862355882
train 5, step: 1000, loss: 0.9850125718390805, grad_norm: 0.15161471598370516, ic: -0.03738342170205275
train 5, step: 1500, loss: 1.5295879369855476, grad_norm: 0.145030299559541, ic: -0.0051500881146942686
train 5, step: 2000, loss: 1.1103317366951855, grad_norm: 0.026027749289265125, ic: 0.10759495434088984
Epoch 5: 2022-05-05 12:20:36.306621: train loss: 1.6461785573252
Eval step 0: eval loss: 0.83809257483206
Eval: 2022-05-05 12:20:38.657000: total loss: 1.0797411529467338, mse:4.821942308499349, ic :0.025651378851734675, sharpe5:7.280694671273231, irr5:200.06719970703125, ndcg5:0.8566790443102338, pnl5:2.7541961669921875 
train 6, step: 0, loss: 1.3353256882662978, grad_norm: 0.40065276261922056, ic: 0.0924737071833003
train 6, step: 500, loss: 1.010824066208844, grad_norm: 0.042752283518880246, ic: 0.0684675618303602
train 6, step: 1000, loss: 1.1299981062856463, grad_norm: 0.08395017478298278, ic: 0.10478043130394465
train 6, step: 1500, loss: 1.5570820958161156, grad_norm: 0.6658310852241556, ic: 0.09398471000151006
train 6, step: 2000, loss: 0.8112015491299289, grad_norm: 0.04485090663215857, ic: 0.016318951102622943
Epoch 6: 2022-05-05 12:20:58.276333: train loss: 1.6456433259702414
Eval step 0: eval loss: 0.835800765814344
Eval: 2022-05-05 12:21:00.665711: total loss: 1.0784735006661874, mse:4.819955810150633, ic :0.03383162782093346, sharpe5:7.231022693216801, irr5:201.41236877441406, ndcg5:0.87959154932402, pnl5:2.872297763824463 
train 7, step: 0, loss: 0.9979022979736328, grad_norm: 0.05054731282490398, ic: 0.10247706858721678
train 7, step: 500, loss: 0.6516129514004322, grad_norm: 0.0013510673009941361, ic: 0.04357716569829894
train 7, step: 1000, loss: 1.0456764238623382, grad_norm: 0.2062372059536558, ic: 0.05312198047643615
train 7, step: 1500, loss: 2.2657076885718115, grad_norm: 0.6533828982971791, ic: 0.16465108185803418
train 7, step: 2000, loss: 0.9106218525974354, grad_norm: 0.03486069505169313, ic: -0.046114630794805614
Epoch 7: 2022-05-05 12:21:19.092408: train loss: 1.645533451146591
Eval step 0: eval loss: 0.8403142159304201
Eval: 2022-05-05 12:21:21.594150: total loss: 1.0799055528886077, mse:4.818248991348327, ic :0.037312305457351265, sharpe5:6.954195168614387, irr5:195.2099151611328, ndcg5:0.8581336220547168, pnl5:2.723217487335205 
train 8, step: 0, loss: 3.5886973505434785, grad_norm: 1.072108470906703, ic: 0.03796978675294409
train 8, step: 500, loss: 2.7889699269210677, grad_norm: 0.9035627732613514, ic: 0.013356449176651412
train 8, step: 1000, loss: 3.048304107223732, grad_norm: 0.8931222432502421, ic: 0.046118214029951615
train 8, step: 1500, loss: 0.7516312416913918, grad_norm: 0.0004634849221686529, ic: 0.1196824633122123
train 8, step: 2000, loss: 1.123356442889268, grad_norm: 0.30972097433828616, ic: 0.1355369166975823
Epoch 8: 2022-05-05 12:21:40.408208: train loss: 1.6448649792089587
Eval step 0: eval loss: 0.8347146101570732
Eval: 2022-05-05 12:21:42.726376: total loss: 1.07780205120282, mse:4.819958953190075, ic :0.0402966549009799, sharpe5:6.371407499313354, irr5:184.40162658691406, ndcg5:0.8441673786499013, pnl5:3.04315185546875 
train 9, step: 0, loss: 5.468300656648724, grad_norm: 0.9072588609172124, ic: 0.20188920081475467
train 9, step: 500, loss: 1.3821086140422079, grad_norm: 0.9797623495801865, ic: 0.12104926266569856
train 9, step: 1000, loss: 0.9307793177211617, grad_norm: 0.013612153139871103, ic: 0.08396256760815689
train 9, step: 1500, loss: 1.1028094509388806, grad_norm: 0.01007462886696172, ic: 0.4547916237111897
train 9, step: 2000, loss: 1.0853607404707573, grad_norm: 0.16759937049436802, ic: 0.09759818482408197
Epoch 9: 2022-05-05 12:22:02.208502: train loss: 1.6431455364186605
Eval step 0: eval loss: 0.8310045859333838
Eval: 2022-05-05 12:22:04.681594: total loss: 1.076002959815804, mse:4.722874600940957, ic :0.12966810229157422, sharpe5:10.688520696759223, irr5:340.1137390136719, ndcg5:0.8500056756868579, pnl5:2.474879503250122 
train 10, step: 0, loss: 7.116213784620991, grad_norm: 1.38944953821184, ic: 0.05495422480528241
train 10, step: 500, loss: 1.1316412382260597, grad_norm: 0.04969586053650899, ic: -0.04144739522188071
train 10, step: 1000, loss: 2.4308572780866564, grad_norm: 0.6283995907243277, ic: -0.028563800829570204
train 10, step: 1500, loss: 1.1255782486556414, grad_norm: 0.32623510387353427, ic: 0.012113233161030202
train 10, step: 2000, loss: 2.774222608757599, grad_norm: 0.2709394600573521, ic: 0.4933146741138984
Epoch 10: 2022-05-05 12:22:24.634766: train loss: 1.6385483868286634
Eval step 0: eval loss: 0.8324127679629872
Eval: 2022-05-05 12:22:27.014951: total loss: 1.0728816153139242, mse:4.631442684814788, ic :0.15277832216666148, sharpe5:11.23267770588398, irr5:375.7210998535156, ndcg5:0.8442587838009554, pnl5:1.8932734727859497 
train 11, step: 0, loss: 1.2677034996133025, grad_norm: 0.003452915891979025, ic: 0.1345169679842221
train 11, step: 500, loss: 0.6815205877808379, grad_norm: 0.006145140934194318, ic: 0.5710169353197556
train 11, step: 1000, loss: 0.9436378321761645, grad_norm: 0.19622621826872094, ic: 0.043050350001205426
train 11, step: 1500, loss: 1.0598844561660499, grad_norm: 0.05157615735412878, ic: 0.1834741633990681
train 11, step: 2000, loss: 0.7915147055193523, grad_norm: 0.0004928458742541569, ic: 0.11927684634788269
Epoch 11: 2022-05-05 12:22:46.416568: train loss: 1.6341883467410883
Eval step 0: eval loss: 0.8364414741668862
Eval: 2022-05-05 12:22:48.851328: total loss: 1.0732739854554811, mse:4.623161430663184, ic :0.15511327556926766, sharpe5:11.340537831187248, irr5:382.027587890625, ndcg5:0.8532213896687226, pnl5:2.366497755050659 
train 12, step: 0, loss: 0.99966828028361, grad_norm: 0.08034496791262474, ic: 0.2857909144174063
train 12, step: 500, loss: 0.9431761195677212, grad_norm: 0.08106985775901945, ic: 0.043971082426549374
train 12, step: 1000, loss: 2.981622975343352, grad_norm: 0.1916991305222839, ic: 0.344658628846816
train 12, step: 1500, loss: 0.9646025844321211, grad_norm: 0.12479229626826915, ic: -0.13030399454968355
train 12, step: 2000, loss: 0.8740995931481307, grad_norm: 0.0005154723908061028, ic: 0.13009851042820259
Epoch 12: 2022-05-05 12:23:08.888822: train loss: 1.6323166822275734
Eval step 0: eval loss: 0.8325450000823235
Eval: 2022-05-05 12:23:11.243270: total loss: 1.070724968936418, mse:4.621609635920623, ic :0.16004807623669362, sharpe5:11.550498340129852, irr5:385.5256042480469, ndcg5:0.8520094831175585, pnl5:2.7895710468292236 
train 13, step: 0, loss: 2.048971721967397, grad_norm: 0.7654073675354567, ic: 0.4332938138042698
train 13, step: 500, loss: 0.8338085138130968, grad_norm: 0.020979061653971537, ic: 0.5614007853447155
train 13, step: 1000, loss: 0.9468791782455955, grad_norm: 0.27911928808731573, ic: 0.568865681458265
train 13, step: 1500, loss: 2.3398875847726384, grad_norm: 0.1315649567875839, ic: -0.08701592159275451
train 13, step: 2000, loss: 1.492726056551915, grad_norm: 0.017613681640044527, ic: 0.0007438188222812416
Epoch 13: 2022-05-05 12:23:30.782464: train loss: 1.6319245274006913
Eval step 0: eval loss: 0.8331440321637907
Eval: 2022-05-05 12:23:33.071238: total loss: 1.073019608845459, mse:4.641986003625056, ic :0.15208961573135382, sharpe5:11.8457690513134, irr5:392.2269287109375, ndcg5:0.8506990298355087, pnl5:2.334576368331909 
train 14, step: 0, loss: 4.610956391380656, grad_norm: 1.3804224201176627, ic: 0.16121019871933778
train 14, step: 500, loss: 0.8259244679675555, grad_norm: 0.0010220935899383043, ic: 0.08092350630306722
train 14, step: 1000, loss: 1.9387672325835232, grad_norm: 0.28799950230442356, ic: 0.39168715094707685
train 14, step: 1500, loss: 1.1290468129108615, grad_norm: 0.06042902195448112, ic: -0.001044831417608888
train 14, step: 2000, loss: 1.1361255335973752, grad_norm: 0.14575373034932693, ic: 0.12747941309348546
Epoch 14: 2022-05-05 12:23:52.275630: train loss: 1.6322783484202024
Eval step 0: eval loss: 0.837446463999934
Eval: 2022-05-05 12:23:54.621737: total loss: 1.0713728369593667, mse:4.610531343191858, ic :0.16630230469919338, sharpe5:12.319014739394188, irr5:414.02789306640625, ndcg5:0.8480190350459834, pnl5:3.5909647941589355 
train 15, step: 0, loss: 3.3066835633511675, grad_norm: 0.48100749600902915, ic: 0.06780252507063865
train 15, step: 500, loss: 1.2595300079878429, grad_norm: 0.004327582670729854, ic: -0.06339552476518169
train 15, step: 1000, loss: 1.3220754731961382, grad_norm: 0.11210284076137418, ic: -0.11305964803327019
train 15, step: 1500, loss: 0.8526495024913878, grad_norm: 0.1554392636354767, ic: 0.02022917456043436
train 15, step: 2000, loss: 1.4671892298208535, grad_norm: 0.5241659285730943, ic: -0.029832010958467048
Epoch 15: 2022-05-05 12:24:14.423185: train loss: 1.6319295863423937
Eval step 0: eval loss: 0.839780914017222
Eval: 2022-05-05 12:24:16.806016: total loss: 1.0729872540843675, mse:4.614121271155367, ic :0.16184010027561435, sharpe5:11.509813129305838, irr5:396.06292724609375, ndcg5:0.8444301162367367, pnl5:3.830657720565796 
train 16, step: 0, loss: 0.6926819959143655, grad_norm: 0.17928719066143586, ic: -0.04187873720883063
train 16, step: 500, loss: 1.5705463011596745, grad_norm: 0.20807533464886524, ic: 0.12721031740881555
train 16, step: 1000, loss: 0.8763522986209754, grad_norm: 0.003797779411341277, ic: -0.08593813407847062
train 16, step: 1500, loss: 0.880551457686909, grad_norm: 0.21164856080935263, ic: 0.15836670223951574
train 16, step: 2000, loss: 3.3508270540875307, grad_norm: 0.9727821424940608, ic: 0.04112523214867844
Epoch 16: 2022-05-05 12:24:36.469856: train loss: 1.6307277489244418
Eval step 0: eval loss: 0.8331348994006849
Eval: 2022-05-05 12:24:38.904578: total loss: 1.0700205901324256, mse:4.608952094406443, ic :0.16714915194879898, sharpe5:12.33372010052204, irr5:413.8621826171875, ndcg5:0.8581411907171898, pnl5:3.7752389907836914 
train 17, step: 0, loss: 1.2670996870855435, grad_norm: 0.2067105108753297, ic: -0.10924075571937408
train 17, step: 500, loss: 1.7817451621781843, grad_norm: 0.3827946499336397, ic: 0.18031028188362697
train 17, step: 1000, loss: 1.2875718959189424, grad_norm: 0.09073502397191638, ic: 0.15509780080226518
train 17, step: 1500, loss: 4.536098012146399, grad_norm: 1.147235862919659, ic: 0.10877464037525977
train 17, step: 2000, loss: 1.2730939162564638, grad_norm: 0.5481488050538997, ic: -0.009160847914761638
Epoch 17: 2022-05-05 12:24:58.562290: train loss: 1.6311766293415109
Eval step 0: eval loss: 0.8383581967449288
Eval: 2022-05-05 12:25:00.922667: total loss: 1.0714368562079397, mse:4.6102876055476605, ic :0.16931453641748764, sharpe5:12.252024280428886, irr5:414.92926025390625, ndcg5:0.8363184457830171, pnl5:3.539741277694702 
train 18, step: 0, loss: 1.4119261254671518, grad_norm: 0.4239810211414101, ic: 0.04914106153957405
train 18, step: 500, loss: 1.5105226776886602, grad_norm: 0.6124138307429063, ic: -0.08065036407307949
train 18, step: 1000, loss: 0.6602823335830479, grad_norm: 0.0027854803120047973, ic: 0.5705619247874155
train 18, step: 1500, loss: 1.4426865386338044, grad_norm: 0.044973397529091644, ic: 0.0547653312758969
train 18, step: 2000, loss: 0.9130595990806628, grad_norm: 0.00883108947835154, ic: -0.04331171427676502
Epoch 18: 2022-05-05 12:25:20.355735: train loss: 1.6310798077225117
Eval step 0: eval loss: 0.829777129708904
Eval: 2022-05-05 12:25:22.655854: total loss: 1.069080902927368, mse:4.608179285320122, ic :0.16866939452486637, sharpe5:12.219359573721885, irr5:403.4487609863281, ndcg5:0.8480202853478643, pnl5:5.860268592834473 
train 19, step: 0, loss: 1.4551056392609127, grad_norm: 0.6555248726415172, ic: 0.048019321721383956
train 19, step: 500, loss: 0.8657713289614076, grad_norm: 0.022417011959071455, ic: 0.23345492745620042
train 19, step: 1000, loss: 0.9702579437464408, grad_norm: 0.001508763792349771, ic: 0.08704847337485501
train 19, step: 1500, loss: 3.9797141959109275, grad_norm: 0.7517159683164443, ic: 0.005422523336800808
train 19, step: 2000, loss: 1.0192436335637018, grad_norm: 0.08313896848246907, ic: 0.24666715445521253
Epoch 19: 2022-05-05 12:25:41.832415: train loss: 1.630594442209909
Eval step 0: eval loss: 0.8359844501201923
Eval: 2022-05-05 12:25:44.241933: total loss: 1.070971652670527, mse:4.612329605466436, ic :0.16518331516001594, sharpe5:12.010393232703208, irr5:406.7497253417969, ndcg5:0.8386101788004753, pnl5:3.5490238666534424 
train 20, step: 0, loss: 2.3119657855731224, grad_norm: 0.495943559794433, ic: 0.03671746946142254
train 20, step: 500, loss: 3.173043323863636, grad_norm: 0.42752038387765984, ic: 0.13686693806805889
train 20, step: 1000, loss: 0.9921384811401368, grad_norm: 0.0484639862422515, ic: 0.04807528013033546
train 20, step: 1500, loss: 1.9503039232987176, grad_norm: 0.2872238754185065, ic: 0.17946899217119772
train 20, step: 2000, loss: 1.0408951477747757, grad_norm: 0.010312716906473281, ic: -0.008521544285180295
Epoch 20: 2022-05-05 12:26:04.061740: train loss: 1.6301718636689047
Eval step 0: eval loss: 0.8348267759236696
Eval: 2022-05-05 12:26:06.454592: total loss: 1.06989678814247, mse:4.610599678408677, ic :0.16740594641307902, sharpe5:11.842697630524635, irr5:399.8409118652344, ndcg5:0.8677673083955605, pnl5:3.8483190536499023 
train 21, step: 0, loss: 1.0110904277507629, grad_norm: 0.2607683338625211, ic: 0.033291756290332805
train 21, step: 500, loss: 0.7782712278112901, grad_norm: 0.006644874148834936, ic: 0.16876909076387905
train 21, step: 1000, loss: 0.9248817845394737, grad_norm: 0.3710249984279019, ic: 0.16395968375105935
train 21, step: 1500, loss: 1.0045206442078383, grad_norm: 0.16582109833039238, ic: 0.22095780038751014
train 21, step: 2000, loss: 0.9411830627508997, grad_norm: 0.032401062662059485, ic: 0.08898073086469685
Epoch 21: 2022-05-05 12:26:26.775580: train loss: 1.6304401990432078
Eval step 0: eval loss: 0.8343072374703635
Eval: 2022-05-05 12:26:29.113365: total loss: 1.0713473568985308, mse:4.619644909306181, ic :0.16231293610229067, sharpe5:11.661235025525093, irr5:401.1150817871094, ndcg5:0.8479020089229186, pnl5:3.1395368576049805 
train 22, step: 0, loss: 1.0633193193855932, grad_norm: 0.008226563925342876, ic: 0.06284960719270391
train 22, step: 500, loss: 3.2345278360010163, grad_norm: 0.4927441495273487, ic: -0.07904151640202543
train 22, step: 1000, loss: 1.210164858426662, grad_norm: 0.005884521348936078, ic: 0.43327517704154206
train 22, step: 1500, loss: 0.9763898935828189, grad_norm: 0.046474703058876514, ic: 0.0841122882780551
train 22, step: 2000, loss: 1.7804627710459184, grad_norm: 0.4201785807509381, ic: 0.19853966456005218
Epoch 22: 2022-05-05 12:26:48.367383: train loss: 1.6307735835951167
Eval step 0: eval loss: 0.8315618774285432
Eval: 2022-05-05 12:26:50.740646: total loss: 1.0714212814342716, mse:4.62131309608876, ic :0.16060515254330537, sharpe5:12.060552835464478, irr5:407.3218688964844, ndcg5:0.8496768952309508, pnl5:2.916918992996216 
train 23, step: 0, loss: 0.9917346085869957, grad_norm: 0.03505179399369261, ic: 0.18672320466323186
train 23, step: 500, loss: 1.4277946436236755, grad_norm: 0.08079506132833103, ic: -0.007032079948470448
train 23, step: 1000, loss: 1.6615454101562501, grad_norm: 0.04435539055945551, ic: 0.26092981036386037
train 23, step: 1500, loss: 1.108773548421911, grad_norm: 0.14577847358326054, ic: 0.05665631922324699
train 23, step: 2000, loss: 1.9487731322772324, grad_norm: 0.6241063725696181, ic: 0.4398089809587221
Epoch 23: 2022-05-05 12:27:10.108709: train loss: 1.6304944475083163
Eval step 0: eval loss: 0.8358610935030294
Eval: 2022-05-05 12:27:12.426794: total loss: 1.0708183354504097, mse:4.609964925385917, ic :0.17028955599553797, sharpe5:11.945253004431724, irr5:408.5238037109375, ndcg5:0.8571111408200948, pnl5:2.789762496948242 
train 24, step: 0, loss: 2.2016539337752996, grad_norm: 0.012004441706957619, ic: 0.3000573301750732
train 24, step: 500, loss: 1.2307674185311286, grad_norm: 0.036621589774288046, ic: 0.2359032230090911
train 24, step: 1000, loss: 0.9217019090774815, grad_norm: 0.004384271852839224, ic: 0.5036361746662987
train 24, step: 1500, loss: 2.592994029523908, grad_norm: 0.5661305732877165, ic: -0.07369347840371755
train 24, step: 2000, loss: 0.9334191506532701, grad_norm: 0.011148656702095305, ic: 0.10799422863719386
Epoch 24: 2022-05-05 12:27:32.196957: train loss: 1.6299689566965114
Eval step 0: eval loss: 0.832278606386657
Eval: 2022-05-05 12:27:34.575678: total loss: 1.0700699463184649, mse:4.611505449261799, ic :0.16590960827947646, sharpe5:11.948279966711997, irr5:408.1448974609375, ndcg5:0.8440380304176439, pnl5:2.73933482170105 
train 25, step: 0, loss: 0.8727035110061233, grad_norm: 0.036932752116143316, ic: 0.572993357956532
train 25, step: 500, loss: 0.8681068996648413, grad_norm: 0.0009397539403847142, ic: 0.27508768245198734
train 25, step: 1000, loss: 2.1722651043650036, grad_norm: 0.0071490812402227304, ic: 0.12523139985771348
train 25, step: 1500, loss: 1.170591196929973, grad_norm: 0.23230121954527172, ic: 0.47469283249205274
train 25, step: 2000, loss: 0.999380075956367, grad_norm: 0.341479104979574, ic: 0.5440681342970813
Epoch 25: 2022-05-05 12:27:53.775158: train loss: 1.629498816495553
Eval step 0: eval loss: 0.836664905286815
Eval: 2022-05-05 12:27:55.916007: total loss: 1.0714508317106874, mse:4.6079530829456425, ic :0.16917289864541632, sharpe5:12.027404760718346, irr5:411.8336486816406, ndcg5:0.8286083392956695, pnl5:3.0424351692199707 
train 26, step: 0, loss: 6.690718288238817, grad_norm: 0.23692110386063409, ic: 0.08438639503663678
train 26, step: 500, loss: 3.8216246365568804, grad_norm: 0.5033578737853428, ic: 0.31665721692767634
train 26, step: 1000, loss: 1.2623172203075943, grad_norm: 0.7232326665585349, ic: -0.009549637125456232
train 26, step: 1500, loss: 0.8506350127666304, grad_norm: 0.13198021400986043, ic: 0.20645582007100644
train 26, step: 2000, loss: 0.9538793196179189, grad_norm: 0.08384309002031898, ic: 0.07762443831163111
Epoch 26: 2022-05-05 12:28:15.669927: train loss: 1.6299413695252822
Eval step 0: eval loss: 0.8357352285917742
Eval: 2022-05-05 12:28:17.855361: total loss: 1.0716053774020668, mse:4.620639076675074, ic :0.16464895995120063, sharpe5:12.188293481469154, irr5:414.9802551269531, ndcg5:0.8499803740276405, pnl5:3.065716505050659 
train 27, step: 0, loss: 0.8324423636642156, grad_norm: 0.0005494481342856435, ic: -0.06217771351680688
train 27, step: 500, loss: 0.9014908259909568, grad_norm: 0.32503116277747496, ic: 0.2927285160322651
train 27, step: 1000, loss: 0.7537379666805637, grad_norm: 0.0809725308794673, ic: 0.011031715674750774
train 27, step: 1500, loss: 0.6357753948755441, grad_norm: 0.017423036884053854, ic: 0.5110857190891355
train 27, step: 2000, loss: 1.3838222448628512, grad_norm: 0.007484187985639757, ic: -0.019585437626557834
Epoch 27: 2022-05-05 12:28:36.348260: train loss: 1.6292205262820245
Eval step 0: eval loss: 0.8377949239330874
Eval: 2022-05-05 12:28:38.611866: total loss: 1.0721481911159674, mse:4.611168024621599, ic :0.16527894676816454, sharpe5:11.849835585951805, irr5:405.9498596191406, ndcg5:0.8516984455408956, pnl5:3.171459436416626 
train 28, step: 0, loss: 1.539272894546332, grad_norm: 0.10144903052499099, ic: 0.2142257797106164
train 28, step: 500, loss: 1.3699236763729739, grad_norm: 0.17346928318984384, ic: 0.14258829307701984
train 28, step: 1000, loss: 0.9168311638560721, grad_norm: 0.15331155219482331, ic: 0.5415224703431476
train 28, step: 1500, loss: 1.0357046653433373, grad_norm: 0.022144536712957567, ic: 0.034060569879849296
train 28, step: 2000, loss: 1.0464750886694785, grad_norm: 0.04394072366040371, ic: 0.02530293512463552
Epoch 28: 2022-05-05 12:28:57.462529: train loss: 1.6289975568267059
Eval step 0: eval loss: 0.8373369994731296
Eval: 2022-05-05 12:28:59.820212: total loss: 1.0934174815434297, mse:4.77015246675098, ic :0.14165822168393952, sharpe5:12.64095488011837, irr5:422.973876953125, ndcg5:0.8354418676625888, pnl5:3.1030097007751465 
train 29, step: 0, loss: 0.9046713226757961, grad_norm: 0.014445785766115712, ic: 0.07801240473557261
train 29, step: 500, loss: 1.1338006745907956, grad_norm: 0.04441648654624604, ic: 0.5878758393856262
train 29, step: 1000, loss: 1.0460168541346893, grad_norm: 0.22279200868411747, ic: -0.03968650282408601
train 29, step: 1500, loss: 2.3213349937182866, grad_norm: 0.13261913856351681, ic: -0.09629270243896243
train 29, step: 2000, loss: 4.375363950376157, grad_norm: 1.4000103854025587, ic: 0.01875327557894936
Epoch 29: 2022-05-05 12:29:19.414455: train loss: 1.6294043882520821
Eval step 0: eval loss: 0.8389307309503424
Eval: 2022-05-05 12:29:21.761497: total loss: 1.0712018405872545, mse:4.612693799101308, ic :0.16718582509842747, sharpe5:12.37322574198246, irr5:417.00115966796875, ndcg5:0.8390646871448727, pnl5:3.1812191009521484 
train 30, step: 0, loss: 1.015526991255689, grad_norm: 0.015867882284985556, ic: 0.5047947383411195
train 30, step: 500, loss: 1.3816001084713394, grad_norm: 0.7533879028548164, ic: 0.08551626859892035
train 30, step: 1000, loss: 0.9757516571969697, grad_norm: 0.018075280048424555, ic: -0.043188429469850714
train 30, step: 1500, loss: 1.52952532367267, grad_norm: 0.44212841653802637, ic: 0.15221619414135307
train 30, step: 2000, loss: 1.8535189873039402, grad_norm: 0.06898750967802356, ic: -0.2672015806535877
Epoch 30: 2022-05-05 12:29:41.100135: train loss: 1.6295080392000871
Eval step 0: eval loss: 0.8370235270268045
Eval: 2022-05-05 12:29:43.485978: total loss: 1.0715610446907682, mse:4.611462032767526, ic :0.16507669818278795, sharpe5:12.267563948035239, irr5:418.33795166015625, ndcg5:0.8445720284237644, pnl5:3.266453266143799 
train 31, step: 0, loss: 1.0756369564178279, grad_norm: 0.013831809998427636, ic: 0.2963323949683826
train 31, step: 500, loss: 1.4925684799382715, grad_norm: 0.4043964764879357, ic: 0.0337808022084417
train 31, step: 1000, loss: 4.297448282591725, grad_norm: 0.7927706480459314, ic: 0.4227510980723738
train 31, step: 1500, loss: 0.7715880778753329, grad_norm: 0.00885327224285943, ic: 0.7072505953406272
train 31, step: 2000, loss: 1.2439799671115122, grad_norm: 0.35507941482413946, ic: 0.11077202864222116
Epoch 31: 2022-05-05 12:30:02.457159: train loss: 1.6290616699798754
Eval step 0: eval loss: 0.8419137357786156
Eval: 2022-05-05 12:30:04.852517: total loss: 1.0730376947780902, mse:4.613715601148382, ic :0.1657363516771291, sharpe5:12.21450224518776, irr5:413.5790100097656, ndcg5:0.8576477700364691, pnl5:3.4371962547302246 
train 32, step: 0, loss: 1.1449839472306118, grad_norm: 0.001248737448443553, ic: 0.0403672469166399
train 32, step: 500, loss: 1.4994398222194882, grad_norm: 0.3041191077881311, ic: 0.03756737437926295
train 32, step: 1000, loss: 1.035955214529898, grad_norm: 0.06842553527580682, ic: 0.5218363622766312
train 32, step: 1500, loss: 1.0052511650219298, grad_norm: 0.2843452254785868, ic: 0.04392580144305711
train 32, step: 2000, loss: 0.9686334269933683, grad_norm: 0.00755723282060747, ic: 0.5179553884690817
Epoch 32: 2022-05-05 12:30:24.162662: train loss: 1.629926148508657
Eval step 0: eval loss: 0.831944553065727
Eval: 2022-05-05 12:30:26.491397: total loss: 1.0693597381723428, mse:4.614884766790067, ic :0.16871391366479369, sharpe5:13.295098455548287, irr5:435.3470764160156, ndcg5:0.8445867701831432, pnl5:4.286742687225342 
train 33, step: 0, loss: 1.2765458548472373, grad_norm: 0.11868341771416197, ic: 0.20664628690562734
train 33, step: 500, loss: 1.0086337002840908, grad_norm: 0.005123373965474657, ic: 0.02981098748766077
train 33, step: 1000, loss: 1.0306963005760985, grad_norm: 0.17260883365845342, ic: 0.19224173611490453
train 33, step: 1500, loss: 0.9083632065308053, grad_norm: 0.005469943359160917, ic: 0.5193644222662792
train 33, step: 2000, loss: 0.8161487609573098, grad_norm: 0.01429302752752145, ic: 0.2153674008615392
Epoch 33: 2022-05-05 12:30:45.429750: train loss: 1.6291832681802163
Eval step 0: eval loss: 0.8354339117245125
Eval: 2022-05-05 12:30:47.826412: total loss: 1.0699622321241335, mse:4.608876745752403, ic :0.16881299445893452, sharpe5:12.91022114753723, irr5:429.6028747558594, ndcg5:0.8615822099282766, pnl5:4.000170707702637 
train 34, step: 0, loss: 1.0470362920714782, grad_norm: 0.28849178383748797, ic: 0.5461788735111591
train 34, step: 500, loss: 0.8045532039910646, grad_norm: 0.06752804842876815, ic: 0.1894899109638168
train 34, step: 1000, loss: 3.1760752688172045, grad_norm: 0.13621070273699865, ic: 0.2305719374936957
train 34, step: 1500, loss: 0.8000558846329335, grad_norm: 0.11403516729217905, ic: 0.6822852126558617
train 34, step: 2000, loss: 6.50354315937258, grad_norm: 3.0747384157686373, ic: 0.39388449287240734
Epoch 34: 2022-05-05 12:31:07.059771: train loss: 1.6291543717418342
Eval step 0: eval loss: 0.8310723741891135
Eval: 2022-05-05 12:31:09.461410: total loss: 1.0695854153641697, mse:4.612648473059036, ic :0.16888989727662354, sharpe5:12.59697028040886, irr5:418.3375244140625, ndcg5:0.849032316053182, pnl5:4.04697847366333 
train 35, step: 0, loss: 1.2438674747242646, grad_norm: 0.4837001250571489, ic: 0.55057706941777
train 35, step: 500, loss: 1.1533782035721587, grad_norm: 0.3446319529366883, ic: 0.054509481372779195
train 35, step: 1000, loss: 1.878598093733413, grad_norm: 0.4513838722813554, ic: 0.09239363891256676
train 35, step: 1500, loss: 1.6823100842927632, grad_norm: 0.6608432766281852, ic: 0.05890401895906432
train 35, step: 2000, loss: 0.8036969842757771, grad_norm: 0.018179200809244296, ic: 0.524143082620366
Epoch 35: 2022-05-05 12:31:28.716577: train loss: 1.6293013592700796
Eval step 0: eval loss: 0.8358951162613606
Eval: 2022-05-05 12:31:30.998911: total loss: 1.0703123627329512, mse:4.611125515758118, ic :0.16885725230805612, sharpe5:13.03270528435707, irr5:427.1943664550781, ndcg5:0.865667298898026, pnl5:5.661886692047119 
train 36, step: 0, loss: 1.8461199270874216, grad_norm: 0.5623323857183204, ic: -0.0559754151813426
train 36, step: 500, loss: 0.8458931083468775, grad_norm: 0.004917696331482217, ic: 0.08513777503991721
train 36, step: 1000, loss: 1.6290397727272727, grad_norm: 0.1991993583926857, ic: 0.17529280880620582
train 36, step: 1500, loss: 0.7992431164717348, grad_norm: 0.024905540853813572, ic: 0.23899647187929193
train 36, step: 2000, loss: 1.140097741573173, grad_norm: 0.5295142657774791, ic: 0.7789007318891445
Epoch 36: 2022-05-05 12:31:50.262244: train loss: 1.6287969586680728
Eval step 0: eval loss: 0.8368102577137118
Eval: 2022-05-05 12:31:52.555533: total loss: 1.0698998283607581, mse:4.609828449721383, ic :0.169012593369045, sharpe5:12.677327615618704, irr5:419.61163330078125, ndcg5:0.83987527597118, pnl5:4.61035680770874 
train 37, step: 0, loss: 2.028882994951187, grad_norm: 0.8233335941378066, ic: 0.23069191750820903
train 37, step: 500, loss: 2.3375753928553222, grad_norm: 0.46677042084208664, ic: -0.0644434705469866
train 37, step: 1000, loss: 1.069604417867675, grad_norm: 0.04459757225644957, ic: -0.022891580209079776
train 37, step: 1500, loss: 2.0367065621320646, grad_norm: 0.5475455153239595, ic: 0.6092674907624565
train 37, step: 2000, loss: 1.3158407116253115, grad_norm: 0.05291072845477432, ic: 0.16764766154929148
Epoch 37: 2022-05-05 12:32:11.979342: train loss: 1.629116494604913
Eval step 0: eval loss: 0.8342380342795047
Eval: 2022-05-05 12:32:14.342825: total loss: 1.0742588207015005, mse:4.642973683000931, ic :0.15827528222674644, sharpe5:12.640274759531021, irr5:417.9455871582031, ndcg5:0.8395488032743006, pnl5:4.10482931137085 
train 38, step: 0, loss: 1.329364869652725, grad_norm: 0.20933626631463872, ic: -0.08301848457383351
train 38, step: 500, loss: 0.9246384608892747, grad_norm: 0.0644479906350844, ic: 0.25321238150232694
train 38, step: 1000, loss: 0.8939399085968379, grad_norm: 0.10939719615130787, ic: 0.1617894716826438
train 38, step: 1500, loss: 0.9659075320626899, grad_norm: 0.001959813557675258, ic: 0.09390243437595872
train 38, step: 2000, loss: 2.2893077470024545, grad_norm: 0.7594659807956936, ic: 0.052229302995420356
Epoch 38: 2022-05-05 12:32:33.509173: train loss: 1.6287998256038132
Eval step 0: eval loss: 0.8354205341560195
Eval: 2022-05-05 12:32:35.825458: total loss: 1.0700776139905235, mse:4.6145384506190865, ic :0.16840783850147079, sharpe5:13.044972048997879, irr5:433.4839782714844, ndcg5:0.8591439280958456, pnl5:3.3941500186920166 
train 39, step: 0, loss: 0.9686708596139144, grad_norm: 0.003164763207954076, ic: 0.07955697768101276
train 39, step: 500, loss: 0.8943747447876633, grad_norm: 0.06951319643087985, ic: 0.2133078049762842
train 39, step: 1000, loss: 0.9415491457123477, grad_norm: 0.007866702777832562, ic: 0.15373996912856927
train 39, step: 1500, loss: 2.102144800539818, grad_norm: 0.02451930620937721, ic: -0.003351796984311775
train 39, step: 2000, loss: 0.6210235547492101, grad_norm: 0.019088083586864105, ic: 0.13194521177372925
Epoch 39: 2022-05-05 12:32:55.145907: train loss: 1.629260156475128
Eval step 0: eval loss: 0.8352027627766069
Eval: 2022-05-05 12:32:57.429396: total loss: 1.0700992186964076, mse:4.607420186028474, ic :0.16945249198567663, sharpe5:12.327771173715592, irr5:414.0209655761719, ndcg5:0.8382520984662861, pnl5:4.011877536773682 

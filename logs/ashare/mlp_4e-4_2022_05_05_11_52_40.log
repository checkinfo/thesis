Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path='./data/ann_type_2431_1931_25.npz', batch_size=1, dataset_type='AdjTimeDataset', dout=0.3, epochs=40, glstm_layers=1, gnn_layers=2, gpu=0, graph_attn=False, hidden_dim=128, inner_prod=False, input_dim=9, input_graph=True, label_cnt=3, lr=0.0004, lstm_layers=3, market=None, mask_adj=False, mask_type='soft', model_type='MlpModel', normalize_adj=False, num_days=1, num_heads=1, print_inteval=500, rank_loss=False, relation_num=1, rsr_data_path=None, seed=10086, shuffle=True, side_info=False, sparse_adj_path='./data/icgraph_window_250_0.8/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=False)
65427
MlpModel(
  (fc1): Linear(in_features=9, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
  (fc4): Linear(in_features=128, out_features=1, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
  (relu): ReLU()
)
train 0, step: 0, loss: 2.081331058547431, grad_norm: 0.4922886230290927, ic: -0.12157467715456352
train 0, step: 500, loss: 1.3652685250722612, grad_norm: 0.94731823088557, ic: -0.04169796837218476
train 0, step: 1000, loss: 1.506396004884411, grad_norm: 0.03746904911421203, ic: 0.25998874962568597
train 0, step: 1500, loss: 1.1864243550634128, grad_norm: 0.12182122995455578, ic: 0.053215208605625466
train 0, step: 2000, loss: 1.5628535573075457, grad_norm: 0.06055290543091289, ic: 0.022971578926266625
Epoch 0: 2022-05-05 11:53:02.239351: train loss: 1.6466655593926114
Eval step 0: eval loss: 1.0088370806797986
len(ic 126
Eval: 2022-05-05 11:53:04.550791: total loss: 1.0916672706373085, mse:4.889297685455451, ic :0.023942528179570703, sharpe5:6.80071210026741, irr5:208.3561248779297, ndcg5:0.845058674731758, pnl5:2.6511170864105225 
train 1, step: 0, loss: 0.6423076214176594, grad_norm: 0.07810666713030222, ic: 0.06255616167574399
train 1, step: 500, loss: 1.2718756545325067, grad_norm: 0.42776221942326564, ic: 0.21814481581092646
train 1, step: 1000, loss: 0.8771761887365107, grad_norm: 0.07122043623861293, ic: 0.05537940594395462
train 1, step: 1500, loss: 1.8694417069597942, grad_norm: 0.6346912138385092, ic: 0.0810915888946281
train 1, step: 2000, loss: 1.3684984005611123, grad_norm: 0.2526992555537968, ic: 0.08776158854745202
Epoch 1: 2022-05-05 11:53:19.236114: train loss: 1.6457810866712062
Eval step 0: eval loss: 1.007581408492134
len(ic 126
Eval: 2022-05-05 11:53:21.535647: total loss: 1.0895149686386945, mse:4.8824907655804894, ic :0.03869769520321893, sharpe5:6.902514044344425, irr5:208.96875, ndcg5:0.8526385705512891, pnl5:2.802316904067993 
train 2, step: 0, loss: 1.3350183186668514, grad_norm: 0.6118527154830358, ic: 0.14979749466880493
train 2, step: 500, loss: 0.9428568306027125, grad_norm: 0.29183481686171214, ic: 0.06139584013238214
train 2, step: 1000, loss: 3.065485475890914, grad_norm: 1.3726940816535482, ic: 0.15776447967960422
train 2, step: 1500, loss: 2.266461002552538, grad_norm: 1.0184371895286313, ic: 0.09973330198541219
train 2, step: 2000, loss: 1.4566318016021056, grad_norm: 0.3253613073918056, ic: -0.06919593482798932
Epoch 2: 2022-05-05 11:53:36.485582: train loss: 1.64504808190525
Eval step 0: eval loss: 1.0039008503653237
len(ic 126
Eval: 2022-05-05 11:53:38.829727: total loss: 1.0905607872035694, mse:4.885004233452757, ic :0.036403178572917895, sharpe5:6.826466819643974, irr5:199.97299194335938, ndcg5:0.8525078120102075, pnl5:2.842684745788574 
train 3, step: 0, loss: 1.8306157200411246, grad_norm: 0.07513368423717408, ic: -0.10705596662449479
train 3, step: 500, loss: 0.7810762906290427, grad_norm: 0.023012102843460128, ic: 0.0830789764329627
train 3, step: 1000, loss: 1.3715520246206716, grad_norm: 0.5245806214807536, ic: 0.24624186112202784
train 3, step: 1500, loss: 2.5797703529824054, grad_norm: 0.7181289511630997, ic: -0.04798507350392866
train 3, step: 2000, loss: 1.3635448109019885, grad_norm: 0.18336607381278008, ic: 0.0857029422401819
Epoch 3: 2022-05-05 11:53:54.733902: train loss: 1.6450179655972132
Eval step 0: eval loss: 1.0040461905320233
len(ic 126
Eval: 2022-05-05 11:53:56.698112: total loss: 1.090848127877484, mse:4.8800397770391, ic :0.04875337513542536, sharpe5:6.805063358545303, irr5:206.7999725341797, ndcg5:0.8506979930862806, pnl5:2.538161277770996 
train 4, step: 0, loss: 1.1581561177107116, grad_norm: 0.16765197099844864, ic: 0.09097268283526981
train 4, step: 500, loss: 0.9920318358167132, grad_norm: 0.004718544737212844, ic: 0.15587276771690708
train 4, step: 1000, loss: 1.3414624153794814, grad_norm: 0.07966431203157621, ic: 0.06674490257775602
train 4, step: 1500, loss: 1.0610593355618991, grad_norm: 0.0884546008935513, ic: 0.1923238950601024
train 4, step: 2000, loss: 4.192667867328875, grad_norm: 1.0020691641214865, ic: 0.007318641422507181
Epoch 4: 2022-05-05 11:54:10.993633: train loss: 1.6447913184327951
Eval step 0: eval loss: 1.0042396131598867
len(ic 126
Eval: 2022-05-05 11:54:13.230331: total loss: 1.0910789255913058, mse:4.880149261161394, ic :0.04894148730957674, sharpe5:6.939361634552478, irr5:209.0807342529297, ndcg5:0.854648345623813, pnl5:2.607820510864258 
train 5, step: 0, loss: 0.9803778248167365, grad_norm: 0.1642385916280197, ic: -0.10578111762253715
train 5, step: 500, loss: 0.7884927421196188, grad_norm: 0.007413708832651295, ic: 0.13158636863150694
train 5, step: 1000, loss: 1.1218651354199651, grad_norm: 0.04322368672413247, ic: -0.11326353736063083
train 5, step: 1500, loss: 1.7759630652947154, grad_norm: 0.4402109529476981, ic: -0.005118851228665629
train 5, step: 2000, loss: 2.165284888641795, grad_norm: 0.9147509935768885, ic: 0.07658339571040992
Epoch 5: 2022-05-05 11:54:27.238587: train loss: 1.644756325137717
Eval step 0: eval loss: 1.0033106188701288
len(ic 126
Eval: 2022-05-05 11:54:29.544955: total loss: 1.0911367814029043, mse:4.88150358386411, ic :0.0466506454870009, sharpe5:6.677158594429493, irr5:203.01492309570312, ndcg5:0.8554288136253414, pnl5:2.8448359966278076 
train 6, step: 0, loss: 0.7807596299356178, grad_norm: 0.010571296073290142, ic: -0.07776266960007026
train 6, step: 500, loss: 1.4566359492073282, grad_norm: 0.3403098119270739, ic: 0.10872531622554571
train 6, step: 1000, loss: 1.2328812672201277, grad_norm: 0.20042616954896353, ic: 0.19029072600621322
train 6, step: 1500, loss: 1.0930718418337264, grad_norm: 0.36392208452915126, ic: 0.07597339502203622
train 6, step: 2000, loss: 2.2563292757774143, grad_norm: 0.9948285312879703, ic: 0.0758085668014869
Epoch 6: 2022-05-05 11:54:44.509161: train loss: 1.6445258663996718
Eval step 0: eval loss: 1.0040371268595312
len(ic 126
Eval: 2022-05-05 11:54:46.815896: total loss: 1.0900371457023255, mse:4.880055792478296, ic :0.04553663187096758, sharpe5:6.820599715411663, irr5:205.807861328125, ndcg5:0.852711360867282, pnl5:2.7346558570861816 
train 7, step: 0, loss: 1.4570720741737027, grad_norm: 0.5380339994015254, ic: 0.17177703353412166
train 7, step: 500, loss: 1.3227511069307945, grad_norm: 0.026720253429084698, ic: 0.12513494484493234
train 7, step: 1000, loss: 0.6554295482821192, grad_norm: 0.0062555491339733125, ic: 0.26512641204116083
train 7, step: 1500, loss: 0.9988947156202034, grad_norm: 0.1369372934347746, ic: 0.07263211824493329
train 7, step: 2000, loss: 1.5987772591455363, grad_norm: 0.6336067389613728, ic: 0.11325133935605446
Epoch 7: 2022-05-05 11:55:01.157792: train loss: 1.6445679234129256
Eval step 0: eval loss: 0.9989199445020405
len(ic 126
Eval: 2022-05-05 11:55:03.571489: total loss: 1.0940560059968123, mse:4.925327323597838, ic :0.03744455681679579, sharpe5:6.84859296798706, irr5:204.1433563232422, ndcg5:0.8562982113429755, pnl5:2.496799945831299 
train 8, step: 0, loss: 1.2019769990990323, grad_norm: 0.11311643476099562, ic: 0.0569739439236715
train 8, step: 500, loss: 5.603133724774686, grad_norm: 1.3354655094572405, ic: 0.1481478921817736
train 8, step: 1000, loss: 1.9419112164301848, grad_norm: 1.0968474520430216, ic: 0.004978629686410977
train 8, step: 1500, loss: 1.1382593954763105, grad_norm: 0.34843119088624647, ic: 0.20509468568392164
train 8, step: 2000, loss: 1.116572062174479, grad_norm: 0.5056750145069074, ic: 0.002615322709712065
Epoch 8: 2022-05-05 11:55:18.592472: train loss: 1.6445053777958607
Eval step 0: eval loss: 0.9998503529818324
len(ic 126
Eval: 2022-05-05 11:55:20.905902: total loss: 1.092504034957727, mse:4.883887282361026, ic :0.048609214799135825, sharpe5:6.86813910394907, irr5:207.8128662109375, ndcg5:0.8508853516959953, pnl5:2.4952125549316406 
train 9, step: 0, loss: 1.1552544700530114, grad_norm: 0.019949904541136213, ic: 0.05414579934971213
train 9, step: 500, loss: 3.339730040667808, grad_norm: 1.848053516266454, ic: 0.16989861163344483
train 9, step: 1000, loss: 0.8827647042629209, grad_norm: 0.15139447678318785, ic: 0.15014259255564816
train 9, step: 1500, loss: 2.1498457601043355, grad_norm: 0.9385887922305451, ic: -0.008846441040563487
train 9, step: 2000, loss: 0.6054680777008753, grad_norm: 0.006667561485126068, ic: 0.07515249704333227
Epoch 9: 2022-05-05 11:55:36.142565: train loss: 1.6445783592420882
Eval step 0: eval loss: 1.0025549914222947
len(ic 126
Eval: 2022-05-05 11:55:38.615263: total loss: 1.0901567963298877, mse:4.877679976084, ic :0.05528989514498195, sharpe5:7.197614488899707, irr5:216.57855224609375, ndcg5:0.8337813179123664, pnl5:2.62776780128479 
train 10, step: 0, loss: 1.339141177672851, grad_norm: 0.027550156843861452, ic: 0.15574617802249305
train 10, step: 500, loss: 0.8997155826502085, grad_norm: 0.004960143762807306, ic: 0.11974032456349573
train 10, step: 1000, loss: 1.5552730512658723, grad_norm: 0.5432367945425298, ic: 0.013114943584528232
train 10, step: 1500, loss: 3.1381747578186467, grad_norm: 0.7755557548978228, ic: 0.027327244829356123
train 10, step: 2000, loss: 1.3828076765530015, grad_norm: 0.1350208713250036, ic: 0.03564829919491255
Epoch 10: 2022-05-05 11:55:53.563846: train loss: 1.6444436985623003
Eval step 0: eval loss: 1.003833676338698
len(ic 126
Eval: 2022-05-05 11:55:55.843978: total loss: 1.0908116058588027, mse:4.877205226300929, ic :0.05647542205007972, sharpe5:6.78406333476305, irr5:206.5018310546875, ndcg5:0.8553560037247524, pnl5:2.7658329010009766 
train 11, step: 0, loss: 4.664242312719899, grad_norm: 2.4154841768921465, ic: 0.1363322018792813
train 11, step: 500, loss: 1.0012556741131433, grad_norm: 0.07210624012180336, ic: 0.02878812973877127
train 11, step: 1000, loss: 1.0245349223517353, grad_norm: 0.2963615864689812, ic: 0.03881379478270759
train 11, step: 1500, loss: 0.6971281644601606, grad_norm: 0.0073738178062039954, ic: 0.07265692698646434
train 11, step: 2000, loss: 1.0964996065190902, grad_norm: 0.0380666720255257, ic: -0.0444508179762218
Epoch 11: 2022-05-05 11:56:10.839177: train loss: 1.6440679007957522
Eval step 0: eval loss: 0.9998669375740521
len(ic 126
Eval: 2022-05-05 11:56:13.121216: total loss: 1.0895840902540357, mse:4.877777156701305, ic :0.0539279887912351, sharpe5:6.749670894742012, irr5:206.09036254882812, ndcg5:0.8623344758563535, pnl5:2.8486297130584717 
train 12, step: 0, loss: 1.408700689163498, grad_norm: 0.2619861101989911, ic: 0.06345022076706279
train 12, step: 500, loss: 0.7957647575011099, grad_norm: 0.3325718209228322, ic: 0.06308085052083108
train 12, step: 1000, loss: 1.2722908764841687, grad_norm: 0.19791327159797592, ic: 0.014978376411281458
train 12, step: 1500, loss: 1.0917037357248662, grad_norm: 0.19054298293055208, ic: -0.08034338292307439
train 12, step: 2000, loss: 1.1142719594897446, grad_norm: 0.05836012687260605, ic: 0.10738433343400265
Epoch 12: 2022-05-05 11:56:28.139342: train loss: 1.6442326769076057
Eval step 0: eval loss: 1.0025579483650935
len(ic 126
Eval: 2022-05-05 11:56:30.349799: total loss: 1.0913211608242768, mse:4.873229812931147, ic :0.06559210048387869, sharpe5:6.748546189069748, irr5:206.2896270751953, ndcg5:0.8632321595631969, pnl5:2.7073073387145996 
train 13, step: 0, loss: 1.1047672907914552, grad_norm: 0.027743037366745892, ic: 0.03977064754858514
train 13, step: 500, loss: 1.143264700620229, grad_norm: 0.006300312211534844, ic: -0.17125493480366877
train 13, step: 1000, loss: 1.40095708503393, grad_norm: 0.4334910016194915, ic: 0.004335845958489588
train 13, step: 1500, loss: 0.7745791454111967, grad_norm: 0.0003168389739294366, ic: -0.043838601876223605
train 13, step: 2000, loss: 1.0367077242943548, grad_norm: 0.022374393589112133, ic: 0.025977111006011248
Epoch 13: 2022-05-05 11:56:45.919431: train loss: 1.6442393415143504
Eval step 0: eval loss: 0.9916562787980515
len(ic 126
Eval: 2022-05-05 11:56:48.272292: total loss: 1.0893451844756026, mse:4.873199198279935, ic :0.07089952078513921, sharpe5:7.814823448956012, irr5:227.2910614013672, ndcg5:0.8591321958739915, pnl5:2.435359001159668 
train 14, step: 0, loss: 1.779220322431144, grad_norm: 0.5241106837412237, ic: 0.17262764968162392
train 14, step: 500, loss: 1.2758995353255878, grad_norm: 0.14388978780972603, ic: 0.15459737648928565
train 14, step: 1000, loss: 1.070429828738378, grad_norm: 0.14089147237750915, ic: 0.12368822451776927
train 14, step: 1500, loss: 0.9898723928262124, grad_norm: 0.07768785509239581, ic: 0.15418525841751313
train 14, step: 2000, loss: 2.309409808956974, grad_norm: 0.4845051360212874, ic: -0.05949651114478188
Epoch 14: 2022-05-05 11:57:02.995436: train loss: 1.6435444750630386
Eval step 0: eval loss: 1.000476903448361
len(ic 126
Eval: 2022-05-05 11:57:05.258534: total loss: 1.091183247549477, mse:4.797805974698692, ic :0.11170341962438514, sharpe5:7.9767995113134385, irr5:238.72799682617188, ndcg5:0.8432563325884405, pnl5:2.59352970123291 
train 15, step: 0, loss: 0.980913775688348, grad_norm: 0.1650662741506367, ic: 0.11513083194414966
train 15, step: 500, loss: 1.227196258474981, grad_norm: 0.00398977218040642, ic: 0.0560129407935011
train 15, step: 1000, loss: 1.7622552083333334, grad_norm: 0.03825213325007432, ic: -0.09575465470086306
train 15, step: 1500, loss: 5.4157471269576565, grad_norm: 1.0247355133984346, ic: 0.006150229471248457
train 15, step: 2000, loss: 0.934331241240137, grad_norm: 0.019291993687548647, ic: -0.11021058619064249
Epoch 15: 2022-05-05 11:57:19.963152: train loss: 1.6391086121813128
Eval step 0: eval loss: 0.9998765797788309
len(ic 126
Eval: 2022-05-05 11:57:22.201022: total loss: 1.0868533811615606, mse:4.71886319000211, ic :0.12124384489301618, sharpe5:10.617141142487526, irr5:315.8858642578125, ndcg5:0.8506039722203811, pnl5:3.026251792907715 
train 16, step: 0, loss: 6.262651838159522, grad_norm: 1.208445488118052, ic: 0.01495186061462501
train 16, step: 500, loss: 1.343693130735367, grad_norm: 0.9264682940038718, ic: 0.019248076847903257
train 16, step: 1000, loss: 0.8168072819613719, grad_norm: 0.07409902972262519, ic: -0.039746151498323175
train 16, step: 1500, loss: 1.2243999781823833, grad_norm: 0.352992772088072, ic: 0.09574658650027705
train 16, step: 2000, loss: 0.9653354489215612, grad_norm: 0.20318412961218707, ic: 0.514904898502334
Epoch 16: 2022-05-05 11:57:37.271096: train loss: 1.63682161374586
Eval step 0: eval loss: 0.9993012615603606
len(ic 126
Eval: 2022-05-05 11:57:39.516113: total loss: 1.0844527028588988, mse:4.711214889676959, ic :0.1361533209637398, sharpe5:13.56573442339897, irr5:396.57354736328125, ndcg5:0.8584108996949374, pnl5:7.962116718292236 
train 17, step: 0, loss: 1.1949982438350748, grad_norm: 0.007251741571619297, ic: 0.07445989414943165
train 17, step: 500, loss: 1.0500171655153956, grad_norm: 0.016541041787068427, ic: -0.0328794275441144
train 17, step: 1000, loss: 3.373266440413573, grad_norm: 0.7834188185991435, ic: -0.019926891600143038
train 17, step: 1500, loss: 0.886730799011428, grad_norm: 0.005434642640687411, ic: 0.06570101481013796
train 17, step: 2000, loss: 1.0251420603502517, grad_norm: 0.4803591024564419, ic: 0.5358846786901312
Epoch 17: 2022-05-05 11:57:53.978853: train loss: 1.636434645434548
Eval step 0: eval loss: 1.001546481083794
len(ic 126
Eval: 2022-05-05 11:57:56.324311: total loss: 1.0875806578146114, mse:4.72394974765972, ic :0.1333278639229994, sharpe5:14.265951202511786, irr5:424.162353515625, ndcg5:0.841531797662835, pnl5:6.612006187438965 
train 18, step: 0, loss: 0.8559724980578388, grad_norm: 0.13424217485756676, ic: 0.01905571423408807
train 18, step: 500, loss: 2.4937135293626747, grad_norm: 1.0545683323087038, ic: 0.039626979963003094
train 18, step: 1000, loss: 1.358667606930081, grad_norm: 0.3075921770365016, ic: 0.5075300821772544
train 18, step: 1500, loss: 1.7654545157989794, grad_norm: 0.7042044750556039, ic: 0.359300737315489
train 18, step: 2000, loss: 1.2694477541883304, grad_norm: 0.29731062751750903, ic: 0.13825098856584847
Epoch 18: 2022-05-05 11:58:10.492219: train loss: 1.6350596030264635
Eval step 0: eval loss: 0.9989080524494799
len(ic 126
Eval: 2022-05-05 11:58:12.765725: total loss: 1.085627626561693, mse:4.70857964416197, ic :0.145512900979578, sharpe5:14.37098490178585, irr5:434.1382751464844, ndcg5:0.8464791409388893, pnl5:7.177569389343262 
train 19, step: 0, loss: 2.369626291124713, grad_norm: 1.905228016601073, ic: 0.19375103108834887
train 19, step: 500, loss: 1.023994694199673, grad_norm: 0.046013676180690466, ic: 0.023307579566979784
train 19, step: 1000, loss: 1.0190878700251318, grad_norm: 0.055703608775247215, ic: 0.49700212099718705
train 19, step: 1500, loss: 1.5687664644217785, grad_norm: 0.030955225595197023, ic: 0.18386356363126696
train 19, step: 2000, loss: 1.9375122731172663, grad_norm: 0.7862030892882363, ic: 0.6186473395585093
Epoch 19: 2022-05-05 11:58:27.584076: train loss: 1.6332650271481464
Eval step 0: eval loss: 1.0057502252419035
len(ic 126
Eval: 2022-05-05 11:58:29.933130: total loss: 1.0849358493019288, mse:4.69934386199426, ic :0.14874965497789422, sharpe5:13.394858618974686, irr5:412.5704040527344, ndcg5:0.8463829503999136, pnl5:3.1479995250701904 
train 20, step: 0, loss: 1.224837838265664, grad_norm: 0.3053707438972245, ic: 0.4570272995229946
train 20, step: 500, loss: 1.2636037457736342, grad_norm: 0.6631547015677189, ic: 0.01719901327982709
train 20, step: 1000, loss: 1.5409201141890552, grad_norm: 0.21860831316404652, ic: 0.1657622287830377
train 20, step: 1500, loss: 0.8309652146501316, grad_norm: 0.18466791695755863, ic: 0.557426857965045
train 20, step: 2000, loss: 1.3648840519528092, grad_norm: 0.09404809681691842, ic: -0.05741043380905232
Epoch 20: 2022-05-05 11:58:44.774800: train loss: 1.631983575185455
Eval step 0: eval loss: 1.0064174658125986
len(ic 126
Eval: 2022-05-05 11:58:46.987570: total loss: 1.0846950711521344, mse:4.691599671331637, ic :0.15695074826600344, sharpe5:14.729300615787505, irr5:463.6231689453125, ndcg5:0.860567751425752, pnl5:5.351953983306885 
train 21, step: 0, loss: 1.4170143950437317, grad_norm: 0.2292256435757094, ic: 0.3079019041705939
train 21, step: 500, loss: 1.1076443474440512, grad_norm: 0.08095054155431075, ic: 0.018257204921381106
train 21, step: 1000, loss: 0.9300499996790262, grad_norm: 0.23669100043320646, ic: 0.07943165911527712
train 21, step: 1500, loss: 0.7507530279372047, grad_norm: 0.12255405934014205, ic: 0.6209106737735594
train 21, step: 2000, loss: 1.171696286194475, grad_norm: 0.04570583342329631, ic: 0.10681365527328526
Epoch 21: 2022-05-05 11:59:01.837084: train loss: 1.6310780663841178
Eval step 0: eval loss: 1.0056498177494733
len(ic 126
Eval: 2022-05-05 11:59:04.133186: total loss: 1.0827292403616013, mse:4.683873969016428, ic :0.16402096997742874, sharpe5:14.31985194146633, irr5:450.19537353515625, ndcg5:0.8460601304999565, pnl5:5.361927509307861 
train 22, step: 0, loss: 1.067992509880761, grad_norm: 0.20277407188423335, ic: 0.10553014601661445
train 22, step: 500, loss: 1.0295433224655512, grad_norm: 0.006026487858754307, ic: 0.032110143896601155
train 22, step: 1000, loss: 0.9185504285816756, grad_norm: 0.02417917584235655, ic: 0.09104537637705785
train 22, step: 1500, loss: 1.0182525539695289, grad_norm: 0.013091349443034937, ic: 0.20992374562992194
train 22, step: 2000, loss: 1.0585320761037427, grad_norm: 0.11987034341233063, ic: 0.12451418538011388
Epoch 22: 2022-05-05 11:59:19.767092: train loss: 1.6302463563096135
Eval step 0: eval loss: 1.0047325226681805
len(ic 126
Eval: 2022-05-05 11:59:21.971786: total loss: 1.0834153115437914, mse:4.686889464266536, ic :0.1624317423123842, sharpe5:15.110565433502197, irr5:461.4447021484375, ndcg5:0.8510992647168456, pnl5:5.766331195831299 
train 23, step: 0, loss: 1.2748949658739699, grad_norm: 0.90174672628084, ic: -0.02638230491104432
train 23, step: 500, loss: 0.9072109683529362, grad_norm: 0.13982140843694008, ic: 0.5714078550134227
train 23, step: 1000, loss: 2.346152134818245, grad_norm: 0.9503181204252937, ic: -0.02338753783032129
train 23, step: 1500, loss: 0.7726182265319027, grad_norm: 0.22543716039291434, ic: 0.7016202866975366
train 23, step: 2000, loss: 1.426724042481576, grad_norm: 0.5089620027598025, ic: 0.42104433472321534
Epoch 23: 2022-05-05 11:59:37.804501: train loss: 1.6292607792969342
Eval step 0: eval loss: 1.012246500008228
len(ic 126
Eval: 2022-05-05 11:59:40.153307: total loss: 1.0919802936890042, mse:4.709624852797815, ic :0.15530067383296492, sharpe5:13.675491129755974, irr5:428.6729431152344, ndcg5:0.844340941296587, pnl5:3.4713284969329834 
train 24, step: 0, loss: 1.1800716260184914, grad_norm: 0.4215219660045962, ic: 0.2652502292501439
train 24, step: 500, loss: 1.233982717599876, grad_norm: 0.199765198995001, ic: 0.04823682769247725
train 24, step: 1000, loss: 1.0945348972227515, grad_norm: 0.7418519264140856, ic: 0.16672621525117276
train 24, step: 1500, loss: 1.2008906326894684, grad_norm: 0.22270220438812965, ic: 0.16132045383277238
train 24, step: 2000, loss: 1.356688810311348, grad_norm: 0.4917510722349568, ic: 0.4466500744377027
Epoch 24: 2022-05-05 11:59:54.806436: train loss: 1.6294971020431304
Eval step 0: eval loss: 1.0100012804847947
len(ic 126
Eval: 2022-05-05 11:59:57.139251: total loss: 1.0837497207332376, mse:4.683955227216505, ic :0.16661679708299448, sharpe5:14.480244051218031, irr5:470.0685119628906, ndcg5:0.8367036726126141, pnl5:4.5859808921813965 
train 25, step: 0, loss: 1.353145099148375, grad_norm: 0.3916070741103234, ic: 0.1386918494524242
train 25, step: 500, loss: 1.524423376306311, grad_norm: 0.30891712230755547, ic: 0.11416481777359404
train 25, step: 1000, loss: 1.374609150373778, grad_norm: 0.24077038982307325, ic: 0.2574562686653304
train 25, step: 1500, loss: 2.9005317549473495, grad_norm: 0.9773873043352841, ic: 0.17989352464827227
train 25, step: 2000, loss: 1.206970504567593, grad_norm: 0.15149187923191137, ic: 0.11350387934451935
Epoch 25: 2022-05-05 12:00:11.753214: train loss: 1.629125601932267
Eval step 0: eval loss: 1.0033067619882174
len(ic 126
Eval: 2022-05-05 12:00:14.013724: total loss: 1.082357929360045, mse:4.679002280099726, ic :0.17023200879794512, sharpe5:14.256876937150954, irr5:470.8079833984375, ndcg5:0.8614232255921921, pnl5:4.03326940536499 
train 26, step: 0, loss: 1.612801846590909, grad_norm: 0.1863426546648118, ic: 0.14725365516778266
train 26, step: 500, loss: 1.016856736596138, grad_norm: 0.15247000755703824, ic: -0.05171442776449063
train 26, step: 1000, loss: 1.8700529506661117, grad_norm: 0.38178820627027077, ic: 0.17263570725456476
train 26, step: 1500, loss: 0.926698841957915, grad_norm: 0.005051780586579589, ic: -0.1035899862649062
train 26, step: 2000, loss: 0.9816325510580709, grad_norm: 0.12700069169179035, ic: 0.13049032841656205
Epoch 26: 2022-05-05 12:00:28.846372: train loss: 1.6288375018769876
Eval step 0: eval loss: 1.0021333056666337
len(ic 126
Eval: 2022-05-05 12:00:31.060636: total loss: 1.0846785750836387, mse:4.689795521996212, ic :0.16525687761607535, sharpe5:14.723325203061103, irr5:485.4093322753906, ndcg5:0.8486676745483329, pnl5:4.4907145500183105 
train 27, step: 0, loss: 1.6181484360292735, grad_norm: 0.37343237090507275, ic: 0.6480243324396822
train 27, step: 500, loss: 1.5114091128620724, grad_norm: 0.4556008975219828, ic: 0.10673327992331634
train 27, step: 1000, loss: 2.634155747681138, grad_norm: 1.6129005500913098, ic: 0.40085507983072904
train 27, step: 1500, loss: 0.834932982466603, grad_norm: 0.2863062570892139, ic: 0.5547524763485563
train 27, step: 2000, loss: 1.373604723202285, grad_norm: 0.5960398323099988, ic: 0.010082377280600633
Epoch 27: 2022-05-05 12:00:45.415868: train loss: 1.627988692472151
Eval step 0: eval loss: 1.0063430922730712
len(ic 126
Eval: 2022-05-05 12:00:47.458775: total loss: 1.0824377666623908, mse:4.6771262746148174, ic :0.1708828929284401, sharpe5:15.288909321427344, irr5:498.0772399902344, ndcg5:0.8443671013885535, pnl5:4.6601033210754395 
train 28, step: 0, loss: 1.179113092929056, grad_norm: 0.11707737562940414, ic: 0.08864435149928188
train 28, step: 500, loss: 2.957686246717978, grad_norm: 0.3609696394538457, ic: 0.0658202798103039
train 28, step: 1000, loss: 2.6917986877344986, grad_norm: 1.0763595378449384, ic: -0.09486186681500987
train 28, step: 1500, loss: 1.0252082351863485, grad_norm: 0.006738156830288497, ic: 0.2023876011078835
train 28, step: 2000, loss: 1.7174430669740188, grad_norm: 1.0334344534149174, ic: 0.12342023431524796
Epoch 28: 2022-05-05 12:01:02.277215: train loss: 1.627931459564831
Eval step 0: eval loss: 1.0029274376522181
len(ic 126
Eval: 2022-05-05 12:01:04.704173: total loss: 1.0822761367033655, mse:4.679107640832698, ic :0.1702496283917739, sharpe5:15.184340071678161, irr5:505.7037048339844, ndcg5:0.8606131168317086, pnl5:6.055483341217041 
train 29, step: 0, loss: 1.5142875017769144, grad_norm: 0.13099428143606556, ic: 0.08066770648324052
train 29, step: 500, loss: 2.5175986376390034, grad_norm: 1.8007835905748264, ic: -0.028935129143642664
train 29, step: 1000, loss: 1.6477924280925604, grad_norm: 2.335410908742153, ic: 0.48636256919907517
train 29, step: 1500, loss: 3.980142704978529, grad_norm: 1.3861314455007558, ic: 0.1262855600879761
train 29, step: 2000, loss: 0.9598904397809003, grad_norm: 0.23938697274045778, ic: 0.4601791746859324
Epoch 29: 2022-05-05 12:01:18.762091: train loss: 1.6278535117214348
Eval step 0: eval loss: 1.0046556421554107
len(ic 126
Eval: 2022-05-05 12:01:21.014205: total loss: 1.0828702791458558, mse:4.679473603836487, ic :0.16906926332345362, sharpe5:15.21164800107479, irr5:510.088134765625, ndcg5:0.8496982828346255, pnl5:6.392088890075684 
train 30, step: 0, loss: 1.2576001475563021, grad_norm: 0.061025959047116045, ic: 0.9729324403385284
train 30, step: 500, loss: 1.9569095659859572, grad_norm: 2.508950014956823, ic: 0.18028310102429126
train 30, step: 1000, loss: 3.426587414284534, grad_norm: 0.5431963905790287, ic: 0.3867554978516435
train 30, step: 1500, loss: 1.0946704818382988, grad_norm: 0.24297931357253638, ic: 0.17494744626299738
train 30, step: 2000, loss: 1.1065334823056445, grad_norm: 0.11521641281684022, ic: 0.4344433561682823
Epoch 30: 2022-05-05 12:01:35.886855: train loss: 1.6277542157366696
Eval step 0: eval loss: 1.005414933641061
len(ic 126
Eval: 2022-05-05 12:01:38.240998: total loss: 1.0827377702923515, mse:4.6747640552053165, ic :0.1715536113059459, sharpe5:14.416973918080329, irr5:489.9692077636719, ndcg5:0.8518491025732668, pnl5:3.501467227935791 
train 31, step: 0, loss: 1.182184928857186, grad_norm: 0.23754063648512458, ic: 0.1439690301912983
train 31, step: 500, loss: 0.8464582976458497, grad_norm: 0.09149304394014345, ic: 0.07667937784808529
train 31, step: 1000, loss: 5.0409863661235415, grad_norm: 2.0023110627462675, ic: -0.16193858861246146
train 31, step: 1500, loss: 1.634702797466673, grad_norm: 0.2648354700282171, ic: 0.28070813015512175
train 31, step: 2000, loss: 1.0294923745809388, grad_norm: 0.36225506843144095, ic: 0.223486118225303
Epoch 31: 2022-05-05 12:01:53.136693: train loss: 1.6276330063097173
Eval step 0: eval loss: 1.0055796224986835
len(ic 126
Eval: 2022-05-05 12:01:55.400586: total loss: 1.0836132810785852, mse:4.677224224478752, ic :0.1714649764317204, sharpe5:14.75250890314579, irr5:489.83380126953125, ndcg5:0.8425418991958821, pnl5:3.6474356651306152 
train 32, step: 0, loss: 0.8592752336642343, grad_norm: 0.4856615123955713, ic: 0.10832623146814074
train 32, step: 500, loss: 1.1570940715510671, grad_norm: 0.9167696387995696, ic: 0.12408464827443795
train 32, step: 1000, loss: 1.3745821063300854, grad_norm: 0.03270100495864613, ic: 0.08830500545352478
train 32, step: 1500, loss: 2.137886921318692, grad_norm: 0.5518077943015995, ic: 0.4328350965764799
train 32, step: 2000, loss: 1.063865156570372, grad_norm: 0.3586117670581259, ic: 0.4709100011503751
Epoch 32: 2022-05-05 12:02:09.867020: train loss: 1.6268363985122039
Eval step 0: eval loss: 1.0066045888666733
len(ic 126
Eval: 2022-05-05 12:02:12.117817: total loss: 1.084644796708972, mse:4.68837008857583, ic :0.16406010219450223, sharpe5:15.174842031598091, irr5:493.9287414550781, ndcg5:0.8492591216256836, pnl5:3.5375845432281494 
train 33, step: 0, loss: 1.1687119894122422, grad_norm: 0.015639655526458504, ic: 0.021708552181065356
train 33, step: 500, loss: 3.169807029448501, grad_norm: 1.7321096402950256, ic: 0.5340475704631883
train 33, step: 1000, loss: 5.297064551279133, grad_norm: 1.8788639531763098, ic: 0.025593435463579114
train 33, step: 1500, loss: 1.3510712414253048, grad_norm: 1.0415991582512372, ic: 0.020831419656022924
train 33, step: 2000, loss: 1.8958639928536822, grad_norm: 0.31933487183259895, ic: 0.05824884122666951
Epoch 33: 2022-05-05 12:02:26.722743: train loss: 1.6268025746755734
Eval step 0: eval loss: 1.00944460386223
len(ic 126
Eval: 2022-05-05 12:02:29.014187: total loss: 1.0882171773900193, mse:4.691263075009622, ic :0.1684809796924581, sharpe5:16.264182379245756, irr5:538.834716796875, ndcg5:0.845774060386677, pnl5:4.083821773529053 
train 34, step: 0, loss: 0.7155154269017433, grad_norm: 0.31729494312227613, ic: 0.16011523529550017
train 34, step: 500, loss: 1.7689916572199886, grad_norm: 0.16948836103661208, ic: 0.8964087154712534
train 34, step: 1000, loss: 0.7085030812230603, grad_norm: 0.1606594666569669, ic: 0.43072102308610716
train 34, step: 1500, loss: 1.6518773788060896, grad_norm: 0.8372753857726765, ic: 0.6299931482969756
train 34, step: 2000, loss: 3.0159067471298395, grad_norm: 0.7474924707287536, ic: 0.0659603401791769
Epoch 34: 2022-05-05 12:02:43.982538: train loss: 1.6272640284794686
Eval step 0: eval loss: 1.0040001650745458
len(ic 126
Eval: 2022-05-05 12:02:46.187962: total loss: 1.0833743661784105, mse:4.684453971181247, ic :0.16845145738625855, sharpe5:15.08417316019535, irr5:507.22320556640625, ndcg5:0.83999334230047, pnl5:3.499680995941162 
train 35, step: 0, loss: 1.0427404476117483, grad_norm: 0.4033326764533609, ic: -0.06221025869370453
train 35, step: 500, loss: 3.361161295572917, grad_norm: 1.3182883022296572, ic: -0.11572596387026768
train 35, step: 1000, loss: 1.338493897249706, grad_norm: 0.02874437291568101, ic: 0.4903319343635241
train 35, step: 1500, loss: 1.641436802569615, grad_norm: 0.39680111879430585, ic: 0.10267806436018886
train 35, step: 2000, loss: 1.2817450472719398, grad_norm: 0.24563980816813746, ic: -0.03694520732432145
Epoch 35: 2022-05-05 12:03:01.770095: train loss: 1.6272316913883682
Eval step 0: eval loss: 1.0034405957905477
len(ic 126
Eval: 2022-05-05 12:03:04.087215: total loss: 1.0851329886593832, mse:4.689470781031129, ic :0.16394957495590387, sharpe5:13.704926446080208, irr5:458.3493957519531, ndcg5:0.8424348305828312, pnl5:2.890209436416626 
train 36, step: 0, loss: 9.022169587361878, grad_norm: 3.0743611636718864, ic: -0.08955662978899692
train 36, step: 500, loss: 0.8644045556160106, grad_norm: 0.006798086293327535, ic: 0.0802407223802466
train 36, step: 1000, loss: 1.9292582132171352, grad_norm: 1.2131785584757113, ic: 0.06792492178999841
train 36, step: 1500, loss: 1.0501080244468786, grad_norm: 0.09420523996241108, ic: 0.1342923617116015
train 36, step: 2000, loss: 2.0974934416844464, grad_norm: 2.0252459741259474, ic: 0.40864693264731805
Epoch 36: 2022-05-05 12:03:19.255623: train loss: 1.6268866873472738
Eval step 0: eval loss: 1.0070999410668444
len(ic 126
Eval: 2022-05-05 12:03:21.489072: total loss: 1.0884487383463672, mse:4.70093185754701, ic :0.1542659033451803, sharpe5:11.880259394645691, irr5:385.97198486328125, ndcg5:0.8572250967819114, pnl5:2.171684741973877 
train 37, step: 0, loss: 1.1641307363258877, grad_norm: 0.44562260337338794, ic: 0.12484031352781051
train 37, step: 500, loss: 2.3341780666493777, grad_norm: 0.10452772389512861, ic: 0.18170323942633815
train 37, step: 1000, loss: 0.7539122471151941, grad_norm: 0.337203124649695, ic: 0.1782795463366169
train 37, step: 1500, loss: 3.179774250475888, grad_norm: 0.783184253291865, ic: 0.18466901201963426
train 37, step: 2000, loss: 3.1234044528279465, grad_norm: 2.071601313348489, ic: -0.0219356894871788
Epoch 37: 2022-05-05 12:03:36.203121: train loss: 1.6256235642788237
Eval step 0: eval loss: 1.0047811193802658
len(ic 126
Eval: 2022-05-05 12:03:38.415299: total loss: 1.081361392477057, mse:4.676328347852462, ic :0.1731035826179228, sharpe5:14.567035573124885, irr5:498.0376892089844, ndcg5:0.857294575101233, pnl5:3.1643433570861816 
train 38, step: 0, loss: 1.3298724550189394, grad_norm: 0.33758209528347777, ic: -0.14656543551446916
train 38, step: 500, loss: 1.7577867611434108, grad_norm: 0.8024474617647199, ic: 0.20356877137282672
train 38, step: 1000, loss: 1.8237492635506678, grad_norm: 1.0684896169098415, ic: 0.16664765840362133
train 38, step: 1500, loss: 1.0643102318158992, grad_norm: 0.17712389425441533, ic: 0.4861785975269469
train 38, step: 2000, loss: 0.7580728831768689, grad_norm: 0.008470630111361347, ic: 0.553382069287101
Epoch 38: 2022-05-05 12:03:53.394421: train loss: 1.6264601601553752
Eval step 0: eval loss: 1.0015284180201751
len(ic 126
Eval: 2022-05-05 12:03:55.705326: total loss: 1.081015305625273, mse:4.674574973853351, ic :0.17493898535553631, sharpe5:15.125817539691925, irr5:516.1104125976562, ndcg5:0.8423942268177994, pnl5:3.8755970001220703 
train 39, step: 0, loss: 0.8686206208962777, grad_norm: 0.023536941215062765, ic: 0.5397695658557341
train 39, step: 500, loss: 1.267755503834202, grad_norm: 0.42355702145691543, ic: 0.10619701312416242
train 39, step: 1000, loss: 1.3770084265506628, grad_norm: 0.2544342142048672, ic: 0.07250263070968371
train 39, step: 1500, loss: 2.480667469113372, grad_norm: 1.015965936906933, ic: -0.0629285311093214
train 39, step: 2000, loss: 2.7615221928106743, grad_norm: 0.8774161522910842, ic: 0.27432348707020715
Epoch 39: 2022-05-05 12:04:11.101696: train loss: 1.6246308229198596
Eval step 0: eval loss: 1.004882169686348
len(ic 126
Eval: 2022-05-05 12:04:13.381448: total loss: 1.081758514381829, mse:4.676511814174045, ic :0.1729145616352132, sharpe5:14.577490890026091, irr5:498.6178894042969, ndcg5:0.8435173410562212, pnl5:4.186623573303223 

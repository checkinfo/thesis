Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='RGCNSeqTimeDataset', dout=0.3, epochs=40, glstm_layers=1, gnn_layers=1, gpu=0, graph_attn=False, hidden_dim=128, inner_prod=False, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=3, market=None, mask_adj=True, mask_type='soft', model_type='RGCNModel', normalize_adj=True, num_days=1, num_heads=1, print_inteval=500, rank_loss=False, relation_num=2, rsr_data_path=None, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_750_0.6/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
load 2305 train graphs successful!
load 126 test graphs successful!
61265
RGCNModel(
  (fc1): Linear(in_features=9, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
  (fc4): Linear(in_features=128, out_features=1, bias=True)
  (gnns): ModuleList(
    (0): RGCN(
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
        (1): Linear(in_features=128, out_features=128, bias=False)
      )
      (lin_gate): Linear(in_features=256, out_features=256, bias=True)
    )
  )
  (dropout): Dropout(p=0.3, inplace=False)
  (relu): LeakyReLU(negative_slope=0.01)
)
train 0, step: 0, loss: 2.0732753829051385, grad_norm: 0.45669546890550583, ic: -0.004685670802866745
train 0, step: 500, loss: 1.3582947841641395, grad_norm: 0.8615317641616657, ic: -0.03147362310004938
train 0, step: 1000, loss: 1.5061313860154972, grad_norm: 0.03271727663607011, ic: 0.13316652180182909
train 0, step: 1500, loss: 1.1837050300850307, grad_norm: 0.09559008543225309, ic: 0.03443793278099115
train 0, step: 2000, loss: 1.561093214081555, grad_norm: 0.05082779110374743, ic: -0.05148943359627786
Epoch 0: 2022-05-13 01:49:55.142053: train loss: 1.6477422567151427
Eval step 0: eval loss: 1.013413078223736
Eval: 2022-05-13 01:50:02.607384: total loss: 1.0921734701900487, mse:4.8900265019142815, ic :0.009234798846000413, sharpe5:0.11936996462289243, sharpe5_real:67.35841650009155, irr5:1.5642117261886597, irr5_real:1417.9013671875, ndcg5:0.8351302268073751, pnl5:1.0870389938354492 
train 1, step: 0, loss: 0.6379532011428682, grad_norm: 0.050662540666808045, ic: 0.07272459688045674
train 1, step: 500, loss: 1.2643528506199733, grad_norm: 0.3080674828947234, ic: 0.19087633301277898
train 1, step: 1000, loss: 0.8764882174789015, grad_norm: 0.0625041814671357, ic: 0.08172635422454859
train 1, step: 1500, loss: 1.8588805780178164, grad_norm: 0.5639250083859078, ic: 0.08163242157323372
train 1, step: 2000, loss: 1.3713707916586908, grad_norm: 0.23978306985741363, ic: 0.16821295826242866
Epoch 1: 2022-05-13 01:50:54.846210: train loss: 1.6460008196126856
Eval step 0: eval loss: 1.0028915043690758
Eval: 2022-05-13 01:51:02.318718: total loss: 1.088689961352157, mse:4.877833662836637, ic :0.051837214548737874, sharpe5:3.167048675715923, sharpe5_real:67.35842406749725, irr5:54.018333435058594, irr5_real:1417.9013671875, ndcg5:0.843774444705887, pnl5:1.4099507331848145 
train 2, step: 0, loss: 1.327636538306079, grad_norm: 0.5090804785647407, ic: 0.06156813163497607
train 2, step: 500, loss: 0.95085095418603, grad_norm: 0.28145950972638856, ic: 0.08944460394631966
train 2, step: 1000, loss: 3.1030772876428183, grad_norm: 1.5872520008278526, ic: 0.18882543947728053
train 2, step: 1500, loss: 2.291089196322363, grad_norm: 0.8884321087864016, ic: 0.0878707077576659
train 2, step: 2000, loss: 1.4576269291700736, grad_norm: 0.2780812672251614, ic: -0.10812965848416652
Epoch 2: 2022-05-13 01:51:51.544848: train loss: 1.644415395311243
Eval step 0: eval loss: 0.99675597662421
Eval: 2022-05-13 01:51:58.994088: total loss: 1.0887438807719458, mse:4.877060707914205, ic :0.05319399028005589, sharpe5:7.354942745268344, sharpe5_real:67.35841650009155, irr5:213.10946655273438, irr5_real:1417.9013671875, ndcg5:0.8592322934248442, pnl5:3.056121826171875 
train 3, step: 0, loss: 1.8321011112040932, grad_norm: 0.06960354775232754, ic: -0.1480002189873175
train 3, step: 500, loss: 0.7820771724409767, grad_norm: 0.022344056282713194, ic: 0.06759893597604692
train 3, step: 1000, loss: 1.387769632324962, grad_norm: 0.47159979261538953, ic: 0.24020942976197535
train 3, step: 1500, loss: 2.626106279908643, grad_norm: 0.3918616108784713, ic: -0.06390564493153647
train 3, step: 2000, loss: 1.3561016660748106, grad_norm: 0.16259307920325586, ic: 0.08329264005126139
Epoch 3: 2022-05-13 01:52:50.453544: train loss: 1.644517441925959
Eval step 0: eval loss: 1.000852820872005
Eval: 2022-05-13 01:52:57.899401: total loss: 1.0911644745957176, mse:4.880906384525017, ic :0.05098252100373259, sharpe5:3.0139449235796927, sharpe5_real:67.35842406749725, irr5:32.388179779052734, irr5_real:1417.9013671875, ndcg5:0.8474194932259909, pnl5:1.2027924060821533 
train 4, step: 0, loss: 1.1560385600979832, grad_norm: 0.16752667362340112, ic: 0.0775863524909301
train 4, step: 500, loss: 0.9832656473455861, grad_norm: 0.011749097991966363, ic: 0.18849978843461046
train 4, step: 1000, loss: 1.3260182395952518, grad_norm: 0.059178119493184626, ic: 0.08008880564035549
train 4, step: 1500, loss: 1.0732779478415464, grad_norm: 0.09627932810588177, ic: 0.17764236392581484
train 4, step: 2000, loss: 4.184886101003147, grad_norm: 0.9229269232487926, ic: -0.03002119431247042
Epoch 4: 2022-05-13 01:53:46.825296: train loss: 1.6440016726242939
Eval step 0: eval loss: 1.0021813881277974
Eval: 2022-05-13 01:53:54.203980: total loss: 1.0920605058555202, mse:4.881359113621002, ic :0.05339594529480917, sharpe5:3.5389360588788983, sharpe5_real:67.35841650009155, irr5:39.213279724121094, irr5_real:1417.9013671875, ndcg5:0.8446108488335745, pnl5:1.079960823059082 
train 5, step: 0, loss: 0.9882928713168793, grad_norm: 0.1687781462512638, ic: -0.13023316644154476
train 5, step: 500, loss: 0.7879966024727241, grad_norm: 0.01638359956851379, ic: 0.14834023942503083
train 5, step: 1000, loss: 1.122565164982782, grad_norm: 0.04423459173625092, ic: -0.14469544747432092
train 5, step: 1500, loss: 1.7699353722052846, grad_norm: 0.41244512783576626, ic: -0.024248611512802686
train 5, step: 2000, loss: 2.175679600371747, grad_norm: 0.8806958898844508, ic: 0.043381412189257534
Epoch 5: 2022-05-13 01:54:42.829727: train loss: 1.6442883728246707
Eval step 0: eval loss: 1.004000615044102
Eval: 2022-05-13 01:54:50.306728: total loss: 1.0902911349970925, mse:4.8768433348755895, ic :0.058311218186876186, sharpe5:7.445867962539196, sharpe5_real:67.35841650009155, irr5:220.4466094970703, irr5_real:1417.9013671875, ndcg5:0.8455016450001724, pnl5:3.5226340293884277 
train 6, step: 0, loss: 0.7797359437831537, grad_norm: 0.011727434865196512, ic: -0.07923573750672316
train 6, step: 500, loss: 1.4168539660715918, grad_norm: 0.2883671284751026, ic: 0.05645231794408242
train 6, step: 1000, loss: 1.2252747667730086, grad_norm: 0.20297796985430874, ic: 0.2120902601415146
train 6, step: 1500, loss: 1.0595360406839622, grad_norm: 0.3164264509080188, ic: 0.07158172029932017
train 6, step: 2000, loss: 2.3131620965885844, grad_norm: 1.1517791144439566, ic: 0.11213342335587469
Epoch 6: 2022-05-13 01:55:38.531904: train loss: 1.641136543042906
Eval step 0: eval loss: 0.9980009781052527
Eval: 2022-05-13 01:55:46.011291: total loss: 1.0852559738573142, mse:4.715677648249475, ic :0.12519305399415961, sharpe5:8.67376987338066, sharpe5_real:67.35841650009155, irr5:247.00311279296875, irr5_real:1417.9013671875, ndcg5:0.8533766347540681, pnl5:3.3604001998901367 
train 7, step: 0, loss: 1.4538555113841125, grad_norm: 0.5400155921495853, ic: 0.2073810805132051
train 7, step: 500, loss: 1.3490069215166873, grad_norm: 0.08926666587682006, ic: 0.18164634651616807
train 7, step: 1000, loss: 0.6365168416284553, grad_norm: 0.019249518819810164, ic: 0.2947099140671422
train 7, step: 1500, loss: 1.0045292489087683, grad_norm: 0.13585373733717535, ic: 0.10708149071375873
train 7, step: 2000, loss: 1.5819930748151083, grad_norm: 0.6198066963201057, ic: 0.41991297571606945
Epoch 7: 2022-05-13 01:56:35.376863: train loss: 1.6376453457374052
Eval step 0: eval loss: 0.9909952092384149
Eval: 2022-05-13 01:56:42.744387: total loss: 1.0835882674669002, mse:4.7229865064080085, ic :0.12281491674026064, sharpe5:7.704773505628109, sharpe5_real:67.35842406749725, irr5:224.82923889160156, irr5_real:1417.9013671875, ndcg5:0.8383762467544784, pnl5:3.0080626010894775 
train 8, step: 0, loss: 1.2037419082617495, grad_norm: 0.08445356044123314, ic: 0.0683449351567479
train 8, step: 500, loss: 5.551337263053488, grad_norm: 1.2672054975029046, ic: 0.13959588861181504
train 8, step: 1000, loss: 1.895864530145326, grad_norm: 0.6591442528133669, ic: 0.17960071890267426
train 8, step: 1500, loss: 1.0768730977628722, grad_norm: 0.35563684850229915, ic: 0.6424790812659229
train 8, step: 2000, loss: 1.1303919278658352, grad_norm: 0.5231731716517841, ic: -0.008191269850581561
Epoch 8: 2022-05-13 01:57:31.586556: train loss: 1.6371979812442177
Eval step 0: eval loss: 0.9964697959863743
Eval: 2022-05-13 01:57:38.899811: total loss: 1.086472247054778, mse:4.713930088310012, ic :0.12718177332034075, sharpe5:10.423935815691948, sharpe5_real:67.35841650009155, irr5:303.74835205078125, irr5_real:1417.9013671875, ndcg5:0.8499837060010754, pnl5:3.8614072799682617 
train 9, step: 0, loss: 1.121632147073236, grad_norm: 0.02839891295353748, ic: 0.43923669657011827
train 9, step: 500, loss: 3.163363150447108, grad_norm: 1.2630046699976691, ic: 0.18625378527781286
train 9, step: 1000, loss: 0.8726260813307557, grad_norm: 0.1125357552338238, ic: 0.23994408258875272
train 9, step: 1500, loss: 2.1998850916734196, grad_norm: 1.1977897879538486, ic: 0.02232193881342589
train 9, step: 2000, loss: 0.6049579947506885, grad_norm: 0.006690939694755314, ic: 0.07394637103254718
Epoch 9: 2022-05-13 01:58:26.998758: train loss: 1.636384864121336
Eval step 0: eval loss: 0.9904454750032912
Eval: 2022-05-13 01:58:34.386121: total loss: 1.083880021246827, mse:4.73122098477912, ic :0.1343503954218025, sharpe5:11.184224553108216, sharpe5_real:67.35841650009155, irr5:350.5704040527344, irr5_real:1417.9013671875, ndcg5:0.8442451351770549, pnl5:4.90861177444458 
train 10, step: 0, loss: 1.295161844509143, grad_norm: 0.0491134915326185, ic: 0.39632064113314425
train 10, step: 500, loss: 0.8993279006645659, grad_norm: 0.007447528098763339, ic: 0.08950045840312193
train 10, step: 1000, loss: 1.5252864434260514, grad_norm: 0.5413077569212909, ic: 0.03493675488972791
train 10, step: 1500, loss: 3.039392502827498, grad_norm: 1.3552892590334815, ic: 0.0864196005859142
train 10, step: 2000, loss: 1.3727737936930091, grad_norm: 0.16472210900864237, ic: 0.13952663213050226
Epoch 10: 2022-05-13 01:59:22.766966: train loss: 1.6304092170639595
Eval step 0: eval loss: 1.0045718835365651
Eval: 2022-05-13 01:59:30.176391: total loss: 1.0838388415114792, mse:4.69200810516944, ic :0.15322243234688648, sharpe5:12.87508662879467, sharpe5_real:67.35842406749725, irr5:417.790771484375, irr5_real:1417.9012451171875, ndcg5:0.8472373112121204, pnl5:5.373793125152588 
train 11, step: 0, loss: 4.702686348587764, grad_norm: 1.4399409744683764, ic: 0.4243283510157267
train 11, step: 500, loss: 0.9922049386160714, grad_norm: 0.06165577585598065, ic: 0.030147005658391943
train 11, step: 1000, loss: 1.0360938915307971, grad_norm: 0.3327464762304829, ic: 0.0646492577187033
train 11, step: 1500, loss: 0.692273455853563, grad_norm: 0.0014760440454484242, ic: 0.08048771520057124
train 11, step: 2000, loss: 1.1410787723395612, grad_norm: 0.06935926852750343, ic: -0.1776797630140202
Epoch 11: 2022-05-13 02:00:19.006957: train loss: 1.626407747845603
Eval step 0: eval loss: 0.9963129494553054
Eval: 2022-05-13 02:00:26.610817: total loss: 1.0805887697882475, mse:4.684154317039883, ic :0.16127974212839213, sharpe5:14.470204941630362, sharpe5_real:67.35842406749725, irr5:477.5853576660156, irr5_real:1417.9012451171875, ndcg5:0.8527089183541736, pnl5:5.4919114112854 
train 12, step: 0, loss: 1.378866890446768, grad_norm: 0.32396884429254297, ic: 0.16674903103688232
train 12, step: 500, loss: 0.8279576470932813, grad_norm: 0.41625734522599694, ic: 0.013083941068063574
train 12, step: 1000, loss: 1.163072570961824, grad_norm: 0.2609466842545376, ic: 0.631578666530133
train 12, step: 1500, loss: 1.083046169455992, grad_norm: 0.26602364169652165, ic: 0.08037330301750745
train 12, step: 2000, loss: 1.106110687168316, grad_norm: 0.06845896820053171, ic: 0.15800531063702525
Epoch 12: 2022-05-13 02:01:15.284005: train loss: 1.6255079159892958
Eval step 0: eval loss: 1.002711002295616
Eval: 2022-05-13 02:01:22.757648: total loss: 1.0828370836740635, mse:4.691749621419382, ic :0.16384669831148146, sharpe5:13.701570301651953, sharpe5_real:67.35841650009155, irr5:457.4943542480469, irr5_real:1417.9012451171875, ndcg5:0.8560055687668815, pnl5:6.754086494445801 
train 13, step: 0, loss: 1.085172102885225, grad_norm: 0.08373147889337838, ic: 0.4348005570451634
train 13, step: 500, loss: 1.1482561650166985, grad_norm: 0.012026566708690503, ic: -0.14191458701697934
train 13, step: 1000, loss: 1.3689481553648701, grad_norm: 0.5862589540892759, ic: 0.13516307394830043
train 13, step: 1500, loss: 0.7746961991355118, grad_norm: 0.007699238399438305, ic: 0.0012777242314358514
train 13, step: 2000, loss: 1.0333441340245775, grad_norm: 0.03848594411630746, ic: 0.057655850634814404
Epoch 13: 2022-05-13 02:02:13.039998: train loss: 1.626092737373517
Eval step 0: eval loss: 0.9919154612625065
Eval: 2022-05-13 02:02:20.425287: total loss: 1.084129691936549, mse:4.731120917582069, ic :0.12311528634340234, sharpe5:7.758976467847824, sharpe5_real:67.35841650009155, irr5:225.02572631835938, irr5_real:1417.9013671875, ndcg5:0.8437011635690864, pnl5:2.7719128131866455 
train 14, step: 0, loss: 1.7484042927370234, grad_norm: 0.6097306024859198, ic: 0.14768619343993272
train 14, step: 500, loss: 1.2602752528586516, grad_norm: 0.20046594806053433, ic: 0.274144983849942
train 14, step: 1000, loss: 1.0625157379907024, grad_norm: 0.1915179924992812, ic: 0.15488671020852085
train 14, step: 1500, loss: 0.9648916759887413, grad_norm: 0.1468279814785159, ic: 0.2005606884778372
train 14, step: 2000, loss: 2.3131915990135603, grad_norm: 0.7998552534085367, ic: -0.04841024394601963
Epoch 14: 2022-05-13 02:03:09.374979: train loss: 1.62560192920605
Eval step 0: eval loss: 1.009201748864534
Eval: 2022-05-13 02:03:16.744277: total loss: 1.0836935294161114, mse:4.673592780161067, ic :0.1721519459323825, sharpe5:15.395198264122008, sharpe5_real:67.35842406749725, irr5:516.8643798828125, irr5_real:1417.9013671875, ndcg5:0.8402877400237699, pnl5:7.902799606323242 
train 15, step: 0, loss: 0.9700770884252794, grad_norm: 0.156243693100062, ic: 0.10903859927642623
train 15, step: 500, loss: 1.2295046836206074, grad_norm: 0.04427006815121966, ic: 0.09058097526313202
train 15, step: 1000, loss: 1.7570138020833335, grad_norm: 0.0483557919817403, ic: -0.03299011755161665
train 15, step: 1500, loss: 5.385070942394141, grad_norm: 0.8624460266365724, ic: 0.012144653214519758
train 15, step: 2000, loss: 0.9244705149501661, grad_norm: 0.01646488216821776, ic: 0.0568183625826756
Epoch 15: 2022-05-13 02:04:05.742437: train loss: 1.6252313472491395
Eval step 0: eval loss: 1.0099537122745523
Eval: 2022-05-13 02:04:13.163998: total loss: 1.0812996806064386, mse:4.665060833148028, ic :0.17457928623942337, sharpe5:15.181342433094978, sharpe5_real:67.35841650009155, irr5:509.4214782714844, irr5_real:1417.9012451171875, ndcg5:0.8349928126758565, pnl5:5.504445552825928 
train 16, step: 0, loss: 6.369252531172712, grad_norm: 1.6841180113419207, ic: 0.15994939754383203
train 16, step: 500, loss: 1.3735408722408233, grad_norm: 0.7926630821698478, ic: -0.010411750930969924
train 16, step: 1000, loss: 0.8383737912973408, grad_norm: 0.27133270135946047, ic: -0.012941467979053324
train 16, step: 1500, loss: 1.2353226093271805, grad_norm: 0.4690297242131107, ic: 0.12663326404731617
train 16, step: 2000, loss: 0.9460367491821363, grad_norm: 0.37725540017728726, ic: 0.5549928771807995
Epoch 16: 2022-05-13 02:05:01.927593: train loss: 1.6230216760758431
Eval step 0: eval loss: 0.9989721409705765
Eval: 2022-05-13 02:05:09.278114: total loss: 1.079063369916028, mse:4.698673531634722, ic :0.17007655446153175, sharpe5:15.13156782209873, sharpe5_real:67.35841650009155, irr5:534.8276977539062, irr5_real:1417.9012451171875, ndcg5:0.8422327113349019, pnl5:4.996695518493652 
train 17, step: 0, loss: 1.1827782004888805, grad_norm: 0.010506356999075902, ic: 0.11254538053297959
train 17, step: 500, loss: 1.0425579326187806, grad_norm: 0.023529753486295015, ic: -0.01948379593885641
train 17, step: 1000, loss: 3.3769615853186883, grad_norm: 0.7531131044067549, ic: -0.020561032930542164
train 17, step: 1500, loss: 0.8795678592422634, grad_norm: 0.02433845777276864, ic: 0.09416203302209701
train 17, step: 2000, loss: 1.0059306509542785, grad_norm: 0.7440948153682524, ic: 0.5836136706588841
Epoch 17: 2022-05-13 02:05:59.445470: train loss: 1.6251634142220008
Eval step 0: eval loss: 0.9998378823969851
Eval: 2022-05-13 02:06:06.835975: total loss: 1.0836917969121944, mse:4.699822927085852, ic :0.1655082821976586, sharpe5:15.442877649664878, sharpe5_real:67.35842406749725, irr5:527.0457153320312, irr5_real:1417.9013671875, ndcg5:0.8558959838772275, pnl5:6.831535339355469 
train 18, step: 0, loss: 0.849699434893745, grad_norm: 0.0040626031124636475, ic: 0.0394165349403533
train 18, step: 500, loss: 2.528228634385271, grad_norm: 1.0617211729426899, ic: 0.03694631077985498
train 18, step: 1000, loss: 1.371372140568795, grad_norm: 0.551812601800505, ic: 0.5331213103424072
train 18, step: 1500, loss: 1.6890914447739926, grad_norm: 2.0987223184244015, ic: 0.3205016313256182
train 18, step: 2000, loss: 1.2375154015922876, grad_norm: 0.4166183155744408, ic: 0.2461974731080661
Epoch 18: 2022-05-13 02:06:55.613503: train loss: 1.6243825392597522
Eval step 0: eval loss: 1.0036640378159556
Eval: 2022-05-13 02:07:03.054949: total loss: 1.079238692411844, mse:4.672698721530651, ic :0.17661926140971088, sharpe5:15.735752331018448, sharpe5_real:67.35842406749725, irr5:536.1249389648438, irr5_real:1417.9013671875, ndcg5:0.8566536009733404, pnl5:5.390361785888672 
train 19, step: 0, loss: 2.2294535210046864, grad_norm: 0.9608005374362134, ic: 0.2501911142380776
train 19, step: 500, loss: 1.023407834075218, grad_norm: 0.11477412123490643, ic: 0.08013144368625663
train 19, step: 1000, loss: 0.966750203423698, grad_norm: 0.03267503678948416, ic: 0.5654466278905095
train 19, step: 1500, loss: 1.5827069694613232, grad_norm: 0.14691513802782094, ic: 0.13144870816121526
train 19, step: 2000, loss: 1.583496660201566, grad_norm: 2.7709940455404585, ic: 0.6414793959128309
Epoch 19: 2022-05-13 02:07:52.907094: train loss: 1.623702567413565
Eval step 0: eval loss: 1.0011279451150277
Eval: 2022-05-13 02:08:00.273508: total loss: 1.0784463733534593, mse:4.676629307473441, ic :0.17142108346459578, sharpe5:15.326211901903152, sharpe5_real:67.35840893268585, irr5:521.69482421875, irr5_real:1417.9013671875, ndcg5:0.8512017710133493, pnl5:5.412625789642334 
train 20, step: 0, loss: 1.2563693458005376, grad_norm: 0.3754231686170782, ic: 0.46647832533273687
train 20, step: 500, loss: 1.2268567241061863, grad_norm: 0.5282402289994156, ic: 0.04362928268754485
train 20, step: 1000, loss: 1.5687756677226707, grad_norm: 0.4399695707684503, ic: 0.19239176695883542
train 20, step: 1500, loss: 0.8626966133732187, grad_norm: 0.5946421448087443, ic: 0.5939162092630521
train 20, step: 2000, loss: 1.3451178388048202, grad_norm: 0.14859289643655652, ic: -0.039656759809429655
Epoch 20: 2022-05-13 02:08:49.256329: train loss: 1.6229364813147489
Eval step 0: eval loss: 1.0013060687779751
Eval: 2022-05-13 02:08:56.628788: total loss: 1.0799437727584844, mse:4.67900659420367, ic :0.16578714134629702, sharpe5:14.791406314373015, sharpe5_real:67.35842406749725, irr5:504.703857421875, irr5_real:1417.9013671875, ndcg5:0.8430113634214836, pnl5:3.882819414138794 
train 21, step: 0, loss: 1.3854766934675655, grad_norm: 0.3468391421486118, ic: 0.3020113211723696
train 21, step: 500, loss: 1.1132128831532135, grad_norm: 0.127625302239098, ic: -0.00017105989144335088
train 21, step: 1000, loss: 0.8962849700852505, grad_norm: 0.27922229050199, ic: 0.09280775165497741
train 21, step: 1500, loss: 0.7418196405775237, grad_norm: 0.21880053665274957, ic: 0.63081677645103
train 21, step: 2000, loss: 1.1230596018607746, grad_norm: 0.2544204659667172, ic: 0.30223050286687686
Epoch 21: 2022-05-13 02:09:45.244158: train loss: 1.6228224282707444
Eval step 0: eval loss: 1.004412015781332
Eval: 2022-05-13 02:09:52.580858: total loss: 1.0809779208729884, mse:4.690711290680362, ic :0.15541756028494164, sharpe5:12.824285688400268, sharpe5_real:67.35842406749725, irr5:403.7856140136719, irr5_real:1417.9013671875, ndcg5:0.8369199561117956, pnl5:4.858111381530762 
train 22, step: 0, loss: 1.0380949652079985, grad_norm: 0.3944694226074587, ic: 0.1099718575310169
train 22, step: 500, loss: 1.0284135473056102, grad_norm: 0.0012777464336378767, ic: -0.024119433752269066
train 22, step: 1000, loss: 0.9065409326881695, grad_norm: 0.027732659865358833, ic: 0.140176603937836
train 22, step: 1500, loss: 0.996674724828417, grad_norm: 0.01477951305826387, ic: 0.276006735435106
train 22, step: 2000, loss: 1.0462650742641715, grad_norm: 0.1326166984722847, ic: 0.1545695956793177
Epoch 22: 2022-05-13 02:10:41.208544: train loss: 1.6221134597206974
Eval step 0: eval loss: 1.0074954643068719
Eval: 2022-05-13 02:10:48.538175: total loss: 1.0803390673525324, mse:4.6735291030996455, ic :0.17062528203892197, sharpe5:14.38839655637741, sharpe5_real:67.35842406749725, irr5:490.0520324707031, irr5_real:1417.9013671875, ndcg5:0.8422570825737801, pnl5:4.622806072235107 
train 23, step: 0, loss: 1.2841564998896193, grad_norm: 0.9540536390498673, ic: 0.002059433219207138
train 23, step: 500, loss: 0.8973990639487467, grad_norm: 0.13198248769784945, ic: 0.6000565014058037
train 23, step: 1000, loss: 2.281385612185519, grad_norm: 1.020999782855538, ic: 0.08009807629742868
train 23, step: 1500, loss: 0.7711297177147928, grad_norm: 0.4481171562814853, ic: 0.7325485970207777
train 23, step: 2000, loss: 1.471169677180768, grad_norm: 0.4404630695397092, ic: 0.4044045397893279
Epoch 23: 2022-05-13 02:11:37.962797: train loss: 1.6217588191461274
Eval step 0: eval loss: 1.0088963480985058
Eval: 2022-05-13 02:11:45.387110: total loss: 1.0855234297256104, mse:4.685473482357288, ic :0.16222682606866487, sharpe5:14.217302243113517, sharpe5_real:67.35842406749725, irr5:466.1092834472656, irr5_real:1417.9013671875, ndcg5:0.8331229866469093, pnl5:7.45496129989624 
train 24, step: 0, loss: 1.1948446114485753, grad_norm: 1.0960319668462881, ic: 0.34175960586631027
train 24, step: 500, loss: 1.236185569966867, grad_norm: 0.32733106156758507, ic: 0.00728137181799582
train 24, step: 1000, loss: 1.0275694684284489, grad_norm: 0.43142794372857135, ic: 0.13501730128658
train 24, step: 1500, loss: 1.202940644992618, grad_norm: 0.08170374645445917, ic: 0.07069694439258545
train 24, step: 2000, loss: 1.3531854759083728, grad_norm: 0.4303011507847396, ic: 0.4468842841634891
Epoch 24: 2022-05-13 02:12:33.497796: train loss: 1.6227352877858041
Eval step 0: eval loss: 1.0107402590590442
Eval: 2022-05-13 02:12:40.981714: total loss: 1.0801789882689357, mse:4.6814106274220535, ic :0.16797692934146652, sharpe5:14.871681354045867, sharpe5_real:67.35841650009155, irr5:517.741455078125, irr5_real:1417.9013671875, ndcg5:0.8427856522552459, pnl5:5.837943077087402 
train 25, step: 0, loss: 1.301561553502708, grad_norm: 0.6051560363833665, ic: 0.23591735066012198
train 25, step: 500, loss: 1.4609960580801036, grad_norm: 0.4464848288800832, ic: 0.13468294665193883
train 25, step: 1000, loss: 1.349589720205578, grad_norm: 0.2045995280146396, ic: 0.26589881499967083
train 25, step: 1500, loss: 2.8546521111338055, grad_norm: 1.151736096209245, ic: 0.28073994049897516
train 25, step: 2000, loss: 1.1992384512213212, grad_norm: 0.23779534982583103, ic: 0.14958745584365588
Epoch 25: 2022-05-13 02:13:29.914179: train loss: 1.6227707600130792
Eval step 0: eval loss: 1.0026706335982754
Eval: 2022-05-13 02:13:37.316171: total loss: 1.0780475932414224, mse:4.66890074797281, ic :0.17466671129215905, sharpe5:15.54512275993824, sharpe5_real:67.35842406749725, irr5:527.2305297851562, irr5_real:1417.9013671875, ndcg5:0.8467945400054813, pnl5:6.221334457397461 
train 26, step: 0, loss: 1.620730646306818, grad_norm: 0.34658322049576684, ic: 0.2186926133456657
train 26, step: 500, loss: 1.0157865902000307, grad_norm: 0.1981007243910322, ic: -0.05227507017546493
train 26, step: 1000, loss: 1.8173413431515404, grad_norm: 0.7068756898046465, ic: 0.18310973951960485
train 26, step: 1500, loss: 0.9180589478313294, grad_norm: 0.007512293474525192, ic: 0.056786510207298316
train 26, step: 2000, loss: 0.9845278281865157, grad_norm: 0.12970348531353473, ic: 0.16847471051642887
Epoch 26: 2022-05-13 02:14:28.528630: train loss: 1.6222831174990635
Eval step 0: eval loss: 1.0001340266464256
Eval: 2022-05-13 02:14:36.000879: total loss: 1.0803287706314084, mse:4.6818711808115685, ic :0.16648899329290962, sharpe5:14.51738960802555, sharpe5_real:67.35841650009155, irr5:478.48931884765625, irr5_real:1417.9013671875, ndcg5:0.8361641561863302, pnl5:6.6822710037231445 
train 27, step: 0, loss: 1.621809258518449, grad_norm: 0.35174094495079583, ic: 0.6483590911370596
train 27, step: 500, loss: 1.50995252736805, grad_norm: 0.3300710028290132, ic: 0.06431276785096332
train 27, step: 1000, loss: 2.560078511982809, grad_norm: 0.925177665953417, ic: 0.41431575672493137
train 27, step: 1500, loss: 0.8577252294684681, grad_norm: 0.8132154970249472, ic: 0.5507826230224013
train 27, step: 2000, loss: 1.3516656316004225, grad_norm: 1.2180140766239125, ic: 0.00866714207701819
Epoch 27: 2022-05-13 02:15:25.974569: train loss: 1.6212799154179756
Eval step 0: eval loss: 1.0017774440289295
Eval: 2022-05-13 02:15:33.302071: total loss: 1.0777623752705103, mse:4.670820155044622, ic :0.1743596269081277, sharpe5:15.444795987010002, sharpe5_real:67.35842406749725, irr5:516.9732055664062, irr5_real:1417.9013671875, ndcg5:0.8495067776139495, pnl5:3.9277796745300293 
train 28, step: 0, loss: 1.1530106260374566, grad_norm: 0.13609727380145803, ic: 0.16251740690186312
train 28, step: 500, loss: 2.946202386544996, grad_norm: 0.7107150241630491, ic: 0.10815549969050796
train 28, step: 1000, loss: 2.7939460838763823, grad_norm: 3.0817913487672506, ic: -0.04950257388730527
train 28, step: 1500, loss: 1.0271350513417783, grad_norm: 0.06487790612317912, ic: 0.1903100036924087
train 28, step: 2000, loss: 1.7572424245435139, grad_norm: 0.37736953841329435, ic: 0.09244531010094234
Epoch 28: 2022-05-13 02:16:25.083180: train loss: 1.6208441897917387
Eval step 0: eval loss: 1.0029863836640995
Eval: 2022-05-13 02:16:32.450953: total loss: 1.0784022081951339, mse:4.676564398419197, ic :0.1711634272853301, sharpe5:15.301997149586677, sharpe5_real:67.35841650009155, irr5:513.8275756835938, irr5_real:1417.9013671875, ndcg5:0.8555986967230669, pnl5:4.479024410247803 
train 29, step: 0, loss: 1.5223174886869788, grad_norm: 0.1443464525601042, ic: 0.07670390112914768
train 29, step: 500, loss: 2.576098673033361, grad_norm: 3.33170877064381, ic: -0.1911226336246839
train 29, step: 1000, loss: 1.7196836478157438, grad_norm: 0.9750598499148648, ic: 0.4887981243816837
train 29, step: 1500, loss: 3.931244076674047, grad_norm: 1.3323273406332117, ic: 0.16796299435840562
train 29, step: 2000, loss: 0.9352097346164091, grad_norm: 0.24375408413146102, ic: 0.4694929890909496
Epoch 29: 2022-05-13 02:17:24.557841: train loss: 1.6225020012170563
Eval step 0: eval loss: 1.0060846169036335
Eval: 2022-05-13 02:17:31.971182: total loss: 1.078755495526615, mse:4.675038805658475, ic :0.17349740542839268, sharpe5:15.332045425772666, sharpe5_real:67.35842406749725, irr5:527.698486328125, irr5_real:1417.9013671875, ndcg5:0.8599780509510476, pnl5:4.180174827575684 
train 30, step: 0, loss: 1.2409429557390235, grad_norm: 0.048710520438229175, ic: 0.9856558319231793
train 30, step: 500, loss: 1.9500050605097903, grad_norm: 0.3102496089354504, ic: 0.16787680390066145
train 30, step: 1000, loss: 3.4140818634335757, grad_norm: 0.8002741416275293, ic: 0.40622251245181656
train 30, step: 1500, loss: 1.0707662754794547, grad_norm: 0.2580188281109972, ic: 0.1582277019646403
train 30, step: 2000, loss: 1.0877139292909495, grad_norm: 0.11579740675931716, ic: 0.4344604481944123
Epoch 30: 2022-05-13 02:18:22.769806: train loss: 1.6224734079145096
Eval step 0: eval loss: 1.0011407371067007
Eval: 2022-05-13 02:18:30.146027: total loss: 1.0790163069389531, mse:4.679088696994734, ic :0.1685128265718742, sharpe5:14.867714141607284, sharpe5_real:67.35842406749725, irr5:510.364013671875, irr5_real:1417.9013671875, ndcg5:0.852577350450912, pnl5:4.28320837020874 
train 31, step: 0, loss: 1.1603517394134963, grad_norm: 0.3118676908133111, ic: 0.19883533002051812
train 31, step: 500, loss: 0.8276783010412588, grad_norm: 0.10621902318661947, ic: 0.26458837964548654
train 31, step: 1000, loss: 5.198853584022374, grad_norm: 1.9636085726359316, ic: -0.009257376179509103
train 31, step: 1500, loss: 1.690822123744204, grad_norm: 0.46197177079147544, ic: 0.2744584467624901
train 31, step: 2000, loss: 0.892282724197797, grad_norm: 0.8697098457326474, ic: 0.14418106413320747
Epoch 31: 2022-05-13 02:19:21.765901: train loss: 1.622285186145221
Eval step 0: eval loss: 1.0076361762152777
Eval: 2022-05-13 02:19:29.274288: total loss: 1.0799369400841772, mse:4.6681933427868, ic :0.17182136914972163, sharpe5:15.674427021145819, sharpe5_real:67.35842406749725, irr5:523.4421997070312, irr5_real:1417.9013671875, ndcg5:0.8433845959307259, pnl5:6.605398654937744 
train 32, step: 0, loss: 0.8895124850443044, grad_norm: 0.5849561082111545, ic: 0.11221076752561122
train 32, step: 500, loss: 1.102778551055164, grad_norm: 0.356369140055069, ic: 0.11531785350353405
train 32, step: 1000, loss: 1.3795594206737185, grad_norm: 0.05458826291387876, ic: 0.08622671164602358
train 32, step: 1500, loss: 2.034967475631289, grad_norm: 0.718232497555346, ic: 0.45042369885551053
train 32, step: 2000, loss: 1.0935038570500146, grad_norm: 0.4785282827877167, ic: 0.4644013436220472
Epoch 32: 2022-05-13 02:20:17.189020: train loss: 1.6193835900786593
Eval step 0: eval loss: 1.0078726030764547
Eval: 2022-05-13 02:20:24.570369: total loss: 1.0777299002593903, mse:4.659221286860467, ic :0.1818513981823868, sharpe5:16.835559346675872, sharpe5_real:67.35841650009155, irr5:580.5478515625, irr5_real:1417.9013671875, ndcg5:0.8276389726276489, pnl5:6.988759517669678 
train 33, step: 0, loss: 1.164898061497326, grad_norm: 0.01938520342269697, ic: 0.024423402261290108
train 33, step: 500, loss: 3.1503271972280937, grad_norm: 0.3037425986201893, ic: 0.5231323360249129
train 33, step: 1000, loss: 5.188309415968682, grad_norm: 3.1246640081944306, ic: 0.05607343144762733
train 33, step: 1500, loss: 1.327744646770198, grad_norm: 1.289190887130151, ic: 0.10509448362915444
train 33, step: 2000, loss: 1.8590648089268411, grad_norm: 0.30453125795685937, ic: 0.08431111677848348
Epoch 33: 2022-05-13 02:21:15.017710: train loss: 1.6224489998792415
Eval step 0: eval loss: 1.0172445047146523
Eval: 2022-05-13 02:21:22.469303: total loss: 1.0846073822330815, mse:4.6793353956485655, ic :0.17011530787753737, sharpe5:15.233188621401785, sharpe5_real:67.35842406749725, irr5:511.59393310546875, irr5_real:1417.9013671875, ndcg5:0.8407125173746667, pnl5:6.767631530761719 
train 34, step: 0, loss: 0.7221994052409371, grad_norm: 0.3141679464086344, ic: 0.16789483960202684
train 34, step: 500, loss: 1.8246902317455123, grad_norm: 0.5618373470409762, ic: 0.8663247011741775
train 34, step: 1000, loss: 0.6810508570177801, grad_norm: 0.036407584614123696, ic: 0.49782674111467823
train 34, step: 1500, loss: 1.615682905148237, grad_norm: 1.1021230677659424, ic: 0.6533489709570008
train 34, step: 2000, loss: 2.9909865050967874, grad_norm: 0.5044196197670989, ic: 0.1006017654295934
Epoch 34: 2022-05-13 02:22:11.654713: train loss: 1.621297155085421
Eval step 0: eval loss: 1.0085330941038047
Eval: 2022-05-13 02:22:19.177062: total loss: 1.0796459391355893, mse:4.676413548808525, ic :0.1687588039135518, sharpe5:15.151157943606377, sharpe5_real:67.35842406749725, irr5:509.84552001953125, irr5_real:1417.9013671875, ndcg5:0.8539754174770605, pnl5:6.269507884979248 
train 35, step: 0, loss: 1.0519793546652492, grad_norm: 0.647598960130881, ic: 0.01348568543456418
train 35, step: 500, loss: 3.2766645951704545, grad_norm: 1.7172020844044062, ic: -0.07068322089068912
train 35, step: 1000, loss: 1.3550267712823276, grad_norm: 0.1063358376932599, ic: 0.5020939094172101
train 35, step: 1500, loss: 1.644631525612971, grad_norm: 0.3674805091639966, ic: 0.008619281760242566
train 35, step: 2000, loss: 1.2954411671838915, grad_norm: 0.09798822900389714, ic: -0.0969244905924184
Epoch 35: 2022-05-13 02:23:11.605736: train loss: 1.6214871984735255
Eval step 0: eval loss: 1.0000885797212349
Eval: 2022-05-13 02:23:19.123013: total loss: 1.0793892368647884, mse:4.672582190936422, ic :0.17378585946927552, sharpe5:16.201412640810013, sharpe5_real:67.35840893268585, irr5:541.374755859375, irr5_real:1417.9013671875, ndcg5:0.841699471212761, pnl5:6.689273834228516 
train 36, step: 0, loss: 8.968469440607734, grad_norm: 1.1660252860102684, ic: -0.06492509118369266
train 36, step: 500, loss: 0.8609083177103047, grad_norm: 0.020405027270491857, ic: 0.10753173655562123
train 36, step: 1000, loss: 1.9678270519685601, grad_norm: 2.164193724912828, ic: 0.038385790092908434
train 36, step: 1500, loss: 1.0436083814636443, grad_norm: 0.1629854881888115, ic: 0.06914322225972558
train 36, step: 2000, loss: 2.1311841294511478, grad_norm: 2.2831899252976235, ic: 0.3786438652410074
Epoch 36: 2022-05-13 02:24:08.377376: train loss: 1.6204311042254118
Eval step 0: eval loss: 1.0178083165687533
Eval: 2022-05-13 02:24:15.740417: total loss: 1.0831268532535197, mse:4.677529708604163, ic :0.16793473745037543, sharpe5:14.56302011847496, sharpe5_real:67.35841650009155, irr5:501.9211730957031, irr5_real:1417.9013671875, ndcg5:0.8501067427404926, pnl5:4.4822306632995605 
train 37, step: 0, loss: 1.199898876002291, grad_norm: 0.3477914038533803, ic: 0.1423420803947892
train 37, step: 500, loss: 2.3385191098288383, grad_norm: 0.03662776533450577, ic: 0.18013498803395153
train 37, step: 1000, loss: 0.7639950904906646, grad_norm: 0.3563403969827524, ic: 0.17749117011149285
train 37, step: 1500, loss: 3.1100535126506976, grad_norm: 1.0844445279174888, ic: 0.2332848286335958
train 37, step: 2000, loss: 3.1504021358127376, grad_norm: 1.6279054315207764, ic: -0.006536195699011281
Epoch 37: 2022-05-13 02:25:04.326780: train loss: 1.6206164458645054
Eval step 0: eval loss: 1.0053248754484267
Eval: 2022-05-13 02:25:11.870474: total loss: 1.0780723193251158, mse:4.669821448579588, ic :0.17396093386823736, sharpe5:16.300958079099654, sharpe5_real:67.35841650009155, irr5:548.6585083007812, irr5_real:1417.9013671875, ndcg5:0.8277007823790405, pnl5:4.439235687255859 
train 38, step: 0, loss: 1.3531042850378787, grad_norm: 0.49844044328590087, ic: -0.2788409356911181
train 38, step: 500, loss: 1.664541129178779, grad_norm: 0.9914105381657816, ic: 0.2004549448774351
train 38, step: 1000, loss: 1.825552030145326, grad_norm: 0.7582683819512552, ic: 0.11480818269437071
train 38, step: 1500, loss: 1.0774136273321615, grad_norm: 0.2140968384432533, ic: 0.48296012628377427
train 38, step: 2000, loss: 0.7448628324867111, grad_norm: 0.01773690829098997, ic: 0.5795260729487676
Epoch 38: 2022-05-13 02:26:00.494694: train loss: 1.6200955948571623
Eval step 0: eval loss: 0.9938338743253027
Eval: 2022-05-13 02:26:07.876931: total loss: 1.077747566864997, mse:4.691513934597954, ic :0.17388733599427647, sharpe5:15.721186966896056, sharpe5_real:67.35842406749725, irr5:547.6134033203125, irr5_real:1417.9013671875, ndcg5:0.839953045994875, pnl5:7.145259857177734 
train 39, step: 0, loss: 0.8638235275967614, grad_norm: 0.02251118807256308, ic: 0.5377286378520773
train 39, step: 500, loss: 1.2454168324290797, grad_norm: 0.3802806055705678, ic: 0.00035188329993322137
train 39, step: 1000, loss: 1.4173608953302557, grad_norm: 0.5077800097640837, ic: 0.09342667201046943
train 39, step: 1500, loss: 2.449744950101225, grad_norm: 0.5641732902772849, ic: -0.02923203779048432
train 39, step: 2000, loss: 2.9304026777416357, grad_norm: 2.3244049839550356, ic: 0.19201129923138607
Epoch 39: 2022-05-13 02:26:58.886736: train loss: 1.6185473495253948
Eval step 0: eval loss: 0.9987964599995063
Eval: 2022-05-13 02:27:06.287441: total loss: 1.0771048576992739, mse:4.669652116513723, ic :0.18023904509048214, sharpe5:16.44321584701538, sharpe5_real:67.35841650009155, irr5:588.2844848632812, irr5_real:1417.9012451171875, ndcg5:0.8568726991078318, pnl5:5.769766330718994 

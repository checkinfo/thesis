Namespace(adj_path='./data/graphs/concepts_graph_multihot_1931_1931_824.npy', ann_embed_dim=128, ann_embed_num=89, ann_path='./data/ann_type_2431_1931_25.npz', batch_size=1, dataset_type='TimeDataset', dout=0.3, epochs=40, glstm_layers=1, gnn_layers=1, gpu=0, graph_attn=False, hidden_dim=128, inner_prod=False, input_dim=9, input_graph=False, label_cnt=3, lr=0.001, lstm_layers=1, market=None, mask_adj=False, mask_type='soft', model_type='ReRaLSTM', normalize_adj=False, num_days=8, num_heads=1, print_inteval=500, rank_loss=False, relation_num=1, rsr_data_path=None, seed=10086, shuffle=True, side_info=False, sparse_adj_path='./data/icgraph_window_250_0.8/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=False)
relation encoding shape: torch.Size([1931, 1931, 824]) torch.float32
relation mask shape: torch.Size([1931, 1931]) torch.float32
14067
ReRaLSTM(
  (rnn1): LSTM(9, 128, batch_first=True, dropout=0.3, bidirectional=True)
  (fc0): Linear(in_features=256, out_features=128, bias=True)
  (fc1): Linear(in_features=824, out_features=1, bias=True)
  (fc2): Linear(in_features=128, out_features=1, bias=True)
  (fc3): Linear(in_features=128, out_features=1, bias=True)
  (predict): Linear(in_features=256, out_features=1, bias=True)
  (relu): LeakyReLU(negative_slope=0.01)
  (dropout): Dropout(p=0.3, inplace=False)
)
train 0, step: 0, loss: 4.838890857114934, grad_norm: 7.969782670579446e-05, ic: 0.007738848460723634
train 0, step: 500, loss: 0.8794439297110493, grad_norm: 4.8287911527186985e-06, ic: 0.03162095677307899
train 0, step: 1000, loss: 1.9048312339978055, grad_norm: 4.332143649978197e-05, ic: 0.01828804971192898
train 0, step: 1500, loss: 0.9318893975419961, grad_norm: 3.4996120005729395e-07, ic: 0.00827688558852761
train 0, step: 2000, loss: 0.9832015782487401, grad_norm: 1.1406394421918822e-05, ic: 0.12934617717225372
Epoch 0: 2022-05-05 14:19:43.745343: train loss: 1.646850301048791
Eval step 0: eval loss: 0.8334212308186248
Eval: 2022-05-05 14:19:47.647378: total loss: 1.078701802557209, mse:4.826308360895146, ic :0.020393790742892964, sharpe5:4.347122217714786, irr5:76.46409606933594, ndcg5:0.8488765877610773, pnl5:1.7565827369689941 
train 1, step: 0, loss: 2.730032447076613, grad_norm: 7.39353584024462e-05, ic: 0.13818803716916211
train 1, step: 500, loss: 1.7923292828626496, grad_norm: 6.752550763022719e-05, ic: 0.05145732850564509
train 1, step: 1000, loss: 0.8479500610752669, grad_norm: 0.00035390027121700516, ic: -0.00025618916138382165
train 1, step: 1500, loss: 1.683587716639727, grad_norm: 0.05248188402147685, ic: 0.002793845322377239
train 1, step: 2000, loss: 2.1972365234375, grad_norm: 0.0001003997836738006, ic: 0.02512571339339268
Epoch 1: 2022-05-05 14:21:27.016071: train loss: 1.6470439745608647
Eval step 0: eval loss: 0.8335391849562038
Eval: 2022-05-05 14:21:30.905044: total loss: 1.0786594264581149, mse:4.8248328346612634, ic :0.03630309997497577, sharpe5:6.988691187500954, irr5:197.32321166992188, ndcg5:0.8450304980592737, pnl5:2.871767044067383 
train 2, step: 0, loss: 2.1442428977272727, grad_norm: 3.3599896591510182e-06, ic: 0.15857016366729373
train 2, step: 500, loss: 3.309613486037754, grad_norm: 3.647405013219061e-05, ic: -0.08920181864052991
train 2, step: 1000, loss: 2.073528421336207, grad_norm: 0.00016089584969878733, ic: 0.35817667479750404
train 2, step: 1500, loss: 1.4738211362416507, grad_norm: 0.036416412620918485, ic: -0.04033541260379109
train 2, step: 2000, loss: 3.257248347355769, grad_norm: 0.012210537164125847, ic: 0.10669446519025261
Epoch 2: 2022-05-05 14:23:10.152092: train loss: 1.6468932418085152
Eval step 0: eval loss: 0.8357671932626448
Eval: 2022-05-05 14:23:14.089927: total loss: 1.0790993897052548, mse:4.822771321562214, ic :0.016276326475902925, sharpe5:7.090000777244567, irr5:191.041015625, ndcg5:0.8378843778865487, pnl5:2.944589138031006 
train 3, step: 0, loss: 1.508128890370935, grad_norm: 0.05426597167713077, ic: 0.07013382740360409
train 3, step: 500, loss: 1.4713809641432556, grad_norm: 0.07421226443838022, ic: 0.14957213859020185
train 3, step: 1000, loss: 3.681613638816926, grad_norm: 0.33854523406817605, ic: -0.009144594475170313
train 3, step: 1500, loss: 1.9492924716780893, grad_norm: 0.006414235618919891, ic: -0.007469523233071697
train 3, step: 2000, loss: 0.896689453125, grad_norm: 0.0011407413293022318, ic: 0.00961998865622273
Epoch 3: 2022-05-05 14:24:53.392912: train loss: 1.6464427783747007
Eval step 0: eval loss: 0.8348846596334957
Eval: 2022-05-05 14:24:57.297236: total loss: 1.0784848979776906, mse:4.820190285359138, ic :0.02223987691695362, sharpe5:7.205603304505348, irr5:182.5452117919922, ndcg5:0.8609085053835269, pnl5:3.181140661239624 
train 4, step: 0, loss: 1.4395454001913266, grad_norm: 0.017739797730852488, ic: 0.06304615030900348
train 4, step: 500, loss: 1.6472398652805118, grad_norm: 0.40043468909014057, ic: -0.003594717121534434
train 4, step: 1000, loss: 2.944739364996189, grad_norm: 0.03131223521332451, ic: 0.06571604505463385
train 4, step: 1500, loss: 2.1507557027953585, grad_norm: 0.022274447931315083, ic: 0.027489085567860394
train 4, step: 2000, loss: 1.104272536875486, grad_norm: 0.10593371691871191, ic: 0.10887113980604012
Epoch 4: 2022-05-05 14:26:36.399138: train loss: 1.6456323451372208
Eval step 0: eval loss: 0.857268161592795
Eval: 2022-05-05 14:26:40.350369: total loss: 1.0937326551216306, mse:4.859888081912384, ic :0.022808162339097965, sharpe5:5.8633252590894696, irr5:112.56627655029297, ndcg5:0.8546698183589541, pnl5:2.1655213832855225 
train 5, step: 0, loss: 1.3714337444945468, grad_norm: 0.1754263536902595, ic: 0.07276126722659561
train 5, step: 500, loss: 0.8922540239641158, grad_norm: 1.841866918766632e-05, ic: 0.009201091379781359
train 5, step: 1000, loss: 0.9973582300646552, grad_norm: 0.06306730854839396, ic: -0.030570907589247173
train 5, step: 1500, loss: 1.5056492570348392, grad_norm: 0.004597607730877454, ic: 0.05035254523256909
train 5, step: 2000, loss: 1.1238042207439094, grad_norm: 0.02213992326180774, ic: 0.0767175918455274
Epoch 5: 2022-05-05 14:28:19.731557: train loss: 1.645700673994792
Eval step 0: eval loss: 0.8413037701075144
Eval: 2022-05-05 14:28:23.660704: total loss: 1.0819758412211553, mse:4.825129355423541, ic :0.024519192611828656, sharpe5:5.091003873646259, irr5:97.16775512695312, ndcg5:0.8498991597038016, pnl5:1.9417363405227661 
train 6, step: 0, loss: 1.3221096787156101, grad_norm: 0.23319514528755378, ic: 0.10281169376119914
train 6, step: 500, loss: 1.0068493035449368, grad_norm: 0.036703469059797475, ic: 0.011029305519760689
train 6, step: 1000, loss: 1.1152105179123097, grad_norm: 0.04361280025009179, ic: 0.16286525351149697
train 6, step: 1500, loss: 1.6116860634039256, grad_norm: 0.20625925881057602, ic: 0.056872762817737794
train 6, step: 2000, loss: 0.7973030768364692, grad_norm: 0.0044857083209715095, ic: 0.03159720879813835
Epoch 6: 2022-05-05 14:30:03.040981: train loss: 1.6445366994312942
Eval step 0: eval loss: 0.8333972412366636
Eval: 2022-05-05 14:30:06.929444: total loss: 1.078716428102981, mse:4.826113974932006, ic :0.020266948104154626, sharpe5:2.863684387654066, irr5:39.38855743408203, ndcg5:0.8590784822964567, pnl5:1.2840988636016846 
train 7, step: 0, loss: 0.9884400367736816, grad_norm: 0.00024957796730677213, ic: -0.002102426700315952
train 7, step: 500, loss: 0.6531061329015483, grad_norm: 0.0025575196051100344, ic: 0.05385441184941116
train 7, step: 1000, loss: 1.036138297761567, grad_norm: 0.01230647181367021, ic: 0.006975223788042989
train 7, step: 1500, loss: 2.2723285311160235, grad_norm: 0.2310024671311905, ic: 0.08914435639372287
train 7, step: 2000, loss: 0.9074556168909027, grad_norm: 0.03755124926939002, ic: 0.011084142005826999
Epoch 7: 2022-05-05 14:31:46.051092: train loss: 1.643994270804352
Eval step 0: eval loss: 0.8363956817208904
Eval: 2022-05-05 14:31:50.022539: total loss: 1.078579353137932, mse:4.817912568711034, ic :0.026141883979942705, sharpe5:2.6039667673408986, irr5:34.455101013183594, ndcg5:0.8474151199242868, pnl5:1.5808868408203125 
train 8, step: 0, loss: 3.628255562160326, grad_norm: 0.5458930689595438, ic: 0.0027281366669341563
train 8, step: 500, loss: 2.762873965556136, grad_norm: 0.3005661026071026, ic: 0.05353967148273385
train 8, step: 1000, loss: 3.0362453294836955, grad_norm: 0.41406762052514345, ic: 0.0002854693363611542
train 8, step: 1500, loss: 0.756604741445746, grad_norm: 0.003354500403663051, ic: 0.10052842299581835
train 8, step: 2000, loss: 1.1218014851988989, grad_norm: 0.1956495081467733, ic: 0.2111681883705482
Epoch 8: 2022-05-05 14:33:29.280021: train loss: 1.6436927563539327
Eval step 0: eval loss: 0.8352904887546101
Eval: 2022-05-05 14:33:33.194893: total loss: 1.0783445758329222, mse:4.819171698696028, ic :0.02479276836959425, sharpe5:4.690811082422733, irr5:94.89854431152344, ndcg5:0.8488177749503905, pnl5:2.1866507530212402 
train 9, step: 0, loss: 5.322827498878588, grad_norm: 0.4526063901137843, ic: -0.011953746680236903
train 9, step: 500, loss: 1.3086867003268114, grad_norm: 0.16550544592568464, ic: 0.11258462331106506
train 9, step: 1000, loss: 0.9280479694234913, grad_norm: 0.014791976709484556, ic: 0.09258805988658378
train 9, step: 1500, loss: 1.1106366928617453, grad_norm: 0.012564972089987232, ic: 0.1429108293516282
train 9, step: 2000, loss: 1.115869899953516, grad_norm: 0.09214134877816374, ic: -0.0015558177824920773
Epoch 9: 2022-05-05 14:35:12.680376: train loss: 1.642690723807698
Eval step 0: eval loss: 0.8363187607020547
Eval: 2022-05-05 14:35:16.589536: total loss: 1.0787950429615623, mse:4.819717267185856, ic :0.023717977901682955, sharpe5:4.7688627237081525, irr5:92.42494201660156, ndcg5:0.8684911288173401, pnl5:1.8987959623336792 
train 10, step: 0, loss: 7.240390966654519, grad_norm: 0.32854927255744726, ic: -0.015771819348283245
train 10, step: 500, loss: 1.1329692559114992, grad_norm: 0.044776448892821154, ic: -0.05191109787784173
train 10, step: 1000, loss: 2.3666516637509587, grad_norm: 0.005224634429482001, ic: 0.012597238923049817
train 10, step: 1500, loss: 1.0922161944500812, grad_norm: 0.04312883684476844, ic: 0.006350098713262406
train 10, step: 2000, loss: 2.9340206250593655, grad_norm: 0.14420732659314664, ic: 0.20541070127373207
Epoch 10: 2022-05-05 14:36:56.013296: train loss: 1.6428501300968021
Eval step 0: eval loss: 0.8373150036633956
Eval: 2022-05-05 14:37:00.028974: total loss: 1.0793351552725585, mse:4.820879178434845, ic :0.021550782725681162, sharpe5:4.083688528239727, irr5:62.44954299926758, ndcg5:0.8550767125986338, pnl5:1.4774794578552246 
train 11, step: 0, loss: 1.288390310808198, grad_norm: 0.027156958135395735, ic: 0.1348503361019132
train 11, step: 500, loss: 0.7122738353085964, grad_norm: 0.00012991479393879623, ic: 0.09422065671522818
train 11, step: 1000, loss: 0.9308878748454246, grad_norm: 0.017658627054985464, ic: 0.01441748091243675
train 11, step: 1500, loss: 1.0651764451411732, grad_norm: 0.011077047356551104, ic: -0.03256110525732474
train 11, step: 2000, loss: 0.7941841499123716, grad_norm: 0.004560175243230127, ic: 0.08898679815994436
Epoch 11: 2022-05-05 14:38:39.288072: train loss: 1.6425227829916422
Eval step 0: eval loss: 0.8370443008471088
Eval: 2022-05-05 14:38:43.076678: total loss: 1.0791011039709826, mse:4.820661671151869, ic :0.020871620926760218, sharpe5:3.451631608754396, irr5:49.49109649658203, ndcg5:0.8617448781118692, pnl5:1.4026521444320679 
train 12, step: 0, loss: 1.0331037044525146, grad_norm: 0.021543901609651122, ic: 0.09696770817766989
train 12, step: 500, loss: 0.9343583640458641, grad_norm: 0.014709679768768743, ic: 0.08911324103415195
train 12, step: 1000, loss: 2.888926317737361, grad_norm: 0.35291832109304366, ic: 0.28641842197390555
train 12, step: 1500, loss: 0.9448387221534653, grad_norm: 9.728811806085228e-05, ic: -0.09347697878258245
train 12, step: 2000, loss: 0.8777993193565898, grad_norm: 0.00010388487944935133, ic: 0.004409944594885244
Epoch 12: 2022-05-05 14:40:22.369511: train loss: 1.6416865396314484
Eval step 0: eval loss: 0.8365117707167083
Eval: 2022-05-05 14:40:26.236777: total loss: 1.0790383085270674, mse:4.819553022468859, ic :0.02391852207256455, sharpe5:3.8412444573640823, irr5:53.857688903808594, ndcg5:0.8384781469670547, pnl5:1.6160231828689575 
train 13, step: 0, loss: 2.09982438374472, grad_norm: 0.25846213569801146, ic: 0.07965587957762554
train 13, step: 500, loss: 0.8972923205949437, grad_norm: 6.635950566950886e-05, ic: 0.18126612152456972
train 13, step: 1000, loss: 1.022150436503775, grad_norm: 0.05349947847303098, ic: 0.1032585450068233
train 13, step: 1500, loss: 2.409279363961261, grad_norm: 0.17802419919473392, ic: 0.016214555650011335
train 13, step: 2000, loss: 1.533595930162625, grad_norm: 0.057323689930941564, ic: 0.023809412555405085
Epoch 13: 2022-05-05 14:42:05.815167: train loss: 1.6421135570436536
Eval step 0: eval loss: 0.8360689603365384
Eval: 2022-05-05 14:42:09.792908: total loss: 1.0791440884561734, mse:4.822184326713577, ic :0.018071563055500527, sharpe5:3.9769043934345243, irr5:55.610145568847656, ndcg5:0.8636091375999958, pnl5:1.308851957321167 
train 14, step: 0, loss: 4.402546756167122, grad_norm: 0.6587540836812005, ic: 0.051484822919658384
train 14, step: 500, loss: 0.8286375459910168, grad_norm: 0.002267447915525823, ic: 0.05360870927125522
train 14, step: 1000, loss: 1.938266531119495, grad_norm: 0.03437854249496535, ic: 0.19997421792506834
train 14, step: 1500, loss: 1.115577110877404, grad_norm: 0.010737627778173756, ic: -0.00749058533987702
train 14, step: 2000, loss: 1.1498362813361005, grad_norm: 0.04473362465779978, ic: -0.03702478330890322
Epoch 14: 2022-05-05 14:43:49.059825: train loss: 1.641381720842916
Eval step 0: eval loss: 0.8421395465621706
Eval: 2022-05-05 14:43:53.085914: total loss: 1.0818635869177624, mse:4.826332707925274, ic :0.021475256155009285, sharpe5:5.303960602283477, irr5:104.93238067626953, ndcg5:0.8547052275580085, pnl5:1.6896083354949951 
train 15, step: 0, loss: 3.5349917163180935, grad_norm: 1.0592585968479904, ic: 0.012214306847801325
train 15, step: 500, loss: 1.256317214775561, grad_norm: 6.56164681303405e-05, ic: 0.024353172790327476
train 15, step: 1000, loss: 1.311827025374746, grad_norm: 0.006610409841437439, ic: -0.03180917550073941
train 15, step: 1500, loss: 0.8801930825541339, grad_norm: 0.08907320526278528, ic: 0.009893388712153894
train 15, step: 2000, loss: 1.4765120796535327, grad_norm: 0.37190401536535383, ic: 0.04527867348442992
Epoch 15: 2022-05-05 14:45:32.285395: train loss: 1.6385344417589465
Eval step 0: eval loss: 0.8509142024499472
Eval: 2022-05-05 14:45:36.209658: total loss: 1.0813942887257244, mse:4.657140051652777, ic :0.12689294382567, sharpe5:11.922072148919105, irr5:365.0211181640625, ndcg5:0.842312001486221, pnl5:3.757798910140991 
train 16, step: 0, loss: 0.7145479976989311, grad_norm: 0.08786376918870424, ic: 0.027062189393096528
train 16, step: 500, loss: 1.6426437806048175, grad_norm: 0.22742899827517477, ic: 0.12271094843963506
train 16, step: 1000, loss: 0.8907115589488637, grad_norm: 0.005251676814993311, ic: -0.1882220838299796
train 16, step: 1500, loss: 0.8743939771719859, grad_norm: 0.0005852870910418714, ic: 0.050095274907924106
train 16, step: 2000, loss: 3.346585539133464, grad_norm: 0.00954660400029182, ic: 0.009740189096703215
Epoch 16: 2022-05-05 14:47:15.647034: train loss: 1.6329953654363767
Eval step 0: eval loss: 0.8333900379305519
Eval: 2022-05-05 14:47:19.570067: total loss: 1.0737805468639168, mse:4.631316273844491, ic :0.134406762828744, sharpe5:12.350142316818237, irr5:379.3498840332031, ndcg5:0.8399010819598257, pnl5:2.5889182090759277 
train 17, step: 0, loss: 1.276153224469496, grad_norm: 0.039597069753778996, ic: -0.05924762422810015
train 17, step: 500, loss: 1.7953664888211383, grad_norm: 0.09761888261939758, ic: 0.12144255088950848
train 17, step: 1000, loss: 1.2888724690151114, grad_norm: 0.02353713860960034, ic: 0.011190574184295733
train 17, step: 1500, loss: 4.622162874265245, grad_norm: 0.03758622913526185, ic: 0.16456550200632664
train 17, step: 2000, loss: 1.2750463614695207, grad_norm: 0.009980265464270575, ic: -0.04608250074479404
Epoch 17: 2022-05-05 14:48:58.921040: train loss: 1.631196170017519
Eval step 0: eval loss: 0.843266349446786
Eval: 2022-05-05 14:49:02.897599: total loss: 1.0797019558081182, mse:4.646246381524372, ic :0.1327465934227677, sharpe5:12.676862220168113, irr5:398.53912353515625, ndcg5:0.8443270730369709, pnl5:4.719204425811768 
train 18, step: 0, loss: 1.3873411069040127, grad_norm: 0.12271497677486051, ic: 0.016415282598660506
train 18, step: 500, loss: 1.5380903710464588, grad_norm: 0.20814186193712675, ic: -0.0813503416583165
train 18, step: 1000, loss: 0.6642774106378424, grad_norm: 0.004127088553351122, ic: 0.5631585750806922
train 18, step: 1500, loss: 1.4407200168918919, grad_norm: 0.013189715741492114, ic: 0.0319640628259691
train 18, step: 2000, loss: 0.9087792657742835, grad_norm: 4.199155088178139e-05, ic: 0.016279338141973094
Epoch 18: 2022-05-05 14:50:42.293224: train loss: 1.6301907935978397
Eval step 0: eval loss: 0.8300947183301501
Eval: 2022-05-05 14:50:46.242360: total loss: 1.0718730943632142, mse:4.6203529094408005, ic :0.14203300614696415, sharpe5:12.618578061461449, irr5:400.31903076171875, ndcg5:0.8537532980356564, pnl5:4.6681952476501465 
train 19, step: 0, loss: 1.471212913876488, grad_norm: 0.02340248970606948, ic: 0.02948703920112198
train 19, step: 500, loss: 0.8711153666178385, grad_norm: 0.0003371403847016156, ic: 0.24702446998538238
train 19, step: 1000, loss: 0.9699396525899298, grad_norm: 0.0007488706775955197, ic: 0.0770740012892018
train 19, step: 1500, loss: 3.9717912064081164, grad_norm: 0.03538196867423396, ic: -0.04456375222272335
train 19, step: 2000, loss: 1.0087081204927884, grad_norm: 0.005259166358354554, ic: 0.08194973047794951
Epoch 19: 2022-05-05 14:52:25.294596: train loss: 1.6309051357662858
Eval step 0: eval loss: 0.8400521956706072
Eval: 2022-05-05 14:52:29.301192: total loss: 1.074700523823234, mse:4.6285411571346025, ic :0.13764073129220258, sharpe5:12.029797006845474, irr5:391.1266784667969, ndcg5:0.8465575626574554, pnl5:2.9645960330963135 
train 20, step: 0, loss: 2.268207679718379, grad_norm: 0.13834490986224796, ic: 0.03844982939104594
train 20, step: 500, loss: 3.241654829545454, grad_norm: 0.15022417401877053, ic: 0.06681172518905866
train 20, step: 1000, loss: 0.991158390045166, grad_norm: 0.0026753849958313708, ic: 0.02208757025958917
train 20, step: 1500, loss: 1.649335548669602, grad_norm: 0.25927574016385435, ic: 0.1993497448993989
train 20, step: 2000, loss: 1.07363428610573, grad_norm: 0.006444570321949324, ic: -0.03564780802447388
Epoch 20: 2022-05-05 14:54:08.720068: train loss: 1.6287354850418798
Eval step 0: eval loss: 0.8307363270959562
Eval: 2022-05-05 14:54:12.773070: total loss: 1.071118789647188, mse:4.620225561461487, ic :0.1434613765466812, sharpe5:12.452266348600388, irr5:411.0588684082031, ndcg5:0.8323497364900212, pnl5:3.9160642623901367 
train 21, step: 0, loss: 1.053117066826373, grad_norm: 0.013432345699856227, ic: -0.003873487519292139
train 21, step: 500, loss: 0.7833191188035813, grad_norm: 0.0007589155102487206, ic: 0.14137074938509311
train 21, step: 1000, loss: 0.9399586727744654, grad_norm: 0.08856752637127721, ic: 0.1804950086115152
train 21, step: 1500, loss: 1.0230565246186554, grad_norm: 0.024235647045189435, ic: 0.14254288568798537
train 21, step: 2000, loss: 0.9314655629239341, grad_norm: 0.02064517590423004, ic: 0.11511566658280319
Epoch 21: 2022-05-05 14:55:52.266357: train loss: 1.6285233596588669
Eval step 0: eval loss: 0.8367676167141398
Eval: 2022-05-05 14:55:56.245219: total loss: 1.072915498384843, mse:4.6216036138468635, ic :0.14245835854526678, sharpe5:12.584891754984856, irr5:415.25872802734375, ndcg5:0.8455880630714357, pnl5:4.547628879547119 
train 22, step: 0, loss: 1.061769819529043, grad_norm: 0.0027848880694889234, ic: 0.09062216509692562
train 22, step: 500, loss: 3.2804115853658535, grad_norm: 0.4967711525576485, ic: 0.03095441703977827
train 22, step: 1000, loss: 1.2238834447254336, grad_norm: 0.002194795170115933, ic: 0.4177503117088965
train 22, step: 1500, loss: 0.9794954025205761, grad_norm: 0.005345295440107007, ic: 0.031595958816530496
train 22, step: 2000, loss: 1.7772445159704506, grad_norm: 0.11544729420385758, ic: 0.16134188731913068
Epoch 22: 2022-05-05 14:57:35.572254: train loss: 1.6281287526416255
Eval step 0: eval loss: 0.8413472472051172
Eval: 2022-05-05 14:57:39.535070: total loss: 1.0749400028553766, mse:4.629758864498036, ic :0.13982687954293277, sharpe5:12.182495902776717, irr5:404.7693786621094, ndcg5:0.8398496237005112, pnl5:4.007055282592773 
train 23, step: 0, loss: 1.0103653525756484, grad_norm: 0.014688030560858767, ic: 0.16031851403132663
train 23, step: 500, loss: 1.4429815702573097, grad_norm: 0.04066660300439871, ic: -0.020662803480698114
train 23, step: 1000, loss: 1.6677048746744794, grad_norm: 0.004682119455606157, ic: 0.2545687618954668
train 23, step: 1500, loss: 1.1277758582957598, grad_norm: 0.06912483676769807, ic: -0.05211281674962365
train 23, step: 2000, loss: 1.654179973176482, grad_norm: 0.2709525378786799, ic: 0.3985631329007124
Epoch 23: 2022-05-05 14:59:18.979999: train loss: 1.6267591126212186
Eval step 0: eval loss: 0.8536792429531085
Eval: 2022-05-05 14:59:22.875980: total loss: 1.0765662167964196, mse:4.639439166614188, ic :0.13971399084621047, sharpe5:12.179603261947632, irr5:401.299072265625, ndcg5:0.8482258018139825, pnl5:4.711574554443359 
train 24, step: 0, loss: 2.240664823838081, grad_norm: 0.24319907202123617, ic: 0.09700045183805822
train 24, step: 500, loss: 1.2308175766050584, grad_norm: 0.048860555095890254, ic: 0.08670196726166986
train 24, step: 1000, loss: 0.9261462245737678, grad_norm: 0.005085400242412249, ic: 0.5047864552420486
train 24, step: 1500, loss: 2.6203295274500205, grad_norm: 0.1630801775190345, ic: -0.05259701139385302
train 24, step: 2000, loss: 0.9293454643566625, grad_norm: 0.00119348093586275, ic: 0.10505208854634965
Epoch 24: 2022-05-05 15:01:02.131518: train loss: 1.6259837523335086
Eval step 0: eval loss: 0.834663157970561
Eval: 2022-05-05 15:01:06.032525: total loss: 1.0714760238895733, mse:4.6203297101026894, ic :0.1412722947543771, sharpe5:12.136187163591384, irr5:403.4115295410156, ndcg5:0.8554422108502934, pnl5:4.2873053550720215 
train 25, step: 0, loss: 0.8833558778505068, grad_norm: 0.0015138992345496139, ic: 0.550274826385838
train 25, step: 500, loss: 0.877221605929003, grad_norm: 1.6179522718375646e-05, ic: 0.03230201944386557
train 25, step: 1000, loss: 2.1828841988766183, grad_norm: 0.18847849433946584, ic: 0.21442605089920502
train 25, step: 1500, loss: 1.1843826644959405, grad_norm: 0.04453403114776239, ic: 0.5021410544829104
train 25, step: 2000, loss: 1.0413249940362594, grad_norm: 0.056321901815723864, ic: 0.5503681484773925
Epoch 25: 2022-05-05 15:02:45.596245: train loss: 1.6256025309235194
Eval step 0: eval loss: 0.8526091661041227
Eval: 2022-05-05 15:02:49.511786: total loss: 1.0752648036140813, mse:4.63183322538395, ic :0.13560430412758093, sharpe5:12.501556645631789, irr5:408.0636901855469, ndcg5:0.8449901660560484, pnl5:4.945536136627197 
train 26, step: 0, loss: 6.708480493710064, grad_norm: 0.18765657596432062, ic: 0.0936436677646405
train 26, step: 500, loss: 4.089597891419078, grad_norm: 0.7597714831435036, ic: 0.322834996405888
train 26, step: 1000, loss: 1.2965926285628435, grad_norm: 0.2561662692667718, ic: 0.029738035436483724
train 26, step: 1500, loss: 0.863305258044107, grad_norm: 0.02800539188217629, ic: 0.15928626136161886
train 26, step: 2000, loss: 0.9604275130925453, grad_norm: 0.03284601163984761, ic: 0.07458942633120703
Epoch 26: 2022-05-05 15:04:29.059061: train loss: 1.6251024171056752
Eval step 0: eval loss: 0.8414632075704689
Eval: 2022-05-05 15:04:32.798354: total loss: 1.0740521048718208, mse:4.624153932077701, ic :0.14278034124922453, sharpe5:12.163906570672989, irr5:405.4883728027344, ndcg5:0.8533004350415592, pnl5:4.966349124908447 
train 27, step: 0, loss: 0.8292735140931372, grad_norm: 0.0004364123569145044, ic: 0.0076187704023966
train 27, step: 500, loss: 0.8987635160475829, grad_norm: 0.09028140877677156, ic: 0.27093779469342505
train 27, step: 1000, loss: 0.761961285678896, grad_norm: 0.04142112707814019, ic: 0.01801003131924674
train 27, step: 1500, loss: 0.6196105093639486, grad_norm: 0.0019383211189391977, ic: 0.5486212665418053
train 27, step: 2000, loss: 1.381494752366885, grad_norm: 0.001565923536988695, ic: 0.03221814454511429
Epoch 27: 2022-05-05 15:06:12.016469: train loss: 1.6253723586478015
Eval step 0: eval loss: 0.8527736844704952
Eval: 2022-05-05 15:06:16.073395: total loss: 1.079224149320443, mse:4.647503050321301, ic :0.129927347327637, sharpe5:11.38908936023712, irr5:361.29815673828125, ndcg5:0.8481340078566039, pnl5:4.3642497062683105 
train 28, step: 0, loss: 1.549216299167471, grad_norm: 0.06024167519065204, ic: 0.1248255784997532
train 28, step: 500, loss: 1.3738918826858582, grad_norm: 0.1364487271766242, ic: 0.14259967216000063
train 28, step: 1000, loss: 0.9121016008744072, grad_norm: 0.03982707790510497, ic: 0.5538552536651684
train 28, step: 1500, loss: 1.038637767397533, grad_norm: 0.003468940673558691, ic: 0.04375452337421574
train 28, step: 2000, loss: 1.0507354736328125, grad_norm: 0.02078080900662712, ic: -0.009277509250252296
Epoch 28: 2022-05-05 15:07:55.512830: train loss: 1.6243158466708818
Eval step 0: eval loss: 0.8363470594046364
Eval: 2022-05-05 15:07:59.490188: total loss: 1.0715329478102633, mse:4.619513738256133, ic :0.14233522870278054, sharpe5:12.064485994577407, irr5:402.1658020019531, ndcg5:0.85363248635352, pnl5:4.549508571624756 
train 29, step: 0, loss: 0.9085873827236542, grad_norm: 0.008686591827571111, ic: 0.11489678484104138
train 29, step: 500, loss: 1.1448448481310554, grad_norm: 0.0638359370502142, ic: 0.585495410346679
train 29, step: 1000, loss: 1.0562371278120204, grad_norm: 0.03743222070508733, ic: 0.04711236236320829
train 29, step: 1500, loss: 2.3323823093530445, grad_norm: 0.04982847409857266, ic: 0.049867407408763005
train 29, step: 2000, loss: 4.636997552565586, grad_norm: 0.1514606685745986, ic: 0.10949026527835118
Epoch 29: 2022-05-05 15:09:38.869741: train loss: 1.6241813981335347
Eval step 0: eval loss: 0.8460113235972075
Eval: 2022-05-05 15:09:42.908155: total loss: 1.0752115723832398, mse:4.629168286873793, ic :0.14233696712870939, sharpe5:11.82222212255001, irr5:393.72900390625, ndcg5:0.8661710065780752, pnl5:4.176754951477051 
train 30, step: 0, loss: 1.0100052445023149, grad_norm: 0.012023998389783273, ic: 0.5178697069046712
train 30, step: 500, loss: 1.4221363646559682, grad_norm: 0.18581993906517746, ic: 0.02799215413787888
train 30, step: 1000, loss: 0.9710818204012784, grad_norm: 0.012736158770747102, ic: 0.024323599757572367
train 30, step: 1500, loss: 1.52641870941015, grad_norm: 0.21092351549155333, ic: 0.12370208849044137
train 30, step: 2000, loss: 1.8284907439508415, grad_norm: 0.05807584969656377, ic: 0.16148769019832215
Epoch 30: 2022-05-05 15:11:22.082976: train loss: 1.6234252978076975
Eval step 0: eval loss: 0.8499121711176237
Eval: 2022-05-05 15:11:26.086236: total loss: 1.07596577421203, mse:4.6349088468004735, ic :0.13890735852627936, sharpe5:11.967050916552543, irr5:396.3326110839844, ndcg5:0.8465175462456836, pnl5:4.728905200958252 
train 31, step: 0, loss: 1.0770108490716348, grad_norm: 0.005849365258312879, ic: 0.250192285497237
train 31, step: 500, loss: 1.5276526933834875, grad_norm: 0.0788051437535003, ic: 0.05686958109081272
train 31, step: 1000, loss: 4.657094295838212, grad_norm: 1.385516282212952, ic: 0.39354381413089107
train 31, step: 1500, loss: 0.7767021900486851, grad_norm: 0.003169234723438835, ic: 0.6952975763369618
train 31, step: 2000, loss: 1.224259489575418, grad_norm: 0.16534493697564587, ic: 0.09823438682693675
Epoch 31: 2022-05-05 15:13:05.468935: train loss: 1.6227474174019778
Eval step 0: eval loss: 0.8410791169981559
Eval: 2022-05-05 15:13:09.608400: total loss: 1.0745057605152424, mse:4.625860177482105, ic :0.14050051652995732, sharpe5:11.88534469127655, irr5:396.75396728515625, ndcg5:0.8444845095505077, pnl5:4.805258274078369 
train 32, step: 0, loss: 1.1648147119178682, grad_norm: 0.03195643124239393, ic: 0.09600980817188426
train 32, step: 500, loss: 1.4672096072219487, grad_norm: 0.12179882847725522, ic: 0.01789740492672956
train 32, step: 1000, loss: 1.02507948904898, grad_norm: 0.03320645623050716, ic: 0.5328674285656277
train 32, step: 1500, loss: 1.0038563417715485, grad_norm: 0.13854113640074578, ic: -0.012298419530482604
train 32, step: 2000, loss: 0.9864528310070945, grad_norm: 0.001325081004322486, ic: 0.5026473016842292
Epoch 32: 2022-05-05 15:14:48.802611: train loss: 1.6232478731529476
Eval step 0: eval loss: 0.8372494021255926
Eval: 2022-05-05 15:14:52.802527: total loss: 1.0729528619528617, mse:4.6253845672116, ic :0.1413554533949553, sharpe5:11.940738101005554, irr5:396.0453186035156, ndcg5:0.8498094142465384, pnl5:4.557159900665283 
train 33, step: 0, loss: 1.2891953799946003, grad_norm: 0.08283267187830141, ic: 0.23069114402788352
train 33, step: 500, loss: 1.0105338566534567, grad_norm: 0.010365812237770137, ic: 0.0522941450164633
train 33, step: 1000, loss: 1.0250804120193595, grad_norm: 0.10279387097401191, ic: 0.12768319872558703
train 33, step: 1500, loss: 0.9084444419344974, grad_norm: 0.00445621373076219, ic: 0.5222428583309527
train 33, step: 2000, loss: 0.824307545995939, grad_norm: 0.005223550420160648, ic: 0.2001078925803343
Epoch 33: 2022-05-05 15:16:32.370343: train loss: 1.62265465646968
Eval step 0: eval loss: 0.8383655286815068
Eval: 2022-05-05 15:16:36.281906: total loss: 1.0734258643480803, mse:4.624531972323645, ic :0.138773210798352, sharpe5:11.712679195404052, irr5:391.7725830078125, ndcg5:0.8596512846308413, pnl5:4.394176959991455 
train 34, step: 0, loss: 1.0437396312239764, grad_norm: 0.06356524464930315, ic: 0.5493481146774541
train 34, step: 500, loss: 0.8158993035646025, grad_norm: 0.05867011806210441, ic: 0.08836728510569872
train 34, step: 1000, loss: 3.4449119743663594, grad_norm: 0.4125670502392624, ic: 0.08559065535719175
train 34, step: 1500, loss: 0.8029861541129693, grad_norm: 0.044647379990492626, ic: 0.6794112797966195
train 34, step: 2000, loss: 7.089165980828815, grad_norm: 0.7047332951177052, ic: 0.42121500526200584
Epoch 34: 2022-05-05 15:18:15.692450: train loss: 1.6221057316564231
Eval step 0: eval loss: 0.8350613978941649
Eval: 2022-05-05 15:18:19.536617: total loss: 1.0717721577548818, mse:4.6173938468775, ic :0.1418123307159509, sharpe5:11.798907891511917, irr5:391.52294921875, ndcg5:0.8347693630146534, pnl5:4.363539218902588 
train 35, step: 0, loss: 1.2539613970588235, grad_norm: 0.04698134346777729, ic: 0.5442499214263444
train 35, step: 500, loss: 1.1873552723196035, grad_norm: 0.04228452632961713, ic: -0.020039774734901657
train 35, step: 1000, loss: 1.8538494393577494, grad_norm: 0.2610892691351837, ic: 0.013964539372200834
train 35, step: 1500, loss: 1.637772225975094, grad_norm: 0.03439638750518531, ic: 0.024502713848425842
train 35, step: 2000, loss: 0.7837747992041276, grad_norm: 0.0015807398899449808, ic: 0.5596256574878442
Epoch 35: 2022-05-05 15:19:58.800438: train loss: 1.6210395946194778
Eval step 0: eval loss: 0.841428863235972
Eval: 2022-05-05 15:20:02.860465: total loss: 1.0741275018236138, mse:4.629443461780673, ic :0.14000668445038159, sharpe5:11.74876342356205, irr5:387.3290710449219, ndcg5:0.8312091760507929, pnl5:5.2781476974487305 
train 36, step: 0, loss: 1.8167868334232733, grad_norm: 0.2664359325288129, ic: 0.024900196087932286
train 36, step: 500, loss: 0.8490919469377955, grad_norm: 8.584384225560928e-05, ic: 0.048490865730932364
train 36, step: 1000, loss: 1.7442340198863635, grad_norm: 0.4094717890061912, ic: 0.1826242299932609
train 36, step: 1500, loss: 0.8109122134401396, grad_norm: 0.008765233847306667, ic: 0.19234014381011685
train 36, step: 2000, loss: 1.0937882984697676, grad_norm: 0.20832776966261696, ic: 0.7814193496760167
Epoch 36: 2022-05-05 15:21:42.202144: train loss: 1.620038261588218
Eval step 0: eval loss: 0.8362107111103793
Eval: 2022-05-05 15:21:46.230783: total loss: 1.0725917385939356, mse:4.622591980955929, ic :0.1421978689200325, sharpe5:11.95379471361637, irr5:394.5592956542969, ndcg5:0.8577105477614658, pnl5:4.460977077484131 
train 37, step: 0, loss: 2.0171186321544794, grad_norm: 0.4233254253930237, ic: 0.062448630994844066
train 37, step: 500, loss: 2.31448657983279, grad_norm: 0.22360730336465556, ic: -0.0023682140217902437
train 37, step: 1000, loss: 1.0722868990498953, grad_norm: 0.028616697084172124, ic: -0.00216894412424057
train 37, step: 1500, loss: 2.031131762350373, grad_norm: 0.17412742287684768, ic: 0.6092573490087763
train 37, step: 2000, loss: 1.3243773197414868, grad_norm: 0.01634714424561352, ic: 0.05330994591846974
Epoch 37: 2022-05-05 15:23:25.550900: train loss: 1.6194256139863052
Eval step 0: eval loss: 0.8346497160868348
Eval: 2022-05-05 15:23:29.441121: total loss: 1.0727364706226377, mse:4.623940500391768, ic :0.14072156871273747, sharpe5:12.303857225775719, irr5:400.9356384277344, ndcg5:0.8386457068189951, pnl5:4.247057914733887 
train 38, step: 0, loss: 1.3494550193228374, grad_norm: 0.04572437535326965, ic: -0.08831068677427015
train 38, step: 500, loss: 0.9352707851080246, grad_norm: 0.007040089722319764, ic: 0.24057117769683978
train 38, step: 1000, loss: 0.9142161252470355, grad_norm: 0.019773937652803445, ic: 0.02758586868997459
train 38, step: 1500, loss: 0.9688371268745255, grad_norm: 0.0004409159223788363, ic: 0.07336850651009674
train 38, step: 2000, loss: 2.2789264229489237, grad_norm: 0.389344661814574, ic: -0.05374355552006371
Epoch 38: 2022-05-05 15:25:08.585940: train loss: 1.6191809970619586
Eval step 0: eval loss: 0.8332071897227344
Eval: 2022-05-05 15:25:12.499905: total loss: 1.0721878658814947, mse:4.624515065102753, ic :0.14152764610866853, sharpe5:11.991956194639206, irr5:393.9284973144531, ndcg5:0.8518061473703684, pnl5:5.295365810394287 
train 39, step: 0, loss: 0.96486698815582, grad_norm: 0.0029181068380480842, ic: 0.18621444860993838
train 39, step: 500, loss: 0.9043707176871156, grad_norm: 0.01891421088303318, ic: 0.15215109861807838
train 39, step: 1000, loss: 0.9574422727353865, grad_norm: 0.006635844805865883, ic: 0.08756667828508469
train 39, step: 1500, loss: 2.192533707656498, grad_norm: 0.15787541330746746, ic: 0.04464184099431602
train 39, step: 2000, loss: 0.6295132267908274, grad_norm: 0.02034672290878233, ic: 0.041719619414548666
Epoch 39: 2022-05-05 15:26:51.829336: train loss: 1.6194454623787857
Eval step 0: eval loss: 0.8375683413667346
Eval: 2022-05-05 15:26:55.958654: total loss: 1.0732554408296409, mse:4.622964250943795, ic :0.14326501545521897, sharpe5:11.98259531378746, irr5:396.5793151855469, ndcg5:0.8525452014149312, pnl5:4.363546371459961 

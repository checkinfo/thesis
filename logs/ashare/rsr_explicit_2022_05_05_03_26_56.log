Namespace(adj_path='./data/graphs/concepts_graph_multihot_1931_1931_824.npy', ann_embed_dim=128, ann_embed_num=89, ann_path='./data/ann_type_2431_1931_25.npz', batch_size=1, dataset_type='TimeDataset', dout=0.3, epochs=40, glstm_layers=1, gnn_layers=1, gpu=0, graph_attn=False, hidden_dim=128, inner_prod=True, input_dim=9, input_graph=False, label_cnt=3, lr=0.001, lstm_layers=1, market=None, mask_adj=False, mask_type='soft', model_type='ReRaLSTM', normalize_adj=False, num_days=8, num_heads=1, print_inteval=500, rank_loss=False, relation_num=1, rsr_data_path=None, seed=10086, shuffle=True, side_info=False, sparse_adj_path='./data/icgraph_window_250_0.8/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=False)
relation encoding shape: torch.Size([1931, 1931, 824]) torch.float32
relation mask shape: torch.Size([1931, 1931]) torch.float32
53534
ReRaLSTM(
  (rnn1): LSTM(9, 128, batch_first=True, dropout=0.3, bidirectional=True)
  (fc0): Linear(in_features=256, out_features=128, bias=True)
  (fc1): Linear(in_features=824, out_features=1, bias=True)
  (fc2): Linear(in_features=128, out_features=1, bias=True)
  (fc3): Linear(in_features=128, out_features=1, bias=True)
  (predict): Linear(in_features=256, out_features=1, bias=True)
  (relu): LeakyReLU(negative_slope=0.01)
  (dropout): Dropout(p=0.3, inplace=False)
)
train 0, step: 0, loss: 4.838890857114934, grad_norm: 7.969836008369453e-05, ic: 0.007738539775790629
train 0, step: 500, loss: 0.8796574377708176, grad_norm: 3.259852085502645e-06, ic: -0.04274661032810349
train 0, step: 1000, loss: 1.9049433922366497, grad_norm: 5.9053602131251643e-05, ic: 0.006893947816010751
train 0, step: 1500, loss: 0.9318469383028656, grad_norm: 4.236479067720571e-07, ic: 0.07524777479961094
train 0, step: 2000, loss: 0.9832790915789237, grad_norm: 4.3395030124492446e-05, ic: 0.020937383126348564
Epoch 0: 2022-05-05 15:28:53.801444: train loss: 1.647030771987666
Eval step 0: eval loss: 0.8334183366331335
Eval: 2022-05-05 15:28:57.773781: total loss: 1.078703937820427, mse:4.826340353463508, ic :0.01956824965104718, sharpe5:7.2157686951756475, irr5:173.18002319335938, ndcg5:0.8443001026687533, pnl5:2.994931936264038 
train 1, step: 0, loss: 2.73000724546371, grad_norm: 7.699706884654943e-05, ic: 0.08995600139952617
train 1, step: 500, loss: 1.7924457451620517, grad_norm: 6.882382940095928e-05, ic: 0.04072680239418852
train 1, step: 1000, loss: 0.8481754833610008, grad_norm: 0.0012133545060062302, ic: 0.035079757710106366
train 1, step: 1500, loss: 1.6970632969647987, grad_norm: 0.07999266276748608, ic: -0.013597666264906804
train 1, step: 2000, loss: 2.1956330078125, grad_norm: 0.007060131104868226, ic: 0.011820976899172015
Epoch 1: 2022-05-05 15:30:37.113104: train loss: 1.6470073160317815
Eval step 0: eval loss: 0.8335284443122695
Eval: 2022-05-05 15:30:40.961014: total loss: 1.078647425348695, mse:4.825137552993243, ic :0.04084060238741494, sharpe5:7.2986199635267255, irr5:200.15060424804688, ndcg5:0.8509147279945778, pnl5:2.2990736961364746 
train 2, step: 0, loss: 2.1439909446022725, grad_norm: 4.31588370086684e-06, ic: 0.12084563878995735
train 2, step: 500, loss: 3.3133451315532083, grad_norm: 0.00041379572939455924, ic: -0.06524568002622666
train 2, step: 1000, loss: 2.072020361889368, grad_norm: 0.0008004884623779184, ic: 0.3119049597795189
train 2, step: 1500, loss: 1.47425537109375, grad_norm: 0.03370529858843289, ic: -0.07969418881933053
train 2, step: 2000, loss: 3.25603515625, grad_norm: 0.031075618352891517, ic: 0.13093926816632556
Epoch 2: 2022-05-05 15:32:19.921989: train loss: 1.6467064376859866
Eval step 0: eval loss: 0.8362212588086143
Eval: 2022-05-05 15:32:23.909773: total loss: 1.0791748846169973, mse:4.822984258106831, ic :0.0168991735384092, sharpe5:7.090831772983074, irr5:175.3507537841797, ndcg5:0.855277901214441, pnl5:3.1046414375305176 
train 3, step: 0, loss: 1.5067818494347054, grad_norm: 0.04538939154738668, ic: 0.07550064503746559
train 3, step: 500, loss: 1.4679737972298355, grad_norm: 0.008572035440065722, ic: 0.15763622794923204
train 3, step: 1000, loss: 3.6424229544473232, grad_norm: 0.00019735540155942484, ic: 0.004509910439618749
train 3, step: 1500, loss: 1.950485803881956, grad_norm: 0.0001241454422330937, ic: 0.038422209480600975
train 3, step: 2000, loss: 0.914837745460304, grad_norm: 5.398592960290005e-06, ic: 0.02049811176871465
Epoch 3: 2022-05-05 15:34:03.383907: train loss: 1.6467417478812627
Eval step 0: eval loss: 0.8333457890501514
Eval: 2022-05-05 15:34:07.299257: total loss: 1.0786699092804721, mse:4.825886303821212, ic :0.022201918298417063, sharpe5:3.9852488771080967, irr5:49.55725860595703, ndcg5:0.8411181192779276, pnl5:1.2544630765914917 
train 4, step: 0, loss: 1.4471478396045918, grad_norm: 1.5341848157583033e-05, ic: -0.06157751855225138
train 4, step: 500, loss: 1.6026606522207185, grad_norm: 0.00024561677284680564, ic: 0.09344867941981747
train 4, step: 1000, loss: 2.9403545100514483, grad_norm: 0.00015258481672264705, ic: 0.06282902349096553
train 4, step: 1500, loss: 2.1355744824630802, grad_norm: 9.872822408876848e-05, ic: 0.056883555551621875
train 4, step: 2000, loss: 1.1269373678679044, grad_norm: 0.0013679125182476462, ic: 0.1561700691621683
Epoch 4: 2022-05-05 15:35:46.409390: train loss: 1.646630053010273
Eval step 0: eval loss: 0.8757789861037935
Eval: 2022-05-05 15:35:50.290379: total loss: 1.1099211669257645, mse:4.91428603555044, ic :0.021727581215645744, sharpe5:5.125381178855895, irr5:98.9378433227539, ndcg5:0.8520138692897785, pnl5:2.054560422897339 
train 5, step: 0, loss: 1.4093684458892617, grad_norm: 0.5695572477345576, ic: 0.07953973109919289
train 5, step: 500, loss: 0.8922778378395123, grad_norm: 8.110025965942113e-06, ic: 0.009189824991033305
train 5, step: 1000, loss: 0.9967167295258621, grad_norm: 0.07407876480761322, ic: -0.03533441826484666
train 5, step: 1500, loss: 1.519615652367678, grad_norm: 0.09651291862246797, ic: -0.006733635925662935
train 5, step: 2000, loss: 1.1186040537539879, grad_norm: 0.015253420218933864, ic: 0.07245911135794571
Epoch 5: 2022-05-05 15:37:29.647640: train loss: 1.6461933310952055
Eval step 0: eval loss: 0.8396547275298011
Eval: 2022-05-05 15:37:33.500449: total loss: 1.0810499389101373, mse:4.821634456747696, ic :0.026965070189496225, sharpe5:6.44392783999443, irr5:153.5930633544922, ndcg5:0.8572583630036059, pnl5:2.751293182373047 
train 6, step: 0, loss: 1.3197951126707037, grad_norm: 0.26319690279222735, ic: 0.10518641988019312
train 6, step: 500, loss: 1.004721485272301, grad_norm: 0.025814708195377165, ic: 0.023846631297414714
train 6, step: 1000, loss: 1.1201342680608364, grad_norm: 0.0486707520972498, ic: 0.17407668351622568
train 6, step: 1500, loss: 1.6095668824251033, grad_norm: 0.19684495678802283, ic: 0.08215416730041944
train 6, step: 2000, loss: 0.8015798869564401, grad_norm: 0.023565885135227095, ic: 0.053796457809578806
Epoch 6: 2022-05-05 15:39:12.521831: train loss: 1.6458569324443997
Eval step 0: eval loss: 0.8330747003424657
Eval: 2022-05-05 15:39:16.407817: total loss: 1.0782744727166402, mse:4.822142984876221, ic :0.025743091393333434, sharpe5:3.756964841187, irr5:44.82624816894531, ndcg5:0.8328853727431014, pnl5:1.2459650039672852 
train 7, step: 0, loss: 0.9885503768920899, grad_norm: 4.412073726038911e-06, ic: 0.030056872502775174
train 7, step: 500, loss: 0.6523446775859613, grad_norm: 0.0038822170794871524, ic: 0.056646397140393726
train 7, step: 1000, loss: 1.0342616875119002, grad_norm: 0.0021579228338442866, ic: 0.03927604570863418
train 7, step: 1500, loss: 2.2619804226956055, grad_norm: 0.0632937291741717, ic: 0.11330603924340313
train 7, step: 2000, loss: 0.8968557132850364, grad_norm: 0.017325599535297696, ic: 0.02455545607601568
Epoch 7: 2022-05-05 15:40:55.389363: train loss: 1.6457855354796114
Eval step 0: eval loss: 0.8332296357391004
Eval: 2022-05-05 15:40:59.254720: total loss: 1.0783900593893403, mse:4.823304774078699, ic :0.04602063730914537, sharpe5:6.216667768657207, irr5:147.4596710205078, ndcg5:0.8470485308075034, pnl5:2.644523859024048 
train 8, step: 0, loss: 3.6763303894927537, grad_norm: 0.00025153450550472725, ic: 0.0010192946564781206
train 8, step: 500, loss: 2.7486746651785716, grad_norm: 0.19965271886886105, ic: 0.04372374071157011
train 8, step: 1000, loss: 3.073309414628623, grad_norm: 0.14746786885260166, ic: -0.04772149099818359
train 8, step: 1500, loss: 0.756315595859664, grad_norm: 0.0017565013187365143, ic: 0.05609694372194263
train 8, step: 2000, loss: 1.1166078931936259, grad_norm: 0.11794204655110563, ic: 0.08703516052729068
Epoch 8: 2022-05-05 15:42:38.660680: train loss: 1.6460045875042226
Eval step 0: eval loss: 0.8331267956813092
Eval: 2022-05-05 15:42:42.678499: total loss: 1.0783831264984673, mse:4.820291568161388, ic :0.06377149578414607, sharpe5:7.137537800967693, irr5:198.87367248535156, ndcg5:0.8502264361188063, pnl5:2.9531948566436768 
train 9, step: 0, loss: 5.439773194527512, grad_norm: 0.0017360671002654557, ic: 0.10412463412587364
train 9, step: 500, loss: 1.3418125614106289, grad_norm: 0.0015454103331387801, ic: 0.09570376961843056
train 9, step: 1000, loss: 0.9279179815784072, grad_norm: 0.017494555012093314, ic: 0.10863262791276236
train 9, step: 1500, loss: 1.1135980215620398, grad_norm: 0.010876041612410296, ic: 0.154664826519476
train 9, step: 2000, loss: 1.1202606345609365, grad_norm: 0.14064199591157667, ic: -0.03488251368111516
Epoch 9: 2022-05-05 15:44:21.695061: train loss: 1.6455448192022595
Eval step 0: eval loss: 0.8350126469474446
Eval: 2022-05-05 15:44:25.632664: total loss: 1.0782870148616712, mse:4.817241987202024, ic :0.029149068098526545, sharpe5:5.845665771961212, irr5:129.78839111328125, ndcg5:0.8587682646503665, pnl5:2.221778154373169 
train 10, step: 0, loss: 7.213642264941691, grad_norm: 0.22124387687295238, ic: 0.08416954779467281
train 10, step: 500, loss: 1.1240956831951532, grad_norm: 0.01785620911958754, ic: -0.019971724519433257
train 10, step: 1000, loss: 2.3648782741804064, grad_norm: 0.0001125451803284506, ic: 0.03252561249875929
train 10, step: 1500, loss: 1.103708836939428, grad_norm: 0.017031184166274485, ic: 0.0005975907298371823
train 10, step: 2000, loss: 2.8835514149767287, grad_norm: 0.00028252905881834115, ic: 0.3856722010843381
Epoch 10: 2022-05-05 15:46:04.733315: train loss: 1.6459063586174414
Eval step 0: eval loss: 0.8352886879280821
Eval: 2022-05-05 15:46:08.804133: total loss: 1.0784217557178288, mse:4.818519749253671, ic :0.026322299139036727, sharpe5:6.463568095564842, irr5:151.04263305664062, ndcg5:0.8364607779361459, pnl5:2.8758130073547363 
train 11, step: 0, loss: 1.2710753025606631, grad_norm: 0.00023034422606608174, ic: 0.10184630303918213
train 11, step: 500, loss: 0.7126314055994101, grad_norm: 0.0002395615856226341, ic: 0.1890574879276768
train 11, step: 1000, loss: 0.9337188393639221, grad_norm: 0.005824646672185038, ic: 0.023359940367280157
train 11, step: 1500, loss: 1.069852862441749, grad_norm: 0.025195469565390996, ic: -0.008981296840438243
train 11, step: 2000, loss: 0.790997835132183, grad_norm: 0.0016914363035903262, ic: 0.1323784332921593
Epoch 11: 2022-05-05 15:47:48.171758: train loss: 1.6454728008613926
Eval step 0: eval loss: 0.8368829982423932
Eval: 2022-05-05 15:47:51.956384: total loss: 1.079428463504325, mse:4.816824880442322, ic :0.03037681612796665, sharpe5:3.3223817382752894, irr5:39.519798278808594, ndcg5:0.844895780402019, pnl5:1.2259281873703003 
train 12, step: 0, loss: 1.0399258931477864, grad_norm: 0.03710618337185681, ic: 0.0677001949169659
train 12, step: 500, loss: 0.9355070846770066, grad_norm: 0.015315354401228718, ic: 0.09703205816847921
train 12, step: 1000, loss: 3.004519322875199, grad_norm: 0.048371116089200084, ic: 0.11548548253360205
train 12, step: 1500, loss: 0.9448516450578351, grad_norm: 1.202579362132959e-05, ic: -0.07223985049145673
train 12, step: 2000, loss: 0.8771981876062123, grad_norm: 7.863685172727788e-06, ic: 0.048782620062471964
Epoch 12: 2022-05-05 15:49:31.005519: train loss: 1.6451660491345217
Eval step 0: eval loss: 0.8355833803263303
Eval: 2022-05-05 15:49:34.832147: total loss: 1.0788103501848174, mse:4.816170708522845, ic :0.030390204517216638, sharpe5:3.698336602002382, irr5:41.29463577270508, ndcg5:0.8588682363096832, pnl5:1.3320010900497437 
train 13, step: 0, loss: 2.130602859770987, grad_norm: 0.4373331766014678, ic: 0.09486839833881802
train 13, step: 500, loss: 0.8987103679495652, grad_norm: 9.865836975424124e-05, ic: 0.06412253729625977
train 13, step: 1000, loss: 1.0258905397965603, grad_norm: 0.0872513388487369, ic: 0.06908537029702164
train 13, step: 1500, loss: 2.403325267735168, grad_norm: 0.1622144363625918, ic: -0.015034229440592132
train 13, step: 2000, loss: 1.5098159942744418, grad_norm: 0.01770408975626523, ic: -0.0014737164460766443
Epoch 13: 2022-05-05 15:51:14.226682: train loss: 1.6455140773902117
Eval step 0: eval loss: 0.8332582560178476
Eval: 2022-05-05 15:51:18.020179: total loss: 1.0782068085033187, mse:4.8221806607440865, ic :0.025825953055929655, sharpe5:3.4897807927429674, irr5:41.66646957397461, ndcg5:0.8474617465392511, pnl5:1.3529479503631592 
train 14, step: 0, loss: 4.511454803895281, grad_norm: 0.3709786399420302, ic: 0.026849909965909812
train 14, step: 500, loss: 0.8291024957592699, grad_norm: 0.0013385770090272517, ic: 0.05599045120157216
train 14, step: 1000, loss: 1.951303677569761, grad_norm: 0.00818788713336321, ic: 0.27579639635897213
train 14, step: 1500, loss: 1.1180346143114699, grad_norm: 0.027751710820872993, ic: -0.016711019229754116
train 14, step: 2000, loss: 1.1400929603665169, grad_norm: 0.0844436325960874, ic: -0.08083385026790799
Epoch 14: 2022-05-05 15:52:56.791880: train loss: 1.6455840885223065
Eval step 0: eval loss: 0.8380156538132244
Eval: 2022-05-05 15:53:00.652852: total loss: 1.0798178547411499, mse:4.8170756398092145, ic :0.03260551968287783, sharpe5:7.902329144775867, irr5:202.03172302246094, ndcg5:0.8461772203396306, pnl5:3.5158636569976807 
train 15, step: 0, loss: 3.3922030794017513, grad_norm: 0.3503581362481183, ic: -0.021168563157305868
train 15, step: 500, loss: 1.2587470532652743, grad_norm: 5.6279608323914985e-05, ic: -0.04793167221987421
train 15, step: 1000, loss: 1.3121624706237296, grad_norm: 0.027638452578595478, ic: 0.0006745465559190814
train 15, step: 1500, loss: 0.8532986858698327, grad_norm: 0.1733068517508378, ic: -0.029115348012467478
train 15, step: 2000, loss: 1.4642545297717895, grad_norm: 0.3879751076444956, ic: 0.008411262047088568
Epoch 15: 2022-05-05 15:54:40.155789: train loss: 1.6449555405422345
Eval step 0: eval loss: 0.8456458844425052
Eval: 2022-05-05 15:54:44.110372: total loss: 1.084698994843064, mse:4.824754496916492, ic :0.039639342987446154, sharpe5:6.736402867734432, irr5:155.04421997070312, ndcg5:0.8412917852886337, pnl5:2.7345781326293945 
train 16, step: 0, loss: 0.7130816075316706, grad_norm: 0.18680012318277983, ic: -0.03263577706662972
train 16, step: 500, loss: 1.653678574973531, grad_norm: 0.24923788374108966, ic: 0.04218194041325718
train 16, step: 1000, loss: 0.8717126094933713, grad_norm: 0.0007699272995493311, ic: -0.021407686181270764
train 16, step: 1500, loss: 0.8772418996872539, grad_norm: 0.012547628411392113, ic: 0.07901089591219444
train 16, step: 2000, loss: 3.3652690506296445, grad_norm: 0.16466461988435205, ic: 0.04111641585609124
Epoch 16: 2022-05-05 15:56:23.377930: train loss: 1.6451257518805242
Eval step 0: eval loss: 0.8338122674361169
Eval: 2022-05-05 15:56:27.192502: total loss: 1.0779780121380544, mse:4.816917321611968, ic :0.03894495792990656, sharpe5:8.147971390485763, irr5:208.29530334472656, ndcg5:0.8392491396996915, pnl5:3.3518829345703125 
train 17, step: 0, loss: 1.2725803527022546, grad_norm: 0.0507013499846678, ic: -0.07095311536327441
train 17, step: 500, loss: 1.7985722074017616, grad_norm: 0.12609892088768826, ic: 0.12650419531804036
train 17, step: 1000, loss: 1.2800186820652175, grad_norm: 0.038215461951045936, ic: 0.02546729797872663
train 17, step: 1500, loss: 4.62672100305382, grad_norm: 0.006086849114415564, ic: 0.048070781804985016
train 17, step: 2000, loss: 1.24699398213753, grad_norm: 0.16493500180224516, ic: 0.020246047244868212
Epoch 17: 2022-05-05 15:58:06.521738: train loss: 1.6449865745190193
Eval step 0: eval loss: 0.8392220146412341
Eval: 2022-05-05 15:58:10.343482: total loss: 1.0805130546926385, mse:4.818166331995173, ic :0.03335096153221516, sharpe5:8.21441510438919, irr5:218.68655395507812, ndcg5:0.8346463812817472, pnl5:3.5218019485473633 
train 18, step: 0, loss: 1.416134910073269, grad_norm: 0.24046896617801078, ic: 0.004620900098162052
train 18, step: 500, loss: 1.433783308741929, grad_norm: 0.6276642917371097, ic: -0.054731416366762084
train 18, step: 1000, loss: 0.6866632330907534, grad_norm: 0.002674080410997871, ic: 0.2796988196167973
train 18, step: 1500, loss: 1.4422322491170148, grad_norm: 0.023597166380446462, ic: 0.17238694367798296
train 18, step: 2000, loss: 0.9096219008135948, grad_norm: 0.0004085520450959508, ic: 0.017742596952485888
Epoch 18: 2022-05-05 15:59:50.105719: train loss: 1.6456964860499732
Eval step 0: eval loss: 0.83342174534049
Eval: 2022-05-05 15:59:54.187811: total loss: 1.0782792696374737, mse:4.819076611658252, ic :0.06113287976389466, sharpe5:7.786388449072837, irr5:215.2776336669922, ndcg5:0.8594060232563515, pnl5:3.071643352508545 
train 19, step: 0, loss: 1.4772803896949405, grad_norm: 0.02629593685657322, ic: 0.015366052923817763
train 19, step: 500, loss: 0.8918577123571325, grad_norm: 0.0023949428121755553, ic: -0.06035758854462756
train 19, step: 1000, loss: 0.96995401925541, grad_norm: 0.001470368215591763, ic: 0.07145112009992265
train 19, step: 1500, loss: 3.984967594320977, grad_norm: 0.18179466284874224, ic: 0.04262238118122133
train 19, step: 2000, loss: 1.018548583984375, grad_norm: 0.04231333128578457, ic: 0.10851104106581669
Epoch 19: 2022-05-05 16:01:33.496691: train loss: 1.6455138694522775
Eval step 0: eval loss: 0.835824176559207
Eval: 2022-05-05 16:01:37.562685: total loss: 1.0785583462106014, mse:4.810841180733022, ic :0.049200415233326786, sharpe5:7.65076871484518, irr5:211.93910217285156, ndcg5:0.8529095501056609, pnl5:2.7749738693237305 
train 20, step: 0, loss: 2.254728801259881, grad_norm: 0.3060178266818951, ic: 0.018769732478309493
train 20, step: 500, loss: 3.230541193181818, grad_norm: 0.1812164569821594, ic: 0.15728318852342182
train 20, step: 1000, loss: 0.9905858993530274, grad_norm: 0.0030580224250100958, ic: 0.030917353471278906
train 20, step: 1500, loss: 1.908245746793645, grad_norm: 0.23054467882399093, ic: 0.1459419308816805
train 20, step: 2000, loss: 1.0233367372298126, grad_norm: 0.0034113563854012, ic: 0.0101367603356072
Epoch 20: 2022-05-05 16:03:17.207057: train loss: 1.6444732902534493
Eval step 0: eval loss: 0.8332927289828108
Eval: 2022-05-05 16:03:21.200407: total loss: 1.0784497907669528, mse:4.8096116099514035, ic :0.07888450868338004, sharpe5:8.05463406264782, irr5:224.47364807128906, ndcg5:0.8506552843971891, pnl5:2.864128351211548 
train 21, step: 0, loss: 1.0496530074549486, grad_norm: 0.039116088855282324, ic: -0.024762479308148837
train 21, step: 500, loss: 0.788640385180448, grad_norm: 3.770009777221649e-05, ic: 0.04069382078562297
train 21, step: 1000, loss: 0.9565539443702028, grad_norm: 0.03224450437507671, ic: 0.06375623246102176
train 21, step: 1500, loss: 1.033486637475252, grad_norm: 0.06299231050013177, ic: 0.07809586952657029
train 21, step: 2000, loss: 0.9340632408032253, grad_norm: 0.014721337790689631, ic: 0.020905023140964034
Epoch 21: 2022-05-05 16:05:00.688527: train loss: 1.643988320193251
Eval step 0: eval loss: 0.8330161734803082
Eval: 2022-05-05 16:05:04.610872: total loss: 1.0753526897589822, mse:4.690435239162512, ic :0.12665370522457725, sharpe5:11.348314286470412, irr5:362.7300720214844, ndcg5:0.8539772939610748, pnl5:3.3725366592407227 
train 22, step: 0, loss: 1.0667229776328566, grad_norm: 0.0031428795172074022, ic: 0.040834874400073926
train 22, step: 500, loss: 3.284964708777947, grad_norm: 1.0668355673178294, ic: 0.04025392096678238
train 22, step: 1000, loss: 1.21898341537211, grad_norm: 0.003908937977952059, ic: 0.42362621510887044
train 22, step: 1500, loss: 0.976270736882716, grad_norm: 0.08747739379821523, ic: 0.005392046202243917
train 22, step: 2000, loss: 1.7697244587939343, grad_norm: 0.055743427088078674, ic: 0.15715805914200898
Epoch 22: 2022-05-05 16:06:43.787464: train loss: 1.6361451609866284
Eval step 0: eval loss: 0.8292339232498024
Eval: 2022-05-05 16:06:47.869961: total loss: 1.0720949723695627, mse:4.619609341366229, ic :0.14524796274000687, sharpe5:12.067809977531432, irr5:407.3524475097656, ndcg5:0.8591171319112826, pnl5:3.6028735637664795 
train 23, step: 0, loss: 1.0077930109645172, grad_norm: 0.012799325819641905, ic: 0.14821012043450607
train 23, step: 500, loss: 1.4373588621897078, grad_norm: 0.07152816123140701, ic: 0.023984314309897652
train 23, step: 1000, loss: 1.6602494303385418, grad_norm: 0.015006201763106386, ic: 0.25161704617915204
train 23, step: 1500, loss: 1.113193936468726, grad_norm: 0.19806356722738194, ic: 0.04551962903652857
train 23, step: 2000, loss: 1.902072733232294, grad_norm: 0.32604414023637035, ic: 0.44273794832687696
Epoch 23: 2022-05-05 16:08:27.474641: train loss: 1.6333735253680761
Eval step 0: eval loss: 0.8329505719425052
Eval: 2022-05-05 16:08:31.481872: total loss: 1.073302824720142, mse:4.616866389632071, ic :0.1497191564293794, sharpe5:12.437507069706916, irr5:417.2362976074219, ndcg5:0.8462743470718979, pnl5:3.85361647605896 
train 24, step: 0, loss: 2.1813262070136807, grad_norm: 0.015074458009945184, ic: 0.27417815190710176
train 24, step: 500, loss: 1.2324009758025292, grad_norm: 0.11058751109311815, ic: 0.1410549262714417
train 24, step: 1000, loss: 0.9326885668994768, grad_norm: 0.0036169266756236208, ic: 0.5059033724072116
train 24, step: 1500, loss: 2.6404543229596045, grad_norm: 0.8284387706806912, ic: -0.0389306543239502
train 24, step: 2000, loss: 0.9332724076125712, grad_norm: 0.01133146621564838, ic: 0.13624439323100068
Epoch 24: 2022-05-05 16:10:10.763698: train loss: 1.632446497144686
Eval step 0: eval loss: 0.8280399752617886
Eval: 2022-05-05 16:10:14.620074: total loss: 1.0710558795188494, mse:4.618207580341704, ic :0.14787411657158891, sharpe5:12.189727504849433, irr5:414.86590576171875, ndcg5:0.8413523841875956, pnl5:4.562690734863281 
train 25, step: 0, loss: 0.8937627019108954, grad_norm: 0.0005491220417158904, ic: 0.5452564957492426
train 25, step: 500, loss: 0.8774685124976397, grad_norm: 1.529407696607128e-05, ic: 0.0546918646864635
train 25, step: 1000, loss: 2.1618603999071784, grad_norm: 0.009777953046314715, ic: 0.1767360258786091
train 25, step: 1500, loss: 1.1729519938261164, grad_norm: 0.028993099131272577, ic: 0.5092709335560198
train 25, step: 2000, loss: 1.0465961273638098, grad_norm: 0.091423040651326, ic: 0.5511409763357793
Epoch 25: 2022-05-05 16:11:54.415398: train loss: 1.632371259059291
Eval step 0: eval loss: 0.8292669169644032
Eval: 2022-05-05 16:11:58.464739: total loss: 1.0711109110925832, mse:4.612818202462011, ic :0.14856355893563647, sharpe5:12.335120070576668, irr5:414.0553283691406, ndcg5:0.8464346032264064, pnl5:4.683000564575195 
train 26, step: 0, loss: 6.717818677615814, grad_norm: 0.21506176212872635, ic: 0.0778262653912203
train 26, step: 500, loss: 3.913017601031079, grad_norm: 0.4905559775289969, ic: 0.3271457002983597
train 26, step: 1000, loss: 1.312496742236558, grad_norm: 0.2915084792156298, ic: 0.004636103031972974
train 26, step: 1500, loss: 0.8553089023239786, grad_norm: 0.006211460916520045, ic: 0.16401640336547235
train 26, step: 2000, loss: 0.9680924914560386, grad_norm: 0.02508530278975801, ic: 0.02566748902051945
Epoch 26: 2022-05-05 16:13:37.882864: train loss: 1.632394358163684
Eval step 0: eval loss: 0.8292564335814014
Eval: 2022-05-05 16:13:41.828772: total loss: 1.0708457077353297, mse:4.613411042886204, ic :0.14669379990095588, sharpe5:12.355375177860259, irr5:420.108154296875, ndcg5:0.8445400896661356, pnl5:4.5003743171691895 
train 27, step: 0, loss: 0.8298219209558824, grad_norm: 0.0002808657534671235, ic: 0.005850987526462092
train 27, step: 500, loss: 0.9007801935429344, grad_norm: 0.24737464970465117, ic: 0.28041989801036304
train 27, step: 1000, loss: 0.7707358564596627, grad_norm: 0.03368810162301496, ic: 0.013900482891104253
train 27, step: 1500, loss: 0.6205615021847797, grad_norm: 0.00016439470816879547, ic: 0.5428963922361131
train 27, step: 2000, loss: 1.3801658821540435, grad_norm: 0.00020800710901845384, ic: 0.03051004166151873
Epoch 27: 2022-05-05 16:15:21.262994: train loss: 1.6322163792207907
Eval step 0: eval loss: 0.8322886395630268
Eval: 2022-05-05 16:15:25.154759: total loss: 1.072531651773808, mse:4.617963876011163, ic :0.1444746757455618, sharpe5:12.169035379886626, irr5:412.2799072265625, ndcg5:0.8573084799821259, pnl5:4.480733871459961 
train 28, step: 0, loss: 1.5583033263453185, grad_norm: 0.1378117137504642, ic: 0.12163774235962392
train 28, step: 500, loss: 1.4049478256882337, grad_norm: 0.1366017201788641, ic: 0.1345519492968093
train 28, step: 1000, loss: 0.9325518517636349, grad_norm: 0.015814491788314424, ic: 0.5421086500744927
train 28, step: 1500, loss: 1.0372120013233295, grad_norm: 0.00015926682879389623, ic: 0.05074615998964555
train 28, step: 2000, loss: 1.0464156449206767, grad_norm: 0.033364651387905286, ic: 0.0005650045295645147
Epoch 28: 2022-05-05 16:17:05.015276: train loss: 1.6316351293665434
Eval step 0: eval loss: 0.8288632102459825
Eval: 2022-05-05 16:17:08.948390: total loss: 1.0709811364915993, mse:4.614437595239485, ic :0.14647736191590502, sharpe5:11.91993341088295, irr5:402.547119140625, ndcg5:0.8688806328393727, pnl5:4.500581741333008 
train 29, step: 0, loss: 0.9118350638504549, grad_norm: 0.0005232706966852702, ic: 0.08176018623446785
train 29, step: 500, loss: 1.143113069651901, grad_norm: 0.0820950436507816, ic: 0.5850489407136064
train 29, step: 1000, loss: 1.0615675626858692, grad_norm: 0.030566215200640203, ic: 0.051172860144424015
train 29, step: 1500, loss: 2.3115594582479506, grad_norm: 0.0016140091864312238, ic: 0.03411860084583161
train 29, step: 2000, loss: 4.594630111882716, grad_norm: 0.03280635718198571, ic: 0.1749564705716409
Epoch 29: 2022-05-05 16:18:48.314715: train loss: 1.6320895956659707
Eval step 0: eval loss: 0.829256690842334
Eval: 2022-05-05 16:18:52.271907: total loss: 1.0706426190647844, mse:4.611506899473117, ic :0.1487865929972322, sharpe5:12.664708966612816, irr5:422.6215515136719, ndcg5:0.8566041605390005, pnl5:3.8347651958465576 
train 30, step: 0, loss: 1.0053340052181419, grad_norm: 0.00410474926475794, ic: 0.5176206902020853
train 30, step: 500, loss: 1.415984080989797, grad_norm: 0.4395247074586223, ic: 0.03782676132684673
train 30, step: 1000, loss: 0.9658926299124053, grad_norm: 0.007376344616194012, ic: 0.02969552793516047
train 30, step: 1500, loss: 1.5003423460933316, grad_norm: 0.07611507205479388, ic: 0.12946337987038126
train 30, step: 2000, loss: 1.8464189221499616, grad_norm: 0.12901795631764545, ic: 0.007484831459564353
Epoch 30: 2022-05-05 16:20:31.956752: train loss: 1.631561560089616
Eval step 0: eval loss: 0.8309366047319546
Eval: 2022-05-05 16:20:35.849940: total loss: 1.071596360461839, mse:4.6101059454320605, ic :0.15037120434359394, sharpe5:13.747772151231764, irr5:456.3453369140625, ndcg5:0.8523853933960847, pnl5:4.430576801300049 
train 31, step: 0, loss: 1.079499722499575, grad_norm: 0.004325062245295479, ic: 0.2552487178556436
train 31, step: 500, loss: 1.521873794367284, grad_norm: 0.12378343060947308, ic: 0.041484400134541015
train 31, step: 1000, loss: 4.37494206186573, grad_norm: 0.23001671657955897, ic: 0.4129823445315059
train 31, step: 1500, loss: 0.7829658112100533, grad_norm: 0.006433663006525281, ic: 0.6921880324679559
train 31, step: 2000, loss: 1.2075318681432845, grad_norm: 0.25964052310886565, ic: 0.12266419447417093
Epoch 31: 2022-05-05 16:22:15.401057: train loss: 1.6309187474758282
Eval step 0: eval loss: 0.8280722615088251
Eval: 2022-05-05 16:22:19.295501: total loss: 1.0708701514825278, mse:4.611423468638561, ic :0.1474468250157579, sharpe5:13.343644309043883, irr5:450.3306884765625, ndcg5:0.8476753547537479, pnl5:3.103780746459961 
train 32, step: 0, loss: 1.1475161212733826, grad_norm: 0.0008553552034787486, ic: 0.07109296134216077
train 32, step: 500, loss: 1.468831316129429, grad_norm: 0.1352778291815463, ic: 0.029250266942084654
train 32, step: 1000, loss: 1.01930174574127, grad_norm: 0.008958973137076828, ic: 0.5378033827064751
train 32, step: 1500, loss: 1.0053301243087338, grad_norm: 0.30002539047998816, ic: -0.009523027095221244
train 32, step: 2000, loss: 0.9956276838901527, grad_norm: 0.004811353242933139, ic: 0.49953938983392204
Epoch 32: 2022-05-05 16:23:58.708156: train loss: 1.6310177797487568
Eval step 0: eval loss: 0.8274471174427028
Eval: 2022-05-05 16:24:02.724345: total loss: 1.070760369953604, mse:4.611150444909529, ic :0.14960619775365017, sharpe5:14.275784100294112, irr5:481.7945556640625, ndcg5:0.8371375222687221, pnl5:4.737066745758057 
train 33, step: 0, loss: 1.261419770012149, grad_norm: 0.003992516384409808, ic: 0.2198089470724484
train 33, step: 500, loss: 1.014734418270149, grad_norm: 0.002566402727914618, ic: 0.014671645180330485
train 33, step: 1000, loss: 1.0423665102910638, grad_norm: 0.12948714419005922, ic: 0.13279886690166706
train 33, step: 1500, loss: 0.9006881985375891, grad_norm: 0.0008874798285588598, ic: 0.5343112258271016
train 33, step: 2000, loss: 0.830264422481676, grad_norm: 0.002621646995656451, ic: 0.2104874956896937
Epoch 33: 2022-05-05 16:25:42.394215: train loss: 1.630686900813774
Eval step 0: eval loss: 0.8275452624884746
Eval: 2022-05-05 16:25:46.349266: total loss: 1.0705639704338104, mse:4.608979280984274, ic :0.15499278922373197, sharpe5:16.14450953364372, irr5:526.6597900390625, ndcg5:0.843430610900462, pnl5:5.121373653411865 
train 34, step: 0, loss: 1.03249806517284, grad_norm: 0.014064101283393804, ic: 0.5671097532618391
train 34, step: 500, loss: 0.8021916847345661, grad_norm: 0.04348581234687267, ic: 0.10808526086839583
train 34, step: 1000, loss: 3.1993770101286483, grad_norm: 0.03654474430790378, ic: 0.27628510496719433
train 34, step: 1500, loss: 0.8107851230771379, grad_norm: 0.04201107631206613, ic: 0.6847494971444625
train 34, step: 2000, loss: 6.996124007552286, grad_norm: 0.08228030314001976, ic: 0.46325441224306374
Epoch 34: 2022-05-05 16:27:25.676068: train loss: 1.6293482568063136
Eval step 0: eval loss: 0.8247613133067703
Eval: 2022-05-05 16:27:29.552128: total loss: 1.0699257912685292, mse:4.598540488462691, ic :0.16903280668853587, sharpe5:16.599178186655045, irr5:574.1624755859375, ndcg5:0.8417974094715018, pnl5:4.949952125549316 
train 35, step: 0, loss: 1.2421987017463234, grad_norm: 0.0005317110777835306, ic: 0.54440013083184
train 35, step: 500, loss: 1.191944537158882, grad_norm: 0.016906925850999052, ic: -0.011120539811995036
train 35, step: 1000, loss: 1.780512783431197, grad_norm: 0.6609532098310147, ic: -0.013046067753260976
train 35, step: 1500, loss: 1.639101048519737, grad_norm: 0.22157744692783984, ic: -0.009670573911104319
train 35, step: 2000, loss: 0.7664220473345588, grad_norm: 0.005300587680664126, ic: 0.5919638316041392
Epoch 35: 2022-05-05 16:29:09.408301: train loss: 1.6280772213842034
Eval step 0: eval loss: 0.8229211901713974
Eval: 2022-05-05 16:29:13.370140: total loss: 1.0687876824590101, mse:4.591239189734366, ic :0.17487212192279825, sharpe5:16.794129692316055, irr5:572.6396484375, ndcg5:0.8619843247414286, pnl5:5.997405529022217 
train 36, step: 0, loss: 1.7685811328738228, grad_norm: 0.03156108618413506, ic: 0.15869261213219946
train 36, step: 500, loss: 0.8440046257818657, grad_norm: 0.002068805015977686, ic: 0.1687938403827607
train 36, step: 1000, loss: 1.7141713423295453, grad_norm: 0.5603518877382108, ic: 0.19189741270343486
train 36, step: 1500, loss: 0.7846162534519168, grad_norm: 0.004191839836103701, ic: 0.331632682812961
train 36, step: 2000, loss: 1.0797644653805103, grad_norm: 0.269520885700801, ic: 0.7772664290861311
Epoch 36: 2022-05-05 16:30:53.009004: train loss: 1.6267195090845046
Eval step 0: eval loss: 0.8236386265970758
Eval: 2022-05-05 16:30:56.969523: total loss: 1.068622563456784, mse:4.590667314452078, ic :0.17456708770616416, sharpe5:16.890216826200483, irr5:562.0186157226562, ndcg5:0.8543761452123902, pnl5:6.593064785003662 
train 37, step: 0, loss: 2.0821643496362943, grad_norm: 0.3709392053047204, ic: 0.06443745055249515
train 37, step: 500, loss: 2.329265849625306, grad_norm: 0.5037381536149064, ic: -0.01938825808653736
train 37, step: 1000, loss: 1.0704311330205956, grad_norm: 0.06290017498961685, ic: 0.10169475092929768
train 37, step: 1500, loss: 2.0341260302197806, grad_norm: 0.36001531490289573, ic: 0.6098400496929994
train 37, step: 2000, loss: 1.3303971908417256, grad_norm: 0.007592707306294304, ic: 0.12620297419660295
Epoch 37: 2022-05-05 16:32:36.352595: train loss: 1.6254902544646201
Eval step 0: eval loss: 0.8222952100072444
Eval: 2022-05-05 16:32:40.447730: total loss: 1.068467411122455, mse:4.587101014892861, ic :0.18096539907588938, sharpe5:18.076186323165892, irr5:607.4522094726562, ndcg5:0.8343300275631431, pnl5:7.343138217926025 
train 38, step: 0, loss: 1.3674217782369475, grad_norm: 0.011905034289212179, ic: -0.09153667606831897
train 38, step: 500, loss: 0.9278308256172839, grad_norm: 0.0036695082976753056, ic: 0.26048818578185534
train 38, step: 1000, loss: 0.9235446130805336, grad_norm: 0.0012928867159166556, ic: 0.0331193651005219
train 38, step: 1500, loss: 0.9634048589360289, grad_norm: 0.0031545202571862533, ic: 0.18318558324987932
train 38, step: 2000, loss: 2.2771611977199773, grad_norm: 0.8444549991168254, ic: -0.00898709131807069
Epoch 38: 2022-05-05 16:34:20.144892: train loss: 1.6254687198309192
Eval step 0: eval loss: 0.8216851157056769
Eval: 2022-05-05 16:34:24.043153: total loss: 1.0680680251973107, mse:4.5875015643381545, ic :0.18217036234582318, sharpe5:18.048644750118253, irr5:605.709716796875, ndcg5:0.8622417660679803, pnl5:8.1874361038208 
train 39, step: 0, loss: 0.9782053162927656, grad_norm: 0.011637467087484258, ic: 0.014459119739360315
train 39, step: 500, loss: 0.9231980695438605, grad_norm: 0.092717881335971, ic: 0.15525682031790747
train 39, step: 1000, loss: 0.9555641749571592, grad_norm: 0.005652402867258303, ic: 0.13869486530975036
train 39, step: 1500, loss: 2.1267981672815965, grad_norm: 0.15353083347753238, ic: 0.18191404953231954
train 39, step: 2000, loss: 0.6349646401066351, grad_norm: 0.04965122277949269, ic: -0.07346412071865571
Epoch 39: 2022-05-05 16:36:03.546656: train loss: 1.6248239183487176
Eval step 0: eval loss: 0.8230472480283522
Eval: 2022-05-05 16:36:07.511937: total loss: 1.0681944971869637, mse:4.583871626648536, ic :0.18159769812152624, sharpe5:17.78467472076416, irr5:599.068603515625, ndcg5:0.8491406775522117, pnl5:6.661083221435547 

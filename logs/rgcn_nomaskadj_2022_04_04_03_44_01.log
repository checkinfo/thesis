Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='AdjTimeDataset', dout=0.3, epochs=40, gnn_layers=2, gpu=0, hidden_dim=128, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=3, mask_adj=False, mask_type='soft', model_type='RGCNModel', normalize_adj=True, num_days=1, num_heads=1, print_inteval=500, relation_num=1, seed=10086, shuffle=True, side_info=False, sparse_adj_path=None, stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
34681
RGCNModel(
  (fc1): Linear(in_features=9, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
  (fc4): Linear(in_features=128, out_features=1, bias=True)
  (gnns): ModuleList(
    (0): RGCN(
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
    )
    (1): RGCN(
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
    )
  )
  (dropout): Dropout(p=0.3, inplace=False)
  (relu): LeakyReLU(negative_slope=0.01)
)
train 0, step: 0, loss: 2.0732888926630433, grad_norm: 0.4571042908578977, ic: -0.009383623809844158
train 0, step: 500, loss: 1.3642069113082829, grad_norm: 0.8709415292848554, ic: -0.03471360904052029
train 0, step: 1000, loss: 1.5054260353800124, grad_norm: 0.03234126869268386, ic: 0.22009186953017285
train 0, step: 1500, loss: 1.1944716128819177, grad_norm: 0.10910087294106885, ic: 0.05278342677172869
train 0, step: 2000, loss: 1.5635163842177973, grad_norm: 0.05292158802960662, ic: 0.021641517416896572
Epoch 0: 2022-04-04 15:44:39.272994: train loss: 1.6477371688872686
Eval step 0: eval loss: 1.007662724419102
Eval: 2022-04-04 15:44:42.112455: total loss: 1.0910365849393473, mse:4.884575347268827, ic :0.03431469832619059, sharpe5:1.584269845560193, irr5:22.713781356811523, ndcg5:0.8446222366497903, pnl5:1.0610520839691162 
train 1, step: 0, loss: 0.6397175552821396, grad_norm: 0.05391009182037028, ic: 0.046985675409951244
train 1, step: 500, loss: 1.2563311620308313, grad_norm: 0.31319390668036456, ic: 0.304531613643935
train 1, step: 1000, loss: 0.8759340033982429, grad_norm: 0.06519491802093107, ic: 0.10299954405852016
train 1, step: 1500, loss: 1.8634031342297066, grad_norm: 0.5629659216250589, ic: 0.076288315329989
train 1, step: 2000, loss: 1.3655231937332504, grad_norm: 0.23401349030790394, ic: 0.18218356951900486
Epoch 1: 2022-04-04 15:45:13.762277: train loss: 1.6450969830906985
Eval step 0: eval loss: 1.0038463397676407
Eval: 2022-04-04 15:45:16.609061: total loss: 1.0888247165814144, mse:4.878873213203536, ic :0.048564224709722395, sharpe5:3.074063468724489, irr5:34.28750228881836, ndcg5:0.8378842914591428, pnl5:1.3445452451705933 
train 2, step: 0, loss: 1.3252821060259607, grad_norm: 0.5155483194293228, ic: 0.08350285546468028
train 2, step: 500, loss: 0.9555962291943285, grad_norm: 0.29028865847237845, ic: 0.09146384391969499
train 2, step: 1000, loss: 3.1133651982453756, grad_norm: 1.608644635167092, ic: 0.14136338932714118
train 2, step: 1500, loss: 2.28738197611023, grad_norm: 0.8899886188088072, ic: 0.09717394677989
train 2, step: 2000, loss: 1.4515124342038022, grad_norm: 0.27636029537415713, ic: -0.11287969938374447
Epoch 2: 2022-04-04 15:45:48.150460: train loss: 1.6442169423769024
Eval step 0: eval loss: 0.9991420366187795
Eval: 2022-04-04 15:45:50.930369: total loss: 1.0891313172479926, mse:4.881060877143391, ic :0.04891268322192231, sharpe5:4.971925542354583, irr5:76.88797760009766, ndcg5:0.8595599822345467, pnl5:1.8802961111068726 
train 3, step: 0, loss: 1.8284220035147283, grad_norm: 0.06303381416571364, ic: -0.10750256773430836
train 3, step: 500, loss: 0.7756085513017466, grad_norm: 0.016520461202513787, ic: 0.08298993933988197
train 3, step: 1000, loss: 1.4194160356913526, grad_norm: 0.37871936970489395, ic: 0.20068388394162634
train 3, step: 1500, loss: 2.626274138389405, grad_norm: 0.3956203319956766, ic: -0.06341252191090185
train 3, step: 2000, loss: 1.3566114021070075, grad_norm: 0.16521764512087098, ic: 0.0756856411749276
Epoch 3: 2022-04-04 15:46:21.911029: train loss: 1.6450954068241508
Eval step 0: eval loss: 1.0039650031677856
Eval: 2022-04-04 15:46:24.670171: total loss: 1.0911835733413788, mse:4.880776885126208, ic :0.04928362340201767, sharpe5:3.202394135892391, irr5:37.52853775024414, ndcg5:0.8549321493474985, pnl5:1.221868634223938 
train 4, step: 0, loss: 1.154948102466229, grad_norm: 0.14809219917147243, ic: 0.09030782795729518
train 4, step: 500, loss: 0.989967813297194, grad_norm: 0.007251532384107573, ic: 0.159787577026765
train 4, step: 1000, loss: 1.3309194883438216, grad_norm: 0.06230894828373706, ic: 0.06732919407513861
train 4, step: 1500, loss: 1.0791671361678685, grad_norm: 0.09473302367101274, ic: 0.15896263324857157
train 4, step: 2000, loss: 4.189468491837136, grad_norm: 0.8998810774126124, ic: -0.03143788726055941
Epoch 4: 2022-04-04 15:46:55.246780: train loss: 1.6441632304049254
Eval step 0: eval loss: 1.0069200175256714
Eval: 2022-04-04 15:46:58.049037: total loss: 1.0938191044665844, mse:4.886504854483237, ic :0.049257645104097074, sharpe5:5.245450840294361, irr5:90.55558013916016, ndcg5:0.8481025307845101, pnl5:1.8823227882385254 
train 5, step: 0, loss: 0.9883589733672887, grad_norm: 0.15436104420272828, ic: -0.09592525856003419
train 5, step: 500, loss: 0.7890693941764169, grad_norm: 0.018078389456857382, ic: 0.15100753058545519
train 5, step: 1000, loss: 1.1213555942992004, grad_norm: 0.04423131364552928, ic: -0.1375282298237556
train 5, step: 1500, loss: 1.7636827918572155, grad_norm: 0.34803980898488285, ic: -0.03532020841008892
train 5, step: 2000, loss: 2.173793377422995, grad_norm: 0.8425951663219322, ic: 0.03464872666063412
Epoch 5: 2022-04-04 15:47:29.019271: train loss: 1.644185302956074
Eval step 0: eval loss: 1.00334443086822
Eval: 2022-04-04 15:47:31.759911: total loss: 1.0896091080629622, mse:4.875942389439197, ic :0.0543636780604073, sharpe5:4.576843587756157, irr5:82.25358581542969, ndcg5:0.8312882329215853, pnl5:2.1088829040527344 
train 6, step: 0, loss: 0.7801990757079911, grad_norm: 0.010863077469935254, ic: -0.0835392076289764
train 6, step: 500, loss: 1.4222735131693165, grad_norm: 0.25963162242389676, ic: 0.06066472320020086
train 6, step: 1000, loss: 1.2255386387942286, grad_norm: 0.18646089910040023, ic: 0.1921447602848245
train 6, step: 1500, loss: 1.0649336674528302, grad_norm: 0.31275708279961745, ic: 0.06249128920304525
train 6, step: 2000, loss: 2.2911454870345747, grad_norm: 1.0083398889836657, ic: 0.12471505080544382
Epoch 6: 2022-04-04 15:48:02.700277: train loss: 1.6436728818801305
Eval step 0: eval loss: 0.9996150189038638
Eval: 2022-04-04 15:48:05.447716: total loss: 1.0890079883315777, mse:4.876395215035188, ic :0.05399732313082154, sharpe5:7.660372225642204, irr5:216.3984832763672, ndcg5:0.8673446621554941, pnl5:3.434837818145752 
train 7, step: 0, loss: 1.4493649528289745, grad_norm: 0.531082262381899, ic: 0.2057391694633105
train 7, step: 500, loss: 1.3226603290079852, grad_norm: 0.02404296905988514, ic: 0.0952278711192906
train 7, step: 1000, loss: 0.6400174497729051, grad_norm: 0.020171926457779536, ic: 0.28539039979418773
train 7, step: 1500, loss: 1.006050303086627, grad_norm: 0.13117484443709768, ic: 0.08300396398750728
train 7, step: 2000, loss: 1.5963479760961437, grad_norm: 0.5508603137110588, ic: 0.3507826543626803
Epoch 7: 2022-04-04 15:48:36.340799: train loss: 1.6437614403589338
Eval step 0: eval loss: 0.9931061449899617
Eval: 2022-04-04 15:48:39.146487: total loss: 1.0865093502159617, mse:4.777095729700395, ic :0.11848861177684204, sharpe5:7.6893180254101745, irr5:227.1935577392578, ndcg5:0.8490144734328278, pnl5:4.029417514801025 
train 8, step: 0, loss: 1.2069826532879147, grad_norm: 0.08213835362603172, ic: 0.04073112773432251
train 8, step: 500, loss: 5.461303328271943, grad_norm: 1.8506536862879672, ic: 0.13685685287903152
train 8, step: 1000, loss: 1.878726356907895, grad_norm: 0.5466187773360437, ic: 0.06867661918511712
train 8, step: 1500, loss: 1.083202352594797, grad_norm: 0.3500106259724032, ic: 0.6400124417203301
train 8, step: 2000, loss: 1.1439222678160055, grad_norm: 0.5495118941941417, ic: -0.004027929249923795
Epoch 8: 2022-04-04 15:49:09.687999: train loss: 1.6377296074957781
Eval step 0: eval loss: 0.9996489594646852
Eval: 2022-04-04 15:49:12.418945: total loss: 1.0867759540715294, mse:4.71567236097729, ic :0.12454750076856232, sharpe5:7.981458195447922, irr5:232.68701171875, ndcg5:0.84097906463952, pnl5:4.083739280700684 
train 9, step: 0, loss: 1.1209348758798112, grad_norm: 0.026769935221331042, ic: 0.44057265221734065
train 9, step: 500, loss: 3.1755044086520168, grad_norm: 1.241466842516124, ic: 0.19990683018407504
train 9, step: 1000, loss: 0.8649975949185101, grad_norm: 0.0913855421395323, ic: 0.25360869923760976
train 9, step: 1500, loss: 2.162866329644449, grad_norm: 1.0564000008885095, ic: -0.024380329025146953
train 9, step: 2000, loss: 0.6027579438864575, grad_norm: 0.0006226520390467774, ic: 0.07358762256008501
Epoch 9: 2022-04-04 15:49:44.338991: train loss: 1.6365101228459606
Eval step 0: eval loss: 0.9944908941589322
Eval: 2022-04-04 15:49:47.271790: total loss: 1.0852856950907055, mse:4.739544179564671, ic :0.12304141203882844, sharpe5:9.269636857509612, irr5:270.8259582519531, ndcg5:0.8421510528180527, pnl5:3.421959400177002 
train 10, step: 0, loss: 1.2945287473304858, grad_norm: 0.05202258655198366, ic: 0.4010665128428193
train 10, step: 500, loss: 0.900275588306719, grad_norm: 0.006794346262509415, ic: 0.10151406020222054
train 10, step: 1000, loss: 1.529468037702956, grad_norm: 0.5087566189834705, ic: 0.037616031282198814
train 10, step: 1500, loss: 3.053917237288552, grad_norm: 1.1180217744919527, ic: 0.11101358889808075
train 10, step: 2000, loss: 1.3772172087231669, grad_norm: 0.1648066319399696, ic: 0.12736092396655704
Epoch 10: 2022-04-04 15:50:19.083877: train loss: 1.6344383394335773
Eval step 0: eval loss: 1.008916468165811
Eval: 2022-04-04 15:50:21.910866: total loss: 1.0842722427844158, mse:4.69169284397485, ic :0.15153318181868922, sharpe5:13.777381517887115, irr5:417.3154602050781, ndcg5:0.8527667432027051, pnl5:5.759860515594482 
train 11, step: 0, loss: 4.724029851202111, grad_norm: 1.4361146453585016, ic: 0.40609643379470806
train 11, step: 500, loss: 0.9889390420986943, grad_norm: 0.05684658573967764, ic: 0.03538823498539343
train 11, step: 1000, loss: 1.0383070793704712, grad_norm: 0.3665265130335181, ic: 0.0567698491277672
train 11, step: 1500, loss: 0.6924858601091425, grad_norm: 0.004296546931888624, ic: 0.0811612474432778
train 11, step: 2000, loss: 1.1251640164881194, grad_norm: 0.05500836398741676, ic: -0.1761062266655104
Epoch 11: 2022-04-04 15:50:52.630787: train loss: 1.6295260684865984
Eval step 0: eval loss: 0.9985336777786005
Eval: 2022-04-04 15:50:55.480831: total loss: 1.0817449974658815, mse:4.702217681722722, ic :0.1546406620061295, sharpe5:14.21774966597557, irr5:458.6300354003906, ndcg5:0.839932374841481, pnl5:6.222629070281982 
train 12, step: 0, loss: 1.375424971779943, grad_norm: 0.2755942969142391, ic: 0.14155844106008347
train 12, step: 500, loss: 0.8250669797010655, grad_norm: 0.4317260036370251, ic: 0.021406357406889315
train 12, step: 1000, loss: 1.1917693206062416, grad_norm: 0.5148695087700927, ic: 0.6187483940767446
train 12, step: 1500, loss: 1.0844735895092699, grad_norm: 0.24549909201219955, ic: 0.06804401352011497
train 12, step: 2000, loss: 1.1108473374524883, grad_norm: 0.06107973317353066, ic: 0.12803971231451933
Epoch 12: 2022-04-04 15:51:26.590816: train loss: 1.6281764936541883
Eval step 0: eval loss: 1.0051221320226105
Eval: 2022-04-04 15:51:29.347820: total loss: 1.0841867006430148, mse:4.699122870463223, ic :0.15308122009574598, sharpe5:13.294844947457312, irr5:413.7691345214844, ndcg5:0.8491842020629466, pnl5:6.356634616851807 
train 13, step: 0, loss: 1.0766878678364775, grad_norm: 0.04536657382478303, ic: 0.44212370727345035
train 13, step: 500, loss: 1.1475537482108777, grad_norm: 0.009889740044779272, ic: -0.17239479565606425
train 13, step: 1000, loss: 1.3825328235641228, grad_norm: 0.4135659950952032, ic: 0.06686319816812752
train 13, step: 1500, loss: 0.775158236197322, grad_norm: 0.012170407842130925, ic: -0.01355586135054556
train 13, step: 2000, loss: 1.0345300536734352, grad_norm: 0.030386202560441156, ic: 0.06968048180151315
Epoch 13: 2022-04-04 15:52:00.468715: train loss: 1.6289079630301153
Eval step 0: eval loss: 0.9927279134371708
Eval: 2022-04-04 15:52:03.294858: total loss: 1.0854117877222105, mse:4.7430080185114445, ic :0.12186397411775214, sharpe5:7.67343404084444, irr5:218.19639587402344, ndcg5:0.8443988396425363, pnl5:2.9917521476745605 
train 14, step: 0, loss: 1.7559840315479343, grad_norm: 0.504455228147892, ic: 0.1658879926696681
train 14, step: 500, loss: 1.268600968382623, grad_norm: 0.15900760111451423, ic: 0.2231153343745228
train 14, step: 1000, loss: 1.065679477660124, grad_norm: 0.1960656364935629, ic: 0.1492347351135314
train 14, step: 1500, loss: 0.9739561719652136, grad_norm: 0.10646193113020319, ic: 0.16615221265470584
train 14, step: 2000, loss: 2.3118436480424145, grad_norm: 0.5447673612551027, ic: -0.07483167875200561
Epoch 14: 2022-04-04 15:52:34.735555: train loss: 1.6283867714627178
Eval step 0: eval loss: 1.0032282101599526
Eval: 2022-04-04 15:52:37.617070: total loss: 1.0876172287292487, mse:4.7217126166632415, ic :0.12238615659220127, sharpe5:8.301196221113205, irr5:236.64559936523438, ndcg5:0.8536585986422771, pnl5:4.164678573608398 
train 15, step: 0, loss: 0.9806921396460994, grad_norm: 0.16420847015511641, ic: 0.126595778000614
train 15, step: 500, loss: 1.22708547197288, grad_norm: 0.016200330958363873, ic: 0.07447514468848222
train 15, step: 1000, loss: 1.7522885416666667, grad_norm: 0.06420662250253112, ic: -0.014937095029847094
train 15, step: 1500, loss: 5.39626062663138, grad_norm: 0.8564628171219592, ic: 0.007497337464133953
train 15, step: 2000, loss: 0.9269673462589978, grad_norm: 0.019665301373501223, ic: 0.026637772407049096
Epoch 15: 2022-04-04 15:53:08.703963: train loss: 1.6295931222968714
Eval step 0: eval loss: 1.0104430863077605
Eval: 2022-04-04 15:53:11.536723: total loss: 1.083791802716534, mse:4.681801066382861, ic :0.1684081659677521, sharpe5:15.56364303946495, irr5:523.7938842773438, ndcg5:0.8395444884222565, pnl5:6.769381046295166 
train 16, step: 0, loss: 6.382372926112943, grad_norm: 3.5985210901426883, ic: 0.16024506146327305
train 16, step: 500, loss: 1.3600681849888392, grad_norm: 0.7386129320127285, ic: -0.02023128100825453
train 16, step: 1000, loss: 0.8408769704371474, grad_norm: 0.3174633822307539, ic: -0.030527942914010196
train 16, step: 1500, loss: 1.232797892657326, grad_norm: 0.3352709564657749, ic: 0.13090068157586096
train 16, step: 2000, loss: 0.9553883901399879, grad_norm: 0.33165467927127285, ic: 0.547161535328652
Epoch 16: 2022-04-04 15:53:43.015245: train loss: 1.6255605327868679
Eval step 0: eval loss: 0.9971035459658043
Eval: 2022-04-04 15:53:45.764278: total loss: 1.0819553169076208, mse:4.71336184685126, ic :0.1597028713073728, sharpe5:14.85836461186409, irr5:485.1055603027344, ndcg5:0.8467909706897327, pnl5:4.75657844543457 
train 17, step: 0, loss: 1.1850786267614073, grad_norm: 0.0077189535324579854, ic: 0.10371550297186533
train 17, step: 500, loss: 1.0402923633768353, grad_norm: 0.027765961990499268, ic: -0.021775805561654128
train 17, step: 1000, loss: 3.3858779554713285, grad_norm: 1.4513584382471767, ic: -0.01630387207126867
train 17, step: 1500, loss: 0.8870454559819985, grad_norm: 0.0060557411310736935, ic: 0.029321713048042444
train 17, step: 2000, loss: 1.0111839345637583, grad_norm: 0.6507902506084466, ic: 0.5840124600981305
Epoch 17: 2022-04-04 15:54:17.337561: train loss: 1.628643373080663
Eval step 0: eval loss: 1.00886433597864
Eval: 2022-04-04 15:54:20.203189: total loss: 1.0861767208088458, mse:4.7220863013904735, ic :0.15110823862452488, sharpe5:13.399492709040642, irr5:430.0302429199219, ndcg5:0.8546245025296548, pnl5:4.871937274932861 
train 18, step: 0, loss: 0.8491063121804832, grad_norm: 0.0643028658311699, ic: 0.05463098874927079
train 18, step: 500, loss: 2.515255880238291, grad_norm: 1.0561380684429857, ic: 0.08020460566488385
train 18, step: 1000, loss: 1.36775648816884, grad_norm: 0.5012898070607685, ic: 0.5343807807086745
train 18, step: 1500, loss: 1.6874893851902175, grad_norm: 2.6824621929950476, ic: 0.34613127311856406
train 18, step: 2000, loss: 1.248066902711583, grad_norm: 0.3244108488699868, ic: 0.22821520589304095
Epoch 18: 2022-04-04 15:54:49.076004: train loss: 1.6262892305089234
Eval step 0: eval loss: 0.9993840559587281
Eval: 2022-04-04 15:54:51.564710: total loss: 1.0819918137274107, mse:4.686370642455283, ic :0.16984973012610452, sharpe5:15.586534441709517, irr5:520.727294921875, ndcg5:0.8388258158583126, pnl5:7.121762275695801 
train 19, step: 0, loss: 2.210667768506121, grad_norm: 0.7221342033482467, ic: 0.25239112557664345
train 19, step: 500, loss: 1.0188952068949855, grad_norm: 0.060340465789250425, ic: 0.08451928335526213
train 19, step: 1000, loss: 0.9776003792950725, grad_norm: 0.5501888952155469, ic: 0.561463008978117
train 19, step: 1500, loss: 1.5728379237798995, grad_norm: 0.055798061876223604, ic: 0.16010776574522526
train 19, step: 2000, loss: 1.6733789289080627, grad_norm: 1.7458121229871726, ic: 0.6382827817927539
Epoch 19: 2022-04-04 15:55:19.309076: train loss: 1.625906229190579
Eval step 0: eval loss: 0.998792024585308
Eval: 2022-04-04 15:55:21.749507: total loss: 1.0799911150238555, mse:4.685177158713042, ic :0.16529246583727364, sharpe5:15.009449758529662, irr5:485.0023193359375, ndcg5:0.8537018217796699, pnl5:6.1599297523498535 
train 20, step: 0, loss: 1.2518894262147366, grad_norm: 0.38876036174449485, ic: 0.46419616780325323
train 20, step: 500, loss: 1.219100322835766, grad_norm: 0.4410764964258499, ic: 0.02830811458781343
train 20, step: 1000, loss: 1.5583275087678667, grad_norm: 0.4246381469987386, ic: 0.1936124453881704
train 20, step: 1500, loss: 0.9131137701363073, grad_norm: 1.1231751244654313, ic: 0.5671486204924173
train 20, step: 2000, loss: 1.3528177420169765, grad_norm: 0.17342413867752265, ic: -0.03715238242760947
Epoch 20: 2022-04-04 15:55:48.943586: train loss: 1.6249710075948773
Eval step 0: eval loss: 0.9990846976410281
Eval: 2022-04-04 15:55:51.405000: total loss: 1.0860495729611666, mse:4.734415049188565, ic :0.15438700697578586, sharpe5:14.437753068208695, irr5:465.6962890625, ndcg5:0.860021191117663, pnl5:6.124816417694092 
train 21, step: 0, loss: 1.3735677557853498, grad_norm: 0.31093817448339156, ic: 0.3074525972994072
train 21, step: 500, loss: 1.108109652950459, grad_norm: 0.08822493523394223, ic: 0.07428804778758949
train 21, step: 1000, loss: 0.9069721908381265, grad_norm: 0.2876316129935062, ic: 0.07136183983431872
train 21, step: 1500, loss: 0.732730471387576, grad_norm: 0.2266884805602879, ic: 0.6317343219158945
train 21, step: 2000, loss: 1.1283641932819382, grad_norm: 0.15222518602258478, ic: 0.29933804416374915
Epoch 21: 2022-04-04 15:56:20.083854: train loss: 1.62477397223433
Eval step 0: eval loss: 1.0023965378570958
Eval: 2022-04-04 15:56:22.964009: total loss: 1.080873054745009, mse:4.692862715962178, ic :0.1581222602142499, sharpe5:13.351551302075386, irr5:424.133056640625, ndcg5:0.8598494784353636, pnl5:4.789018630981445 
train 22, step: 0, loss: 1.0493154249773915, grad_norm: 0.44653032106338997, ic: 0.0687382236562961
train 22, step: 500, loss: 1.0251804141547736, grad_norm: 0.0007444033003963808, ic: 0.007319598020773858
train 22, step: 1000, loss: 0.9105761644032134, grad_norm: 0.011806602115780378, ic: 0.1343300582945933
train 22, step: 1500, loss: 0.9997362748856113, grad_norm: 0.08932206582628847, ic: 0.2666365132140367
train 22, step: 2000, loss: 1.0440023732739825, grad_norm: 0.11246561636978748, ic: 0.14772406348479844
Epoch 22: 2022-04-04 15:56:54.695383: train loss: 1.6244571088977673
Eval step 0: eval loss: 1.0119292714710044
Eval: 2022-04-04 15:56:57.585059: total loss: 1.0822675963893713, mse:4.682493049434595, ic :0.16226066846062606, sharpe5:14.118271388411522, irr5:445.3383483886719, ndcg5:0.8536608398734287, pnl5:5.3139872550964355 
train 23, step: 0, loss: 1.2792906469228318, grad_norm: 1.514204344195087, ic: 0.019277198101421637
train 23, step: 500, loss: 0.8975769713684754, grad_norm: 0.1549020712819305, ic: 0.6007531262347678
train 23, step: 1000, loss: 2.2820098925316956, grad_norm: 0.9229908744555219, ic: 0.1155606577046474
train 23, step: 1500, loss: 0.7752003482987925, grad_norm: 0.32630959575627916, ic: 0.7194889044608956
train 23, step: 2000, loss: 1.4741617838541667, grad_norm: 0.3872293977527995, ic: 0.40818575107791283
Epoch 23: 2022-04-04 15:57:29.613426: train loss: 1.6240028935717676
Eval step 0: eval loss: 1.003469522404884
Eval: 2022-04-04 15:57:32.301734: total loss: 1.0841164976327933, mse:4.686683826901602, ic :0.15995418391350838, sharpe5:13.192778617143631, irr5:430.7601013183594, ndcg5:0.8378761266447127, pnl5:4.196206092834473 
train 24, step: 0, loss: 1.176514910683792, grad_norm: 0.3950804029723237, ic: 0.32816847255472176
train 24, step: 500, loss: 1.245737502085717, grad_norm: 0.3297640100902443, ic: 0.01946832014299938
train 24, step: 1000, loss: 1.0345380829601754, grad_norm: 0.3322271138549383, ic: 0.11096249815908006
train 24, step: 1500, loss: 1.2032172736220472, grad_norm: 0.07088518702057875, ic: 0.044787272392818295
train 24, step: 2000, loss: 1.3710065844687993, grad_norm: 0.5991447841041466, ic: 0.440427728050409
Epoch 24: 2022-04-04 15:58:04.188042: train loss: 1.624735397368779
Eval step 0: eval loss: 1.0108779497432858
Eval: 2022-04-04 15:58:06.845377: total loss: 1.082327441906629, mse:4.689043753017475, ic :0.16392569926259748, sharpe5:15.45296500146389, irr5:516.7838134765625, ndcg5:0.8564893044087021, pnl5:5.938620090484619 
train 25, step: 0, loss: 1.3001898283833382, grad_norm: 0.44359843780626934, ic: 0.2143513481624556
train 25, step: 500, loss: 1.4886795638443588, grad_norm: 0.6874456564667836, ic: 0.10196833098889736
train 25, step: 1000, loss: 1.361527199989218, grad_norm: 0.1750321126458657, ic: 0.2759331620918361
train 25, step: 1500, loss: 2.879494173248003, grad_norm: 1.3143665409285374, ic: 0.2203455359129784
train 25, step: 2000, loss: 1.1930706169031844, grad_norm: 0.20232563017132943, ic: 0.15053900416665927
Epoch 25: 2022-04-04 15:58:38.888968: train loss: 1.6257902798274384
Eval step 0: eval loss: 1.00170564174401
Eval: 2022-04-04 15:58:41.752692: total loss: 1.0797815668865742, mse:4.678611683331676, ic :0.17106541189310123, sharpe5:15.339247704148292, irr5:503.3046875, ndcg5:0.8491334980267279, pnl5:5.501438617706299 
train 26, step: 0, loss: 1.6152136008522726, grad_norm: 0.3666748928138917, ic: 0.22096238548389668
train 26, step: 500, loss: 1.0260680801278759, grad_norm: 0.24783974704618356, ic: -0.029740413604367015
train 26, step: 1000, loss: 1.8200588051623647, grad_norm: 0.5611907338407875, ic: 0.19334677517224247
train 26, step: 1500, loss: 0.9226383910874736, grad_norm: 0.01910990535572253, ic: -0.027750196757491498
train 26, step: 2000, loss: 0.98705093503937, grad_norm: 0.09969847216761861, ic: 0.17344339248581794
Epoch 26: 2022-04-04 15:59:13.403105: train loss: 1.624615633722102
Eval step 0: eval loss: 0.9974526580601631
Eval: 2022-04-04 15:59:16.257021: total loss: 1.081011377588463, mse:4.687511128999828, ic :0.16405079448172655, sharpe5:14.57850776016712, irr5:479.4165954589844, ndcg5:0.8442581416925046, pnl5:4.958592891693115 
train 27, step: 0, loss: 1.6323468311723457, grad_norm: 0.43390589552712955, ic: 0.6696435807968809
train 27, step: 500, loss: 1.517163883286353, grad_norm: 0.581525802063021, ic: 0.059979205898583826
train 27, step: 1000, loss: 2.563321769376457, grad_norm: 0.835589678358162, ic: 0.4089931520120435
train 27, step: 1500, loss: 0.8636087474518563, grad_norm: 0.7624019971613633, ic: 0.5530247883762768
train 27, step: 2000, loss: 1.3463806996147754, grad_norm: 1.1778860421172606, ic: 0.011104344085539512
Epoch 27: 2022-04-04 15:59:47.557479: train loss: 1.6236701767753128
Eval step 0: eval loss: 1.00193641184505
Eval: 2022-04-04 15:59:50.399831: total loss: 1.079546539920978, mse:4.694724640216428, ic :0.16878453768624457, sharpe5:14.7821002972126, irr5:489.12371826171875, ndcg5:0.843003932017003, pnl5:5.398874759674072 
train 28, step: 0, loss: 1.1577081482074552, grad_norm: 0.12525302793271642, ic: 0.1373084811996329
train 28, step: 500, loss: 2.959002273283052, grad_norm: 1.1048889144530136, ic: 0.08171223072860226
train 28, step: 1000, loss: 2.7812006319115326, grad_norm: 1.8533936645308506, ic: -0.04310236686773395
train 28, step: 1500, loss: 1.0259566059463987, grad_norm: 0.0036168838284340926, ic: 0.1992956365468465
train 28, step: 2000, loss: 1.7701226167900617, grad_norm: 0.4020411889909459, ic: 0.08353578615329488
Epoch 28: 2022-04-04 16:00:22.404338: train loss: 1.6235073612441169
Eval step 0: eval loss: 1.0059748886132502
Eval: 2022-04-04 16:00:25.393625: total loss: 1.0797942828500247, mse:4.684419975427659, ic :0.168359090538395, sharpe5:14.991313524842262, irr5:486.85931396484375, ndcg5:0.8295453252144599, pnl5:4.879267692565918 
train 29, step: 0, loss: 1.5195198666425795, grad_norm: 0.13350396451430235, ic: 0.08057402339354462
train 29, step: 500, loss: 2.591492000875206, grad_norm: 1.4094746234756326, ic: -0.09963340242825633
train 29, step: 1000, loss: 1.7164655533628892, grad_norm: 0.9661083807093209, ic: 0.48362904839414
train 29, step: 1500, loss: 3.934875389995974, grad_norm: 1.11198128318227, ic: 0.13470270714704902
train 29, step: 2000, loss: 0.9371557057888252, grad_norm: 0.1991105603865628, ic: 0.47750988406534345
Epoch 29: 2022-04-04 16:00:57.223640: train loss: 1.624130750346565
Eval step 0: eval loss: 1.001690921311381
Eval: 2022-04-04 16:01:00.049962: total loss: 1.0801568863810669, mse:4.688737214139096, ic :0.1668033015832688, sharpe5:15.156514720916748, irr5:496.97674560546875, ndcg5:0.8505918672595146, pnl5:5.060556411743164 
train 30, step: 0, loss: 1.2495145833826173, grad_norm: 0.04381722772218847, ic: 0.988060512138278
train 30, step: 500, loss: 1.945590828038469, grad_norm: 0.28924180215216144, ic: 0.16083958423014924
train 30, step: 1000, loss: 3.4555221930766686, grad_norm: 1.2695651785302082, ic: 0.39941935295814196
train 30, step: 1500, loss: 1.0727026043915515, grad_norm: 0.1992176008885033, ic: 0.15878905107328747
train 30, step: 2000, loss: 1.0866472028378427, grad_norm: 0.08782795501528676, ic: 0.4420683863271072
Epoch 30: 2022-04-04 16:01:32.080595: train loss: 1.6246591835096522
Eval step 0: eval loss: 0.9978094196369799
Eval: 2022-04-04 16:01:34.896095: total loss: 1.0799579364448293, mse:4.685796227995481, ic :0.1663743138709712, sharpe5:15.010094879865646, irr5:491.0238952636719, ndcg5:0.8563919469270489, pnl5:4.648870944976807 
train 31, step: 0, loss: 1.175224365627516, grad_norm: 0.2816939028109224, ic: 0.19450653606261367
train 31, step: 500, loss: 0.8264371413407889, grad_norm: 0.0801548368254342, ic: 0.19841771716366677
train 31, step: 1000, loss: 5.157194643725681, grad_norm: 1.1689352664923591, ic: 0.041564237293903177
train 31, step: 1500, loss: 1.6897838657385047, grad_norm: 0.3327245045529313, ic: 0.2636792758236156
train 31, step: 2000, loss: 0.970479376197318, grad_norm: 0.39049251500571125, ic: 0.18812204461046683
Epoch 31: 2022-04-04 16:02:06.900894: train loss: 1.624020626673518
Eval step 0: eval loss: 1.0062435847197537
Eval: 2022-04-04 16:02:09.700601: total loss: 1.0804277439197372, mse:4.674163531567068, ic :0.17039094343468744, sharpe5:14.89275279521942, irr5:490.0444641113281, ndcg5:0.857746268756269, pnl5:4.53283166885376 
train 32, step: 0, loss: 0.8766045906581691, grad_norm: 0.42621120062360945, ic: 0.11368299627004892
train 32, step: 500, loss: 1.111769792510242, grad_norm: 0.36207700289902267, ic: 0.1048288286356889
train 32, step: 1000, loss: 1.37781628528764, grad_norm: 0.018503188786903494, ic: 0.08703247261584639
train 32, step: 1500, loss: 2.055888928865132, grad_norm: 0.5053329909837986, ic: 0.44142351996108153
train 32, step: 2000, loss: 1.0753311845525777, grad_norm: 0.3914273572217397, ic: 0.46615974824277073
Epoch 32: 2022-04-04 16:02:42.687206: train loss: 1.6218654662622487
Eval step 0: eval loss: 1.0072232970066481
Eval: 2022-04-04 16:02:45.467569: total loss: 1.0798744718017848, mse:4.67441501953515, ic :0.17501749786286247, sharpe5:15.326181632280349, irr5:522.640380859375, ndcg5:0.8446696268728618, pnl5:5.131994724273682 
train 33, step: 0, loss: 1.1627588002530558, grad_norm: 0.01801369635808792, ic: 0.03546738136725242
train 33, step: 500, loss: 3.1666401446003074, grad_norm: 0.26652127488526384, ic: 0.5260093584645423
train 33, step: 1000, loss: 5.259009553668974, grad_norm: 4.037833532520382, ic: 0.022099978549864605
train 33, step: 1500, loss: 1.3392490293921493, grad_norm: 1.2237059975706674, ic: 0.016339713841533092
train 33, step: 2000, loss: 1.8580119761385658, grad_norm: 0.29938024181684025, ic: 0.07106637112119069
Epoch 33: 2022-04-04 16:03:17.583358: train loss: 1.624115873772633
Eval step 0: eval loss: 1.0112538028855647
Eval: 2022-04-04 16:03:20.520213: total loss: 1.0822588174427332, mse:4.675579542329904, ic :0.16928022910940058, sharpe5:14.571229807734488, irr5:469.4760437011719, ndcg5:0.8499781388798147, pnl5:4.875644207000732 
train 34, step: 0, loss: 0.7219437540238709, grad_norm: 0.298286907886198, ic: 0.16172854896733752
train 34, step: 500, loss: 1.8290084348120792, grad_norm: 0.4351656005146583, ic: 0.8091373904515418
train 34, step: 1000, loss: 0.6873369308997844, grad_norm: 0.0644995173035192, ic: 0.48743069010515105
train 34, step: 1500, loss: 1.6497574243790063, grad_norm: 1.4573969875258108, ic: 0.6449141966740901
train 34, step: 2000, loss: 2.9992971404576814, grad_norm: 0.46543277195315735, ic: 0.07539122625848577
Epoch 34: 2022-04-04 16:03:52.033705: train loss: 1.6234665375170736
Eval step 0: eval loss: 1.0093597524601763
Eval: 2022-04-04 16:03:54.912755: total loss: 1.0803362128394605, mse:4.680728880315308, ic :0.1686967440824958, sharpe5:15.011185532212256, irr5:481.31915283203125, ndcg5:0.8527771000856068, pnl5:3.6788692474365234 
train 35, step: 0, loss: 1.0537364331981804, grad_norm: 0.7015637852755615, ic: -0.003375320730828836
train 35, step: 500, loss: 3.297707297585227, grad_norm: 1.0622700928840907, ic: -0.05505534117805737
train 35, step: 1000, loss: 1.3439424807748823, grad_norm: 0.09242736576671498, ic: 0.505084064529123
train 35, step: 1500, loss: 1.6395196688165439, grad_norm: 0.37117294707181075, ic: 0.09968182776213852
train 35, step: 2000, loss: 1.2828415187163202, grad_norm: 0.0988650813854128, ic: 0.005018371214463281
Epoch 35: 2022-04-04 16:04:27.139788: train loss: 1.623568090647413
Eval step 0: eval loss: 0.9972201523622629
Eval: 2022-04-04 16:04:29.943433: total loss: 1.0803877635248174, mse:4.682035487264971, ic :0.16728258757167982, sharpe5:14.893611695766449, irr5:485.9535217285156, ndcg5:0.862868840050642, pnl5:4.816280364990234 
train 36, step: 0, loss: 8.990113364492897, grad_norm: 1.1405011137704422, ic: 0.0005115319290355524
train 36, step: 500, loss: 0.8601757110202971, grad_norm: 0.006796677100181564, ic: 0.10043285111600879
train 36, step: 1000, loss: 1.961345452305756, grad_norm: 1.877054903026089, ic: 0.07328073717016484
train 36, step: 1500, loss: 1.04772241974761, grad_norm: 0.1269052057344894, ic: 0.0694320879271202
train 36, step: 2000, loss: 2.196406893761036, grad_norm: 1.1237534230456128, ic: 0.3854907786356729
Epoch 36: 2022-04-04 16:05:01.443547: train loss: 1.6233474951906148
Eval step 0: eval loss: 1.0131260619281528
Eval: 2022-04-04 16:05:04.324927: total loss: 1.0825028667181174, mse:4.678872057695224, ic :0.16899828066704248, sharpe5:15.651999122500419, irr5:501.2508239746094, ndcg5:0.8533716971851352, pnl5:5.384904861450195 
train 37, step: 0, loss: 1.201163764944874, grad_norm: 0.17878398287435365, ic: 0.17670677954101283
train 37, step: 500, loss: 2.3402380219139003, grad_norm: 0.03190246112646335, ic: 0.15187794346467653
train 37, step: 1000, loss: 0.7546291925638867, grad_norm: 0.35310877810057756, ic: 0.16104993528116435
train 37, step: 1500, loss: 3.105733029128331, grad_norm: 0.7537472908572938, ic: 0.18845598204925637
train 37, step: 2000, loss: 3.142074248455323, grad_norm: 1.6218731986515085, ic: -0.010727166435749284
Epoch 37: 2022-04-04 16:05:36.046248: train loss: 1.6225057804013499
Eval step 0: eval loss: 1.0056660166535019
Eval: 2022-04-04 16:05:38.870157: total loss: 1.0793618084186203, mse:4.675572430862298, ic :0.17412922358165797, sharpe5:15.568085106611251, irr5:521.200927734375, ndcg5:0.8511509752674142, pnl5:4.9739203453063965 
train 38, step: 0, loss: 1.3403982451467804, grad_norm: 0.28080783954031147, ic: -0.2308439483524196
train 38, step: 500, loss: 1.6972043059593023, grad_norm: 0.928273414083965, ic: 0.24662300044965077
train 38, step: 1000, loss: 1.832837508591909, grad_norm: 0.7199520606704808, ic: 0.14755554417541653
train 38, step: 1500, loss: 1.0735284265393232, grad_norm: 0.3537207216783511, ic: 0.4868182778972513
train 38, step: 2000, loss: 0.7575400604959704, grad_norm: 0.05874113903028091, ic: 0.5606454603109994
Epoch 38: 2022-04-04 16:06:10.581376: train loss: 1.6221508932559427
Eval step 0: eval loss: 0.9961490319740652
Eval: 2022-04-04 16:06:13.313462: total loss: 1.0796759994749736, mse:4.70829206391227, ic :0.16987654755764836, sharpe5:15.717617989182472, irr5:537.9436645507812, ndcg5:0.8493264433574571, pnl5:5.683663368225098 
train 39, step: 0, loss: 0.8722325908064277, grad_norm: 0.03472849374212879, ic: 0.5359130269588938
train 39, step: 500, loss: 1.241043543567061, grad_norm: 0.36063236393432174, ic: 0.06157740918746578
train 39, step: 1000, loss: 1.4067626953125, grad_norm: 0.38455160582915576, ic: 0.08415208918387546
train 39, step: 1500, loss: 2.4462896708238167, grad_norm: 0.5790652332845401, ic: -0.05761728261968863
train 39, step: 2000, loss: 2.9520473064922994, grad_norm: 2.0362902306837585, ic: 0.19146330827503544
Epoch 39: 2022-04-04 16:06:45.628083: train loss: 1.6214064078372963
Eval step 0: eval loss: 0.9991928831786465
Eval: 2022-04-04 16:06:48.379845: total loss: 1.0790822490292822, mse:4.676969405723655, ic :0.17143376022505377, sharpe5:15.059996244907378, irr5:520.7590942382812, ndcg5:0.851853823713443, pnl5:5.137232303619385 

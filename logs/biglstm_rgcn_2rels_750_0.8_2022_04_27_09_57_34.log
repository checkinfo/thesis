Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='RGCNSeqTimeDataset', dout=0.3, epochs=40, glstm_layers=1, gnn_layers=1, gpu=0, graph_attn=False, hidden_dim=128, inner_prod=False, input_dim=9, input_graph=True, label_cnt=3, lr=0.0004, lstm_layers=1, market=None, mask_adj=True, mask_type='soft', model_type='BiGLSTM', normalize_adj=True, num_days=8, num_heads=1, print_inteval=500, rank_loss=False, relation_num=2, rsr_data_path=None, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_750_0.8/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
load 2305 train graphs successful!
load 126 test graphs successful!
12521
BiGLSTM(
  (input_to_hidden): Linear(in_features=9, out_features=128, bias=True)
  (forward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
            (1): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
  )
  (backward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
            (1): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
  )
  (fc0): ModuleList(
    (0): Linear(in_features=256, out_features=128, bias=True)
  )
  (w_out): Linear(in_features=128, out_features=1, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
)
train 0, step: 0, loss: 4.814984546032056, grad_norm: 5.259107504778579, ic: 0.026900975391417687
train 0, step: 500, loss: 0.8633658805105501, grad_norm: 0.02823888442345531, ic: 0.03922672334119818
train 0, step: 1000, loss: 1.9567221004594917, grad_norm: 0.5435984529283888, ic: 0.026946927154836334
train 0, step: 1500, loss: 0.9551477967514822, grad_norm: 0.04682835301280238, ic: 0.03251449345889095
train 0, step: 2000, loss: 1.0046374415046795, grad_norm: 0.16992858327493277, ic: 0.005059220280157718
Epoch 0: 2022-04-27 22:19:00.608748: train loss: 1.6487462555751766
Eval step 0: eval loss: 0.8365250839699683
Eval: 2022-04-27 22:20:26.687710: total loss: 1.079406738478865, mse:4.822805754110541, ic :0.008460207332620893, sharpe5:7.800663886964321, irr5:221.48207092285156, ndcg5:0.8719673977147181, pnl5:2.5669517517089844 
train 1, step: 0, loss: 2.776543992565524, grad_norm: 0.9227254294893494, ic: 0.03014803329712222
train 1, step: 500, loss: 1.7520328663369258, grad_norm: 0.8021285510685079, ic: 0.10523234138230014
train 1, step: 1000, loss: 0.8787752216251369, grad_norm: 0.1836687180032042, ic: 0.06063267036378038
train 1, step: 1500, loss: 1.714752688353089, grad_norm: 0.21720732936567064, ic: -0.013016278945093138
train 1, step: 2000, loss: 2.1811195312500002, grad_norm: 0.9291594455191151, ic: -0.011760094371371078
Epoch 1: 2022-04-27 22:42:41.022384: train loss: 1.6467922903867704
Eval step 0: eval loss: 0.8342994553271535
Eval: 2022-04-27 22:44:02.838046: total loss: 1.078929504855404, mse:4.82376108735069, ic :0.008670920025594485, sharpe5:7.368138408958911, irr5:208.5674285888672, ndcg5:0.8456689622890805, pnl5:2.7551064491271973 
train 2, step: 0, loss: 2.1418052201704545, grad_norm: 0.009909971065853847, ic: 0.14926872820660406
train 2, step: 500, loss: 3.3011140301007433, grad_norm: 0.29337974118920757, ic: 0.06172169570719603
train 2, step: 1000, loss: 2.0724828259698276, grad_norm: 0.00023562854547372607, ic: 0.14414106778435376
train 2, step: 1500, loss: 1.4871609986283396, grad_norm: 0.06305237663093811, ic: -0.06990792262541214
train 2, step: 2000, loss: 3.2329788912259616, grad_norm: 0.8040325673058103, ic: 0.21780271765704487
Epoch 2: 2022-04-27 23:06:15.955409: train loss: 1.646504748394393
Eval step 0: eval loss: 0.836141765180453
Eval: 2022-04-27 23:07:31.846021: total loss: 1.079360323557963, mse:4.8221302278861815, ic :0.0159584828497845, sharpe5:7.552444466650486, irr5:214.1722869873047, ndcg5:0.8383904158235583, pnl5:2.8268654346466064 
train 3, step: 0, loss: 1.5222809086001017, grad_norm: 0.5360935302982417, ic: -0.001284372752631699
train 3, step: 500, loss: 1.5030606478195967, grad_norm: 0.3502575961328011, ic: 0.08743900684425511
train 3, step: 1000, loss: 3.6782369926597585, grad_norm: 0.7185676085107402, ic: 0.0197810434735326
train 3, step: 1500, loss: 1.9768531911697014, grad_norm: 1.1786974271680182, ic: -0.050790594338599185
train 3, step: 2000, loss: 0.8974970967060811, grad_norm: 0.0007432197557364676, ic: 0.028417294050380813
Epoch 3: 2022-04-27 23:29:14.742592: train loss: 1.6458600988521208
Eval step 0: eval loss: 0.8348530808540239
Eval: 2022-04-27 23:30:28.708702: total loss: 1.0779000360812907, mse:4.819136355879881, ic :0.034622041617753216, sharpe5:7.731655295491218, irr5:213.25885009765625, ndcg5:0.870234508692323, pnl5:2.834879159927368 
train 4, step: 0, loss: 1.4373732461734694, grad_norm: 0.04390330389075461, ic: 0.06375529374578201
train 4, step: 500, loss: 1.6461072065698819, grad_norm: 0.5645411966729237, ic: 0.09553683667213483
train 4, step: 1000, loss: 2.962477893364139, grad_norm: 0.7073017057570219, ic: 0.059035277662879304
train 4, step: 1500, loss: 2.1499530261075948, grad_norm: 0.4705423347592365, ic: 0.021374604950093454
train 4, step: 2000, loss: 1.0788000886955675, grad_norm: 0.4002693795468408, ic: 0.233809758865609
Epoch 4: 2022-04-27 23:52:32.475045: train loss: 1.6449656558566943
Eval step 0: eval loss: 0.8597328499571917
Eval: 2022-04-27 23:53:53.771555: total loss: 1.089945265509387, mse:4.837423975373212, ic :0.04534455421156488, sharpe5:11.146016721725463, irr5:326.6740417480469, ndcg5:0.8381854834172768, pnl5:3.1759774684906006 
train 5, step: 0, loss: 1.3546163878984898, grad_norm: 0.15000330129901268, ic: 0.09944585278407861
train 5, step: 500, loss: 0.8915609046639572, grad_norm: 0.012202488306251438, ic: 0.38915109315002255
train 5, step: 1000, loss: 0.9710427704442051, grad_norm: 0.15078488849681543, ic: 0.017220731921258895
train 5, step: 1500, loss: 1.5344650478859592, grad_norm: 0.16157607746928224, ic: 0.020864732655359288
train 5, step: 2000, loss: 1.1008226434481945, grad_norm: 0.03138065886534974, ic: 0.17342920260304384
Epoch 5: 2022-04-28 00:15:39.371051: train loss: 1.6422143618117824
Eval step 0: eval loss: 0.8355067165684272
Eval: 2022-04-28 00:16:59.060736: total loss: 1.0747747206212106, mse:4.707643558695603, ic :0.14686168582100795, sharpe5:12.541084043383597, irr5:428.6150207519531, ndcg5:0.8424701023696747, pnl5:5.178396701812744 
train 6, step: 0, loss: 1.3450562691574461, grad_norm: 0.502047417438546, ic: 0.15641620005036272
train 6, step: 500, loss: 1.0153475844659265, grad_norm: 0.06802872973356978, ic: 0.0033464675912115265
train 6, step: 1000, loss: 1.1151302207105513, grad_norm: 0.09962022219742167, ic: 0.6469469571608132
train 6, step: 1500, loss: 1.5627627033832645, grad_norm: 0.7355557708133538, ic: 0.14841143615028163
train 6, step: 2000, loss: 0.8021917534027221, grad_norm: 0.12079598330111677, ic: 0.3629961764532469
Epoch 6: 2022-04-28 00:38:50.980644: train loss: 1.630310872393367
Eval step 0: eval loss: 0.8245536394189606
Eval: 2022-04-28 00:40:12.198597: total loss: 1.0695998365044757, mse:4.681229829170167, ic :0.17031517902484897, sharpe5:16.825434157848356, irr5:558.0687255859375, ndcg5:0.8509061306692164, pnl5:7.2273993492126465 
train 7, step: 0, loss: 0.9855031967163086, grad_norm: 0.06411341680318156, ic: 0.14693919211713416
train 7, step: 500, loss: 0.6496255520991642, grad_norm: 0.006680250516716919, ic: 0.04369660152816311
train 7, step: 1000, loss: 1.0262375865741622, grad_norm: 1.1336217889476643, ic: 0.1955447383052065
train 7, step: 1500, loss: 2.235088319768221, grad_norm: 0.7792828670063517, ic: 0.4330172575236776
train 7, step: 2000, loss: 0.9204470337111269, grad_norm: 0.054528759371228225, ic: -0.04851594536952425
Epoch 7: 2022-04-28 01:01:38.656728: train loss: 1.6282880878908468
Eval step 0: eval loss: 0.8315779562368282
Eval: 2022-04-28 01:02:59.464838: total loss: 1.0717616014891584, mse:4.683167800109028, ic :0.16727204095906578, sharpe5:16.62240255475044, irr5:556.6702270507812, ndcg5:0.848629540246963, pnl5:7.379826545715332 
train 8, step: 0, loss: 3.5926538439764495, grad_norm: 1.1799107790047818, ic: 0.21195376318833892
train 8, step: 500, loss: 2.7706011276477014, grad_norm: 0.8653622542034372, ic: 0.029211903446772464
train 8, step: 1000, loss: 3.0463690274003623, grad_norm: 0.9357278693809258, ic: 0.10883313640340297
train 8, step: 1500, loss: 0.7116891882128545, grad_norm: 0.05115866165903728, ic: 0.47680273694729675
train 8, step: 2000, loss: 1.0883751199499845, grad_norm: 0.5189285651088169, ic: 0.5045536185351743
Epoch 8: 2022-04-28 01:24:23.729075: train loss: 1.6273893513102002
Eval step 0: eval loss: 0.8246396288856691
Eval: 2022-04-28 01:25:44.606209: total loss: 1.0681232813508175, mse:4.670425363847352, ic :0.1747942021210179, sharpe5:17.22988361477852, irr5:566.5042114257812, ndcg5:0.857620064631706, pnl5:8.149652481079102 
train 9, step: 0, loss: 5.417039691736443, grad_norm: 0.7813269811003332, ic: 0.17542948495647676
train 9, step: 500, loss: 1.3497724135445148, grad_norm: 1.659967695108739, ic: 0.35603405554678935
train 9, step: 1000, loss: 0.935445751071172, grad_norm: 0.8463183301696691, ic: -0.025266336488812765
train 9, step: 1500, loss: 1.0886033610145895, grad_norm: 0.011940302840074642, ic: 0.420648316371225
train 9, step: 2000, loss: 1.0600996965327079, grad_norm: 0.3016851149053887, ic: 0.2664298458169008
Epoch 9: 2022-04-28 01:47:44.114927: train loss: 1.6266264350065858
Eval step 0: eval loss: 0.824055389307824
Eval: 2022-04-28 01:49:09.656527: total loss: 1.069434453648638, mse:4.665196672231429, ic :0.1732680648418527, sharpe5:16.93471884727478, irr5:551.204345703125, ndcg5:0.8383169312594198, pnl5:8.34528636932373 
train 10, step: 0, loss: 7.101047882880831, grad_norm: 1.6817719801149285, ic: 0.2654967272744476
train 10, step: 500, loss: 1.1374435065492543, grad_norm: 0.0858637932042646, ic: 0.023840540652129198
train 10, step: 1000, loss: 2.367189185019651, grad_norm: 0.8949867641452911, ic: 0.09476541312755578
train 10, step: 1500, loss: 1.1125819218623174, grad_norm: 0.3759023283264563, ic: -0.02808702578861703
train 10, step: 2000, loss: 2.7309774381411476, grad_norm: 1.320263810231127, ic: 0.5091914849097048
Epoch 10: 2022-04-28 02:10:53.244393: train loss: 1.6260559479815455
Eval step 0: eval loss: 0.8229338602723261
Eval: 2022-04-28 02:12:16.186808: total loss: 1.0670257356202968, mse:4.635725452195331, ic :0.18136092868262144, sharpe5:17.72038393378258, irr5:597.5147705078125, ndcg5:0.8389161983275828, pnl5:5.92333459854126 
train 11, step: 0, loss: 1.2449597139646171, grad_norm: 0.021084155816918262, ic: 0.2090050415966201
train 11, step: 500, loss: 0.6472230655794586, grad_norm: 0.06451801928204295, ic: 0.633071667302125
train 11, step: 1000, loss: 0.9387150675623455, grad_norm: 0.16419620942607072, ic: 0.05113585785581459
train 11, step: 1500, loss: 1.052875050327234, grad_norm: 0.06043401728725009, ic: 0.15994878145784103
train 11, step: 2000, loss: 0.7835348168443917, grad_norm: 0.0043046871157735415, ic: 0.12433924931922738
Epoch 11: 2022-04-28 02:33:58.695474: train loss: 1.624176450248349
Eval step 0: eval loss: 0.8309093350731032
Eval: 2022-04-28 02:35:19.226761: total loss: 1.0691689834186389, mse:4.663637739066749, ic :0.17840947707121568, sharpe5:17.28701374411583, irr5:582.1016235351562, ndcg5:0.8459730010406358, pnl5:7.659088134765625 
train 12, step: 0, loss: 0.969994068145752, grad_norm: 0.10770703422849902, ic: 0.3823349793618182
train 12, step: 500, loss: 0.9297783778984952, grad_norm: 0.10676559834964872, ic: 0.18923517787850921
train 12, step: 1000, loss: 2.9687995667670184, grad_norm: 0.25955344772847555, ic: 0.24359472795979714
train 12, step: 1500, loss: 0.9296425022610434, grad_norm: 0.1979098305386504, ic: -0.08377295927902344
train 12, step: 2000, loss: 0.873516163437028, grad_norm: 0.0028208361065470595, ic: 0.1356261349564497
Epoch 12: 2022-04-28 02:57:24.526611: train loss: 1.6229315880637136
Eval step 0: eval loss: 0.8286672417306046
Eval: 2022-04-28 02:58:45.260288: total loss: 1.0672001343038302, mse:4.603434262401567, ic :0.18169999916802973, sharpe5:16.10489605665207, irr5:539.399169921875, ndcg5:0.8634367133437034, pnl5:4.600941181182861 
train 13, step: 0, loss: 2.0447545600415786, grad_norm: 0.9280873243984393, ic: 0.4248803501656547
train 13, step: 500, loss: 0.8099413529587313, grad_norm: 0.14000263041350358, ic: 0.5958782500220332
train 13, step: 1000, loss: 0.9440565685297818, grad_norm: 0.5430058825963975, ic: 0.6054332063214871
train 13, step: 1500, loss: 2.411380193086456, grad_norm: 0.5881568382660793, ic: -0.09971494808462461
train 13, step: 2000, loss: 1.4583929119154155, grad_norm: 0.10940529761648532, ic: 0.214917383315187
Epoch 13: 2022-04-28 03:20:44.873265: train loss: 1.6214756198628477
Eval step 0: eval loss: 0.8249900182758166
Eval: 2022-04-28 03:22:09.020369: total loss: 1.0657400278008764, mse:4.604162961219772, ic :0.1867688417554792, sharpe5:17.634838196039198, irr5:591.3017578125, ndcg5:0.8486403811366522, pnl5:5.915938377380371 
train 14, step: 0, loss: 4.517841690230109, grad_norm: 2.6253683650827373, ic: 0.19556662800082347
train 14, step: 500, loss: 0.8264184420991016, grad_norm: 0.009097824371425431, ic: 0.08773061674601204
train 14, step: 1000, loss: 1.7985869503962606, grad_norm: 1.0133172639725934, ic: 0.4724646288970464
train 14, step: 1500, loss: 1.128690471080259, grad_norm: 0.16180421445298598, ic: -0.07641005155495874
train 14, step: 2000, loss: 1.1569508422001884, grad_norm: 0.5692093248911906, ic: 0.07333684799160667
Epoch 14: 2022-04-28 03:44:01.730978: train loss: 1.6207019288491902
Eval step 0: eval loss: 0.8327138275693163
Eval: 2022-04-28 03:45:24.407574: total loss: 1.0662069265162835, mse:4.5894891794443975, ic :0.1863926267419786, sharpe5:17.81348572611809, irr5:599.173583984375, ndcg5:0.8494519385012713, pnl5:9.355059623718262 
train 15, step: 0, loss: 3.4098005836575878, grad_norm: 1.546639959114873, ic: 0.07804362744966155
train 15, step: 500, loss: 1.2563082852763923, grad_norm: 0.04782233880361247, ic: 0.06608488213788334
train 15, step: 1000, loss: 1.3114498975800304, grad_norm: 0.14167214863315686, ic: 0.07740429675119999
train 15, step: 1500, loss: 0.8531906488373524, grad_norm: 0.22180549454691262, ic: 0.04489945227371568
train 15, step: 2000, loss: 1.452130451294535, grad_norm: 0.8265701507513439, ic: 0.05106564699913935
Epoch 15: 2022-04-28 04:07:13.761297: train loss: 1.6200097560654816
Eval step 0: eval loss: 0.8366573804045376
Eval: 2022-04-28 04:08:40.243811: total loss: 1.0711599548791841, mse:4.589519236224563, ic :0.18802222171854896, sharpe5:17.60667798757553, irr5:608.04345703125, ndcg5:0.8396339622639001, pnl5:5.9909820556640625 
train 16, step: 0, loss: 0.6917167899161223, grad_norm: 0.9390385198570699, ic: -0.06442156675490365
train 16, step: 500, loss: 1.6000747801829673, grad_norm: 1.24604666621083, ic: 0.1779684684801408
train 16, step: 1000, loss: 0.8756068374171402, grad_norm: 0.007661860093472633, ic: -0.011839660826962212
train 16, step: 1500, loss: 0.8408968830033492, grad_norm: 0.364844639082647, ic: 0.1000389846353695
train 16, step: 2000, loss: 3.3520431203550785, grad_norm: 1.5774338271992747, ic: -0.0322694692880814
Epoch 16: 2022-04-28 04:29:59.913838: train loss: 1.6190688895268928
Eval step 0: eval loss: 0.8278866477459825
Eval: 2022-04-28 04:31:23.312424: total loss: 1.0685902187307108, mse:4.612185713663386, ic :0.18741993500627677, sharpe5:18.211264514923094, irr5:599.1111450195312, ndcg5:0.8500383780230831, pnl5:7.42686128616333 
train 17, step: 0, loss: 1.2733241721236737, grad_norm: 0.3609866867679039, ic: -0.07513825234515252
train 17, step: 500, loss: 1.7585654323340107, grad_norm: 0.9584455760369794, ic: 0.16585836514086794
train 17, step: 1000, loss: 1.2741558119449232, grad_norm: 0.1704403007221744, ic: 0.17533152854815087
train 17, step: 1500, loss: 4.5221269258587435, grad_norm: 1.581518435553519, ic: 0.1906292292165519
train 17, step: 2000, loss: 1.2850773947145984, grad_norm: 1.3236804790045484, ic: 0.11614252879898236
Epoch 17: 2022-04-28 04:52:56.108362: train loss: 1.6193634364041591
Eval step 0: eval loss: 0.8321484323547813
Eval: 2022-04-28 04:54:28.030145: total loss: 1.0668607625595805, mse:4.580891270556359, ic :0.19406871737675985, sharpe5:18.273014545440674, irr5:607.4329223632812, ndcg5:0.8537670496730342, pnl5:4.995870113372803 
train 18, step: 0, loss: 1.4173081680886113, grad_norm: 0.851278342372707, ic: 0.19072871300819466
train 18, step: 500, loss: 1.509563159711713, grad_norm: 0.913304205288093, ic: 0.045967127640059405
train 18, step: 1000, loss: 0.6660246548587329, grad_norm: 0.04789298764689615, ic: 0.5687534822194701
train 18, step: 1500, loss: 1.4298609578150594, grad_norm: 0.09336612505439058, ic: 0.18684028719777523
train 18, step: 2000, loss: 0.9119136348651473, grad_norm: 0.014373679845099647, ic: -0.007740336487775706
Epoch 18: 2022-04-28 05:16:10.710910: train loss: 1.6189636873890674
Eval step 0: eval loss: 0.8269662967597471
Eval: 2022-04-28 05:17:36.130334: total loss: 1.0645372183240427, mse:4.587660304244173, ic :0.19167258838674364, sharpe5:18.375533974170683, irr5:615.4456787109375, ndcg5:0.8513032667763321, pnl5:15.590694427490234 
train 19, step: 0, loss: 1.4691840277777777, grad_norm: 1.1987694772304542, ic: 0.08274690908860272
train 19, step: 500, loss: 0.868555846037688, grad_norm: 0.14797185038219213, ic: 0.21156013451350916
train 19, step: 1000, loss: 0.9519087459068907, grad_norm: 0.016971833571259642, ic: 0.21173622586737728
train 19, step: 1500, loss: 3.940573804242797, grad_norm: 1.4745479048227503, ic: 0.15532727722461526
train 19, step: 2000, loss: 1.008925499549279, grad_norm: 0.30269254194337936, ic: 0.1848032213077209
Epoch 19: 2022-04-28 05:39:41.723435: train loss: 1.619803651456271
Eval step 0: eval loss: 0.8281138091494336
Eval: 2022-04-28 05:41:08.734225: total loss: 1.064996936363968, mse:4.583900305965203, ic :0.19463454941166267, sharpe5:18.017824598550796, irr5:606.54638671875, ndcg5:0.8533296053292743, pnl5:5.937046051025391 
train 20, step: 0, loss: 2.3328669250247036, grad_norm: 2.411004073572834, ic: 0.03957009309664665
train 20, step: 500, loss: 3.2391871448863636, grad_norm: 1.4256589324799198, ic: 0.04219891473225532
train 20, step: 1000, loss: 0.9593307495117188, grad_norm: 0.12514013160224582, ic: 0.2274991963288688
train 20, step: 1500, loss: 1.820783956857772, grad_norm: 4.775809832215078, ic: 0.24525184225557023
train 20, step: 2000, loss: 1.042178280007392, grad_norm: 0.1639969774358168, ic: -0.013868639840093374
Epoch 20: 2022-04-28 06:03:06.572990: train loss: 1.6174100250893972
Eval step 0: eval loss: 0.8372860618084825
Eval: 2022-04-28 06:04:37.488058: total loss: 1.0673606377379194, mse:4.584853593669395, ic :0.19104514016292645, sharpe5:17.961653637886048, irr5:607.8607177734375, ndcg5:0.8635599196861173, pnl5:6.4089250564575195 
train 21, step: 0, loss: 1.0116807601544624, grad_norm: 0.6462952352950171, ic: 0.05059582354210415
train 21, step: 500, loss: 0.7719544267232439, grad_norm: 0.015279924170369923, ic: 0.1858124945973495
train 21, step: 1000, loss: 0.935429623252467, grad_norm: 1.5628820590175985, ic: 0.13874310630797607
train 21, step: 1500, loss: 0.9845824052825773, grad_norm: 0.5858410041137321, ic: 0.3122212775830928
train 21, step: 2000, loss: 0.9368497694317552, grad_norm: 0.07792836713059806, ic: 0.08814083284220105
Epoch 21: 2022-04-28 06:26:50.435920: train loss: 1.618249023561723
Eval step 0: eval loss: 0.8244266811487421
Eval: 2022-04-28 06:28:17.379129: total loss: 1.0639152604294984, mse:4.585402024881602, ic :0.19484465331438128, sharpe5:18.590832341909408, irr5:619.1503295898438, ndcg5:0.8526645279613295, pnl5:7.270212650299072 
train 22, step: 0, loss: 1.046850430763374, grad_norm: 0.23896746024270743, ic: 0.21567375494128985
train 22, step: 500, loss: 3.2727955887957316, grad_norm: 1.9990298526260069, ic: -0.18898690218881636
train 22, step: 1000, loss: 1.1922202402456648, grad_norm: 0.11199687365518522, ic: 0.47367639196452854
train 22, step: 1500, loss: 0.9659977414480453, grad_norm: 0.2968253345025427, ic: 0.10532686498267174
train 22, step: 2000, loss: 1.738036278964711, grad_norm: 1.0840936867259543, ic: 0.17963796074265814
Epoch 22: 2022-04-28 06:42:36.971288: train loss: 1.6189067503635048
Eval step 0: eval loss: 0.8277454114940068
Eval: 2022-04-28 06:43:23.416275: total loss: 1.0649982301919425, mse:4.590223797534613, ic :0.19220646454302645, sharpe5:17.638349472284315, irr5:598.7625122070312, ndcg5:0.8413021160442028, pnl5:5.2728962898254395 
train 23, step: 0, loss: 0.9820202742255044, grad_norm: 0.06597537258008988, ic: 0.15876681392791872
train 23, step: 500, loss: 1.4225189831792093, grad_norm: 0.2241853770347278, ic: 0.06845163233509301
train 23, step: 1000, loss: 1.65582275390625, grad_norm: 0.12962086858242927, ic: 0.260617313239886
train 23, step: 1500, loss: 1.1450707764233978, grad_norm: 1.7841061101444542, ic: 0.10045027319506512
train 23, step: 2000, loss: 1.922946662697267, grad_norm: 1.702218679771347, ic: 0.4398870150086233
Epoch 23: 2022-04-28 06:55:05.753265: train loss: 1.6152479582876558
Eval step 0: eval loss: 0.8288779384343716
Eval: 2022-04-28 06:55:54.514400: total loss: 1.0641987909021688, mse:4.576987175150509, ic :0.19515655884844285, sharpe5:17.575165418386458, irr5:584.1334838867188, ndcg5:0.844810015426383, pnl5:8.64098072052002 
train 24, step: 0, loss: 2.192265317536544, grad_norm: 0.0857627750203729, ic: 0.14898075766744004
train 24, step: 500, loss: 1.2286017866913912, grad_norm: 0.27236777600329015, ic: 0.2105598600170081
train 24, step: 1000, loss: 0.9114437167665429, grad_norm: 0.05220841683494379, ic: 0.5116746651408784
train 24, step: 1500, loss: 2.6112747884248764, grad_norm: 2.6757785027252607, ic: 0.06299149698198626
train 24, step: 2000, loss: 0.9312130307024246, grad_norm: 0.09644918267000739, ic: 0.11024480719588739
Epoch 24: 2022-04-28 07:07:54.030487: train loss: 1.6128730478678142
Eval step 0: eval loss: 0.82602092714782
Eval: 2022-04-28 07:08:40.544822: total loss: 1.064305074125409, mse:4.593424134960534, ic :0.1939641958194266, sharpe5:18.167258158922195, irr5:600.824951171875, ndcg5:0.8610007271117135, pnl5:6.735071659088135 
train 25, step: 0, loss: 0.8328834327491554, grad_norm: 0.1887604866023942, ic: 0.617210230137987
train 25, step: 500, loss: 0.8715833220236971, grad_norm: 0.024845671159430708, ic: 0.16323201585312286
train 25, step: 1000, loss: 2.093143088347296, grad_norm: 0.1925987062955118, ic: 0.2499976417089
train 25, step: 1500, loss: 1.1216713127167204, grad_norm: 0.5475689435184242, ic: 0.548283930390899
train 25, step: 2000, loss: 1.0473321071521513, grad_norm: 0.9892696155497537, ic: 0.6083424116477414
Epoch 25: 2022-04-28 07:20:35.594047: train loss: 1.616777022488152
Eval step 0: eval loss: 0.8278344880919059
Eval: 2022-04-28 07:21:24.902110: total loss: 1.064075562359086, mse:4.579299503566019, ic :0.19961576235245945, sharpe5:19.348588836193084, irr5:640.238037109375, ndcg5:0.8442685721072599, pnl5:11.806384086608887 
train 26, step: 0, loss: 6.633367861421725, grad_norm: 1.1720710572171311, ic: 0.16767704436509123
train 26, step: 500, loss: 3.931522658693315, grad_norm: 3.0569702549482836, ic: 0.37349752936870273
train 26, step: 1000, loss: 1.2650568077291013, grad_norm: 1.4102683042247766, ic: 0.004699915929612591
train 26, step: 1500, loss: 0.8334369562884129, grad_norm: 0.2872095126123438, ic: 0.31505525722292743
train 26, step: 2000, loss: 0.9589421161978757, grad_norm: 0.5267483085999118, ic: 0.08302136801899125
Epoch 26: 2022-04-28 07:33:21.139165: train loss: 1.6162232472048352
Eval step 0: eval loss: 0.8266925711275026
Eval: 2022-04-28 07:34:09.917453: total loss: 1.0633890415987168, mse:4.5789794007708045, ic :0.1966382767435637, sharpe5:18.166263045072554, irr5:603.7474365234375, ndcg5:0.845061203414126, pnl5:5.193739414215088 
train 27, step: 0, loss: 0.8306567861519607, grad_norm: 0.06380434407273804, ic: 0.11938323798835403
train 27, step: 500, loss: 0.9275231661225912, grad_norm: 3.7242688849149745, ic: 0.2768219356704548
train 27, step: 1000, loss: 0.7481876382141822, grad_norm: 0.27879724342567314, ic: 0.19096274071440716
train 27, step: 1500, loss: 0.6418851534871464, grad_norm: 0.169361310542429, ic: 0.5138943157571678
train 27, step: 2000, loss: 1.3902946593821186, grad_norm: 0.12365277460969039, ic: -0.05631521569197956
Epoch 27: 2022-04-28 07:46:03.641651: train loss: 1.6163394908080488
Eval step 0: eval loss: 0.8328697920096811
Eval: 2022-04-28 07:46:47.441955: total loss: 1.0674878498576343, mse:4.583007027485892, ic :0.19417167549085226, sharpe5:18.506639277935026, irr5:614.3115844726562, ndcg5:0.8517102506392048, pnl5:8.957175254821777 
train 28, step: 0, loss: 1.5381018679114382, grad_norm: 0.6626558396435767, ic: 0.16205179200579767
train 28, step: 500, loss: 1.3741631803731136, grad_norm: 3.6864581435503414, ic: 0.1910627462256856
train 28, step: 1000, loss: 0.9144727091802168, grad_norm: 0.32661840522717867, ic: 0.5816044959213292
train 28, step: 1500, loss: 1.032435703944493, grad_norm: 0.03633441808119272, ic: 0.029448593597998052
train 28, step: 2000, loss: 1.0509930008028183, grad_norm: 0.38023973885473306, ic: 0.09997052484158042
Epoch 28: 2022-04-28 07:58:50.386001: train loss: 1.6112344579705045
Eval step 0: eval loss: 0.8360220102163461
Eval: 2022-04-28 07:59:34.508244: total loss: 1.112209634236643, mse:4.928694503872645, ic :0.15698130931398266, sharpe5:17.865460560321807, irr5:605.9061279296875, ndcg5:0.8396584831108006, pnl5:4.456472873687744 
train 29, step: 0, loss: 0.9100955387604246, grad_norm: 0.2042617256340754, ic: 0.09707529015384429
train 29, step: 500, loss: 1.1091472023176012, grad_norm: 0.2086156013667822, ic: 0.6121998800575282
train 29, step: 1000, loss: 1.0797365529667113, grad_norm: 0.5534717532540093, ic: 0.08901640942127284
train 29, step: 1500, loss: 2.352018762807377, grad_norm: 0.26053252275598343, ic: -0.05261130440579348
train 29, step: 2000, loss: 4.138417561848958, grad_norm: 40.16499473259297, ic: 0.20957879291167303
Epoch 29: 2022-04-28 08:11:55.269317: train loss: 1.6167253948330498
Eval step 0: eval loss: 0.8334331934519889
Eval: 2022-04-28 08:12:42.794069: total loss: 1.0645072443169334, mse:4.576402612626743, ic :0.1974110853455842, sharpe5:18.620333873033523, irr5:614.1617431640625, ndcg5:0.8525998341458164, pnl5:5.4342851638793945 
train 30, step: 0, loss: 1.0072313441619587, grad_norm: 0.1280699335294885, ic: 0.5124056896372616
train 30, step: 500, loss: 1.4142932219031994, grad_norm: 1.658960272900676, ic: 0.08457986982352622
train 30, step: 1000, loss: 0.9805290453361742, grad_norm: 0.09713379756099359, ic: -0.00486847965832389
train 30, step: 1500, loss: 1.4866247028990358, grad_norm: 2.4846217162095297, ic: 0.18695136243337293
train 30, step: 2000, loss: 1.8411896055494452, grad_norm: 0.723816745804353, ic: 0.1070768834586669
Epoch 30: 2022-04-28 08:24:59.855838: train loss: 1.6147625707077569
Eval step 0: eval loss: 0.8326175476653055
Eval: 2022-04-28 08:25:47.204125: total loss: 1.072006143597764, mse:4.6737537986019015, ic :0.19646050240241103, sharpe5:17.889547612667084, irr5:604.3074951171875, ndcg5:0.8522402141993899, pnl5:7.185925483703613 
train 31, step: 0, loss: 1.0540340794421312, grad_norm: 0.4072325567322727, ic: 0.35002747035233706
train 31, step: 500, loss: 1.4911008230452674, grad_norm: 2.521284030777353, ic: 0.03732268608207564
train 31, step: 1000, loss: 4.404147074429157, grad_norm: 1.9164095853913332, ic: 0.46932134172228457
train 31, step: 1500, loss: 0.7620426995776465, grad_norm: 0.04416256777873625, ic: 0.7142798134097073
train 31, step: 2000, loss: 1.222683149992876, grad_norm: 2.008235532943891, ic: 0.18485788702146108
Epoch 31: 2022-04-28 08:37:47.286127: train loss: 1.6089884124565548
Eval step 0: eval loss: 0.8325253196209825
Eval: 2022-04-28 08:38:33.880872: total loss: 1.0655463101270746, mse:4.580422144126875, ic :0.1941389356554922, sharpe5:18.196256457567213, irr5:607.26513671875, ndcg5:0.8430608551823626, pnl5:6.948563098907471 
train 32, step: 0, loss: 1.1252249214487529, grad_norm: 0.10897328283660844, ic: 0.20303794584568047
train 32, step: 500, loss: 1.5103719395915354, grad_norm: 2.1334837480811766, ic: 0.011311532469349187
train 32, step: 1000, loss: 1.0437247107733312, grad_norm: 0.22555149712648354, ic: 0.5033957413427727
train 32, step: 1500, loss: 0.9586148120173056, grad_norm: 2.5202205051075497, ic: 0.07292912486472211
train 32, step: 2000, loss: 0.9465893810726403, grad_norm: 0.20791874727221316, ic: 0.557038231181064
Epoch 32: 2022-04-28 08:50:53.870020: train loss: 1.6103564940632595
Eval step 0: eval loss: 0.8258434814195863
Eval: 2022-04-28 08:51:41.250620: total loss: 1.0642022766498433, mse:4.585712775516287, ic :0.1980622983816133, sharpe5:18.40657925605774, irr5:622.2438354492188, ndcg5:0.8611071716453543, pnl5:9.391590118408203 
train 33, step: 0, loss: 1.2601981880512059, grad_norm: 0.4282164726730292, ic: 0.21950629402284969
train 33, step: 500, loss: 0.9866807207613159, grad_norm: 0.06532891737247305, ic: 0.21807968888320386
train 33, step: 1000, loss: 1.073360267303892, grad_norm: 0.6339573738531664, ic: 0.2122275000579697
train 33, step: 1500, loss: 0.9241762353573547, grad_norm: 0.4832720869779742, ic: 0.5118135370540915
train 33, step: 2000, loss: 0.8087478371694236, grad_norm: 0.04235031156979402, ic: 0.29197909834834235
Epoch 33: 2022-04-28 09:03:40.581328: train loss: 1.6075087303081474
Eval step 0: eval loss: 0.8284980283522128
Eval: 2022-04-28 09:04:28.463828: total loss: 1.0640218138337498, mse:4.5729064323810755, ic :0.19837515409835713, sharpe5:18.227199579477308, irr5:606.28369140625, ndcg5:0.8555088665204575, pnl5:10.78447151184082 
train 34, step: 0, loss: 1.0105130409383674, grad_norm: 1.0079106750812021, ic: 0.607515528234601
train 34, step: 500, loss: 0.7888960065462538, grad_norm: 0.35327641068727667, ic: 0.277192033958614
train 34, step: 1000, loss: 3.1104588193644394, grad_norm: 4.302434589239627, ic: 0.32816234056749194
train 34, step: 1500, loss: 0.8001660243547005, grad_norm: 0.42573011621650303, ic: 0.6860488870432928
train 34, step: 2000, loss: 4.234249431158017, grad_norm: 231.9132994207961, ic: 0.4728688194495062
Epoch 34: 2022-04-28 09:16:09.417161: train loss: 1.6032127075975324
Eval step 0: eval loss: 0.8614638301419256
Eval: 2022-04-28 09:16:53.673543: total loss: 1.1335179686238412, mse:5.02746710085947, ic :0.14374455842047532, sharpe5:17.869282100200653, irr5:596.6808471679688, ndcg5:0.8501929685035122, pnl5:6.773960113525391 
train 35, step: 0, loss: 1.092381663602941, grad_norm: 10.482633956829043, ic: 0.5471909439850083
train 35, step: 500, loss: 1.1696751392579723, grad_norm: 1.1062087298315326, ic: 0.09644131022710013
train 35, step: 1000, loss: 1.865051399117569, grad_norm: 3.68007714628848, ic: 0.048377222104564646
train 35, step: 1500, loss: 1.631218977619831, grad_norm: 2.8916754046281854, ic: 0.03498604715073171
train 35, step: 2000, loss: 0.7879863881809825, grad_norm: 0.12349532628294099, ic: 0.547820062554006
Epoch 35: 2022-04-28 09:29:00.281007: train loss: 1.6129778733184075
Eval step 0: eval loss: 0.8317865948531348
Eval: 2022-04-28 09:29:47.302345: total loss: 1.066068460273268, mse:4.585232238085734, ic :0.19336400808218687, sharpe5:17.730459934473036, irr5:590.39208984375, ndcg5:0.8438192787896586, pnl5:5.379926681518555 
train 36, step: 0, loss: 1.864305529152767, grad_norm: 3.3483516069704886, ic: 0.09670151957409473
train 36, step: 500, loss: 0.8469511472493105, grad_norm: 0.11246891927358668, ic: 0.09062907119888942
train 36, step: 1000, loss: 1.6321012073863634, grad_norm: 0.5307723184171436, ic: 0.20805075520809257
train 36, step: 1500, loss: 0.7734896912057342, grad_norm: 0.05253910910487464, ic: 0.36653509266437667
train 36, step: 2000, loss: 1.1151019301653098, grad_norm: 0.6536794163730749, ic: 0.7762718680933958
Epoch 36: 2022-04-28 09:41:51.656698: train loss: 1.6120245238179927
Eval step 0: eval loss: 0.8310018846935919
Eval: 2022-04-28 09:42:35.491332: total loss: 1.0893921251584349, mse:4.720882296553558, ic :0.16714740409427978, sharpe5:17.881620755195616, irr5:580.8278198242188, ndcg5:0.8459695101221419, pnl5:5.501026630401611 
train 37, step: 0, loss: 1.9612977289313744, grad_norm: 2.854642446794892, ic: 0.2138877984989982
train 37, step: 500, loss: 2.3286527101600734, grad_norm: 1.5998484644370616, ic: 0.06272549314266548
train 37, step: 1000, loss: 1.0653479356925417, grad_norm: 0.2500130057612762, ic: 0.057372740308299586
train 37, step: 1500, loss: 2.0044554705896784, grad_norm: 2.4452532115028753, ic: 0.6111929021533148
train 37, step: 2000, loss: 1.316397632079267, grad_norm: 0.3453107621093925, ic: 0.13928483930711227
Epoch 37: 2022-04-28 09:54:39.062592: train loss: 1.6113438470727557
Eval step 0: eval loss: 0.8247252967762118
Eval: 2022-04-28 09:55:22.578263: total loss: 1.065147410281514, mse:4.592154932459054, ic :0.1966936013228846, sharpe5:18.617448799610138, irr5:631.1285400390625, ndcg5:0.8569127755185203, pnl5:7.838440895080566 
train 38, step: 0, loss: 1.3377572036371, grad_norm: 1.026088353331688, ic: -0.07315400210104261
train 38, step: 500, loss: 0.8936743465470679, grad_norm: 0.13950426481824013, ic: 0.2514366415160866
train 38, step: 1000, loss: 0.9048970942440712, grad_norm: 0.27001470752074863, ic: 0.1601856556320041
train 38, step: 1500, loss: 0.9558500320330297, grad_norm: 0.042492631001880485, ic: 0.1755943754510602
train 38, step: 2000, loss: 2.320925801902379, grad_norm: 3.2448851143914235, ic: 0.0856605156035214
Epoch 38: 2022-04-28 10:07:33.274654: train loss: 1.6051786348915993
Eval step 0: eval loss: 0.8299525816649104
Eval: 2022-04-28 10:08:18.761620: total loss: 1.064133425488764, mse:4.59404181580031, ic :0.19479973788512092, sharpe5:17.740447018146515, irr5:604.3123168945312, ndcg5:0.8539260968833824, pnl5:5.555753231048584 
train 39, step: 0, loss: 0.9713698454224006, grad_norm: 0.014817585712438443, ic: 0.03555912755953731
train 39, step: 500, loss: 0.9119988455394888, grad_norm: 0.3537741185953761, ic: 0.22142147976065038
train 39, step: 1000, loss: 0.9341670063190214, grad_norm: 0.08800740080778956, ic: 0.1945014164371939
train 39, step: 1500, loss: 2.090918007441066, grad_norm: 0.5478656056664843, ic: 0.2194941681845232
train 39, step: 2000, loss: 0.6087563561413902, grad_norm: 0.09762044468345758, ic: 0.13038914981330485
Epoch 39: 2022-04-28 10:20:17.147130: train loss: 1.6097331328483688
Eval step 0: eval loss: 0.8293095579639752
Eval: 2022-04-28 10:21:05.047412: total loss: 1.06490218695214, mse:4.605506768337076, ic :0.1976015023115821, sharpe5:18.661421102285384, irr5:619.5611572265625, ndcg5:0.8438015642503817, pnl5:8.418237686157227 

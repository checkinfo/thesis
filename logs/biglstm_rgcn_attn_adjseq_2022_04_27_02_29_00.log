Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='AdjSeqTimeDataset', dout=0.3, epochs=60, glstm_layers=1, gnn_layers=1, gpu=0, graph_attn=True, hidden_dim=128, inner_prod=False, input_dim=9, input_graph=True, label_cnt=3, lr=0.0004, lstm_layers=1, market=None, mask_adj=True, mask_type='soft', model_type='BiGLSTM', normalize_adj=True, num_days=8, num_heads=1, print_inteval=500, rank_loss=False, relation_num=1, rsr_data_path=None, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_250_0.8/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
70145
BiGLSTM(
  (input_to_hidden): Linear(in_features=9, out_features=128, bias=True)
  (forward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (attention): ModuleList(
            (0): GraphAttentionLayer (128 -> 128)
          )
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
  )
  (backward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (attention): ModuleList(
            (0): GraphAttentionLayer (128 -> 128)
          )
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
  )
  (fc0): ModuleList(
    (0): Linear(in_features=256, out_features=128, bias=True)
  )
  (w_out): Linear(in_features=128, out_features=1, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
)
train 0, step: 0, loss: 4.939038906738663, grad_norm: 4.425279322819397, ic: -0.04507333263499234
train 0, step: 500, loss: 0.8640037369889789, grad_norm: 0.026135063186747666, ic: 0.04958042293679914
train 0, step: 1000, loss: 1.9452528489621435, grad_norm: 0.5094194901636672, ic: 0.04086546317203883
train 0, step: 1500, loss: 0.9546322064908597, grad_norm: 0.04801366155077734, ic: 0.057190927750233815
train 0, step: 2000, loss: 1.001356571161807, grad_norm: 0.15498112113091103, ic: 0.008123275099844136
Epoch 0: 2022-04-27 14:34:05.435781: train loss: 1.64846724359196
Eval step 0: eval loss: 0.8361571365211735
Eval: 2022-04-27 14:34:22.600741: total loss: 1.0792915676028623, mse:4.822931047964774, ic :0.00820232658943891, sharpe5:8.061516618132591, irr5:227.958740234375, ndcg5:0.8677601250710533, pnl5:2.597322940826416 
train 1, step: 0, loss: 2.7721327258694557, grad_norm: 0.8717690116717124, ic: 0.06303863277774337
train 1, step: 500, loss: 1.7562975682426056, grad_norm: 0.7619470748234207, ic: 0.10390215383742622
train 1, step: 1000, loss: 0.8778306808555244, grad_norm: 0.17591519710242715, ic: 0.0649115376802154
train 1, step: 1500, loss: 1.7125401288613507, grad_norm: 0.20713274384044963, ic: -0.007384977031989172
train 1, step: 2000, loss: 2.178121484375, grad_norm: 0.8850947174514574, ic: -0.017861351534757645
Epoch 1: 2022-04-27 14:39:58.240204: train loss: 1.646731405314258
Eval step 0: eval loss: 0.8345075151063619
Eval: 2022-04-27 14:40:16.498334: total loss: 1.0789667151462161, mse:4.823578931857438, ic :0.007574450741039316, sharpe5:7.4980788052082055, irr5:211.5266876220703, ndcg5:0.827245483019627, pnl5:2.544426441192627 
train 2, step: 0, loss: 2.142114346590909, grad_norm: 0.009373233731830525, ic: 0.13059346817595013
train 2, step: 500, loss: 3.299591876344875, grad_norm: 0.27832324142451276, ic: 0.06192441696610866
train 2, step: 1000, loss: 2.072646521791188, grad_norm: 0.00019856556900865797, ic: 0.1747195668879719
train 2, step: 1500, loss: 1.48471139223521, grad_norm: 0.059657924058533686, ic: -0.013229867950784423
train 2, step: 2000, loss: 3.2354642427884617, grad_norm: 0.7775537163475834, ic: 0.1870373542646177
Epoch 2: 2022-04-27 14:45:50.222621: train loss: 1.6465224381663088
Eval step 0: eval loss: 0.8356569569530427
Eval: 2022-04-27 14:46:08.495988: total loss: 1.0794503025703972, mse:4.8233182012090365, ic :0.009014488931983774, sharpe5:7.288459302484989, irr5:206.3148193359375, ndcg5:0.8452174191885896, pnl5:2.9509921073913574 
train 3, step: 0, loss: 1.520559419461382, grad_norm: 0.5180323726357373, ic: 0.0048539710537012426
train 3, step: 500, loss: 1.5009970190754698, grad_norm: 0.34358371091323553, ic: 0.08264658811491835
train 3, step: 1000, loss: 3.6805280071603343, grad_norm: 0.6996341000256033, ic: -0.04300635324343613
train 3, step: 1500, loss: 1.9812339370652619, grad_norm: 1.2344363061099903, ic: -0.04532846318449681
train 3, step: 2000, loss: 0.8977236855996622, grad_norm: 0.0006849448653842274, ic: 0.030777797285322737
Epoch 3: 2022-04-27 14:51:59.415252: train loss: 1.6462051538120424
Eval step 0: eval loss: 0.8347277947798669
Eval: 2022-04-27 14:52:16.721163: total loss: 1.079287376282979, mse:4.8243388914179715, ic :0.01047186786233397, sharpe5:7.8058258035779, irr5:212.6090850830078, ndcg5:0.8532577113984839, pnl5:2.606219530105591 
train 4, step: 0, loss: 1.432655253507653, grad_norm: 0.04504449790260959, ic: 0.13727340924472642
train 4, step: 500, loss: 1.6497575895054133, grad_norm: 0.5677521087387468, ic: 0.04625935389280646
train 4, step: 1000, loss: 2.973443380216273, grad_norm: 0.6998777313735715, ic: 0.03910581069129092
train 4, step: 1500, loss: 2.1401583514636076, grad_norm: 0.48923573230723505, ic: -0.014329996505407363
train 4, step: 2000, loss: 1.0917084072463064, grad_norm: 0.3938449093184757, ic: 0.22685874205798445
Epoch 4: 2022-04-27 14:57:46.306787: train loss: 1.6459768097486531
Eval step 0: eval loss: 0.8430865883701594
Eval: 2022-04-27 14:58:02.767806: total loss: 1.081955901600071, mse:4.823082990981538, ic :0.029266477515497016, sharpe5:10.32384363234043, irr5:308.0088806152344, ndcg5:0.8570583559037045, pnl5:2.8705039024353027 
train 5, step: 0, loss: 1.3411709574244965, grad_norm: 0.11331336075074078, ic: 0.05694820952949578
train 5, step: 500, loss: 0.8885884296317407, grad_norm: 0.006499493856793761, ic: 0.058375250009520416
train 5, step: 1000, loss: 0.982114407477251, grad_norm: 0.15054554168262224, ic: -0.00928176298598157
train 5, step: 1500, loss: 1.533801138674866, grad_norm: 0.16329300810380865, ic: 0.004737247928073413
train 5, step: 2000, loss: 1.106707296349333, grad_norm: 0.032537922086023414, ic: 0.15927465958976272
Epoch 5: 2022-04-27 15:03:33.824013: train loss: 1.643672935060915
Eval step 0: eval loss: 0.8412984319431638
Eval: 2022-04-27 15:03:51.131455: total loss: 1.0820110250550803, mse:4.777867096659049, ic :0.11301192123892409, sharpe5:11.120744424462318, irr5:374.7664794921875, ndcg5:0.8556724953129206, pnl5:2.7287449836730957 
train 6, step: 0, loss: 1.341716273549641, grad_norm: 0.4444942150002782, ic: 0.09691093421397177
train 6, step: 500, loss: 1.0062446535820253, grad_norm: 0.043279948309826226, ic: 0.05706407684494176
train 6, step: 1000, loss: 1.1164633399180133, grad_norm: 0.08632428888657252, ic: 0.748020396179729
train 6, step: 1500, loss: 1.5686324694925102, grad_norm: 0.7397112324540499, ic: 0.14844931837888672
train 6, step: 2000, loss: 0.8028627980509407, grad_norm: 0.061109052706325426, ic: 0.3630996534000259
Epoch 6: 2022-04-27 15:09:33.781296: train loss: 1.6347118015852162
Eval step 0: eval loss: 0.8246951972471022
Eval: 2022-04-27 15:09:52.548657: total loss: 1.0728287891181079, mse:4.711146654361253, ic :0.1542742174037762, sharpe5:16.58991946578026, irr5:530.3446044921875, ndcg5:0.8308192232740538, pnl5:4.740973949432373 
train 7, step: 0, loss: 0.9863481521606445, grad_norm: 0.16700642863585813, ic: 0.1429807055574039
train 7, step: 500, loss: 0.650363864145018, grad_norm: 0.0016899516730297147, ic: 0.03907642623975224
train 7, step: 1000, loss: 1.027981527870335, grad_norm: 0.2203977408834328, ic: 0.09402997884196582
train 7, step: 1500, loss: 2.2509647872286975, grad_norm: 0.6856188096669602, ic: 0.4422400796399997
train 7, step: 2000, loss: 0.9133317543732331, grad_norm: 0.09422900946321935, ic: -0.021784830217541948
Epoch 7: 2022-04-27 15:15:31.684385: train loss: 1.62971430060496
Eval step 0: eval loss: 0.8307256507672549
Eval: 2022-04-27 15:15:50.488484: total loss: 1.0737674535714936, mse:4.707042031188323, ic :0.15192916131335368, sharpe5:14.833511359691618, irr5:494.4117431640625, ndcg5:0.849106968631293, pnl5:3.561476945877075 
train 8, step: 0, loss: 3.6079512001811596, grad_norm: 1.088698232829349, ic: 0.15691749405093725
train 8, step: 500, loss: 2.765479925555661, grad_norm: 0.8562957107452615, ic: 0.03734246540775051
train 8, step: 1000, loss: 3.0452183820199274, grad_norm: 0.8781768726563106, ic: 0.11666668513883224
train 8, step: 1500, loss: 0.7151374111340166, grad_norm: 0.02558318590732324, ic: 0.46729142145023
train 8, step: 2000, loss: 1.0900986437170441, grad_norm: 0.4016162873078948, ic: 0.4935826567327744
Epoch 8: 2022-04-27 15:21:30.502369: train loss: 1.6278885808048444
Eval step 0: eval loss: 0.8246371849068097
Eval: 2022-04-27 15:21:48.628491: total loss: 1.0712888050069427, mse:4.690531818701565, ic :0.16526568713689402, sharpe5:17.010031560659407, irr5:565.282958984375, ndcg5:0.8463488212622176, pnl5:4.867563724517822 
train 9, step: 0, loss: 5.440994676410487, grad_norm: 0.8926807473098177, ic: 0.1394615270534587
train 9, step: 500, loss: 1.340042917351974, grad_norm: 1.4836486799213042, ic: 0.32882197566207527
train 9, step: 1000, loss: 0.9260300008338465, grad_norm: 4.263557793093209, ic: 0.06117956864368964
train 9, step: 1500, loss: 1.0969930432506443, grad_norm: 0.01974016858826964, ic: 0.389950163446284
train 9, step: 2000, loss: 1.0621220689919286, grad_norm: 0.42531008480561183, ic: 0.2768534509139947
Epoch 9: 2022-04-27 15:27:22.690683: train loss: 1.6277713818342687
Eval step 0: eval loss: 0.824401919783983
Eval: 2022-04-27 15:27:41.163051: total loss: 1.0728064492160594, mse:4.705636238463773, ic :0.16074378406568704, sharpe5:18.270212713479996, irr5:610.8309326171875, ndcg5:0.8412191154840846, pnl5:9.158917427062988 
train 10, step: 0, loss: 7.095202031705539, grad_norm: 1.9904768970967233, ic: 0.2523974520299579
train 10, step: 500, loss: 1.1256157172905221, grad_norm: 0.06409819315155879, ic: 0.06510433407122147
train 10, step: 1000, loss: 2.3778158550613497, grad_norm: 1.0628919962378194, ic: 0.1399475862226905
train 10, step: 1500, loss: 1.1276296640371348, grad_norm: 0.5803215584237668, ic: 0.02949118613588606
train 10, step: 2000, loss: 2.7459132417719414, grad_norm: 0.4177433775775513, ic: 0.4368828423612954
Epoch 10: 2022-04-27 15:33:20.762957: train loss: 1.6269518660897622
Eval step 0: eval loss: 0.8267862141069546
Eval: 2022-04-27 15:33:39.767908: total loss: 1.070885125238244, mse:4.677316768728722, ic :0.1733000720943156, sharpe5:18.173745317459105, irr5:599.8589477539062, ndcg5:0.8622200358233586, pnl5:5.911223411560059 
train 11, step: 0, loss: 1.2516334574995167, grad_norm: 0.04976340675178342, ic: 0.21597290548411938
train 11, step: 500, loss: 0.655133408196348, grad_norm: 0.04103330977964172, ic: 0.5351024543002404
train 11, step: 1000, loss: 0.9311564697869436, grad_norm: 0.11069006614128475, ic: 0.003263107894352961
train 11, step: 1500, loss: 1.0582996836879797, grad_norm: 0.09403161390277097, ic: 0.1791606442340625
train 11, step: 2000, loss: 0.7871542112522215, grad_norm: 0.004017950036649288, ic: 0.1372840658745791
Epoch 11: 2022-04-27 15:39:26.810912: train loss: 1.6262195092276321
Eval step 0: eval loss: 0.8291303114092136
Eval: 2022-04-27 15:39:43.580160: total loss: 1.0722198336521314, mse:4.686165577851118, ic :0.16966082668099783, sharpe5:18.471867048740386, irr5:611.1170654296875, ndcg5:0.8520631618370338, pnl5:10.722718238830566 
train 12, step: 0, loss: 0.9573959509531657, grad_norm: 0.19236650546105394, ic: 0.3990132661054851
train 12, step: 500, loss: 0.9232420675291769, grad_norm: 0.16879092175321828, ic: 0.18659873496981486
train 12, step: 1000, loss: 2.958480932150677, grad_norm: 0.3359175258300916, ic: 0.2126238726115737
train 12, step: 1500, loss: 0.9426330891803123, grad_norm: 0.17898674520006636, ic: -0.12126833862001841
train 12, step: 2000, loss: 0.8730868889846111, grad_norm: 0.0032565279169942223, ic: 0.22700189571173932
Epoch 12: 2022-04-27 15:45:24.999192: train loss: 1.624859209592091
Eval step 0: eval loss: 0.8276005735889752
Eval: 2022-04-27 15:45:44.132772: total loss: 1.067937691582558, mse:4.6268571798078355, ic :0.18969171043304608, sharpe5:17.418928760290147, irr5:582.9500732421875, ndcg5:0.8408388296312146, pnl5:5.038577556610107 
train 13, step: 0, loss: 2.071830967034055, grad_norm: 0.7054124865262821, ic: 0.42851520882817307
train 13, step: 500, loss: 0.8333823501982435, grad_norm: 0.2803538662902687, ic: 0.551118835434551
train 13, step: 1000, loss: 0.9623708840184563, grad_norm: 0.3709110742387891, ic: 0.5366385246953547
train 13, step: 1500, loss: 2.420264929742389, grad_norm: 0.48296264178586096, ic: -0.08508498821808295
train 13, step: 2000, loss: 1.4693539614306677, grad_norm: 0.3984963892235732, ic: 0.16860477267613927
Epoch 13: 2022-04-27 15:51:24.496654: train loss: 1.624686864944595
Eval step 0: eval loss: 0.824700599726686
Eval: 2022-04-27 15:51:42.785113: total loss: 1.0678082761034187, mse:4.606437453411093, ic :0.18617846211616185, sharpe5:17.810490925312042, irr5:585.1661376953125, ndcg5:0.8416432431842685, pnl5:8.782369613647461 
train 14, step: 0, loss: 4.5655767050994545, grad_norm: 1.4312549026195156, ic: 0.18479498342337025
train 14, step: 500, loss: 0.827179235055906, grad_norm: 0.004982396400774646, ic: 0.1260238989356638
train 14, step: 1000, loss: 1.8504424562215263, grad_norm: 1.4256566989792872, ic: 0.4315558415788514
train 14, step: 1500, loss: 1.1270860225851158, grad_norm: 0.10506562434191832, ic: -0.07076755089086229
train 14, step: 2000, loss: 1.1400026113417199, grad_norm: 0.22030485700257108, ic: 0.09676274534123039
Epoch 14: 2022-04-27 15:57:36.352404: train loss: 1.6213100085457441
Eval step 0: eval loss: 0.8325040955940463
Eval: 2022-04-27 15:57:54.492778: total loss: 1.0747020650070112, mse:4.820924637451754, ic :0.16790158216174844, sharpe5:18.022444499731062, irr5:593.8289184570312, ndcg5:0.8618005638055031, pnl5:5.5539751052856445 
train 15, step: 0, loss: 3.4144968233219846, grad_norm: 0.9253692848071122, ic: 0.1548223789680511
train 15, step: 500, loss: 1.2640603082138404, grad_norm: 0.08793687539421045, ic: -0.00588227905212118
train 15, step: 1000, loss: 1.3163560324568089, grad_norm: 0.12155091497590367, ic: 0.030124166925035542
train 15, step: 1500, loss: 0.8538734736405019, grad_norm: 0.2963322652547064, ic: 0.08670580839419251
train 15, step: 2000, loss: 1.4579031386813104, grad_norm: 0.6432413511995487, ic: 0.06131295846674601
Epoch 15: 2022-04-27 16:02:49.555629: train loss: 1.6205405887854496
Eval step 0: eval loss: 0.837611625518638
Eval: 2022-04-27 16:03:02.834108: total loss: 1.069833416162951, mse:4.58029519700246, ic :0.19413053729690832, sharpe5:17.401616427898407, irr5:597.3836669921875, ndcg5:0.849205706398744, pnl5:5.7870659828186035 
train 16, step: 0, loss: 0.7045344626818586, grad_norm: 0.36302995476887157, ic: -0.031505763425210526
train 16, step: 500, loss: 1.6228080333509793, grad_norm: 0.692936125307255, ic: 0.14539720123709637
train 16, step: 1000, loss: 0.880140732273911, grad_norm: 0.014644930376118408, ic: -0.1452684846970106
train 16, step: 1500, loss: 0.8545727981555359, grad_norm: 0.36918332139734045, ic: 0.15662176731443656
train 16, step: 2000, loss: 3.3222716730749378, grad_norm: 1.6106256646593768, ic: 0.01565588051165332
Epoch 16: 2022-04-27 16:07:05.807395: train loss: 1.6194249150411337
Eval step 0: eval loss: 0.8285309577515806
Eval: 2022-04-27 16:07:18.871605: total loss: 1.0679438505064656, mse:4.590009265695801, ic :0.188658837413632, sharpe5:17.516007224321363, irr5:580.8907470703125, ndcg5:0.8562505357993287, pnl5:6.197136878967285 
train 17, step: 0, loss: 1.2714250559515914, grad_norm: 0.29450906989773407, ic: -0.09709837527574966
train 17, step: 500, loss: 1.7602668741531164, grad_norm: 1.3497493882157388, ic: 0.23030761798303104
train 17, step: 1000, loss: 1.2810241116698702, grad_norm: 0.14232847495386206, ic: 0.15203422665464808
train 17, step: 1500, loss: 4.4940014235855985, grad_norm: 2.8463564913308774, ic: 0.22070800358344417
train 17, step: 2000, loss: 1.2635483480011933, grad_norm: 0.8206624216407401, ic: 0.0929308290087405
Epoch 17: 2022-04-27 16:11:24.395193: train loss: 1.6207087218007745
Eval step 0: eval loss: 0.8331319408999605
Eval: 2022-04-27 16:11:37.014441: total loss: 1.0784591607888847, mse:4.890142519849456, ic :0.15836873503082688, sharpe5:19.125041996240615, irr5:638.0680541992188, ndcg5:0.8346169342560974, pnl5:6.379505634307861 
train 18, step: 0, loss: 1.3847680260683026, grad_norm: 1.8939296257599976, ic: 0.16435456144088556
train 18, step: 500, loss: 1.5361636502787026, grad_norm: 0.9670498776200637, ic: -0.0700272608137375
train 18, step: 1000, loss: 0.6513101990582192, grad_norm: 0.03210956798134451, ic: 0.5776226756709614
train 18, step: 1500, loss: 1.4278109563754096, grad_norm: 0.047606624551035974, ic: 0.20775682782532218
train 18, step: 2000, loss: 0.9130303449691481, grad_norm: 0.015614377780312765, ic: -0.022628377117256335
Epoch 18: 2022-04-27 16:15:41.664674: train loss: 1.619921485050365
Eval step 0: eval loss: 0.8227225847314606
Eval: 2022-04-27 16:15:54.553442: total loss: 1.070175129935172, mse:4.751025054629789, ic :0.17826116430910632, sharpe5:19.314652805328368, irr5:634.885009765625, ndcg5:0.8507016998687, pnl5:8.636651039123535 
train 19, step: 0, loss: 1.4855508471292163, grad_norm: 0.7551096029126861, ic: -0.007380651225758237
train 19, step: 500, loss: 0.862751148365162, grad_norm: 0.028964523870285665, ic: 0.21804974265731286
train 19, step: 1000, loss: 0.9544068773134966, grad_norm: 0.024039172739631295, ic: 0.20852445267474184
train 19, step: 1500, loss: 3.9409186550202038, grad_norm: 1.0754127148454142, ic: 0.1345663093345999
train 19, step: 2000, loss: 1.0117302997295674, grad_norm: 0.1466595511735962, ic: 0.22914838630744855
Epoch 19: 2022-04-27 16:19:59.929992: train loss: 1.6199764403055048
Eval step 0: eval loss: 0.8317685222726224
Eval: 2022-04-27 16:20:12.986803: total loss: 1.068092438419814, mse:4.583231964449121, ic :0.19596279838474093, sharpe5:19.095534789562226, irr5:628.4801635742188, ndcg5:0.8505834775185205, pnl5:6.156386375427246 
train 20, step: 0, loss: 2.3117685431077075, grad_norm: 1.410942569591579, ic: 0.07582025855147005
train 20, step: 500, loss: 3.2040163352272724, grad_norm: 0.7048877167482893, ic: 0.10485950137405825
train 20, step: 1000, loss: 0.9613176345825196, grad_norm: 0.11878795386111997, ic: 0.1473966754938968
train 20, step: 1500, loss: 1.708634427641654, grad_norm: 5.36739174396698, ic: 0.23833819205773515
train 20, step: 2000, loss: 1.0306745967896105, grad_norm: 0.12832505334216818, ic: -0.002606325876175073
Epoch 20: 2022-04-27 16:24:13.888542: train loss: 1.617926809572461
Eval step 0: eval loss: 0.8303669003967992
Eval: 2022-04-27 16:24:26.873669: total loss: 1.0663326749328585, mse:4.576998265031318, ic :0.19903131805093963, sharpe5:19.097782309055326, irr5:645.03173828125, ndcg5:0.8501428356620665, pnl5:4.840500831604004 
train 21, step: 0, loss: 1.0177196557971016, grad_norm: 0.5886217695898159, ic: 0.0859880763240803
train 21, step: 500, loss: 0.7648917679238109, grad_norm: 0.014929901993746601, ic: 0.2194084059389647
train 21, step: 1000, loss: 0.9224096599378083, grad_norm: 0.7249095020330758, ic: 0.153562039250608
train 21, step: 1500, loss: 0.9844072532791126, grad_norm: 0.6896102302176463, ic: 0.3224311825126962
train 21, step: 2000, loss: 0.9450115824854651, grad_norm: 0.0987065981761047, ic: 0.07358227450413335
Epoch 21: 2022-04-27 16:28:30.798221: train loss: 1.6183263213365078
Eval step 0: eval loss: 0.8292106411354057
Eval: 2022-04-27 16:28:44.151275: total loss: 1.0673417386195128, mse:4.588788037977867, ic :0.19185753149009238, sharpe5:18.656212835311887, irr5:612.430419921875, ndcg5:0.8376427390459418, pnl5:8.194121360778809 
train 22, step: 0, loss: 1.04151847537628, grad_norm: 0.27172629391072345, ic: 0.21292334214573644
train 22, step: 500, loss: 3.2485488519435974, grad_norm: 1.2737159553180866, ic: -0.20621438920409196
train 22, step: 1000, loss: 1.1888149724530348, grad_norm: 0.12000740701956386, ic: 0.46854549897818243
train 22, step: 1500, loss: 0.9748852639531893, grad_norm: 0.20100841299492217, ic: 0.12501015648326474
train 22, step: 2000, loss: 1.7807830326140874, grad_norm: 1.4283099035332478, ic: 0.17932001420552207
Epoch 22: 2022-04-27 16:32:45.910528: train loss: 1.617302080287399
Eval step 0: eval loss: 0.8297776442307692
Eval: 2022-04-27 16:32:58.748719: total loss: 1.0675585735579718, mse:4.591910542005943, ic :0.1903955922185134, sharpe5:18.554873921871184, irr5:616.5731811523438, ndcg5:0.8536522553788324, pnl5:6.074868202209473 
train 23, step: 0, loss: 0.9898626058177233, grad_norm: 0.06157664156189121, ic: 0.15176366788029316
train 23, step: 500, loss: 1.4224367725605869, grad_norm: 0.10600147648075735, ic: 0.0004375978784999287
train 23, step: 1000, loss: 1.6572688802083335, grad_norm: 0.09202001424901005, ic: 0.25621475255979786
train 23, step: 1500, loss: 1.1218899707106198, grad_norm: 1.776950272356755, ic: 0.09793603063442703
train 23, step: 2000, loss: 1.9409608202222863, grad_norm: 1.3641278420165808, ic: 0.4280844092715191
Epoch 23: 2022-04-27 16:37:05.857312: train loss: 1.616305877780094
Eval step 0: eval loss: 0.8301044942455874
Eval: 2022-04-27 16:37:18.876293: total loss: 1.0656045119146993, mse:4.577987011817796, ic :0.19946076753394845, sharpe5:19.27936977624893, irr5:633.2627563476562, ndcg5:0.8405677216938073, pnl5:5.067971229553223 
train 24, step: 0, loss: 2.2047640730416043, grad_norm: 0.45729588133257754, ic: 0.10868477957390038
train 24, step: 500, loss: 1.2173037755350196, grad_norm: 0.0928476787489242, ic: 0.13500717795418174
train 24, step: 1000, loss: 0.9096749748111497, grad_norm: 0.029386953291298597, ic: 0.5314382871207082
train 24, step: 1500, loss: 2.5973305949866035, grad_norm: 2.713936447985399, ic: 0.06065493148671328
train 24, step: 2000, loss: 0.9214589461720659, grad_norm: 0.0780857226439165, ic: 0.1306219089299528
Epoch 24: 2022-04-27 16:41:23.047938: train loss: 1.6144352234030819
Eval step 0: eval loss: 0.824740539486466
Eval: 2022-04-27 16:41:36.075184: total loss: 1.066111697620759, mse:4.5963540640822425, ic :0.1941906498818272, sharpe5:18.575347537994382, irr5:624.858154296875, ndcg5:0.8518573870566026, pnl5:6.5024590492248535 
train 25, step: 0, loss: 0.8413095835092906, grad_norm: 0.05171474924961463, ic: 0.6081974060912997
train 25, step: 500, loss: 0.8637821623926076, grad_norm: 0.007045807476337276, ic: 0.27544279289824614
train 25, step: 1000, loss: 2.1053508633615765, grad_norm: 0.21916329288123185, ic: 0.24991369016766452
train 25, step: 1500, loss: 1.1226790122314785, grad_norm: 0.9284173940910427, ic: 0.5368822229753407
train 25, step: 2000, loss: 1.013858072464868, grad_norm: 0.7628685176795185, ic: 0.566980348547846
Epoch 25: 2022-04-27 16:45:40.948906: train loss: 1.6167441021246127
Eval step 0: eval loss: 0.8257185812368282
Eval: 2022-04-27 16:45:54.118307: total loss: 1.0656194473275746, mse:4.576184832684973, ic :0.19774873357602735, sharpe5:18.932674759626387, irr5:642.46435546875, ndcg5:0.8538242172314541, pnl5:4.376842975616455 
train 26, step: 0, loss: 6.743790404103434, grad_norm: 2.0721588565560634, ic: 0.149680398166481
train 26, step: 500, loss: 3.861830913433346, grad_norm: 3.871625046347117, ic: 0.3782248908883266
train 26, step: 1000, loss: 1.2573602457810047, grad_norm: 2.2267609937933632, ic: 0.01827273640168306
train 26, step: 1500, loss: 0.8382412130558569, grad_norm: 0.1637355973716412, ic: 0.2986606259963375
train 26, step: 2000, loss: 0.9560181912618018, grad_norm: 0.3439147706767367, ic: 0.1424393925250254
Epoch 26: 2022-04-27 16:49:59.144571: train loss: 1.6159102845971762
Eval step 0: eval loss: 0.8262994121073168
Eval: 2022-04-27 16:50:12.224810: total loss: 1.0656448600070023, mse:4.5908656783353505, ic :0.19435284259201105, sharpe5:18.90506697177887, irr5:641.031982421875, ndcg5:0.8424463893405426, pnl5:6.224853515625 
train 27, step: 0, loss: 0.8246392463235294, grad_norm: 0.017118467472979293, ic: 0.15939448193302122
train 27, step: 500, loss: 0.9387628788719151, grad_norm: 3.4144807045404226, ic: 0.2883420439993704
train 27, step: 1000, loss: 0.7555943700756478, grad_norm: 0.5173506041761415, ic: 0.16023648097516296
train 27, step: 1500, loss: 0.6361384179049918, grad_norm: 0.03884417134925523, ic: 0.5195861057122724
train 27, step: 2000, loss: 1.3788099469972002, grad_norm: 0.07264384236741757, ic: 0.048136644945927044
Epoch 27: 2022-04-27 16:54:16.107968: train loss: 1.615221803651364
Eval step 0: eval loss: 0.8309041255392189
Eval: 2022-04-27 16:54:29.257888: total loss: 1.0665251099648272, mse:4.585895001877073, ic :0.19487915786183613, sharpe5:17.802083537578582, irr5:619.8605346679688, ndcg5:0.8642955027763565, pnl5:4.760248184204102 
train 28, step: 0, loss: 1.5363854367760619, grad_norm: 1.4572788921452577, ic: 0.21298381061144575
train 28, step: 500, loss: 1.3593534381113752, grad_norm: 3.0323524351978453, ic: 0.20177349456551533
train 28, step: 1000, loss: 0.9176195759760332, grad_norm: 0.32224237794500143, ic: 0.5748112826090074
train 28, step: 1500, loss: 1.0316329043135684, grad_norm: 0.028907411759325943, ic: 0.03115489844599519
train 28, step: 2000, loss: 1.0464341801368386, grad_norm: 0.2591206755209476, ic: 0.09619551131027917
Epoch 28: 2022-04-27 16:58:36.935861: train loss: 1.6113322286223783
Eval step 0: eval loss: 0.8214558962147654
Eval: 2022-04-27 16:58:49.974556: total loss: 1.0661347349800665, mse:4.601314343310153, ic :0.1958461586603962, sharpe5:18.437548863887788, irr5:617.466552734375, ndcg5:0.8485823232981516, pnl5:8.251054763793945 
train 29, step: 0, loss: 0.9079115999928923, grad_norm: 0.051297988476124504, ic: 0.09849927507096204
train 29, step: 500, loss: 1.0998319400735834, grad_norm: 0.10139587202346702, ic: 0.6177098627800273
train 29, step: 1000, loss: 1.048691721028396, grad_norm: 1.202557215252702, ic: 0.09968327322874512
train 29, step: 1500, loss: 2.3872230404713113, grad_norm: 0.7890645561403579, ic: -0.028952113363709567
train 29, step: 2000, loss: 4.20592357494213, grad_norm: 46.008261565611065, ic: 0.1974265014521608
Epoch 29: 2022-04-27 17:02:54.298972: train loss: 1.612881234024926
Eval step 0: eval loss: 0.8299873118908061
Eval: 2022-04-27 17:03:07.327109: total loss: 1.0668713516025865, mse:4.576103736134805, ic :0.1981416539215351, sharpe5:20.156082104444504, irr5:663.447265625, ndcg5:0.8339529326806498, pnl5:5.4265618324279785 
train 30, step: 0, loss: 1.0046992089414628, grad_norm: 0.22647565271120712, ic: 0.531883649315238
train 30, step: 500, loss: 1.432457965353261, grad_norm: 2.424201563418812, ic: 0.014366301589253483
train 30, step: 1000, loss: 0.9745512066465436, grad_norm: 0.15917142549183394, ic: -0.012647221150415864
train 30, step: 1500, loss: 1.5154319889863417, grad_norm: 7.006541203425044, ic: 0.16418097909009077
train 30, step: 2000, loss: 1.8429142806761667, grad_norm: 1.2369313879294368, ic: 0.07454584223590897
Epoch 30: 2022-04-27 17:07:12.602323: train loss: 1.6168542875441554
Eval step 0: eval loss: 0.8295772379643045
Eval: 2022-04-27 17:07:25.578646: total loss: 1.0703894175074815, mse:4.638626502925091, ic :0.19694958902841375, sharpe5:19.626713697910308, irr5:673.913818359375, ndcg5:0.8550573018116945, pnl5:3.7923600673675537 
train 31, step: 0, loss: 1.0578895428811181, grad_norm: 0.8472075954482793, ic: 0.3524525665177133
train 31, step: 500, loss: 1.4782176327803498, grad_norm: 2.2905164364326023, ic: 0.05683656142904252
train 31, step: 1000, loss: 4.524952277273615, grad_norm: 7.080659073515388, ic: 0.4521695406664076
train 31, step: 1500, loss: 0.7661307546968625, grad_norm: 0.10048075677861815, ic: 0.7121645025429488
train 31, step: 2000, loss: 1.2422175537851443, grad_norm: 2.5839561524428394, ic: 0.13202000789737312
Epoch 31: 2022-04-27 17:11:29.680856: train loss: 1.6117252652277012
Eval step 0: eval loss: 0.8364624409328898
Eval: 2022-04-27 17:11:42.630501: total loss: 1.0681221587034093, mse:4.587413147012681, ic :0.19169484340139478, sharpe5:18.31636064529419, irr5:603.6145629882812, ndcg5:0.87246553531194, pnl5:5.601790428161621 
train 32, step: 0, loss: 1.1288046357414263, grad_norm: 0.07071771740952852, ic: 0.18263407126364595
train 32, step: 500, loss: 1.4855336106668307, grad_norm: 3.3529667502632763, ic: 0.12771339266931403
train 32, step: 1000, loss: 1.0560629412034532, grad_norm: 0.29094455888635806, ic: 0.5214284327044991
train 32, step: 1500, loss: 0.9665111131471682, grad_norm: 2.7789624112525315, ic: 0.08378413569204674
train 32, step: 2000, loss: 0.9385929095899522, grad_norm: 0.0906427663189056, ic: 0.5591603891525991
Epoch 32: 2022-04-27 17:15:46.414595: train loss: 1.6125387326625675
Eval step 0: eval loss: 0.8212268696695534
Eval: 2022-04-27 17:15:59.223107: total loss: 1.0635954328027395, mse:4.5878884215554985, ic :0.20315421297249198, sharpe5:19.80240615606308, irr5:661.6845092773438, ndcg5:0.8380956761138393, pnl5:14.15916633605957 
train 33, step: 0, loss: 1.257566953237491, grad_norm: 0.7567540970873077, ic: 0.2462213446018914
train 33, step: 500, loss: 0.9890142314027883, grad_norm: 0.07518155768535212, ic: 0.1453764232995214
train 33, step: 1000, loss: 1.0406975618384915, grad_norm: 10.619019443005264, ic: 0.2158044874972591
train 33, step: 1500, loss: 0.902513026625519, grad_norm: 0.159449052250824, ic: 0.5580423989433957
train 33, step: 2000, loss: 0.8154196278229002, grad_norm: 0.14585227122974265, ic: 0.23660450148868448
Epoch 33: 2022-04-27 17:20:04.148144: train loss: 1.6100496472556542
Eval step 0: eval loss: 0.827862979740187
Eval: 2022-04-27 17:20:17.087482: total loss: 1.0653196500317943, mse:4.575921914223949, ic :0.19777683839740867, sharpe5:18.681223111152647, irr5:618.2864379882812, ndcg5:0.8471634622873582, pnl5:5.666501998901367 
train 34, step: 0, loss: 1.0122939459901978, grad_norm: 1.1978641049025476, ic: 0.6038190213489136
train 34, step: 500, loss: 0.8235637886443998, grad_norm: 4.172033509479949, ic: 0.21573166993649967
train 34, step: 1000, loss: 3.2011471234158986, grad_norm: 1.9522157708457735, ic: 0.3244417450223613
train 34, step: 1500, loss: 0.8026302005735995, grad_norm: 0.5108002247030585, ic: 0.6939660341057647
train 34, step: 2000, loss: 5.309622506777692, grad_norm: 66.02962099100314, ic: 0.43378953172687923
Epoch 34: 2022-04-27 17:24:19.325259: train loss: 1.6080726121631572
Eval step 0: eval loss: 0.8203972674772787
Eval: 2022-04-27 17:24:32.200434: total loss: 1.0668727376252247, mse:4.602503695611963, ic :0.19849257371037743, sharpe5:18.60226669192314, irr5:628.3640747070312, ndcg5:0.8429228420312599, pnl5:6.564326286315918 
train 35, step: 0, loss: 1.1794479549632353, grad_norm: 0.8145804272170387, ic: 0.5611451659294913
train 35, step: 500, loss: 1.1740211617819911, grad_norm: 0.8359690751991689, ic: 0.2156976068518806
train 35, step: 1000, loss: 1.6543443035927548, grad_norm: 12.91737803610511, ic: 0.01948097971771813
train 35, step: 1500, loss: 1.6097788416353385, grad_norm: 2.6269660627325857, ic: 0.003435433774820189
train 35, step: 2000, loss: 0.7835475493242396, grad_norm: 2.5762123264872, ic: 0.5693917576968202
Epoch 35: 2022-04-27 17:28:33.520499: train loss: 1.6141134416805083
Eval step 0: eval loss: 0.8385643913823762
Eval: 2022-04-27 17:28:47.228504: total loss: 1.069700764753414, mse:4.580327206048852, ic :0.1949921712971078, sharpe5:18.30437955021858, irr5:612.7694702148438, ndcg5:0.8537702924930004, pnl5:8.383615493774414 
train 36, step: 0, loss: 1.8447848189756673, grad_norm: 0.7904556637557048, ic: 0.13524228245737618
train 36, step: 500, loss: 0.8292020853341706, grad_norm: 0.037616151179728274, ic: 0.25366791300850283
train 36, step: 1000, loss: 1.6614563210227271, grad_norm: 0.999692046609066, ic: 0.2281018299412057
train 36, step: 1500, loss: 0.7642569241390513, grad_norm: 0.14181576516056887, ic: 0.38447743250669675
train 36, step: 2000, loss: 1.1467330726581115, grad_norm: 1.4155650010083942, ic: 0.7468898635615655
Epoch 36: 2022-04-27 17:33:09.475064: train loss: 1.6130660317096037
Eval step 0: eval loss: 0.8253166110297022
Eval: 2022-04-27 17:33:22.394504: total loss: 1.0651794828241985, mse:4.588866859747462, ic :0.1963907470602348, sharpe5:19.272031284570694, irr5:637.6329956054688, ndcg5:0.8573999677136733, pnl5:6.034272193908691 
train 37, step: 0, loss: 2.0171014338868685, grad_norm: 3.5995534606011184, ic: 0.18710540352721625
train 37, step: 500, loss: 2.346767108164254, grad_norm: 1.8569957392867658, ic: 0.0014031487879862421
train 37, step: 1000, loss: 1.081419969439688, grad_norm: 0.14834425656088096, ic: 0.07042519679341312
train 37, step: 1500, loss: 2.0066795648547884, grad_norm: 2.0275229698550907, ic: 0.6124144671346851
train 37, step: 2000, loss: 1.3231543860958264, grad_norm: 0.24877776734669038, ic: 0.12461627002777276
Epoch 37: 2022-04-27 17:37:29.338157: train loss: 1.6067385042206874
Eval step 0: eval loss: 0.8231886129107941
Eval: 2022-04-27 17:37:42.343251: total loss: 1.0644238449689671, mse:4.586107763381843, ic :0.1989172997568408, sharpe5:18.413376678228378, irr5:633.639404296875, ndcg5:0.852423749404113, pnl5:7.614592552185059 
train 38, step: 0, loss: 1.3203526938833843, grad_norm: 1.4350235317451687, ic: -0.05257303822329787
train 38, step: 500, loss: 0.9076671459056713, grad_norm: 0.06057557400361174, ic: 0.26461889907686464
train 38, step: 1000, loss: 0.9000814445405139, grad_norm: 0.22716478099316198, ic: 0.17379687855809106
train 38, step: 1500, loss: 0.957186224610858, grad_norm: 0.03684622336736909, ic: 0.18627215610653053
train 38, step: 2000, loss: 2.2982590781958083, grad_norm: 2.3639172878871983, ic: 0.0016157427057359314
Epoch 38: 2022-04-27 17:41:48.038092: train loss: 1.6109739960194212
Eval step 0: eval loss: 0.8239029622052818
Eval: 2022-04-27 17:42:00.874405: total loss: 1.0646623760738885, mse:4.581368067725909, ic :0.1994731603578935, sharpe5:19.193307563066483, irr5:646.4637451171875, ndcg5:0.8490107975401457, pnl5:7.960272312164307 
train 39, step: 0, loss: 0.9678391389525994, grad_norm: 0.009044005508122645, ic: 0.1272681136951112
train 39, step: 500, loss: 0.907898934413432, grad_norm: 1.0121720210369476, ic: 0.2343627739326632
train 39, step: 1000, loss: 0.9482914618835682, grad_norm: 0.3278449344788464, ic: 0.2024218584864636
train 39, step: 1500, loss: 2.067130159840531, grad_norm: 0.33557172403451774, ic: 0.22695560437751552
train 39, step: 2000, loss: 0.6114646586196683, grad_norm: 0.05602016981049261, ic: 0.11730911923175669
Epoch 39: 2022-04-27 17:46:04.627711: train loss: 1.609106142703074
Eval step 0: eval loss: 0.8252206527018572
Eval: 2022-04-27 17:46:18.392158: total loss: 1.0648047097604931, mse:4.589289748764095, ic :0.1965014730903367, sharpe5:19.270750501155852, irr5:647.1160888671875, ndcg5:0.8472709858566377, pnl5:9.469013214111328 
train 40, step: 0, loss: 0.8793691177814328, grad_norm: 0.02482620146870941, ic: 0.23860447437849908
train 40, step: 500, loss: 1.08888279572698, grad_norm: 0.08329448138002477, ic: 0.4742463408191292
train 40, step: 1000, loss: 1.2916386301924543, grad_norm: 1.1915965433080986, ic: 0.10128841268842018
train 40, step: 1500, loss: 2.6070442011171746, grad_norm: 2.494595058424114, ic: 0.08181185861765636
train 40, step: 2000, loss: 1.0607680289602317, grad_norm: 6.381765372624132, ic: 0.10739575074512336
Epoch 40: 2022-04-27 17:50:22.877953: train loss: 1.6102315366718647
Eval step 0: eval loss: 0.8239574372077515
Eval: 2022-04-27 17:50:35.878817: total loss: 1.0635531438856507, mse:4.576907032801703, ic :0.20074865872887782, sharpe5:19.320801322460174, irr5:647.6800537109375, ndcg5:0.8493262197269372, pnl5:8.308510780334473 
train 41, step: 0, loss: 1.6301592245869252, grad_norm: 0.2791099659748027, ic: 0.41372406938009554
train 41, step: 500, loss: 1.2442331808687912, grad_norm: 0.7913318451596967, ic: 0.26474642146872707
train 41, step: 1000, loss: 1.0928087540255247, grad_norm: 6.55525394303971, ic: 0.14003908392276687
train 41, step: 1500, loss: 3.287287961185415, grad_norm: 4.540169125829041, ic: -0.01919704325333439
train 41, step: 2000, loss: 1.0458049054958523, grad_norm: 0.4154200897641862, ic: 0.08350791785183709
Epoch 41: 2022-04-27 17:54:38.977142: train loss: 1.6037555039319038
Eval step 0: eval loss: 0.831643493459398
Eval: 2022-04-27 17:54:52.148282: total loss: 1.068235152190251, mse:4.606349367984533, ic :0.1922377891676951, sharpe5:18.895087455511092, irr5:654.1381225585938, ndcg5:0.854356986393319, pnl5:5.497856616973877 
train 42, step: 0, loss: 2.189416082974138, grad_norm: 4.908520063049758, ic: 0.0878434208610603
train 42, step: 500, loss: 1.4668496414937353, grad_norm: 4.6266495656686, ic: 0.18252068157150095
train 42, step: 1000, loss: 3.422462760011664, grad_norm: 7.994069522101989, ic: 0.07164853670561881
train 42, step: 1500, loss: 1.1970659260490544, grad_norm: 0.1497951076181594, ic: 0.5648059500271643
train 42, step: 2000, loss: 1.185545040417269, grad_norm: 0.05824731865260998, ic: 0.47756068174954364
Epoch 42: 2022-04-27 17:58:53.979158: train loss: 1.60499676294222
Eval step 0: eval loss: 0.8250697691649104
Eval: 2022-04-27 17:59:07.082254: total loss: 1.0636665764175721, mse:4.572781412424394, ic :0.2018334691844495, sharpe5:18.73227661371231, irr5:639.4614868164062, ndcg5:0.8290126187898638, pnl5:3.8557207584381104 
train 43, step: 0, loss: 0.8413087868992286, grad_norm: 0.6188730307334989, ic: 0.06736886723946287
train 43, step: 500, loss: 0.9604802633192701, grad_norm: 2.67303249018694, ic: 0.25796952558667374
train 43, step: 1000, loss: 1.694964243613958, grad_norm: 1.4625541103991073, ic: -0.09781160934342399
train 43, step: 1500, loss: 1.3983932298652093, grad_norm: 0.1509275457276839, ic: 0.1619659323346847
train 43, step: 2000, loss: 1.6804291492372048, grad_norm: 0.9287722481932791, ic: -0.08298294219789921
Epoch 43: 2022-04-27 18:03:29.255705: train loss: 1.6025947732584864
Eval step 0: eval loss: 0.8208059907838843
Eval: 2022-04-27 18:03:41.936184: total loss: 1.0640238127931323, mse:4.598249970290659, ic :0.19976337612450704, sharpe5:19.062077397108077, irr5:652.2379760742188, ndcg5:0.8365331075026382, pnl5:3.2635183334350586 
train 44, step: 0, loss: 1.032504028784458, grad_norm: 0.11635338613692062, ic: 0.065505489573751
train 44, step: 500, loss: 2.103593489174195, grad_norm: 5.425005041709946, ic: 0.12118603001394597
train 44, step: 1000, loss: 1.8266839496159957, grad_norm: 3.2162794404649313, ic: 0.07936740971440287
train 44, step: 1500, loss: 1.0278790967621927, grad_norm: 0.23240794644748697, ic: 0.1676100718689108
train 44, step: 2000, loss: 0.9437418619791667, grad_norm: 0.4656500428607535, ic: 0.6922967615971869
Epoch 44: 2022-04-27 18:08:06.376258: train loss: 1.6049208921505373
Eval step 0: eval loss: 0.8211204279587064
Eval: 2022-04-27 18:08:19.509814: total loss: 1.0638090686392576, mse:4.588855335969017, ic :0.1998871504346692, sharpe5:19.7691568672657, irr5:659.8621215820312, ndcg5:0.8457353016762995, pnl5:4.913285732269287 
train 45, step: 0, loss: 1.6513484639332707, grad_norm: 1.280709900323326, ic: 0.08927249213715939
train 45, step: 500, loss: 0.9552528227440562, grad_norm: 0.10167914653416515, ic: 0.4883237831294433
train 45, step: 1000, loss: 1.5417463057770404, grad_norm: 0.3609092592287584, ic: 0.7601578239280168
train 45, step: 1500, loss: 0.999601749348426, grad_norm: 0.8679273672149541, ic: 0.17921172896848636
train 45, step: 2000, loss: 1.7230784696691175, grad_norm: 0.6411769626568109, ic: 0.4498114227412635
Epoch 45: 2022-04-27 18:12:22.392258: train loss: 1.599597711971638
Eval step 0: eval loss: 0.8239634185244336
Eval: 2022-04-27 18:12:35.754088: total loss: 1.0635781508825193, mse:4.578669937273473, ic :0.19926580384874915, sharpe5:19.29838666677475, irr5:641.1392211914062, ndcg5:0.8534923675147122, pnl5:4.033642292022705 
train 46, step: 0, loss: 2.1316604899392684, grad_norm: 4.822082971510492, ic: 0.026037712716130493
train 46, step: 500, loss: 1.9495752604166667, grad_norm: 3.854105981223417, ic: 0.09343621091243963
train 46, step: 1000, loss: 0.8902730522097876, grad_norm: 1.7935740818603014, ic: 0.08368678347288225
train 46, step: 1500, loss: 1.2658809538810485, grad_norm: 1.1305251204957263, ic: 0.9182583734303531
train 46, step: 2000, loss: 2.621281637897595, grad_norm: 1.938476810435931, ic: 0.33588073747863373
Epoch 46: 2022-04-27 18:16:39.778480: train loss: 1.5969538335442934
Eval step 0: eval loss: 0.8208320384533061
Eval: 2022-04-27 18:16:52.740086: total loss: 1.0647381155822704, mse:4.595092842360458, ic :0.20016703763293295, sharpe5:17.905331329107284, irr5:621.3773193359375, ndcg5:0.8516260599623668, pnl5:5.489781379699707 
train 47, step: 0, loss: 1.0664391041908352, grad_norm: 0.05072399349109709, ic: 0.2191248002255649
train 47, step: 500, loss: 1.4748950686514408, grad_norm: 1.3997439560359497, ic: 0.122673018803679
train 47, step: 1000, loss: 3.294949106797057, grad_norm: 61.52544741282602, ic: 0.4534864343013881
train 47, step: 1500, loss: 1.6542287686975992, grad_norm: 5.6553639192134115, ic: -0.04644910671720135
train 47, step: 2000, loss: 1.2867352323940175, grad_norm: 1.8818926064919277, ic: 0.0839380655866979
Epoch 47: 2022-04-27 18:20:54.569554: train loss: 1.5996858476497626
Eval step 0: eval loss: 0.8244853366413658
Eval: 2022-04-27 18:21:07.373961: total loss: 1.06342631417379, mse:4.590043719813264, ic :0.19906324981926363, sharpe5:18.82866833567619, irr5:645.6375122070312, ndcg5:0.8538702171739375, pnl5:4.170482158660889 
train 48, step: 0, loss: 1.0740104166666666, grad_norm: 2.1942605897749674, ic: 0.24029039393822926
train 48, step: 500, loss: 1.2836464677590875, grad_norm: 0.7020722235055594, ic: 0.20784318905740035
train 48, step: 1000, loss: 1.5798680418996398, grad_norm: 6.456842060934648, ic: 0.13613063331897168
train 48, step: 1500, loss: 1.1410584712503662, grad_norm: 0.09877935330571398, ic: 0.5110446815149143
train 48, step: 2000, loss: 2.351406733658048, grad_norm: 1.9907991147685338, ic: 0.5395236370645571
Epoch 48: 2022-04-27 18:25:09.525004: train loss: 1.5992603754014394
Eval step 0: eval loss: 0.8537157740055321
Eval: 2022-04-27 18:25:22.541304: total loss: 1.0792697751834681, mse:4.625315994145126, ic :0.19868205782072274, sharpe5:19.083824229240417, irr5:647.1368408203125, ndcg5:0.8567135634433828, pnl5:5.284838676452637 
train 49, step: 0, loss: 0.9312328602532921, grad_norm: 2.810880500452722, ic: 0.11396547242330739
train 49, step: 500, loss: 1.5077245360717264, grad_norm: 0.060018397041331245, ic: 0.020794235484607695
train 49, step: 1000, loss: 1.7587844848632814, grad_norm: 0.2683833513733071, ic: 0.13021383790558755
train 49, step: 1500, loss: 1.5943504190716538, grad_norm: 0.49763148516655475, ic: 0.4522617729508617
train 49, step: 2000, loss: 0.9549652304425335, grad_norm: 0.7703158122073174, ic: 0.5860319362764561
Epoch 49: 2022-04-27 18:29:51.632560: train loss: 1.5975223121590247
Eval step 0: eval loss: 0.820877445007903
Eval: 2022-04-27 18:30:04.725860: total loss: 1.0636309672573594, mse:4.591372912079225, ic :0.20185075514748166, sharpe5:18.71681829571724, irr5:634.3798828125, ndcg5:0.8388347486953412, pnl5:3.4548583030700684 
train 50, step: 0, loss: 1.4462183214473432, grad_norm: 3.2324814777556554, ic: 0.15885887298008314
train 50, step: 500, loss: 2.772273730854743, grad_norm: 1.7081434508010616, ic: 0.2960195619564795
train 50, step: 1000, loss: 0.8581405686027735, grad_norm: 0.028567432316106357, ic: 0.1677455607714861
train 50, step: 1500, loss: 1.369896352061682, grad_norm: 1.0663989458195116, ic: 0.37122909866250486
train 50, step: 2000, loss: 9.60575258984682, grad_norm: 10.23021578007248, ic: 0.09558926274953637
Epoch 50: 2022-04-27 18:34:08.491420: train loss: 1.5951560492874168
Eval step 0: eval loss: 0.8229238270959562
Eval: 2022-04-27 18:34:21.669228: total loss: 1.0643019886116394, mse:4.598874545204451, ic :0.19554600853606946, sharpe5:19.57178000807762, irr5:652.7142944335938, ndcg5:0.8381004006693049, pnl5:4.716940402984619 
train 51, step: 0, loss: 3.3587550723188477, grad_norm: 2.047676769778726, ic: 0.04281974391294065
train 51, step: 500, loss: 1.4438435717680607, grad_norm: 3.093043411969517, ic: 0.055594699791551204
train 51, step: 1000, loss: 1.5135886892085975, grad_norm: 0.33803495225482566, ic: 0.917227237146732
train 51, step: 1500, loss: 1.0215084817257574, grad_norm: 0.5814983551764743, ic: 0.22477072668230993
train 51, step: 2000, loss: 2.340177645228216, grad_norm: 0.041235025455144736, ic: 0.16324002655773517
Epoch 51: 2022-04-27 18:38:28.023248: train loss: 1.5947882088841356
Eval step 0: eval loss: 0.8190331413823762
Eval: 2022-04-27 18:38:41.016747: total loss: 1.064050508820969, mse:4.607222849878124, ic :0.20116614986962025, sharpe5:19.666240149736403, irr5:654.1065063476562, ndcg5:0.8381684368346545, pnl5:3.6689395904541016 
train 52, step: 0, loss: 1.2011540299755032, grad_norm: 1.1275950009969287, ic: 0.1379672956378699
train 52, step: 500, loss: 1.6882475697840973, grad_norm: 3.598449192615007, ic: 0.2040186138355665
train 52, step: 1000, loss: 1.1866693515270117, grad_norm: 0.8275100662175137, ic: 0.5777055649827576
train 52, step: 1500, loss: 1.0546345685137664, grad_norm: 0.40312411493621597, ic: -0.03555987816708313
train 52, step: 2000, loss: 1.3896421299154635, grad_norm: 1.7573996813659274, ic: 0.18746600155967208
Epoch 52: 2022-04-27 18:42:42.226044: train loss: 1.5954271818362817
Eval step 0: eval loss: 0.8236909148816187
Eval: 2022-04-27 18:42:55.320693: total loss: 1.0634854885157692, mse:4.603988026939197, ic :0.20237188111230356, sharpe5:18.80989549398422, irr5:645.2880249023438, ndcg5:0.8535390309337847, pnl5:3.2653889656066895 
train 53, step: 0, loss: 3.0479350052045615, grad_norm: 10.430389399769357, ic: 0.15240846706957772
train 53, step: 500, loss: 1.057186435705081, grad_norm: 0.04041255726945595, ic: 0.49821014577403533
train 53, step: 1000, loss: 1.281969562113428, grad_norm: 3.355350407848345, ic: 0.11373287240287414
train 53, step: 1500, loss: 1.3246042488235685, grad_norm: 1.7747556472934967, ic: 0.12372691114447769
train 53, step: 2000, loss: 3.053162341414241, grad_norm: 10.4424980514565, ic: 0.2948465571761291
Epoch 53: 2022-04-27 18:46:59.296594: train loss: 1.5957780534190327
Eval step 0: eval loss: 0.8238345307972207
Eval: 2022-04-27 18:47:12.082679: total loss: 1.064831651760455, mse:4.609055077645507, ic :0.1998033243393764, sharpe5:18.73818486571312, irr5:633.238525390625, ndcg5:0.8384489305231604, pnl5:8.309151649475098 
train 54, step: 0, loss: 1.9086259145585318, grad_norm: 20.327138708029725, ic: 0.05218457113469945
train 54, step: 500, loss: 0.8642730802912979, grad_norm: 0.09133451509869527, ic: 0.5414964220450006
train 54, step: 1000, loss: 2.2302664129691165, grad_norm: 0.3590861054971347, ic: 0.1634540965615182
train 54, step: 1500, loss: 1.7367017629923946, grad_norm: 2.621572407299338, ic: 0.22272819782890257
train 54, step: 2000, loss: 2.1078125, grad_norm: 1.5306712733185306, ic: 0.029937405087312477
Epoch 54: 2022-04-27 18:51:15.688344: train loss: 1.5919038089642323
Eval step 0: eval loss: 0.8237247446942505
Eval: 2022-04-27 18:51:28.835301: total loss: 1.0659482558073297, mse:4.615976697503126, ic :0.1989546459451731, sharpe5:18.866408879756925, irr5:650.624267578125, ndcg5:0.8357711536820943, pnl5:6.128054618835449 
train 55, step: 0, loss: 1.8168493058281006, grad_norm: 2.728038536431601, ic: 0.10543714676967635
train 55, step: 500, loss: 0.8752446660352403, grad_norm: 0.13338074996180319, ic: 0.32525661243569925
train 55, step: 1000, loss: 1.0516518305318163, grad_norm: 1.0128102813569868, ic: 0.11374529909049608
train 55, step: 1500, loss: 1.0525841846288282, grad_norm: 0.15939845753601495, ic: 0.5859241484564126
train 55, step: 2000, loss: 2.2598897516271057, grad_norm: 2.1625275719201955, ic: 0.06261616676260275
Epoch 55: 2022-04-27 18:55:32.507158: train loss: 1.5902084249813846
Eval step 0: eval loss: 0.8276329884664778
Eval: 2022-04-27 18:55:45.141115: total loss: 1.065992706677272, mse:4.600564335731287, ic :0.1904599597611122, sharpe5:18.891324563026426, irr5:628.5989379882812, ndcg5:0.8465688844071232, pnl5:6.749557018280029 
train 56, step: 0, loss: 1.0116105535823794, grad_norm: 0.05086584921383055, ic: 0.11146651105503949
train 56, step: 500, loss: 0.9140193408361146, grad_norm: 0.20570420474123205, ic: 0.050681277349677735
train 56, step: 1000, loss: 5.087959549712529, grad_norm: 19.94699766339999, ic: 0.0875221277418014
train 56, step: 1500, loss: 1.1581926103299325, grad_norm: 0.10950760936978421, ic: 0.11595192082203071
train 56, step: 2000, loss: 0.9663448831662892, grad_norm: 3.1323951677642357, ic: 0.4508182264635574
Epoch 56: 2022-04-27 18:59:50.742624: train loss: 1.6024528573241097
Eval step 0: eval loss: 0.8277742247184535
Eval: 2022-04-27 19:00:03.684545: total loss: 1.064375517568595, mse:4.586611702074982, ic :0.20077545173047254, sharpe5:18.698834356069565, irr5:652.8211059570312, ndcg5:0.8553798914153531, pnl5:4.194868564605713 
train 57, step: 0, loss: 1.0327378166550993, grad_norm: 0.05647191607363228, ic: 0.13171096740691945
train 57, step: 500, loss: 0.901862325736855, grad_norm: 0.3400026314756944, ic: 0.5699645968764417
train 57, step: 1000, loss: 2.282387395332161, grad_norm: 9.883591484845216, ic: 0.11960232023068287
train 57, step: 1500, loss: 1.1192195480764393, grad_norm: 0.44614406134194784, ic: 0.11141642430241346
train 57, step: 2000, loss: 1.0602899153381182, grad_norm: 4.682401087781297, ic: 0.6035334480238796
Epoch 57: 2022-04-27 19:04:05.921416: train loss: 1.5993531038975073
Eval step 0: eval loss: 0.8200335648338711
Eval: 2022-04-27 19:04:18.963826: total loss: 1.0595605661992575, mse:4.56891339028345, ic :0.20133002391027596, sharpe5:19.08197021484375, irr5:663.96728515625, ndcg5:0.8467949640925009, pnl5:5.352551460266113 
train 58, step: 0, loss: 1.5100419799517912, grad_norm: 4.612821028846119, ic: 0.16930845488622945
train 58, step: 500, loss: 1.4085598382473383, grad_norm: 4.492033055662408, ic: 0.13088970228910357
train 58, step: 1000, loss: 1.5245782844387756, grad_norm: 1.29918778698929, ic: 0.09094764028048008
train 58, step: 1500, loss: 2.257980137133271, grad_norm: 0.7276530537634309, ic: 0.42217491387953704
train 58, step: 2000, loss: 0.9489926807420174, grad_norm: 1.185097660157913, ic: 0.2979593051792212
Epoch 58: 2022-04-27 19:08:20.997663: train loss: 1.5942598205482637
Eval step 0: eval loss: 0.8218311112849052
Eval: 2022-04-27 19:08:34.275012: total loss: 1.061696364209844, mse:4.587182812079036, ic :0.20025893043247095, sharpe5:18.821670377254485, irr5:640.5723876953125, ndcg5:0.8439001683566744, pnl5:5.374414443969727 
train 59, step: 0, loss: 1.1843133764405605, grad_norm: 0.8055965790879631, ic: -0.0027896630437339535
train 59, step: 500, loss: 0.7115614417993512, grad_norm: 1.7115339315366316, ic: 0.2106523002568428
train 59, step: 1000, loss: 5.107472906769596, grad_norm: 5.179644045172286, ic: -0.10620938507983688
train 59, step: 1500, loss: 1.365671452913178, grad_norm: 2.397826106295124, ic: 0.1972595664965225
train 59, step: 2000, loss: 0.9986737419577205, grad_norm: 0.28231738551215146, ic: -0.025374199264579858
Epoch 59: 2022-04-27 19:12:39.085991: train loss: 1.591274461838536
Eval step 0: eval loss: 0.8240873539786946
Eval: 2022-04-27 19:12:52.301919: total loss: 1.0632480828229878, mse:4.575778880008498, ic :0.20332442615388874, sharpe5:18.328816595077512, irr5:636.9638061523438, ndcg5:0.84055326137565, pnl5:3.3892178535461426 

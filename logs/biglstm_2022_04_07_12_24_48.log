Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='AdjTimeDataset', dout=0.3, epochs=40, glstm_layers=1, gnn_layers=1, gpu=0, hidden_dim=128, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=1, mask_adj=True, mask_type='soft', model_type='BiGLSTM', normalize_adj=True, num_days=8, num_heads=1, print_inteval=500, relation_num=1, seed=10086, shuffle=True, side_info=False, sparse_adj_path=None, stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
59417
BiGLSTM(
  (input_to_hidden): Linear(in_features=9, out_features=128, bias=True)
  (forward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
  )
  (backward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
  )
  (fc0): ModuleList(
    (0): Linear(in_features=256, out_features=128, bias=True)
  )
  (w_out): Linear(in_features=128, out_features=1, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
)
train 0, step: 0, loss: 4.812226272356333, grad_norm: 4.549448262213707, ic: 0.032209013656201824
train 0, step: 500, loss: 0.8654711564501696, grad_norm: 0.02532535229466532, ic: 0.01999482025725361
train 0, step: 1000, loss: 1.948317912170812, grad_norm: 0.4443499038093347, ic: -0.019702006049628417
train 0, step: 1500, loss: 0.9530059211338933, grad_norm: 0.04499272215545407, ic: 0.05120552631143287
train 0, step: 2000, loss: 1.0006699366394438, grad_norm: 0.1309506477387247, ic: 0.04524766674258038
Epoch 0: 2022-04-07 00:26:14.032361: train loss: 1.649148171060271
Eval step 0: eval loss: 0.836215599068098
Eval: 2022-04-07 00:26:17.256297: total loss: 1.0792882134286272, mse:4.823189844497148, ic :0.007579534812167715, sharpe5:8.010155689716338, irr5:224.1614990234375, ndcg5:0.8414258540114607, pnl5:2.9725594520568848 
train 1, step: 0, loss: 2.767455070249496, grad_norm: 0.7407492902065619, ic: 0.045415074437528326
train 1, step: 500, loss: 1.748753331006136, grad_norm: 0.6574543296683202, ic: 0.1242710350975063
train 1, step: 1000, loss: 0.8749060740476109, grad_norm: 0.14986802933403384, ic: 0.05950170474010899
train 1, step: 1500, loss: 1.7077465539691092, grad_norm: 0.1797688070123732, ic: -0.00800401354796065
train 1, step: 2000, loss: 2.1725787109375, grad_norm: 0.840864837651709, ic: 0.012132510351795054
Epoch 1: 2022-04-07 00:27:36.178061: train loss: 1.6468394902591361
Eval step 0: eval loss: 0.836258304382903
Eval: 2022-04-07 00:27:39.404262: total loss: 1.079298135078924, mse:4.823102312849023, ic :0.011870660537467407, sharpe5:8.23420481622219, irr5:230.510986328125, ndcg5:0.8745553126059399, pnl5:2.6126391887664795 
train 2, step: 0, loss: 2.1404783380681818, grad_norm: 0.0065314504860351326, ic: 0.10149670350884574
train 2, step: 500, loss: 3.2898675145491003, grad_norm: 0.25536724802318667, ic: 0.015604773454548533
train 2, step: 1000, loss: 2.0740297982519156, grad_norm: 2.3297675581817218e-05, ic: 0.2522205585780917
train 2, step: 1500, loss: 1.4807035722805344, grad_norm: 0.05128086414903652, ic: -0.02231494458693043
train 2, step: 2000, loss: 3.2155968299278848, grad_norm: 0.7282780297611381, ic: 0.14084638455674672
Epoch 2: 2022-04-07 00:28:58.972531: train loss: 1.6466233236330623
Eval step 0: eval loss: 0.83667545298505
Eval: 2022-04-07 00:29:02.151276: total loss: 1.0794279121032913, mse:4.822853874273605, ic :0.016861164349388457, sharpe5:10.245851111412048, irr5:295.84100341796875, ndcg5:0.849176589831669, pnl5:2.4435713291168213 
train 3, step: 0, loss: 1.5233125516069614, grad_norm: 0.4929369964987043, ic: -0.012636233963847996
train 3, step: 500, loss: 1.4921961032326743, grad_norm: 0.326091012560543, ic: 0.021801655685159623
train 3, step: 1000, loss: 3.686895621941566, grad_norm: 0.6792168203157014, ic: -0.04140500280194419
train 3, step: 1500, loss: 1.9548733425608635, grad_norm: 0.9374986556220674, ic: 0.007599276582799018
train 3, step: 2000, loss: 0.9003932643581081, grad_norm: 0.0009777618516652194, ic: -0.000513979832090148
Epoch 3: 2022-04-07 00:30:21.181511: train loss: 1.6471679070883982
Eval step 0: eval loss: 0.8359836140221615
Eval: 2022-04-07 00:30:24.394369: total loss: 1.0792064136073702, mse:4.822986306929022, ic :0.026474832267753066, sharpe5:11.613914145827293, irr5:401.0364990234375, ndcg5:0.8488763049043083, pnl5:3.5284817218780518 
train 4, step: 0, loss: 1.4382275390625001, grad_norm: 0.04170582390752245, ic: 0.13216063465673578
train 4, step: 500, loss: 1.6418176365649606, grad_norm: 0.5424261241568832, ic: -0.04829947386358434
train 4, step: 1000, loss: 2.969258750357279, grad_norm: 0.6673708050114637, ic: 0.03819113434009156
train 4, step: 1500, loss: 2.1526791600738395, grad_norm: 0.4550612386483914, ic: -0.06117497225466346
train 4, step: 2000, loss: 1.0889652424244265, grad_norm: 0.39100439095422174, ic: 0.19241398731022258
Epoch 4: 2022-04-07 00:31:43.253841: train loss: 1.6446080996384176
Eval step 0: eval loss: 0.8461788004643045
Eval: 2022-04-07 00:31:46.445533: total loss: 1.0840713475334391, mse:4.748281589502131, ic :0.12261678626962685, sharpe5:11.363525717854499, irr5:390.71917724609375, ndcg5:0.8421778440255278, pnl5:3.4542195796966553 
train 5, step: 0, loss: 1.3209227696361157, grad_norm: 0.1647309794839275, ic: 0.3576615887221288
train 5, step: 500, loss: 0.8899107773468478, grad_norm: 0.010329790473871218, ic: 0.7960106015634124
train 5, step: 1000, loss: 0.9956434461805556, grad_norm: 0.1537260074812919, ic: 0.023412488961159397
train 5, step: 1500, loss: 1.5282174967697169, grad_norm: 0.15192439278910938, ic: 0.01211008990027563
train 5, step: 2000, loss: 1.1386188409721214, grad_norm: 0.12025403158082339, ic: 0.1593298650432382
Epoch 5: 2022-04-07 00:33:04.479444: train loss: 1.639725150786656
Eval step 0: eval loss: 0.8365656025668466
Eval: 2022-04-07 00:33:07.783678: total loss: 1.075320618245692, mse:4.633124432571734, ic :0.14006235503184875, sharpe5:11.543808753490447, irr5:401.5251770019531, ndcg5:0.8502655929598031, pnl5:3.2423336505889893 
train 6, step: 0, loss: 1.338291685356858, grad_norm: 0.46107382113723394, ic: 0.05641077359550757
train 6, step: 500, loss: 1.0087496186471094, grad_norm: 0.04223395383532711, ic: 0.047568853687680206
train 6, step: 1000, loss: 1.0940482600106938, grad_norm: 0.09192191898149607, ic: 0.8027108090632368
train 6, step: 1500, loss: 1.575982212035124, grad_norm: 0.723909007948687, ic: 0.0070896574384996195
train 6, step: 2000, loss: 0.7989018656331315, grad_norm: 0.07268834061187404, ic: 0.3554088879461711
Epoch 6: 2022-04-07 00:34:24.474487: train loss: 1.6351740963152566
Eval step 0: eval loss: 0.8300590233757573
Eval: 2022-04-07 00:34:27.703337: total loss: 1.0718889202036233, mse:4.626640231386856, ic :0.13599696859164087, sharpe5:11.547152600884438, irr5:397.3142395019531, ndcg5:0.850950773562622, pnl5:3.448469638824463 
train 7, step: 0, loss: 0.9958294868469239, grad_norm: 0.04631766089279483, ic: 0.02972044420435163
train 7, step: 500, loss: 0.6557075013505651, grad_norm: 0.013168070789073713, ic: -0.016511928609289794
train 7, step: 1000, loss: 1.036949279738671, grad_norm: 0.25720423279442683, ic: -0.013887887150862761
train 7, step: 1500, loss: 2.2888060607583065, grad_norm: 0.929193817412556, ic: 0.4138316175576954
train 7, step: 2000, loss: 0.9086764186187399, grad_norm: 0.0891532702438565, ic: -0.01939145411735028
Epoch 7: 2022-04-07 00:35:46.485435: train loss: 1.633380982686821
Eval step 0: eval loss: 0.8286155322831599
Eval: 2022-04-07 00:35:49.659894: total loss: 1.071432392445918, mse:4.601130738486127, ic :0.16692036786437878, sharpe5:16.181220910549165, irr5:521.597900390625, ndcg5:0.8551904091943643, pnl5:5.393573760986328 
train 8, step: 0, loss: 3.614741493999094, grad_norm: 1.158893913364682, ic: 0.16988694212906125
train 8, step: 500, loss: 2.757625869704597, grad_norm: 0.9652775133064445, ic: -0.09814140253032094
train 8, step: 1000, loss: 3.076117031816123, grad_norm: 0.9407115955711352, ic: 0.10096948303127858
train 8, step: 1500, loss: 0.69905844804832, grad_norm: 0.10948502237405472, ic: 0.5937165025514437
train 8, step: 2000, loss: 1.0740788083514268, grad_norm: 0.5189879452407085, ic: 0.6560770420730835
Epoch 8: 2022-04-07 00:37:06.647464: train loss: 1.6304499926200504
Eval step 0: eval loss: 0.823559325914614
Eval: 2022-04-07 00:37:09.877684: total loss: 1.0689995986201835, mse:4.598321611262676, ic :0.17059912597659865, sharpe5:16.79884040236473, irr5:546.14111328125, ndcg5:0.8409207520664754, pnl5:8.48997688293457 
train 9, step: 0, loss: 5.434456613835725, grad_norm: 0.9474040591652599, ic: -0.048889087506409856
train 9, step: 500, loss: 1.3339234650012817, grad_norm: 1.113713037209092, ic: 0.3031467012181789
train 9, step: 1000, loss: 0.9245280749692117, grad_norm: 1.812401718191639, ic: 0.11226599429608997
train 9, step: 1500, loss: 1.0767095956254602, grad_norm: 0.015410252892493825, ic: 0.49188435170964034
train 9, step: 2000, loss: 1.0682876514695319, grad_norm: 0.30949258401267377, ic: 0.2970567307605461
Epoch 9: 2022-04-07 00:38:27.401078: train loss: 1.6283049389941233
Eval step 0: eval loss: 0.8245019942867492
Eval: 2022-04-07 00:38:30.541505: total loss: 1.0707750117905777, mse:4.606702890141744, ic :0.1612722276734361, sharpe5:16.163030759096145, irr5:515.028564453125, ndcg5:0.8462339536961813, pnl5:6.450767993927002 
train 10, step: 0, loss: 7.128523312226676, grad_norm: 1.4404101375073857, ic: 0.28116606077226347
train 10, step: 500, loss: 1.1202910945778553, grad_norm: 0.19974950441051506, ic: 0.0838109517835371
train 10, step: 1000, loss: 2.3833752965634587, grad_norm: 0.7095453567369804, ic: 0.002836083697971812
train 10, step: 1500, loss: 1.1011714192179891, grad_norm: 0.25562007919029694, ic: 0.01601303082657119
train 10, step: 2000, loss: 2.716637515731858, grad_norm: 1.0446025251158522, ic: 0.5390007268019462
Epoch 10: 2022-04-07 00:39:49.149756: train loss: 1.6280847440010573
Eval step 0: eval loss: 0.8249701448687763
Eval: 2022-04-07 00:39:52.355594: total loss: 1.0698504561894369, mse:4.609227233649201, ic :0.16565812024949378, sharpe5:16.0772996199131, irr5:527.0060424804688, ndcg5:0.8387594325884413, pnl5:5.337260723114014 
train 11, step: 0, loss: 1.2569701865211718, grad_norm: 0.17094099572170368, ic: 0.1796741560447096
train 11, step: 500, loss: 0.6424787575631072, grad_norm: 0.03620829217088829, ic: 0.6487867914738843
train 11, step: 1000, loss: 0.9459408652359852, grad_norm: 0.13622580172967588, ic: 0.12433584514681865
train 11, step: 1500, loss: 1.059148955763432, grad_norm: 0.06449095359019887, ic: 0.18319826163267003
train 11, step: 2000, loss: 0.7950359422825336, grad_norm: 0.0002543828974820555, ic: 0.027811593222895576
Epoch 11: 2022-04-07 00:41:09.490287: train loss: 1.6272813406674267
Eval step 0: eval loss: 0.8283224477657402
Eval: 2022-04-07 00:41:12.654736: total loss: 1.071082395663976, mse:4.6024653887272615, ic :0.16610721197385336, sharpe5:15.348259538412094, irr5:497.8135681152344, ndcg5:0.8529134563332532, pnl5:3.575395107269287 
train 12, step: 0, loss: 0.9696706930796305, grad_norm: 0.09415507317771915, ic: 0.39600193608567696
train 12, step: 500, loss: 0.9504407528089169, grad_norm: 0.07275685556650247, ic: 0.022243404918358245
train 12, step: 1000, loss: 3.011027147815486, grad_norm: 0.23389927194450078, ic: 0.051123251502472905
train 12, step: 1500, loss: 0.9361498818902323, grad_norm: 0.11226608039636385, ic: -0.011906323135914146
train 12, step: 2000, loss: 0.8789748454021903, grad_norm: 0.0044119246910306964, ic: 0.018818789228360583
Epoch 12: 2022-04-07 00:42:30.670049: train loss: 1.6269649571343603
Eval step 0: eval loss: 0.8262289869270284
Eval: 2022-04-07 00:42:33.775735: total loss: 1.0706832863754037, mse:4.603935206917663, ic :0.16369626738650336, sharpe5:16.095151129961014, irr5:519.2326049804688, ndcg5:0.8246322975006546, pnl5:7.574531555175781 
train 13, step: 0, loss: 2.0581018594904963, grad_norm: 0.6992574930781319, ic: 0.421577473649458
train 13, step: 500, loss: 0.8308015539733971, grad_norm: 0.04271399879387859, ic: 0.5749265722742147
train 13, step: 1000, loss: 0.9542179798919882, grad_norm: 0.36422253040865543, ic: 0.5843808292785866
train 13, step: 1500, loss: 2.3516964819354995, grad_norm: 0.21128592619456155, ic: 0.07588981294852366
train 13, step: 2000, loss: 1.4607569787757408, grad_norm: 0.04554269382259378, ic: 0.19805775143823284
Epoch 13: 2022-04-07 00:43:50.666005: train loss: 1.626496897094668
Eval step 0: eval loss: 0.8220451523807956
Eval: 2022-04-07 00:43:54.218139: total loss: 1.0702896092930783, mse:4.618058562030491, ic :0.16664935247635684, sharpe5:16.785111236572266, irr5:555.1010131835938, ndcg5:0.8493190608305464, pnl5:8.674750328063965 
train 14, step: 0, loss: 4.53076324224844, grad_norm: 1.5392328189345745, ic: 0.10817031217107295
train 14, step: 500, loss: 0.8304387363818807, grad_norm: 0.017536239968942824, ic: 0.02327928894421738
train 14, step: 1000, loss: 1.8413680995515376, grad_norm: 0.6420409543128476, ic: 0.4508043922858569
train 14, step: 1500, loss: 1.1204688343185834, grad_norm: 0.06323618731374994, ic: 0.08119457832576377
train 14, step: 2000, loss: 1.1375020109030598, grad_norm: 0.2473485019237872, ic: 0.11017093843330564
Epoch 14: 2022-04-07 00:45:11.644232: train loss: 1.6268206710828133
Eval step 0: eval loss: 0.8313132347372233
Eval: 2022-04-07 00:45:14.762650: total loss: 1.0707865554915836, mse:4.6010420612103164, ic :0.17692843537730035, sharpe5:16.85719645142555, irr5:564.6187133789062, ndcg5:0.8324033886015769, pnl5:6.055577754974365 
train 15, step: 0, loss: 3.325701073078794, grad_norm: 0.6775317831131582, ic: 0.09310375995559722
train 15, step: 500, loss: 1.256298544004572, grad_norm: 0.09459521201492775, ic: 0.04604589287008893
train 15, step: 1000, loss: 1.3259559197154471, grad_norm: 0.20895863997839143, ic: 0.08179325905224602
train 15, step: 1500, loss: 0.8630113496555119, grad_norm: 0.4996725928249542, ic: 0.017978466641264908
train 15, step: 2000, loss: 1.4626203404916465, grad_norm: 0.7327809859581157, ic: 0.02949309550093454
Epoch 15: 2022-04-07 00:46:32.156559: train loss: 1.625789430084536
Eval step 0: eval loss: 0.8329042649746443
Eval: 2022-04-07 00:46:35.299193: total loss: 1.0735952979348318, mse:4.613517933868086, ic :0.17259074260917162, sharpe5:16.23906994342804, irr5:530.5979614257812, ndcg5:0.8302158961953979, pnl5:5.478876113891602 
train 16, step: 0, loss: 0.7019878034070665, grad_norm: 0.21670255079126036, ic: 0.02721751704244181
train 16, step: 500, loss: 1.5882305349225783, grad_norm: 0.4251621573926294, ic: 0.14587303728839135
train 16, step: 1000, loss: 0.8729101007634943, grad_norm: 0.0016700948256755542, ic: 0.0002574674906646521
train 16, step: 1500, loss: 0.8590871872537431, grad_norm: 0.25827582418310996, ic: 0.1420276704884824
train 16, step: 2000, loss: 3.3692678361761974, grad_norm: 0.8852927567047626, ic: 0.07402928207740717
Epoch 16: 2022-04-07 00:47:52.282656: train loss: 1.626654382288657
Eval step 0: eval loss: 0.8249103960171891
Eval: 2022-04-07 00:47:55.574270: total loss: 1.068055828858314, mse:4.592971473288733, ic :0.18209338639000902, sharpe5:16.27124087691307, irr5:534.5511474609375, ndcg5:0.8468541144776733, pnl5:6.5887370109558105 
train 17, step: 0, loss: 1.2746531519396551, grad_norm: 0.22827311983348683, ic: -0.10914507947786001
train 17, step: 500, loss: 1.7789745299796749, grad_norm: 0.465326451737673, ic: 0.14692111138950373
train 17, step: 1000, loss: 1.282842480365191, grad_norm: 0.10104742404498669, ic: 0.1367227964827251
train 17, step: 1500, loss: 4.517515340856907, grad_norm: 1.2934957882804394, ic: 0.2361966636546639
train 17, step: 2000, loss: 1.2621007902620327, grad_norm: 0.5429316262260726, ic: 0.04190929352057324
Epoch 17: 2022-04-07 00:49:23.079584: train loss: 1.6252674305944494
Eval step 0: eval loss: 0.8319089224265673
Eval: 2022-04-07 00:49:26.235958: total loss: 1.070762670345734, mse:4.592386722206777, ic :0.1833596941561049, sharpe5:16.81287415623665, irr5:550.3162841796875, ndcg5:0.8319387042279136, pnl5:4.0787529945373535 
train 18, step: 0, loss: 1.4197170158524293, grad_norm: 0.5070309040542914, ic: 0.07205168938834135
train 18, step: 500, loss: 1.4458291559473364, grad_norm: 0.881434092941294, ic: 0.010938325998754222
train 18, step: 1000, loss: 0.6612932095462328, grad_norm: 0.047941120145131425, ic: 0.569725829778921
train 18, step: 1500, loss: 1.4405970467982188, grad_norm: 0.045457729592785066, ic: 0.1279182910505754
train 18, step: 2000, loss: 0.910705955165207, grad_norm: 0.006838111054657062, ic: -0.012922561764724104
Epoch 18: 2022-04-07 00:50:45.726563: train loss: 1.625560179138859
Eval step 0: eval loss: 0.823679080878721
Eval: 2022-04-07 00:50:48.873790: total loss: 1.0662652786670688, mse:4.601356322535937, ic :0.18787242565416398, sharpe5:16.593911272287368, irr5:571.66748046875, ndcg5:0.8455019648233834, pnl5:4.248471260070801 
train 19, step: 0, loss: 1.4865930950830852, grad_norm: 0.6730191185289386, ic: 0.028310456376215792
train 19, step: 500, loss: 0.8615810253002025, grad_norm: 0.0432879019552813, ic: 0.23015546552012967
train 19, step: 1000, loss: 0.9660584283943148, grad_norm: 0.006313491290209862, ic: 0.1609006889971317
train 19, step: 1500, loss: 3.9611694593288824, grad_norm: 0.9692610934657723, ic: 0.15400206645523434
train 19, step: 2000, loss: 1.0013858736478365, grad_norm: 0.10637387570969126, ic: 0.17827898269639397
Epoch 19: 2022-04-07 00:52:07.383327: train loss: 1.6247798596668055
Eval step 0: eval loss: 0.8275516940117886
Eval: 2022-04-07 00:52:10.552729: total loss: 1.0689209445369836, mse:4.5953041422440615, ic :0.18692733179185592, sharpe5:17.06819464087486, irr5:578.3008422851562, ndcg5:0.849242018836715, pnl5:5.557066440582275 
train 20, step: 0, loss: 2.2987957015810276, grad_norm: 0.7150582575341209, ic: 0.051523652580347856
train 20, step: 500, loss: 3.1802848011363634, grad_norm: 0.5807971109834321, ic: 0.0899611701596281
train 20, step: 1000, loss: 0.985782814025879, grad_norm: 0.04916352109490235, ic: 0.0004753503795594319
train 20, step: 1500, loss: 1.9149340035174196, grad_norm: 0.35909866563205317, ic: 0.22680274758944227
train 20, step: 2000, loss: 1.048641733788744, grad_norm: 0.05984268340263159, ic: -0.01243452549603357
Epoch 20: 2022-04-07 00:53:29.306142: train loss: 1.6249160204440412
Eval step 0: eval loss: 0.829353099376811
Eval: 2022-04-07 00:53:32.706133: total loss: 1.067653374286615, mse:4.586332323769332, ic :0.18881792812591608, sharpe5:17.21605039715767, irr5:563.8297729492188, ndcg5:0.8372546207356839, pnl5:4.838008403778076 
train 21, step: 0, loss: 1.0162641232837528, grad_norm: 0.39708267528853547, ic: 0.05490945471193988
train 21, step: 500, loss: 0.7746024342764796, grad_norm: 0.012162043304058175, ic: 0.1967139444822299
train 21, step: 1000, loss: 0.9224031682600055, grad_norm: 0.38646721042668436, ic: 0.16477430762840084
train 21, step: 1500, loss: 1.0008565135101692, grad_norm: 0.16653070105432666, ic: 0.2951923523069466
train 21, step: 2000, loss: 0.9429834308814369, grad_norm: 0.05674480659741353, ic: 0.08594180124093861
Epoch 21: 2022-04-07 00:54:52.821824: train loss: 1.624745852648941
Eval step 0: eval loss: 0.8263244307330083
Eval: 2022-04-07 00:54:55.967217: total loss: 1.066871228949484, mse:4.59205936777921, ic :0.18601263934707618, sharpe5:17.252646371126175, irr5:568.9755859375, ndcg5:0.8381264201788376, pnl5:6.036109447479248 
train 22, step: 0, loss: 1.049789687334481, grad_norm: 0.19197330021574002, ic: 0.17742427643656009
train 22, step: 500, loss: 3.2427881256351627, grad_norm: 0.7075122044761402, ic: -0.10214636803526589
train 22, step: 1000, loss: 1.2000448767160405, grad_norm: 0.08147782837982966, ic: 0.4645349911875812
train 22, step: 1500, loss: 0.9732729311342593, grad_norm: 0.06880341975021834, ic: 0.13251802730916487
train 22, step: 2000, loss: 1.7638645301870748, grad_norm: 0.45511288680019973, ic: 0.15733461038089377
Epoch 22: 2022-04-07 00:56:15.354835: train loss: 1.6246708267363317
Eval step 0: eval loss: 0.8236869916523972
Eval: 2022-04-07 00:56:18.576113: total loss: 1.0674620373532255, mse:4.604565296464511, ic :0.182357320581978, sharpe5:16.588188421726226, irr5:563.2314453125, ndcg5:0.8628826660640174, pnl5:5.877404689788818 
train 23, step: 0, loss: 0.9868181651882205, grad_norm: 0.04122686607640969, ic: 0.20620937269741071
train 23, step: 500, loss: 1.4294226629954867, grad_norm: 0.08479688265678806, ic: 0.017976744493810294
train 23, step: 1000, loss: 1.6549629720052084, grad_norm: 0.07282435733119541, ic: 0.2625519741141442
train 23, step: 1500, loss: 1.1308385771416922, grad_norm: 0.2752396460336508, ic: 0.09208205050350717
train 23, step: 2000, loss: 1.916921520159738, grad_norm: 0.6604005851934411, ic: 0.45130620407806143
Epoch 23: 2022-04-07 00:57:36.184498: train loss: 1.6237522816242325
Eval step 0: eval loss: 0.829538906085353
Eval: 2022-04-07 00:57:39.337898: total loss: 1.068327026055348, mse:4.584571018311724, ic :0.1891761929925564, sharpe5:16.661720902919768, irr5:548.4977416992188, ndcg5:0.8396517632355327, pnl5:3.7427215576171875 
train 24, step: 0, loss: 2.210825129427474, grad_norm: 0.022679214512366448, ic: 0.08925195450555864
train 24, step: 500, loss: 1.2209945738083658, grad_norm: 0.08714709361717762, ic: 0.21974128603221488
train 24, step: 1000, loss: 0.9048724435294987, grad_norm: 0.05341867745790861, ic: 0.5359008272380579
train 24, step: 1500, loss: 2.610589866292251, grad_norm: 0.6399596742326819, ic: 0.06883658970956995
train 24, step: 2000, loss: 0.9315698898800427, grad_norm: 0.10517085617768586, ic: 0.08111316425625853
Epoch 24: 2022-04-07 00:58:59.911970: train loss: 1.622406149175396
Eval step 0: eval loss: 0.8220700423760208
Eval: 2022-04-07 00:59:03.169007: total loss: 1.0676709415257482, mse:4.608017628852084, ic :0.1871387681029246, sharpe5:17.13764261484146, irr5:581.812744140625, ndcg5:0.8464054642578807, pnl5:5.651548862457275 
train 25, step: 0, loss: 0.8437357309702281, grad_norm: 0.06074104778930259, ic: 0.6036634077284154
train 25, step: 500, loss: 0.8693851344174849, grad_norm: 0.003401772160492703, ic: 0.21234608445464548
train 25, step: 1000, loss: 2.118277858434882, grad_norm: 0.21423474817958055, ic: 0.21968420386399642
train 25, step: 1500, loss: 1.1432391877748647, grad_norm: 0.47552840672302843, ic: 0.5355539518573939
train 25, step: 2000, loss: 1.0012454390939451, grad_norm: 0.3527465377502691, ic: 0.6062084164333095
Epoch 25: 2022-04-07 01:00:20.785542: train loss: 1.6214212844225782
Eval step 0: eval loss: 0.825112731740648
Eval: 2022-04-07 01:00:24.048069: total loss: 1.0651110464863054, mse:4.580466176843412, ic :0.19499404929584574, sharpe5:16.733802334070205, irr5:566.8721313476562, ndcg5:0.8501692572138289, pnl5:6.649144649505615 
train 26, step: 0, loss: 6.687852560902556, grad_norm: 0.33607618376433085, ic: 0.1450181002931903
train 26, step: 500, loss: 3.867276451939992, grad_norm: 0.8757948747059301, ic: 0.3731485889023773
train 26, step: 1000, loss: 1.2487767098275608, grad_norm: 0.8478482008538478, ic: -0.04567577523282047
train 26, step: 1500, loss: 0.836920417570499, grad_norm: 0.13091527570348163, ic: 0.28763890150600363
train 26, step: 2000, loss: 0.9571037622627361, grad_norm: 0.1090887401999881, ic: 0.11861971242932501
Epoch 26: 2022-04-07 01:01:43.768132: train loss: 1.62277774609705
Eval step 0: eval loss: 0.8244497703174394
Eval: 2022-04-07 01:01:46.999125: total loss: 1.0659020197065494, mse:4.586668696783985, ic :0.1917420934285455, sharpe5:17.517448815107343, irr5:594.9608764648438, ndcg5:0.8555835895524413, pnl5:6.268138885498047 
train 27, step: 0, loss: 0.8262875306372549, grad_norm: 0.041203212835853736, ic: 0.1319755000654357
train 27, step: 500, loss: 0.9282924814591785, grad_norm: 0.7108697967140967, ic: 0.261440111183662
train 27, step: 1000, loss: 0.7545089072620602, grad_norm: 0.18709691819962992, ic: 0.18666254618962286
train 27, step: 1500, loss: 0.6402787134878265, grad_norm: 0.04562512562300401, ic: 0.5126194080562002
train 27, step: 2000, loss: 1.3836259313306758, grad_norm: 0.013831365420082453, ic: 0.033310182433877206
Epoch 27: 2022-04-07 01:03:06.897302: train loss: 1.6205769051611059
Eval step 0: eval loss: 0.8303135187532928
Eval: 2022-04-07 01:03:10.064701: total loss: 1.0679387194834389, mse:4.595816871797954, ic :0.18888866275387226, sharpe5:17.789667316675185, irr5:595.4116821289062, ndcg5:0.8490930190541908, pnl5:5.439996242523193 
train 28, step: 0, loss: 1.5418884984314671, grad_norm: 0.22139599927146436, ic: 0.17289430056097413
train 28, step: 500, loss: 1.3639669999388626, grad_norm: 0.25141032288816756, ic: 0.17814714369054374
train 28, step: 1000, loss: 0.9109250613990515, grad_norm: 0.2406661288091233, ic: 0.5840919098942767
train 28, step: 1500, loss: 1.0352425623421717, grad_norm: 0.018625721096022074, ic: 0.02133410291586256
train 28, step: 2000, loss: 1.050533084050278, grad_norm: 0.06055654889966976, ic: -0.013369951874765258
Epoch 28: 2022-04-07 01:04:27.678633: train loss: 1.620477407135256
Eval step 0: eval loss: 0.8222397702762776
Eval: 2022-04-07 01:04:30.840359: total loss: 1.071720267797772, mse:4.649228340481521, ic :0.17664608377335034, sharpe5:17.000986618995665, irr5:534.809814453125, ndcg5:0.8434590071720088, pnl5:7.162598133087158 
train 29, step: 0, loss: 0.9102269563826763, grad_norm: 0.026032315328908387, ic: 0.08471084155173621
train 29, step: 500, loss: 1.1025468038938637, grad_norm: 0.0954406122487158, ic: 0.6196272389221895
train 29, step: 1000, loss: 1.068978626546911, grad_norm: 0.2927629730029193, ic: 0.10532869252213693
train 29, step: 1500, loss: 2.3534954228873928, grad_norm: 0.3149578905242279, ic: -0.05517172924345648
train 29, step: 2000, loss: 4.496011616271219, grad_norm: 2.240820273076991, ic: 0.20829292414096243
Epoch 29: 2022-04-07 01:05:47.553027: train loss: 1.6206063382788947
Eval step 0: eval loss: 0.8267056914350631
Eval: 2022-04-07 01:05:50.762268: total loss: 1.0659166067323758, mse:4.583346812640193, ic :0.19333502629814217, sharpe5:16.849210946559904, irr5:579.1080322265625, ndcg5:0.8368920618259641, pnl5:4.799551963806152 
train 30, step: 0, loss: 1.010634140330744, grad_norm: 0.14859368881906543, ic: 0.5192894963205352
train 30, step: 500, loss: 1.4150084197472315, grad_norm: 0.8426802574875957, ic: 0.04958229222013437
train 30, step: 1000, loss: 0.9693527684067235, grad_norm: 0.02410379298855643, ic: -0.015176329959702
train 30, step: 1500, loss: 1.510667389193894, grad_norm: 0.600649100191174, ic: 0.11097905856545198
train 30, step: 2000, loss: 1.8540240800736418, grad_norm: 0.25295538700186976, ic: 0.07152764957916849
Epoch 30: 2022-04-07 01:07:07.785009: train loss: 1.6240700061490418
Eval step 0: eval loss: 0.8272504414597602
Eval: 2022-04-07 01:07:10.991323: total loss: 1.066978563040168, mse:4.6090739302485995, ic :0.19422994539346772, sharpe5:17.392168521881104, irr5:601.68212890625, ndcg5:0.8523639227934587, pnl5:6.351437091827393 
train 31, step: 0, loss: 1.0482432497025833, grad_norm: 0.07084309294958868, ic: 0.33371457229618673
train 31, step: 500, loss: 1.5143042293595679, grad_norm: 0.4047409047446294, ic: 0.035221046894801454
train 31, step: 1000, loss: 4.367979194111046, grad_norm: 1.2547769892534346, ic: 0.4635698137448376
train 31, step: 1500, loss: 0.7693597664052098, grad_norm: 0.11105025759704298, ic: 0.7124808542727717
train 31, step: 2000, loss: 1.2211272173014818, grad_norm: 0.46483221422444176, ic: 0.12181660660348465
Epoch 31: 2022-04-07 01:08:32.298181: train loss: 1.6171635346151538
Eval step 0: eval loss: 0.8322625275783719
Eval: 2022-04-07 01:08:35.405051: total loss: 1.0683136242958113, mse:4.589695780581513, ic :0.1881124106670468, sharpe5:16.905521904230117, irr5:556.2534790039062, ndcg5:0.853111406586844, pnl5:5.288228988647461 
train 32, step: 0, loss: 1.1320648550151013, grad_norm: 0.020275632094379128, ic: 0.1894026271901067
train 32, step: 500, loss: 1.4865090197465551, grad_norm: 0.4774112508528646, ic: 0.07295244733090252
train 32, step: 1000, loss: 1.0409557215215544, grad_norm: 0.9286633797668983, ic: 0.5200024930142244
train 32, step: 1500, loss: 0.98263957171291, grad_norm: 0.3493726834277936, ic: 0.0698389337262052
train 32, step: 2000, loss: 0.949193372026334, grad_norm: 0.1932039097511128, ic: 0.5565694283611053
Epoch 32: 2022-04-07 01:09:55.506837: train loss: 1.621535660795772
Eval step 0: eval loss: 0.8207263042100237
Eval: 2022-04-07 01:09:58.691921: total loss: 1.0650700032621176, mse:4.595420901155558, ic :0.1924286112408228, sharpe5:17.544999847412107, irr5:577.1483154296875, ndcg5:0.8362029070642751, pnl5:9.704489707946777 
train 33, step: 0, loss: 1.2578494111096112, grad_norm: 0.1513375613104452, ic: 0.21599168045603878
train 33, step: 500, loss: 0.9969438592198243, grad_norm: 0.011536400508527517, ic: 0.10616658672421289
train 33, step: 1000, loss: 1.0274393913702438, grad_norm: 0.6231595959642482, ic: 0.21296907941233892
train 33, step: 1500, loss: 0.9428803612470344, grad_norm: 0.24913472017373078, ic: 0.5486619497524569
train 33, step: 2000, loss: 0.8165872274601328, grad_norm: 0.024888341386028058, ic: 0.2481223245555182
Epoch 33: 2022-04-07 01:11:15.009252: train loss: 1.6216831311099273
Eval step 0: eval loss: 0.8223653779266004
Eval: 2022-04-07 01:11:18.230898: total loss: 1.0656460086908959, mse:4.587155058830847, ic :0.19674454492574406, sharpe5:17.716726984977722, irr5:592.1978149414062, ndcg5:0.8581024952534606, pnl5:5.495334148406982 
train 34, step: 0, loss: 1.0092388844010236, grad_norm: 0.3919465029755581, ic: 0.6090595816609977
train 34, step: 500, loss: 0.8005791060421446, grad_norm: 0.14678106920975773, ic: 0.25353966153206686
train 34, step: 1000, loss: 3.2131951444892475, grad_norm: 0.8754168689370887, ic: 0.3202422743270852
train 34, step: 1500, loss: 0.7980713327110026, grad_norm: 0.19692402084472382, ic: 0.6856888486610139
train 34, step: 2000, loss: 6.878174017234702, grad_norm: 4.3984317481228095, ic: 0.4467592228573302
Epoch 34: 2022-04-07 01:12:35.851721: train loss: 1.6208485046020389
Eval step 0: eval loss: 0.8202995083229057
Eval: 2022-04-07 01:12:39.028569: total loss: 1.0673543889035202, mse:4.608815170296121, ic :0.19006740341297726, sharpe5:18.06408982515335, irr5:600.5255737304688, ndcg5:0.8455911439129568, pnl5:11.951957702636719 
train 35, step: 0, loss: 1.2133254825367645, grad_norm: 0.6727777498599536, ic: 0.5621721327522007
train 35, step: 500, loss: 1.1876231682466272, grad_norm: 0.4458001553603736, ic: 0.10119655176309218
train 35, step: 1000, loss: 1.8415235774532246, grad_norm: 1.6581913529626446, ic: 0.06453481696513913
train 35, step: 1500, loss: 1.5882206737546993, grad_norm: 0.9491776725021905, ic: 0.047301733136463214
train 35, step: 2000, loss: 0.7813360040838068, grad_norm: 0.024832532386767994, ic: 0.5590892640090724
Epoch 35: 2022-04-07 01:13:55.294586: train loss: 1.6208682133336434
Eval step 0: eval loss: 0.828652770803148
Eval: 2022-04-07 01:13:58.911426: total loss: 1.0662079510256415, mse:4.586921705601628, ic :0.1914283075410216, sharpe5:17.112963413000106, irr5:568.8554077148438, ndcg5:0.8421773714261545, pnl5:3.924074649810791 
train 36, step: 0, loss: 1.8306089488078887, grad_norm: 0.6955036525218959, ic: 0.11356248976839499
train 36, step: 500, loss: 0.8449906153036348, grad_norm: 0.03291235901662637, ic: 0.03611504878571002
train 36, step: 1000, loss: 1.737583274147727, grad_norm: 2.162909778091551, ic: 0.2585597155188926
train 36, step: 1500, loss: 0.7661561129385964, grad_norm: 0.03574030829753793, ic: 0.3893674667479694
train 36, step: 2000, loss: 1.125601334454428, grad_norm: 0.4398213741821638, ic: 0.7748561248910121
Epoch 36: 2022-04-07 01:15:17.518672: train loss: 1.6149736742371283
Eval step 0: eval loss: 0.8252785364116833
Eval: 2022-04-07 01:15:20.751569: total loss: 1.0652717639692388, mse:4.587577995318738, ic :0.19465376831900968, sharpe5:18.183944288492203, irr5:612.4169311523438, ndcg5:0.859761565830203, pnl5:6.790754795074463 
train 37, step: 0, loss: 2.0458670319678407, grad_norm: 0.8922634950899369, ic: 0.18145539955167117
train 37, step: 500, loss: 2.3412699613835644, grad_norm: 0.5313865330296695, ic: -0.053506930800289856
train 37, step: 1000, loss: 1.075448185704433, grad_norm: 0.07204444020397394, ic: 0.08091161036142913
train 37, step: 1500, loss: 2.0180987922512754, grad_norm: 0.7494477914506503, ic: 0.6120971367245716
train 37, step: 2000, loss: 1.3182401435319768, grad_norm: 0.44187479110666333, ic: 0.17887769431272513
Epoch 37: 2022-04-07 01:16:38.517149: train loss: 1.6151130665072646
Eval step 0: eval loss: 0.8237531720272984
Eval: 2022-04-07 01:16:41.752308: total loss: 1.0669728412112394, mse:4.603871324846412, ic :0.1867032785013276, sharpe5:17.589049715995788, irr5:570.7733764648438, ndcg5:0.8574149140530496, pnl5:8.481575965881348 
train 38, step: 0, loss: 1.3414349439667492, grad_norm: 0.2638906246593111, ic: -0.08350622864773317
train 38, step: 500, loss: 0.9129053940007716, grad_norm: 0.05752730387304483, ic: 0.2593320309821443
train 38, step: 1000, loss: 0.9048965152544466, grad_norm: 0.12272918560954521, ic: 0.19786747728067092
train 38, step: 1500, loss: 0.9502474032483865, grad_norm: 0.18368654545273577, ic: 0.21449789679226777
train 38, step: 2000, loss: 2.338152467664275, grad_norm: 1.426487217246165, ic: 0.06906928492184863
Epoch 38: 2022-04-07 01:18:00.293199: train loss: 1.6203311817634667
Eval step 0: eval loss: 0.821737018098821
Eval: 2022-04-07 01:18:03.361147: total loss: 1.0642816369943389, mse:4.592137695137817, ic :0.19787197027748987, sharpe5:18.787079765796662, irr5:623.349609375, ndcg5:0.8723314730395754, pnl5:8.573673248291016 
train 39, step: 0, loss: 0.9712736263916762, grad_norm: 0.0012063776334185776, ic: 0.06186807484819204
train 39, step: 500, loss: 0.8950592205214739, grad_norm: 0.05978560156252312, ic: 0.24736758508964304
train 39, step: 1000, loss: 0.9483256750404608, grad_norm: 0.08288396803713835, ic: 0.20285990214261346
train 39, step: 1500, loss: 2.084408622536153, grad_norm: 0.10648538603710443, ic: 0.18728991050103586
train 39, step: 2000, loss: 0.6171455564092121, grad_norm: 0.022526988302821408, ic: 0.12583320124551714
Epoch 39: 2022-04-07 01:19:20.523877: train loss: 1.6196583183228648
Eval step 0: eval loss: 0.8247407324321654
Eval: 2022-04-07 01:19:23.636581: total loss: 1.0661444620438858, mse:4.591064376714279, ic :0.18947893538989105, sharpe5:17.468495267629624, irr5:582.9586791992188, ndcg5:0.8644947101330726, pnl5:7.607152462005615 

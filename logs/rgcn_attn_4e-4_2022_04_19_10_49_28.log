Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='AdjSeqTimeDataset', dout=0.3, epochs=40, glstm_layers=1, gnn_layers=2, gpu=0, graph_attn=True, hidden_dim=128, input_dim=9, input_graph=True, label_cnt=3, lr=0.0004, lstm_layers=3, mask_adj=True, mask_type='soft', model_type='RGCNModel', normalize_adj=True, num_days=1, num_heads=1, print_inteval=500, relation_num=1, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_250_0.8/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
34532
RGCNModel(
  (fc1): Linear(in_features=9, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
  (fc4): Linear(in_features=128, out_features=1, bias=True)
  (gnns): ModuleList(
    (0): RGCN(
      (attention): ModuleList(
        (0): GraphAttentionLayer (128 -> 128)
      )
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
    )
    (1): RGCN(
      (attention): ModuleList(
        (0): GraphAttentionLayer (128 -> 128)
      )
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
    )
  )
  (dropout): Dropout(p=0.3, inplace=False)
  (relu): LeakyReLU(negative_slope=0.01)
)
train 0, step: 0, loss: 2.0789137768651185, grad_norm: 0.4957569660993771, ic: -0.10487370803820006
train 0, step: 500, loss: 1.3709377147104813, grad_norm: 0.9220528464867491, ic: -0.07066752990832574
train 0, step: 1000, loss: 1.5077753394793372, grad_norm: 0.03701393577781631, ic: 0.15258731751440924
train 0, step: 1500, loss: 1.1906762676546887, grad_norm: 0.12003024438277379, ic: 0.04824237698739968
train 0, step: 2000, loss: 1.5612461741377668, grad_norm: 0.055327311635740235, ic: -0.05264800929771862
Epoch 0: 2022-04-19 10:49:56.413396: train loss: 1.6472531913610267
Eval step 0: eval loss: 1.01305657377238
Eval: 2022-04-19 10:49:58.555374: total loss: 1.0920802574395214, mse:4.8904658147086115, ic :0.011116954530395231, sharpe5:7.321212926208973, irr5:213.90548706054688, ndcg5:0.8463716085878319, pnl5:3.3017969131469727 
train 1, step: 0, loss: 0.6390054532797029, grad_norm: 0.059350628097020346, ic: 0.07286578451006287
train 1, step: 500, loss: 1.2606650835707105, grad_norm: 0.33486028460835726, ic: 0.15815766622642205
train 1, step: 1000, loss: 0.8798960531094354, grad_norm: 0.06840000141495858, ic: 0.015858225122764934
train 1, step: 1500, loss: 1.8639794326410062, grad_norm: 0.6003398704055319, ic: 0.061122528587013975
train 1, step: 2000, loss: 1.3703078639452528, grad_norm: 0.2494331743393341, ic: 0.14532100372157855
Epoch 1: 2022-04-19 10:50:21.144107: train loss: 1.6459464579386103
Eval step 0: eval loss: 1.0070089829350974
Eval: 2022-04-19 10:50:23.306075: total loss: 1.0894732688436415, mse:4.881583156782561, ic :0.04162870955694233, sharpe5:1.9975184217095374, irr5:19.191465377807617, ndcg5:0.8556928646169145, pnl5:1.1921945810317993 
train 2, step: 0, loss: 1.3250823546055064, grad_norm: 0.553932597638844, ic: 0.12543635597169586
train 2, step: 500, loss: 0.950613111574118, grad_norm: 0.2997288412664866, ic: 0.08444218094596641
train 2, step: 1000, loss: 3.075483286860718, grad_norm: 1.6180656907807935, ic: 0.11726084574724094
train 2, step: 1500, loss: 2.271376922147601, grad_norm: 0.9573855336542272, ic: 0.0828994170694351
train 2, step: 2000, loss: 1.4621275607816333, grad_norm: 0.3049144917150746, ic: -0.09755977143366676
Epoch 2: 2022-04-19 10:50:45.675635: train loss: 1.6445198434486887
Eval step 0: eval loss: 0.9981296693983674
Eval: 2022-04-19 10:50:47.859972: total loss: 1.0893735114747534, mse:4.883150678318437, ic :0.045423177288010715, sharpe5:3.6638933184742926, irr5:35.87485885620117, ndcg5:0.8430761728347709, pnl5:1.3348326683044434 
train 3, step: 0, loss: 1.8321054074813503, grad_norm: 0.07063866851221669, ic: -0.13233124185079434
train 3, step: 500, loss: 0.7842266679889636, grad_norm: 0.026920750530032574, ic: 0.07082802691105287
train 3, step: 1000, loss: 1.3929142364083904, grad_norm: 0.4483424483375906, ic: 0.23583397103033393
train 3, step: 1500, loss: 2.6095049062258315, grad_norm: 0.46807794379004614, ic: -0.0705038239885383
train 3, step: 2000, loss: 1.360031035452178, grad_norm: 0.17816643425769224, ic: 0.0767195380721789
Epoch 3: 2022-04-19 10:51:10.630506: train loss: 1.644310444681905
Eval step 0: eval loss: 1.000969555831194
Eval: 2022-04-19 10:51:12.729305: total loss: 1.0906341976679095, mse:4.880700399742872, ic :0.048128999196522824, sharpe5:2.9642135886847973, irr5:29.333755493164062, ndcg5:0.853730220035482, pnl5:1.1701000928878784 
train 4, step: 0, loss: 1.1526845063974505, grad_norm: 0.17366298541418645, ic: 0.08191618783787837
train 4, step: 500, loss: 0.9889130412463282, grad_norm: 0.005646791999031698, ic: 0.14413569813823263
train 4, step: 1000, loss: 1.3358921542775077, grad_norm: 0.07085797445380329, ic: 0.051028219847851705
train 4, step: 1500, loss: 1.0698107597155448, grad_norm: 0.09549606917395602, ic: 0.19059039571617611
train 4, step: 2000, loss: 4.171785488173682, grad_norm: 0.9808162999563238, ic: -0.022072660961172177
Epoch 4: 2022-04-19 10:51:35.010059: train loss: 1.643858362976852
Eval step 0: eval loss: 1.0021530400457477
Eval: 2022-04-19 10:51:37.213036: total loss: 1.0912927694444539, mse:4.88266945339237, ic :0.04722191246961778, sharpe5:2.2197066758573056, irr5:21.808435440063477, ndcg5:0.846539192577753, pnl5:1.1985408067703247 
train 5, step: 0, loss: 0.9854177575209444, grad_norm: 0.18080384752603543, ic: -0.12242553530444439
train 5, step: 500, loss: 0.7877094094033866, grad_norm: 0.014263287459625112, ic: 0.14516032749596633
train 5, step: 1000, loss: 1.1243533906942687, grad_norm: 0.04389323697937554, ic: -0.14071535156144704
train 5, step: 1500, loss: 1.7581654122205284, grad_norm: 0.38921601201646144, ic: -0.06666308496294882
train 5, step: 2000, loss: 2.189548551181625, grad_norm: 0.8876136364946545, ic: 0.03841794312173978
Epoch 5: 2022-04-19 10:51:59.711541: train loss: 1.643687991087446
Eval step 0: eval loss: 0.9981513964998024
Eval: 2022-04-19 10:52:01.881267: total loss: 1.0883503036991935, mse:4.8802604337766615, ic :0.04805728173747589, sharpe5:2.7947358624637126, irr5:27.885215759277344, ndcg5:0.8482747485938646, pnl5:1.1788405179977417 
train 6, step: 0, loss: 0.7818223351407426, grad_norm: 0.011025078162739722, ic: -0.09390811936536797
train 6, step: 500, loss: 1.4166017945049798, grad_norm: 0.3871627649145623, ic: 0.07743095380360823
train 6, step: 1000, loss: 1.2216555188998455, grad_norm: 0.24503742353179483, ic: 0.2059202584142369
train 6, step: 1500, loss: 1.0718071012676886, grad_norm: 0.33373070659234544, ic: 0.058001854385885274
train 6, step: 2000, loss: 2.283596906646379, grad_norm: 1.1162269682786756, ic: 0.08353697798879953
Epoch 6: 2022-04-19 10:52:24.086980: train loss: 1.6432859204254373
Eval step 0: eval loss: 0.9989529851237493
Eval: 2022-04-19 10:52:26.282257: total loss: 1.0886440102131623, mse:4.87976142581113, ic :0.047327273125711715, sharpe5:2.189029832035303, irr5:21.458311080932617, ndcg5:0.851515875512624, pnl5:1.0606062412261963 
train 7, step: 0, loss: 1.458408211169172, grad_norm: 0.5773088884685318, ic: 0.20117978135048226
train 7, step: 500, loss: 1.307552803158272, grad_norm: 0.03379581033895003, ic: 0.124256104101262
train 7, step: 1000, loss: 0.643290513082406, grad_norm: 0.01585722940358186, ic: 0.27704466138500605
train 7, step: 1500, loss: 1.002899052816817, grad_norm: 0.1431761000225587, ic: 0.08470644369549724
train 7, step: 2000, loss: 1.6025335167805732, grad_norm: 0.6723606843224089, ic: 0.09344784934568562
Epoch 7: 2022-04-19 10:52:48.684137: train loss: 1.6434235177987113
Eval step 0: eval loss: 0.9904504246684109
Eval: 2022-04-19 10:52:50.860379: total loss: 1.0885967412195001, mse:4.90069248545307, ic :0.047814117377126424, sharpe5:3.215290177613497, irr5:35.445945739746094, ndcg5:0.8536507423124513, pnl5:1.080116629600525 
train 8, step: 0, loss: 1.2054655487880135, grad_norm: 0.08765089142568913, ic: 0.05207967057731284
train 8, step: 500, loss: 5.530738758816614, grad_norm: 1.5045701349776965, ic: 0.14512112466079424
train 8, step: 1000, loss: 1.9114615297280049, grad_norm: 0.8226056241478596, ic: 0.04753938207911874
train 8, step: 1500, loss: 1.1428924636272875, grad_norm: 0.4006215436681635, ic: 0.13645617037354285
train 8, step: 2000, loss: 1.1317083896734774, grad_norm: 0.5592501721361104, ic: 0.003837325054469624
Epoch 8: 2022-04-19 10:53:13.205411: train loss: 1.6431653731769709
Eval step 0: eval loss: 0.9966396273532121
Eval: 2022-04-19 10:53:15.474928: total loss: 1.0889683355743633, mse:4.879710605717448, ic :0.049154770878863094, sharpe5:3.9189680989086626, irr5:46.148250579833984, ndcg5:0.842188616002574, pnl5:1.2956504821777344 
train 9, step: 0, loss: 1.1536939190016928, grad_norm: 0.021425326327209178, ic: 0.045717394601138536
train 9, step: 500, loss: 3.13531261891172, grad_norm: 2.7340358588359344, ic: 0.18052378256285506
train 9, step: 1000, loss: 0.8727507326130579, grad_norm: 0.15109143398186514, ic: 0.25272306846930614
train 9, step: 1500, loss: 2.1559625313386346, grad_norm: 0.8931379698518616, ic: -0.03290255406828107
train 9, step: 2000, loss: 0.6050614327731609, grad_norm: 0.007282608094518423, ic: 0.07079241174855418
Epoch 9: 2022-04-19 10:53:37.548697: train loss: 1.6425210889966637
Eval step 0: eval loss: 0.9919114115364994
Eval: 2022-04-19 10:53:39.729827: total loss: 1.0876883455837685, mse:4.894076110833723, ic :0.04894417263341874, sharpe5:5.245705767273902, irr5:104.32942962646484, ndcg5:0.8499478517410051, pnl5:1.911693811416626 
train 10, step: 0, loss: 1.3109254037640148, grad_norm: 0.03995528034290673, ic: 0.19660128784655195
train 10, step: 500, loss: 0.8944211183306482, grad_norm: 0.01045866872391528, ic: 0.12759200472262056
train 10, step: 1000, loss: 1.5321012396895817, grad_norm: 0.5476718596322685, ic: 0.04757573925192886
train 10, step: 1500, loss: 3.013239490620083, grad_norm: 2.241135238425221, ic: 0.03102161861980663
train 10, step: 2000, loss: 1.3864087507717515, grad_norm: 0.17338110090109118, ic: 0.050807487922989114
Epoch 10: 2022-04-19 10:54:02.587142: train loss: 1.642999187519357
Eval step 0: eval loss: 1.003507962661269
Eval: 2022-04-19 10:54:04.730546: total loss: 1.088653608878625, mse:4.873115817705817, ic :0.05503433278219095, sharpe5:7.4294178414344785, irr5:216.45083618164062, ndcg5:0.8282332724730239, pnl5:2.790249824523926 
train 11, step: 0, loss: 4.804519522087569, grad_norm: 1.9906679656265465, ic: 0.19591415660881623
train 11, step: 500, loss: 0.9979930590557796, grad_norm: 0.07839692174955715, ic: 0.029916594865033376
train 11, step: 1000, loss: 1.0282041082665905, grad_norm: 0.3856529828899144, ic: 0.022989221121758323
train 11, step: 1500, loss: 0.6913871317051684, grad_norm: 0.0014737616975354988, ic: 0.10138447303236967
train 11, step: 2000, loss: 1.097409332795999, grad_norm: 0.04356855679084783, ic: -0.02146880015372482
Epoch 11: 2022-04-19 10:54:27.084477: train loss: 1.6420113136455874
Eval step 0: eval loss: 0.9940193903452474
Eval: 2022-04-19 10:54:29.264957: total loss: 1.0874992296746484, mse:4.876597394453319, ic :0.060905629287716, sharpe5:8.174995542168617, irr5:241.56390380859375, ndcg5:0.8505582134945855, pnl5:2.6026952266693115 
train 12, step: 0, loss: 1.3897916728552755, grad_norm: 0.24605907627115356, ic: 0.04961602942422361
train 12, step: 500, loss: 0.8167694742132005, grad_norm: 0.3502852035283954, ic: 0.033609428555757416
train 12, step: 1000, loss: 1.2602725871949207, grad_norm: 0.4633527648418476, ic: 0.26378764483635675
train 12, step: 1500, loss: 1.0911423802740348, grad_norm: 0.22792013487356272, ic: -0.04787436918441326
train 12, step: 2000, loss: 1.110419145891602, grad_norm: 0.06918794106131697, ic: 0.10434095343612326
Epoch 12: 2022-04-19 10:54:53.264015: train loss: 1.641726718213493
Eval step 0: eval loss: 1.001211703733873
Eval: 2022-04-19 10:54:55.463695: total loss: 1.087072223696582, mse:4.8208232783452445, ic :0.12067455756019638, sharpe5:13.473931387066841, irr5:402.70709228515625, ndcg5:0.8535779306537842, pnl5:5.2085161209106445 
train 13, step: 0, loss: 1.1071754895816819, grad_norm: 0.04569381387740748, ic: 0.3194110872283591
train 13, step: 500, loss: 1.1445465320849237, grad_norm: 0.018540043079728712, ic: -0.09627896851247078
train 13, step: 1000, loss: 1.371229170252262, grad_norm: 1.084774229375526, ic: 0.05033348737614684
train 13, step: 1500, loss: 0.7769577514091038, grad_norm: 0.006201081073656474, ic: -0.042003151883415885
train 13, step: 2000, loss: 1.037136939264113, grad_norm: 0.04454717388341037, ic: 0.07292526983456331
Epoch 13: 2022-04-19 10:55:19.557460: train loss: 1.6357037177149611
Eval step 0: eval loss: 0.9955217744125197
Eval: 2022-04-19 10:55:21.747765: total loss: 1.0829935453309483, mse:4.71794426345316, ic :0.14746204158062892, sharpe5:14.03714028596878, irr5:455.2489013671875, ndcg5:0.832110543081277, pnl5:4.499923229217529 
train 14, step: 0, loss: 1.745018393306409, grad_norm: 0.5442938588940017, ic: 0.20422550681167845
train 14, step: 500, loss: 1.273681102475202, grad_norm: 0.31722979960426645, ic: 0.23385000897642672
train 14, step: 1000, loss: 1.0703210751872416, grad_norm: 0.17799468359678264, ic: 0.15130959323347704
train 14, step: 1500, loss: 0.9726401806978926, grad_norm: 0.12744458054508084, ic: 0.19793580903452007
train 14, step: 2000, loss: 2.3115529096146004, grad_norm: 0.6221478360630422, ic: -0.08641063316651829
Epoch 14: 2022-04-19 10:55:44.678204: train loss: 1.62891259582493
Eval step 0: eval loss: 1.0066313941959584
Eval: 2022-04-19 10:55:46.874357: total loss: 1.0841756871748063, mse:4.6918118188416305, ic :0.16004561560817346, sharpe5:14.962845890522003, irr5:505.825439453125, ndcg5:0.845251309825016, pnl5:4.217043399810791 
train 15, step: 0, loss: 0.9690074874987531, grad_norm: 0.1848178225051292, ic: 0.12443359315003052
train 15, step: 500, loss: 1.22299644289534, grad_norm: 0.03137270840800419, ic: 0.08551144686140481
train 15, step: 1000, loss: 1.7525755208333333, grad_norm: 0.065387384500403, ic: -0.0022124673687763594
train 15, step: 1500, loss: 5.375280393525232, grad_norm: 1.2861401040180664, ic: 0.008807694429797123
train 15, step: 2000, loss: 0.9290939111382198, grad_norm: 0.014616444296246138, ic: 0.0008691762657043918
Epoch 15: 2022-04-19 10:56:09.804075: train loss: 1.62764831126923
Eval step 0: eval loss: 1.0011151531233544
Eval: 2022-04-19 10:56:11.963842: total loss: 1.0812167571484776, mse:4.676044214135163, ic :0.16591469674267809, sharpe5:15.744993079304693, irr5:522.8858032226562, ndcg5:0.848592669890149, pnl5:5.902643203735352 
train 16, step: 0, loss: 6.3185348825226715, grad_norm: 1.9427290947203864, ic: 0.1339770783230387
train 16, step: 500, loss: 1.335435074094742, grad_norm: 1.3600598357494063, ic: -0.010962472932530228
train 16, step: 1000, loss: 0.8257983850914081, grad_norm: 0.14640582599424729, ic: 0.008582534872768145
train 16, step: 1500, loss: 1.2266195657696537, grad_norm: 0.47096712221382303, ic: 0.14700178963703991
train 16, step: 2000, loss: 0.9446082367667757, grad_norm: 0.28651162636551736, ic: 0.547075570720312
Epoch 16: 2022-04-19 10:56:34.646977: train loss: 1.625816264179069
Eval step 0: eval loss: 0.9976447307793574
Eval: 2022-04-19 10:56:36.863609: total loss: 1.0820601661250806, mse:4.709361151169001, ic :0.15327632363908372, sharpe5:13.87207341134548, irr5:441.8953857421875, ndcg5:0.849076502887603, pnl5:5.046885967254639 
train 17, step: 0, loss: 1.1811783679423888, grad_norm: 0.014575194850971751, ic: 0.13185715661943637
train 17, step: 500, loss: 1.0399032518097473, grad_norm: 0.044013209506783946, ic: -0.024708094530874723
train 17, step: 1000, loss: 3.3742923547725865, grad_norm: 1.1866660156572582, ic: -0.012398830073951704
train 17, step: 1500, loss: 0.8843125031603964, grad_norm: 0.004132099109671977, ic: 0.01964230264116043
train 17, step: 2000, loss: 1.0290073471581376, grad_norm: 0.8440248796246221, ic: 0.5848611209969512
Epoch 17: 2022-04-19 10:56:59.397538: train loss: 1.627147081094277
Eval step 0: eval loss: 1.0003521333185228
Eval: 2022-04-19 10:57:01.623715: total loss: 1.0860751723177493, mse:4.722875147543995, ic :0.15153171696262, sharpe5:14.84863671183586, irr5:489.9250183105469, ndcg5:0.8478360442053053, pnl5:6.339500904083252 
train 18, step: 0, loss: 0.8499191027215317, grad_norm: 0.009339618112725864, ic: 0.03203390106754229
train 18, step: 500, loss: 2.5066525812705422, grad_norm: 1.0740645839353262, ic: 0.10037265021889029
train 18, step: 1000, loss: 1.363659931429856, grad_norm: 0.8163369160785471, ic: 0.5354621106692895
train 18, step: 1500, loss: 1.7479258402786986, grad_norm: 1.5885320639391933, ic: 0.3225097532289612
train 18, step: 2000, loss: 1.2379883094580444, grad_norm: 0.7669323001756583, ic: 0.21280091381217214
Epoch 18: 2022-04-19 10:57:23.820131: train loss: 1.6248630099262336
Eval step 0: eval loss: 0.9969133374062006
Eval: 2022-04-19 10:57:25.974021: total loss: 1.0803125589249962, mse:4.681244168332814, ic :0.16634429993744207, sharpe5:15.142928389906883, irr5:508.0591735839844, ndcg5:0.8455150572369742, pnl5:5.251779556274414 
train 19, step: 0, loss: 2.1939201325793802, grad_norm: 1.1692952741016491, ic: 0.25543574389375345
train 19, step: 500, loss: 1.024801990597747, grad_norm: 0.07765950999380726, ic: 0.07291623776004162
train 19, step: 1000, loss: 0.9876029832471571, grad_norm: 0.37011903605740754, ic: 0.543043425355606
train 19, step: 1500, loss: 1.5647920208212769, grad_norm: 0.03839686438120675, ic: 0.17264048351592623
train 19, step: 2000, loss: 1.6797615163379738, grad_norm: 2.791573915459401, ic: 0.636737343767968
Epoch 19: 2022-04-19 10:57:48.302729: train loss: 1.6259785534525035
Eval step 0: eval loss: 0.9954392371396129
Eval: 2022-04-19 10:57:50.517875: total loss: 1.0838843212123417, mse:4.726674865295196, ic :0.12268522420139027, sharpe5:7.2035227409005165, irr5:210.80026245117188, ndcg5:0.8486458830266753, pnl5:3.4873008728027344 
train 20, step: 0, loss: 1.2675782772073723, grad_norm: 0.3515871995231638, ic: 0.44461355395075786
train 20, step: 500, loss: 1.2074855320199518, grad_norm: 0.6870492567255465, ic: 0.04772880026877928
train 20, step: 1000, loss: 1.5865744110640552, grad_norm: 0.9843237239621694, ic: 0.16807325740605167
train 20, step: 1500, loss: 0.8816586557078686, grad_norm: 0.5465774119229991, ic: 0.5750071215583104
train 20, step: 2000, loss: 1.3451185295826595, grad_norm: 0.15528975244077364, ic: -0.04180874278979959
Epoch 20: 2022-04-19 10:58:13.366009: train loss: 1.625549240284393
Eval step 0: eval loss: 1.0012984835768826
Eval: 2022-04-19 10:58:15.619718: total loss: 1.080949300067491, mse:4.673958708269711, ic :0.16978521766875032, sharpe5:15.455015768408774, irr5:517.1871337890625, ndcg5:0.8397104376630087, pnl5:6.8329925537109375 
train 21, step: 0, loss: 1.3996378462099126, grad_norm: 0.42183066938731484, ic: 0.3191280377091978
train 21, step: 500, loss: 1.114217745044711, grad_norm: 0.14632202331197225, ic: 0.008200378047192286
train 21, step: 1000, loss: 0.9133916649548068, grad_norm: 1.0905542525150582, ic: 0.06548588200192852
train 21, step: 1500, loss: 0.749964145451764, grad_norm: 0.22151583168814726, ic: 0.6218776799580429
train 21, step: 2000, loss: 1.1442370981897025, grad_norm: 0.4528324865014858, ic: 0.26277315538586565
Epoch 21: 2022-04-19 10:58:37.632199: train loss: 1.6265211508742055
Eval step 0: eval loss: 1.0039243773449842
Eval: 2022-04-19 10:58:39.797459: total loss: 1.0813012386390846, mse:4.6892486682519605, ic :0.15952899743461493, sharpe5:14.46171242058277, irr5:462.8415222167969, ndcg5:0.8440415240378129, pnl5:5.016845226287842 
train 22, step: 0, loss: 1.0433094478496785, grad_norm: 0.9080256783612624, ic: 0.1183039975816992
train 22, step: 500, loss: 1.028105391855315, grad_norm: 0.004053827424837906, ic: -0.004485813435364335
train 22, step: 1000, loss: 0.9074290479150726, grad_norm: 0.025016601020909676, ic: 0.1439030711816131
train 22, step: 1500, loss: 1.0050830306293808, grad_norm: 0.05062059331136248, ic: 0.2583777360992382
train 22, step: 2000, loss: 1.0448347934456759, grad_norm: 0.1498085350995063, ic: 0.1358040186505072
Epoch 22: 2022-04-19 10:59:01.514868: train loss: 1.6241533445653136
Eval step 0: eval loss: 1.0006704546389547
Eval: 2022-04-19 10:59:03.678677: total loss: 1.081802265348265, mse:4.687756148009677, ic :0.15970259386060678, sharpe5:13.68886935710907, irr5:430.423828125, ndcg5:0.8498004410386767, pnl5:4.724173069000244 
train 23, step: 0, loss: 1.302325429871468, grad_norm: 2.8240701723677875, ic: 0.00025538029143704066
train 23, step: 500, loss: 0.8987121582031251, grad_norm: 0.29939631311338, ic: 0.5897136448271093
train 23, step: 1000, loss: 2.2886183265649764, grad_norm: 1.621708471232737, ic: 0.07298818470477564
train 23, step: 1500, loss: 0.7755860809246492, grad_norm: 0.4200611457993765, ic: 0.7159622854682383
train 23, step: 2000, loss: 1.455261368870465, grad_norm: 0.6814127188888177, ic: 0.4013499969989328
Epoch 23: 2022-04-19 10:59:25.932032: train loss: 1.6244423832477108
Eval step 0: eval loss: 1.0018069491755528
Eval: 2022-04-19 10:59:28.125863: total loss: 1.083976376327192, mse:4.68764568370472, ic :0.15950859672929954, sharpe5:14.136325326561927, irr5:452.86016845703125, ndcg5:0.8544617865585785, pnl5:5.268525123596191 
train 24, step: 0, loss: 1.1745495881818404, grad_norm: 1.3931480960253197, ic: 0.3155247541143962
train 24, step: 500, loss: 1.250821716634487, grad_norm: 1.27522958623887, ic: 0.017330946408044882
train 24, step: 1000, loss: 1.0397046717201792, grad_norm: 0.514904550480763, ic: 0.10759776398650603
train 24, step: 1500, loss: 1.2065340297428642, grad_norm: 0.1597258606303309, ic: 0.06582687867915116
train 24, step: 2000, loss: 1.3502768726961558, grad_norm: 0.5527864347309124, ic: 0.4533365061647057
Epoch 24: 2022-04-19 10:59:50.636523: train loss: 1.6235773559302298
Eval step 0: eval loss: 1.01530397886223
Eval: 2022-04-19 10:59:52.788187: total loss: 1.0813136792833027, mse:4.678557370593385, ic :0.16904104243689697, sharpe5:15.322320363521575, irr5:516.0731201171875, ndcg5:0.8450302521652094, pnl5:5.623063087463379 
train 25, step: 0, loss: 1.3118341113169898, grad_norm: 1.1462629897754033, ic: 0.20419162274943803
train 25, step: 500, loss: 1.4609026227678572, grad_norm: 1.1174955381461558, ic: 0.11750915362053763
train 25, step: 1000, loss: 1.3618265144299886, grad_norm: 0.40259795470307685, ic: 0.27644753103828035
train 25, step: 1500, loss: 2.86658397444626, grad_norm: 2.0832015660639134, ic: 0.2568374237213287
train 25, step: 2000, loss: 1.2024421209021459, grad_norm: 0.4619997765439647, ic: 0.1224635799431805
Epoch 25: 2022-04-19 11:00:16.294898: train loss: 1.6239200665521678
Eval step 0: eval loss: 0.9990182949907845
Eval: 2022-04-19 11:00:18.507658: total loss: 1.0798136288865996, mse:4.681397959930029, ic :0.1702765973245294, sharpe5:14.9009738355875, irr5:502.1001281738281, ndcg5:0.8428785468147668, pnl5:4.818628311157227 
train 26, step: 0, loss: 1.610390625, grad_norm: 1.6297447118576722, ic: 0.22365031407962843
train 26, step: 500, loss: 1.0129798757510784, grad_norm: 0.35187349712551563, ic: -0.02975037143954634
train 26, step: 1000, loss: 1.817746888985741, grad_norm: 1.0394136206555038, ic: 0.19374864858273794
train 26, step: 1500, loss: 0.9212041294347912, grad_norm: 0.10167840435248257, ic: 0.005320432717020374
train 26, step: 2000, loss: 0.9915166899913878, grad_norm: 0.17023481432200877, ic: 0.17081215593246257
Epoch 26: 2022-04-19 11:00:40.890514: train loss: 1.6244505528092408
Eval step 0: eval loss: 0.9971214804666929
Eval: 2022-04-19 11:00:43.101606: total loss: 1.0811768405717037, mse:4.685258652526126, ic :0.16622831893002368, sharpe5:14.7953962290287, irr5:483.4793395996094, ndcg5:0.8351572682891227, pnl5:4.454363822937012 
train 27, step: 0, loss: 1.6270687608833774, grad_norm: 0.681048202039829, ic: 0.6491841960691841
train 27, step: 500, loss: 1.4985376242345452, grad_norm: 0.2825750271106124, ic: 0.0661852949791245
train 27, step: 1000, loss: 2.627780964695027, grad_norm: 4.706188820547347, ic: 0.4086060976735952
train 27, step: 1500, loss: 0.8734363817986641, grad_norm: 1.4587316532674406, ic: 0.5523919073747464
train 27, step: 2000, loss: 1.3495756228398617, grad_norm: 5.320564312312078, ic: 0.027718643180921803
Epoch 27: 2022-04-19 11:01:05.084860: train loss: 1.6207673086498282
Eval step 0: eval loss: 1.0033783714290416
Eval: 2022-04-19 11:01:07.218374: total loss: 1.0792229511897606, mse:4.682701780133206, ic :0.17177978114150924, sharpe5:15.022773122191428, irr5:489.5624084472656, ndcg5:0.8425573609827869, pnl5:5.32586669921875 
train 28, step: 0, loss: 1.1585284578882795, grad_norm: 0.2503526353358519, ic: 0.1244736799134416
train 28, step: 500, loss: 2.9560943050478787, grad_norm: 2.118549411028408, ic: 0.09515296988996305
train 28, step: 1000, loss: 2.782171023400474, grad_norm: 5.318306255154253, ic: -0.022872916566544076
train 28, step: 1500, loss: 1.0238778664372208, grad_norm: 0.011163487875504127, ic: 0.19990001938828533
train 28, step: 2000, loss: 1.7411491926326308, grad_norm: 0.5360510887724048, ic: 0.11111092575313597
Epoch 28: 2022-04-19 11:01:30.174300: train loss: 1.62286924087798
Eval step 0: eval loss: 1.0037747303268167
Eval: 2022-04-19 11:01:32.345748: total loss: 1.0803909072487647, mse:4.689952505644895, ic :0.16885211243597872, sharpe5:14.716733046770095, irr5:485.56597900390625, ndcg5:0.8315379570268664, pnl5:5.0685014724731445 
train 29, step: 0, loss: 1.510280745060178, grad_norm: 0.19156511188184674, ic: 0.07789522930377793
train 29, step: 500, loss: 2.5644209483113674, grad_norm: 6.378419003854237, ic: -0.1098998162948596
train 29, step: 1000, loss: 1.7356026302984429, grad_norm: 2.452006183710412, ic: 0.4831941472837533
train 29, step: 1500, loss: 3.932901297470478, grad_norm: 2.360263577664117, ic: 0.1562360941487229
train 29, step: 2000, loss: 0.9378128173698055, grad_norm: 0.5292568420870409, ic: 0.47453159473607676
Epoch 29: 2022-04-19 11:01:55.261960: train loss: 1.6233928880327193
Eval step 0: eval loss: 1.002352505121939
Eval: 2022-04-19 11:01:57.419243: total loss: 1.0795634960576386, mse:4.676238278297812, ic :0.1714989118328771, sharpe5:15.297340357303618, irr5:508.192626953125, ndcg5:0.8501071060970685, pnl5:5.257008075714111 
train 30, step: 0, loss: 1.2497921755239876, grad_norm: 0.04939345499316845, ic: 0.9877809866573714
train 30, step: 500, loss: 1.9351267754277097, grad_norm: 0.556039390849169, ic: 0.1598998142313635
train 30, step: 1000, loss: 3.442158196670522, grad_norm: 2.4231670434535046, ic: 0.40324774030318117
train 30, step: 1500, loss: 1.0731668510722512, grad_norm: 0.3013333973535913, ic: 0.14967061028097123
train 30, step: 2000, loss: 1.0891066276345536, grad_norm: 0.080034246071458, ic: 0.4429027489195504
Epoch 30: 2022-04-19 11:02:20.350136: train loss: 1.620791327387839
Eval step 0: eval loss: 1.0081085799680751
Eval: 2022-04-19 11:02:22.486211: total loss: 1.082227208397575, mse:4.692225023086912, ic :0.15945662227477322, sharpe5:13.792445384860038, irr5:448.3043212890625, ndcg5:0.8507395932379423, pnl5:3.4686696529388428 
train 31, step: 0, loss: 1.1753596061669687, grad_norm: 0.49509728560145955, ic: 0.1906570292526883
train 31, step: 500, loss: 0.8275728636452623, grad_norm: 0.08729989832606674, ic: 0.20702587422448085
train 31, step: 1000, loss: 5.221013573078794, grad_norm: 4.964000025081327, ic: -0.020063321155731575
train 31, step: 1500, loss: 1.6645171977637172, grad_norm: 1.0643578929845359, ic: 0.3037036982778125
train 31, step: 2000, loss: 0.9703394396551724, grad_norm: 0.9674397619542647, ic: 0.24700584335837236
Epoch 31: 2022-04-19 11:02:44.669308: train loss: 1.625115019663718
Eval step 0: eval loss: 1.0033061191745656
Eval: 2022-04-19 11:02:46.865476: total loss: 1.080724683109016, mse:4.674693542451777, ic :0.17063526901127613, sharpe5:15.132479694485664, irr5:494.3301696777344, ndcg5:0.8510572760529822, pnl5:5.139094352722168 
train 32, step: 0, loss: 0.8862062212732184, grad_norm: 0.9117890410964252, ic: 0.11230976028781081
train 32, step: 500, loss: 1.1034573810856516, grad_norm: 0.7011903710513263, ic: 0.14683800893306742
train 32, step: 1000, loss: 1.3718337320224905, grad_norm: 0.08267245000843418, ic: 0.11251408706623482
train 32, step: 1500, loss: 2.0573322307952786, grad_norm: 0.8179224279442832, ic: 0.4488324412302769
train 32, step: 2000, loss: 1.0608126121301993, grad_norm: 0.9079308136976698, ic: 0.46521531920579723
Epoch 32: 2022-04-19 11:03:09.640566: train loss: 1.6201909059846538
Eval step 0: eval loss: 1.0095357548380726
Eval: 2022-04-19 11:03:11.809894: total loss: 1.0805878719615563, mse:4.674494755737637, ic :0.17232026243590096, sharpe5:15.610168395638466, irr5:516.9161376953125, ndcg5:0.8506823577104264, pnl5:6.384431838989258 
train 33, step: 0, loss: 1.1617881127948337, grad_norm: 0.046639017479346234, ic: 0.056509575384734015
train 33, step: 500, loss: 3.137949211243755, grad_norm: 1.1287379680065677, ic: 0.5281601281342014
train 33, step: 1000, loss: 5.225388917971595, grad_norm: 5.218904008803709, ic: 0.032176048061002785
train 33, step: 1500, loss: 1.3280993950076219, grad_norm: 1.8315657136429109, ic: 0.03080387464418339
train 33, step: 2000, loss: 1.8446254996366278, grad_norm: 1.0838788222980533, ic: 0.07462788532296596
Epoch 33: 2022-04-19 11:03:34.086085: train loss: 1.62282896410628
Eval step 0: eval loss: 1.0123447219342416
Eval: 2022-04-19 11:03:36.340844: total loss: 1.0843054136553778, mse:4.679023989593523, ic :0.16973987735878737, sharpe5:15.41450177013874, irr5:500.8726501464844, ndcg5:0.8445566507137524, pnl5:5.549137115478516 
train 34, step: 0, loss: 0.7211593893930764, grad_norm: 1.0335398612133209, ic: 0.16782123341537455
train 34, step: 500, loss: 1.8225963195937733, grad_norm: 2.2557877592967546, ic: 0.8312817205358809
train 34, step: 1000, loss: 0.6889548676589439, grad_norm: 0.05568373320718231, ic: 0.47532182984770915
train 34, step: 1500, loss: 1.6343876765324519, grad_norm: 2.4767788240946564, ic: 0.6317294326682343
train 34, step: 2000, loss: 3.013189023566207, grad_norm: 1.2954717670107845, ic: 0.06889550065203329
Epoch 34: 2022-04-19 11:03:59.118246: train loss: 1.6243354687101417
Eval step 0: eval loss: 1.003391934797097
Eval: 2022-04-19 11:04:01.290873: total loss: 1.081075394116441, mse:4.683962753166518, ic :0.16811648065918688, sharpe5:15.081045929789543, irr5:490.1753845214844, ndcg5:0.836989605336486, pnl5:4.743851661682129 
train 35, step: 0, loss: 1.0371872141391416, grad_norm: 0.919799296473362, ic: -0.004359418394449949
train 35, step: 500, loss: 3.3046431107954546, grad_norm: 3.161717223480403, ic: -0.0873434595899458
train 35, step: 1000, loss: 1.3465592435161147, grad_norm: 0.1760305773701502, ic: 0.5046428796023973
train 35, step: 1500, loss: 1.629528398693438, grad_norm: 0.5696127250980302, ic: 0.09208206254507899
train 35, step: 2000, loss: 1.2910125239066108, grad_norm: 0.12452297536064852, ic: -0.0992429302807623
Epoch 35: 2022-04-19 11:04:23.395006: train loss: 1.6229075192731663
Eval step 0: eval loss: 1.0003148501267114
Eval: 2022-04-19 11:04:25.634701: total loss: 1.0811965951523541, mse:4.679349870586109, ic :0.16682651849051688, sharpe5:14.18967648267746, irr5:464.897705078125, ndcg5:0.8516375930521298, pnl5:4.204647541046143 
train 36, step: 0, loss: 8.958004729429755, grad_norm: 2.115850242234844, ic: 0.06832495200000749
train 36, step: 500, loss: 0.8601166626253784, grad_norm: 0.009173320783679953, ic: 0.07111290517696062
train 36, step: 1000, loss: 1.9289621277783056, grad_norm: 5.970572256136256, ic: 0.040108606767200045
train 36, step: 1500, loss: 1.0509268715373334, grad_norm: 0.24883907657194865, ic: 0.0640131465672433
train 36, step: 2000, loss: 2.14685065778583, grad_norm: 2.254167170145877, ic: 0.39000790316182676
Epoch 36: 2022-04-19 11:04:48.011328: train loss: 1.622618902874129
Eval step 0: eval loss: 1.0171937224361505
Eval: 2022-04-19 11:04:50.162175: total loss: 1.083452516678357, mse:4.679712720502013, ic :0.1657187987479314, sharpe5:13.764443145990372, irr5:453.8161926269531, ndcg5:0.8474344915774704, pnl5:4.009673118591309 
train 37, step: 0, loss: 1.1972236764390034, grad_norm: 0.7616314237991972, ic: 0.17564150112841798
train 37, step: 500, loss: 2.337364658973029, grad_norm: 0.057839421600927754, ic: 0.162297749802904
train 37, step: 1000, loss: 0.7555087855803041, grad_norm: 0.9227527140473171, ic: 0.16167419882578926
train 37, step: 1500, loss: 3.0714913770026966, grad_norm: 2.650828569844497, ic: 0.18772781883753123
train 37, step: 2000, loss: 3.125228730988593, grad_norm: 2.8932814896502177, ic: -0.0017327142696707994
Epoch 37: 2022-04-19 11:05:12.752773: train loss: 1.6232810685521903
Eval step 0: eval loss: 1.0016007345560163
Eval: 2022-04-19 11:05:14.933557: total loss: 1.0796139495591803, mse:4.676041588946292, ic :0.17336874392099494, sharpe5:15.338442721366881, irr5:504.15789794921875, ndcg5:0.8481334414716412, pnl5:4.660637378692627 
train 38, step: 0, loss: 1.3429119688091855, grad_norm: 0.5821472474455318, ic: -0.26636050669421696
train 38, step: 500, loss: 1.6789085210755814, grad_norm: 1.250586795679791, ic: 0.22279778557084604
train 38, step: 1000, loss: 1.8296665572221131, grad_norm: 1.8875413147382405, ic: 0.13859019200857683
train 38, step: 1500, loss: 1.0894191444877934, grad_norm: 0.666090249811411, ic: 0.47057190061077403
train 38, step: 2000, loss: 0.7619444712362825, grad_norm: 0.03234362692962293, ic: 0.5529209530733202
Epoch 38: 2022-04-19 11:05:38.279014: train loss: 1.6178907520063774
Eval step 0: eval loss: 1.0001540181510005
Eval: 2022-04-19 11:05:40.496065: total loss: 1.0794880680523902, mse:4.689447634305395, ic :0.1693625575441644, sharpe5:15.368909096717834, irr5:503.3839416503906, ndcg5:0.8514907542719052, pnl5:4.687507152557373 
train 39, step: 0, loss: 0.8723180207407681, grad_norm: 0.08007768702040664, ic: 0.5389018777615142
train 39, step: 500, loss: 1.2502878000952284, grad_norm: 0.43321243805542203, ic: 0.06166141544963191
train 39, step: 1000, loss: 1.4027077414772726, grad_norm: 0.6365228489365942, ic: 0.08050673896588126
train 39, step: 1500, loss: 2.433973749610673, grad_norm: 0.5704963108023209, ic: -0.060341704799191445
train 39, step: 2000, loss: 2.9876135260389005, grad_norm: 11.015334260723808, ic: 0.17860085077151366
Epoch 39: 2022-04-19 11:06:03.165446: train loss: 1.615759054826088
Eval step 0: eval loss: 1.0005038373403765
Eval: 2022-04-19 11:06:05.441390: total loss: 1.078413138767682, mse:4.677898267645122, ic :0.17111600198673302, sharpe5:14.873477666974066, irr5:496.1035461425781, ndcg5:0.8504289930741461, pnl5:4.4128031730651855 

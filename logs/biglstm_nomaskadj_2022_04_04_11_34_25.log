Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='AdjTimeDataset', dout=0.3, epochs=20, glstm_layers=1, gnn_layers=1, gpu=0, hidden_dim=128, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=1, mask_adj=False, mask_type='soft', model_type='BiGLSTM', normalize_adj=True, num_days=8, num_heads=1, print_inteval=500, relation_num=1, seed=10086, shuffle=True, side_info=False, sparse_adj_path=None, stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
66348
BiGLSTM(
  (input_to_hidden): Linear(in_features=9, out_features=128, bias=True)
  (forward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
  )
  (backward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
  )
  (fc0): ModuleList(
    (0): Linear(in_features=256, out_features=128, bias=True)
  )
  (w_out): Linear(in_features=128, out_features=1, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
)
train 0, step: 0, loss: 4.812983700034207, grad_norm: 4.553529075703324, ic: 0.03161013369248165
train 0, step: 500, loss: 0.8656210996373399, grad_norm: 0.025309315554284645, ic: 0.019100561092671813
train 0, step: 1000, loss: 1.9484636464429408, grad_norm: 0.4441113962105849, ic: -0.022537626908348096
train 0, step: 1500, loss: 0.9546164772727272, grad_norm: 0.05094970889249416, ic: 0.047459284835967216
train 0, step: 2000, loss: 1.0006854920356372, grad_norm: 0.13093434980440752, ic: 0.04447706327135963
Epoch 0: 2022-04-04 23:36:02.085049: train loss: 1.649155177047699
Eval step 0: eval loss: 0.8362233168960748
Eval: 2022-04-04 23:36:05.506046: total loss: 1.0792905387837242, mse:4.823188419731919, ic :0.0075883470532928255, sharpe5:8.038887237310409, irr5:224.7877197265625, ndcg5:0.8625794919929239, pnl5:2.9971296787261963 
train 1, step: 0, loss: 2.7675060641381046, grad_norm: 0.74042542877392, ic: 0.04718838447484999
train 1, step: 500, loss: 1.7483269683665041, grad_norm: 0.6561214184054854, ic: 0.12393079751379023
train 1, step: 1000, loss: 0.8749449146015882, grad_norm: 0.14985422019299163, ic: 0.05924257978198689
train 1, step: 1500, loss: 1.7078377559267242, grad_norm: 0.17992642315544297, ic: -0.007119419924796387
train 1, step: 2000, loss: 2.172355859375, grad_norm: 0.8427582951200432, ic: -0.00403448075080561
Epoch 1: 2022-04-04 23:37:41.806810: train loss: 1.6468336163824069
Eval step 0: eval loss: 0.8363076984819546
Eval: 2022-04-04 23:37:45.447924: total loss: 1.0793132652142314, mse:4.823087689509577, ic :0.012042707515229858, sharpe5:8.199445829987525, irr5:229.79457092285156, ndcg5:0.8510680427282974, pnl5:2.574476718902588 
train 2, step: 0, loss: 2.1404479758522728, grad_norm: 0.0065041519203499565, ic: 0.09795168409513617
train 2, step: 500, loss: 3.289776964739828, grad_norm: 0.2555287994287478, ic: 0.0067913910416064795
train 2, step: 1000, loss: 2.0740181992337163, grad_norm: 2.353136593109977e-05, ic: 0.25135497289410014
train 2, step: 1500, loss: 1.4807273340589218, grad_norm: 0.051266147630836534, ic: -0.021672347649860826
train 2, step: 2000, loss: 3.2153635817307693, grad_norm: 0.728196893822819, ic: 0.1329540961480552
Epoch 2: 2022-04-04 23:39:24.025794: train loss: 1.646615739023926
Eval step 0: eval loss: 0.8366919176847338
Eval: 2022-04-04 23:39:27.709581: total loss: 1.0794310747988622, mse:4.8227480724637335, ic :0.020006356512510294, sharpe5:11.478310019373893, irr5:331.6448059082031, ndcg5:0.8491176664695657, pnl5:2.4929068088531494 
train 3, step: 0, loss: 1.5235389275279472, grad_norm: 0.49313961848140875, ic: -0.01200165698490866
train 3, step: 500, loss: 1.4938840574833594, grad_norm: 0.3248030778803756, ic: 0.04631262467859676
train 3, step: 1000, loss: 3.6866094559585494, grad_norm: 0.6791594906931289, ic: -0.02022943747109738
train 3, step: 1500, loss: 1.9602336477726066, grad_norm: 0.9524629067318287, ic: -0.01726592482026458
train 3, step: 2000, loss: 0.8989562658361486, grad_norm: 0.0042917058254164225, ic: -0.0009567063846174818
Epoch 3: 2022-04-04 23:41:08.217321: train loss: 1.648348487379886
Eval step 0: eval loss: 0.8338990930008561
Eval: 2022-04-04 23:41:11.973788: total loss: 1.0787518848836213, mse:4.825319881322713, ic :0.005157474287501512, sharpe5:7.317716311812401, irr5:205.2373809814453, ndcg5:0.8501305822070394, pnl5:2.6437904834747314 
train 4, step: 0, loss: 1.4445085299744898, grad_norm: 0.06978468892387854, ic: 0.02856644964845278
train 4, step: 500, loss: 1.639294721948819, grad_norm: 0.5440851925652144, ic: -0.019817299975535593
train 4, step: 1000, loss: 2.9660666861185216, grad_norm: 0.7639528120988194, ic: -0.040657680669864464
train 4, step: 1500, loss: 2.154429967695148, grad_norm: 0.4528752881195873, ic: -0.029830813157628734
train 4, step: 2000, loss: 1.1021426662130638, grad_norm: 0.3815700282575026, ic: -0.018248089754481587
Epoch 4: 2022-04-04 23:42:54.994326: train loss: 1.6467638109318001
Eval step 0: eval loss: 0.9215550317151276
Eval: 2022-04-04 23:42:58.774403: total loss: 1.1324145440281472, mse:4.988556028571663, ic :0.01748087662594379, sharpe5:7.1605143365263935, irr5:202.06268310546875, ndcg5:0.8586788489706473, pnl5:2.5811572074890137 
train 5, step: 0, loss: 1.4762885381711408, grad_norm: 0.9751262181349956, ic: -0.0024386231914817237
train 5, step: 500, loss: 0.8905252914973235, grad_norm: 0.0071820133047761385, ic: 0.007282743365576569
train 5, step: 1000, loss: 0.9925886950730365, grad_norm: 0.15196098244887699, ic: 0.019332584625427335
train 5, step: 1500, loss: 1.5219249871386868, grad_norm: 0.1353533995875713, ic: 0.018661672574477497
train 5, step: 2000, loss: 1.116061960738109, grad_norm: 0.026498998516326935, ic: 0.014936313047220975
Epoch 5: 2022-04-04 23:44:39.744286: train loss: 1.6473717635854304
Eval step 0: eval loss: 0.8455666480752766
Eval: 2022-04-04 23:44:43.447483: total loss: 1.0832941904913151, mse:4.828390269369106, ic :-0.006666720491866634, sharpe5:0.029717252069385722, irr5:-0.7552410960197449, ndcg5:0.849294984328699, pnl5:1.2514334917068481 
train 6, step: 0, loss: 1.356068296295604, grad_norm: 0.6218042548151133, ic: 0.006073237422865184
train 6, step: 500, loss: 1.0052407047102316, grad_norm: 0.03384540066000551, ic: 0.012890341036909187
train 6, step: 1000, loss: 1.1176464472433458, grad_norm: 0.056735588254705094, ic: -0.013321863525971468
train 6, step: 1500, loss: 1.5721683722882231, grad_norm: 0.6460317177004871, ic: -0.02345429947982733
train 6, step: 2000, loss: 0.8070532109281174, grad_norm: 0.03794557656966448, ic: 0.026131723843722136
Epoch 6: 2022-04-04 23:46:25.108286: train loss: 1.6473759020144185
Eval step 0: eval loss: 0.8372093980505795
Eval: 2022-04-04 23:46:28.792734: total loss: 1.0796048033318342, mse:4.82307432631555, ic :0.01536830696202466, sharpe5:11.796721857190132, irr5:406.9259033203125, ndcg5:0.8340296216228221, pnl5:3.31949782371521 
train 7, step: 0, loss: 0.9996427536010742, grad_norm: 0.04702883177340389, ic: -0.0007251652346846466
train 7, step: 500, loss: 0.6537098986037234, grad_norm: 0.0029983713392585216, ic: -0.007626151207916383
train 7, step: 1000, loss: 1.0370128715846345, grad_norm: 0.20516449479210314, ic: -0.008158116150831916
train 7, step: 1500, loss: 2.269757335209003, grad_norm: 0.6262900693835236, ic: -0.02457595527618904
train 7, step: 2000, loss: 0.9039911076017266, grad_norm: 0.032174011000214664, ic: -0.013260402573210484
Epoch 7: 2022-04-04 23:48:11.234991: train loss: 1.6464991811399816
Eval step 0: eval loss: 0.8348131410942439
Eval: 2022-04-04 23:48:14.976748: total loss: 1.077701071559233, mse:4.754235055547861, ic :0.125395024659914, sharpe5:11.651229969263076, irr5:402.4447326660156, ndcg5:0.8630043317618857, pnl5:3.4360225200653076 
train 8, step: 0, loss: 3.615109474071558, grad_norm: 1.0388784705673821, ic: 0.006009888535039642
train 8, step: 500, loss: 2.75021445787424, grad_norm: 0.8482002834839831, ic: -0.07058507969960771
train 8, step: 1000, loss: 3.0959147135416667, grad_norm: 1.0790853083620897, ic: -0.02710556167472041
train 8, step: 1500, loss: 0.7119215884132244, grad_norm: 0.031083338889227628, ic: 0.5397793794376057
train 8, step: 2000, loss: 1.054820550582545, grad_norm: 0.3210055048467755, ic: 0.6547204135294666
Epoch 8: 2022-04-04 23:49:55.898784: train loss: 1.638269362781845
Eval step 0: eval loss: 0.8285755925233799
Eval: 2022-04-04 23:49:59.514543: total loss: 1.0727311816709895, mse:4.647292021809167, ic :0.13648596194332613, sharpe5:11.498968091011047, irr5:399.32464599609375, ndcg5:0.8475033978678052, pnl5:3.6000192165374756 
train 9, step: 0, loss: 5.43222625099681, grad_norm: 0.7695297106787399, ic: 0.0004670911167768011
train 9, step: 500, loss: 1.3186060187756323, grad_norm: 0.8278334570857702, ic: 0.30213613548345053
train 9, step: 1000, loss: 0.9350169014265188, grad_norm: 0.009634902338960579, ic: -0.006422850986052617
train 9, step: 1500, loss: 1.0871375284770803, grad_norm: 0.012676324586890874, ic: 0.47761835467401703
train 9, step: 2000, loss: 1.083155468882057, grad_norm: 0.20234568935100591, ic: 0.24882627772106253
Epoch 9: 2022-04-04 23:51:38.598648: train loss: 1.6356155366494154
Eval step 0: eval loss: 0.830060245365187
Eval: 2022-04-04 23:51:42.088043: total loss: 1.0731526443527357, mse:4.637506594795754, ic :0.1356059417294338, sharpe5:11.373579016327858, irr5:399.0954284667969, ndcg5:0.8481604639938952, pnl5:3.221991539001465 
train 10, step: 0, loss: 7.181363030703353, grad_norm: 0.9641308040972456, ic: 0.16943250062844586
train 10, step: 500, loss: 1.1389480183599883, grad_norm: 0.11899152402430731, ic: 0.011606554341449426
train 10, step: 1000, loss: 2.3920112094996164, grad_norm: 0.6775729913531797, ic: 0.0798961101573899
train 10, step: 1500, loss: 1.0927716540051746, grad_norm: 0.2154264949560508, ic: -0.03455535208390544
train 10, step: 2000, loss: 2.7894617329977205, grad_norm: 0.7532972996605916, ic: 0.4885711786043651
Epoch 10: 2022-04-04 23:53:23.818454: train loss: 1.6358206239839006
Eval step 0: eval loss: 0.8298075508141793
Eval: 2022-04-04 23:53:27.597160: total loss: 1.0717942451034774, mse:4.624134761497968, ic :0.14026824236182783, sharpe5:11.668912158608435, irr5:395.37744140625, ndcg5:0.8462455991516733, pnl5:3.3051671981811523 
train 11, step: 0, loss: 1.2655477737698184, grad_norm: 0.020914879005933158, ic: 0.12203637602914466
train 11, step: 500, loss: 0.6763579708102012, grad_norm: 0.05434002390284235, ic: 0.5874085547274251
train 11, step: 1000, loss: 0.9406997919672301, grad_norm: 0.12919960354340893, ic: 0.10374457488589417
train 11, step: 1500, loss: 1.0592259189538789, grad_norm: 0.060674183955617245, ic: 0.18432455353147884
train 11, step: 2000, loss: 0.7939769389316745, grad_norm: 0.0007945939438008503, ic: 0.041841428376205705
Epoch 11: 2022-04-04 23:55:09.894168: train loss: 1.6340242642749527
Eval step 0: eval loss: 0.8343454407188488
Eval: 2022-04-04 23:55:13.619184: total loss: 1.074342589813464, mse:4.627584617255223, ic :0.14044278346796682, sharpe5:11.771269834041595, irr5:401.8338623046875, ndcg5:0.8483579958505159, pnl5:3.365978240966797 
train 12, step: 0, loss: 1.002404769261678, grad_norm: 0.1514907016170085, ic: 0.285509137667186
train 12, step: 500, loss: 0.9497964095132064, grad_norm: 0.07151203429509574, ic: 0.023641005026365673
train 12, step: 1000, loss: 3.010407854796975, grad_norm: 0.19072890799722877, ic: 0.21482680433993523
train 12, step: 1500, loss: 0.9237838710253237, grad_norm: 0.18492626291725073, ic: 0.06181555818439637
train 12, step: 2000, loss: 0.8779134606306647, grad_norm: 0.008371381759001264, ic: -0.041306589380497485
Epoch 12: 2022-04-04 23:56:55.022010: train loss: 1.6345429735066306
Eval step 0: eval loss: 0.8271690183746048
Eval: 2022-04-04 23:56:58.659316: total loss: 1.0713468813625295, mse:4.629437969980254, ic :0.14161769493823634, sharpe5:11.71428821504116, irr5:403.8658142089844, ndcg5:0.8497190466665763, pnl5:3.742241382598877 
train 13, step: 0, loss: 2.0239118598204855, grad_norm: 1.5535577697460923, ic: 0.41745105504026553
train 13, step: 500, loss: 0.8427795993029502, grad_norm: 0.06597011712778311, ic: 0.5609618928366239
train 13, step: 1000, loss: 0.9636426272808305, grad_norm: 0.5042744265776091, ic: 0.5736657079776597
train 13, step: 1500, loss: 2.363500042691257, grad_norm: 0.21119876557456085, ic: 0.07934053749205242
train 13, step: 2000, loss: 1.4900126938089395, grad_norm: 0.01807807686049344, ic: 0.07266425552008815
Epoch 13: 2022-04-04 23:58:39.430036: train loss: 1.6337169656676296
Eval step 0: eval loss: 0.8265443888303476
Eval: 2022-04-04 23:58:43.139996: total loss: 1.0711561774915401, mse:4.627320081870529, ic :0.14174944709811865, sharpe5:11.6456849527359, irr5:393.0740661621094, ndcg5:0.8551857274148091, pnl5:4.031961917877197 
train 14, step: 0, loss: 4.557143379485179, grad_norm: 1.3586701047805287, ic: 0.1697141550673576
train 14, step: 500, loss: 0.8279915439244075, grad_norm: 0.002119192504716046, ic: 0.023373961439274216
train 14, step: 1000, loss: 1.886132219295748, grad_norm: 0.16870580817170447, ic: 0.40684318216378335
train 14, step: 1500, loss: 1.1227964104812598, grad_norm: 0.061805563566640256, ic: 0.10387899745544883
train 14, step: 2000, loss: 1.1359829294156032, grad_norm: 0.1537992982145579, ic: 0.1383322933981779
Epoch 14: 2022-04-05 00:00:23.737321: train loss: 1.6316617029642813
Eval step 0: eval loss: 0.831752250518638
Eval: 2022-04-05 00:00:27.388694: total loss: 1.0709232294738409, mse:4.596415561952838, ic :0.17418292766469892, sharpe5:14.99026260137558, irr5:497.4225158691406, ndcg5:0.8420105449592011, pnl5:5.155937671661377 
train 15, step: 0, loss: 3.330805797057393, grad_norm: 0.47858651534622293, ic: 0.0835373118709009
train 15, step: 500, loss: 1.2614488355933084, grad_norm: 0.006825097679319453, ic: -0.048051682622644115
train 15, step: 1000, loss: 1.3268500103213923, grad_norm: 0.14246009608573051, ic: -0.03734205149952951
train 15, step: 1500, loss: 0.8559954785925197, grad_norm: 0.2141746437111668, ic: -0.03124681460493814
train 15, step: 2000, loss: 1.455576824489231, grad_norm: 0.6039201491262676, ic: -0.004197156936617303
Epoch 15: 2022-04-05 00:02:08.505720: train loss: 1.6279118386154026
Eval step 0: eval loss: 0.8352807128391727
Eval: 2022-04-05 00:02:12.225161: total loss: 1.0737461969090423, mse:4.608663497213468, ic :0.16880298903495566, sharpe5:14.159908200502395, irr5:469.3238830566406, ndcg5:0.8484796635184982, pnl5:4.592280387878418 
train 16, step: 0, loss: 0.6946328979395536, grad_norm: 0.22935389478210513, ic: 0.02325409484953263
train 16, step: 500, loss: 1.561580821532557, grad_norm: 0.24673060383175632, ic: 0.19058251882935406
train 16, step: 1000, loss: 0.8719071821732954, grad_norm: 0.002078122953763498, ic: 0.020587998914557384
train 16, step: 1500, loss: 0.8490248996503152, grad_norm: 0.224541708638672, ic: 0.16785128746109768
train 16, step: 2000, loss: 3.3730938483820188, grad_norm: 1.1861150929519284, ic: -0.004990035526466842
Epoch 16: 2022-04-05 00:03:56.817598: train loss: 1.6283063912521398
Eval step 0: eval loss: 0.8266614425546628
Eval: 2022-04-05 00:04:00.460735: total loss: 1.0688717330597857, mse:4.593448770319148, ic :0.1845607828531455, sharpe5:16.052315829992292, irr5:524.224853515625, ndcg5:0.847851764370559, pnl5:2.7335352897644043 
train 17, step: 0, loss: 1.2742877828663792, grad_norm: 0.2760467202405067, ic: -0.08623080476021608
train 17, step: 500, loss: 1.779513756563347, grad_norm: 0.39959309316169644, ic: 0.13779951247251168
train 17, step: 1000, loss: 1.293141046485618, grad_norm: 0.11093020547386633, ic: 0.14165980830319247
train 17, step: 1500, loss: 4.521559715971712, grad_norm: 1.1274170254078026, ic: 0.2379468186448556
train 17, step: 2000, loss: 1.2601857333308473, grad_norm: 0.5429445249504405, ic: 0.029378604086044088
Epoch 17: 2022-04-05 00:05:41.779913: train loss: 1.6274368247957307
Eval step 0: eval loss: 0.8324793985445205
Eval: 2022-04-05 00:05:45.489951: total loss: 1.070298503993567, mse:4.590220179139932, ic :0.18345729389603352, sharpe5:16.365292378664016, irr5:526.86376953125, ndcg5:0.8491994220519231, pnl5:4.983283519744873 
train 18, step: 0, loss: 1.4254691111206728, grad_norm: 0.5686460888451454, ic: 0.026659082623736376
train 18, step: 500, loss: 1.4935062337633676, grad_norm: 0.6555943609691477, ic: -0.02315010713964083
train 18, step: 1000, loss: 0.6550086285316781, grad_norm: 0.03680284376267863, ic: 0.572734565349446
train 18, step: 1500, loss: 1.4406275393824224, grad_norm: 0.029812038186370956, ic: 0.09205120431839417
train 18, step: 2000, loss: 0.9114592728341462, grad_norm: 0.007492828169777975, ic: 0.014488741650898286
Epoch 18: 2022-04-05 00:07:26.769523: train loss: 1.6266007749288542
Eval step 0: eval loss: 0.8239710077219441
Eval: 2022-04-05 00:07:30.640742: total loss: 1.0671336534217521, mse:4.596649649706831, ic :0.1819909102814197, sharpe5:16.5821061193943, irr5:524.635986328125, ndcg5:0.845702512821686, pnl5:4.9163947105407715 
train 19, step: 0, loss: 1.4706298828125, grad_norm: 0.6590541971537649, ic: -0.00269811863834743
train 19, step: 500, loss: 0.8708228358515986, grad_norm: 0.0634760113943891, ic: 0.24093498017436604
train 19, step: 1000, loss: 0.9602883120966211, grad_norm: 0.02988213232631536, ic: 0.19616942173668728
train 19, step: 1500, loss: 3.963091702169712, grad_norm: 0.7477267198058303, ic: 0.09301809522621793
train 19, step: 2000, loss: 1.0214371431790865, grad_norm: 0.08005946632157498, ic: 0.16562267512137516
Epoch 19: 2022-04-05 00:09:12.970929: train loss: 1.6259081657306917
Eval step 0: eval loss: 0.8309225840111301
Eval: 2022-04-05 00:09:16.767454: total loss: 1.0692105692230411, mse:4.592405367405969, ic :0.18418715889648107, sharpe5:16.47137605547905, irr5:528.6631469726562, ndcg5:0.8575828175273381, pnl5:3.7378346920013428 

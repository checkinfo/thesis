Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='RGCNSeqTimeDataset', dout=0.3, epochs=40, glstm_layers=1, gnn_layers=1, gpu=0, graph_attn=False, hidden_dim=128, inner_prod=False, input_dim=9, input_graph=True, label_cnt=3, lr=0.0004, lstm_layers=1, market=None, mask_adj=True, mask_type='soft', model_type='BiGLSTM', normalize_adj=True, num_days=8, num_heads=1, print_inteval=500, rank_loss=False, relation_num=2, rsr_data_path=None, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_250_0.6/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
load 2305 train graphs successful!
load 126 test graphs successful!
11930
BiGLSTM(
  (input_to_hidden): Linear(in_features=9, out_features=128, bias=True)
  (forward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
            (1): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
  )
  (backward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
            (1): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
  )
  (fc0): ModuleList(
    (0): Linear(in_features=256, out_features=128, bias=True)
  )
  (w_out): Linear(in_features=128, out_features=1, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
)
train 0, step: 0, loss: 4.81496469409695, grad_norm: 5.25883707858427, ic: 0.02699700293718544
train 0, step: 500, loss: 0.8634142670850603, grad_norm: 0.02823663625887083, ic: 0.038445924751069165
train 0, step: 1000, loss: 1.9567340663862474, grad_norm: 0.5438068647489426, ic: 0.027571582144021632
train 0, step: 1500, loss: 0.9550292003767292, grad_norm: 0.046655789531996276, ic: 0.03411015671466084
train 0, step: 2000, loss: 1.0046543151547875, grad_norm: 0.16993197345666505, ic: 0.005331723022691767
Epoch 0: 2022-04-27 22:17:11.860277: train loss: 1.6487438226018343
Eval step 0: eval loss: 0.8365117064014752
Eval: 2022-04-27 22:18:32.377007: total loss: 1.0794100712714474, mse:4.822837660134075, ic :0.007529229045732223, sharpe5:7.938258714079857, irr5:225.20703125, ndcg5:0.8466127150452657, pnl5:2.8364062309265137 
train 1, step: 0, loss: 2.7765703755040323, grad_norm: 0.9227116198918741, ic: 0.029846242661966588
train 1, step: 500, loss: 1.7520877173143488, grad_norm: 0.8022349743074264, ic: 0.10516876894046677
train 1, step: 1000, loss: 0.8787560353273891, grad_norm: 0.18364556155937914, ic: 0.06102430290396794
train 1, step: 1500, loss: 1.7147866435434627, grad_norm: 0.21726536375607453, ic: -0.01338791068193974
train 1, step: 2000, loss: 2.18100546875, grad_norm: 0.9287934463555904, ic: -0.012433519871305873
Epoch 1: 2022-04-27 22:41:11.716903: train loss: 1.6467864180807605
Eval step 0: eval loss: 0.8341642003918598
Eval: 2022-04-27 22:42:38.072127: total loss: 1.07898557289702, mse:4.824243033573675, ic :0.006857534847209679, sharpe5:7.44090847402811, irr5:210.03074645996094, ndcg5:0.8418282899642949, pnl5:2.8067452907562256 
train 2, step: 0, loss: 2.141793323863636, grad_norm: 0.009981243473711782, ic: 0.1496371404749955
train 2, step: 500, loss: 3.3013692506602115, grad_norm: 0.2938850160616183, ic: 0.0644574957034572
train 2, step: 1000, loss: 2.0724033165708815, grad_norm: 0.0002511427393678473, ic: 0.14210033223409652
train 2, step: 1500, loss: 1.487256418475668, grad_norm: 0.06316212474018622, ic: -0.0706282326825381
train 2, step: 2000, loss: 3.233153545673077, grad_norm: 0.8043712255431228, ic: 0.22182302120721326
Epoch 2: 2022-04-27 23:05:35.035150: train loss: 1.6464874609029603
Eval step 0: eval loss: 0.8358226329936116
Eval: 2022-04-27 23:06:55.621706: total loss: 1.0795421526088331, mse:4.823481567979928, ic :0.01177929479588741, sharpe5:7.6339028593897815, irr5:215.00389099121094, ndcg5:0.8490249744993986, pnl5:2.681868076324463 
train 3, step: 0, loss: 1.5219044755144817, grad_norm: 0.5354148877421194, ic: 0.0004189400840556162
train 3, step: 500, loss: 1.5030965902138802, grad_norm: 0.3505382696806627, ic: 0.08970409876836741
train 3, step: 1000, loss: 3.678827315414508, grad_norm: 0.7195170258070063, ic: 0.01803507184049069
train 3, step: 1500, loss: 1.9808115857712767, grad_norm: 1.213831838810937, ic: -0.038799314764469496
train 3, step: 2000, loss: 0.8976741976351351, grad_norm: 0.001353013267523414, ic: 0.027683474872708683
Epoch 3: 2022-04-27 23:29:14.910502: train loss: 1.6456461113085088
Eval step 0: eval loss: 0.8338922112709101
Eval: 2022-04-27 23:30:31.686662: total loss: 1.0784704206417144, mse:4.823056501041054, ic :0.027442696990410357, sharpe5:4.821239103376866, irr5:100.598876953125, ndcg5:0.844881499419199, pnl5:1.817671775817871 
train 4, step: 0, loss: 1.4363077965561224, grad_norm: 0.044046387246572456, ic: 0.08125399391868804
train 4, step: 500, loss: 1.6481451079601377, grad_norm: 0.5640853987206749, ic: 0.07498723955626213
train 4, step: 1000, loss: 2.9713947947432358, grad_norm: 0.694928967027673, ic: 0.060089463816712936
train 4, step: 1500, loss: 2.1455762130801688, grad_norm: 0.4835436876507219, ic: 0.017981232553486708
train 4, step: 2000, loss: 1.0831850327748347, grad_norm: 0.39604997331922365, ic: 0.25873729678179436
Epoch 4: 2022-04-27 23:52:51.565015: train loss: 1.6457017444809297
Eval step 0: eval loss: 0.8514141890723788
Eval: 2022-04-27 23:54:16.896708: total loss: 1.0862819327464586, mse:4.829816246900491, ic :0.03743482567262705, sharpe5:10.120654059648514, irr5:308.5361633300781, ndcg5:0.842314255638014, pnl5:2.431657075881958 
train 5, step: 0, loss: 1.3604046507969798, grad_norm: 0.1774391978981555, ic: 0.04414803380560103
train 5, step: 500, loss: 0.8874758569897403, grad_norm: 0.006667753922945085, ic: 0.05139209831796285
train 5, step: 1000, loss: 0.9815291247605364, grad_norm: 0.14934019354782033, ic: 0.011979394995141524
train 5, step: 1500, loss: 1.529247523449464, grad_norm: 0.1519303037174846, ic: 0.010055907505790475
train 5, step: 2000, loss: 1.1003410888105423, grad_norm: 0.029344791385053554, ic: 0.17097541796267687
Epoch 5: 2022-04-28 00:17:03.415626: train loss: 1.6432296755586475
Eval step 0: eval loss: 0.8355777205858139
Eval: 2022-04-28 00:18:25.472465: total loss: 1.0767973893266813, mse:4.726318780321513, ic :0.1365727977589579, sharpe5:12.997596305608749, irr5:449.0087890625, ndcg5:0.8542817399485391, pnl5:3.6975111961364746 
train 6, step: 0, loss: 1.3310329796214613, grad_norm: 0.43171073632946894, ic: 0.18198757385832043
train 6, step: 500, loss: 1.008693630808528, grad_norm: 0.048889082871515804, ic: 0.036058894805617546
train 6, step: 1000, loss: 1.1034044156962928, grad_norm: 1.7990012514847977, ic: 0.6466691298261534
train 6, step: 1500, loss: 1.57520943633781, grad_norm: 0.7052500016431381, ic: 0.1345735350284465
train 6, step: 2000, loss: 0.8005601747022617, grad_norm: 0.043120432142376874, ic: 0.3577083018144003
Epoch 6: 2022-04-28 00:40:59.517662: train loss: 1.6309645721927035
Eval step 0: eval loss: 0.823362456985972
Eval: 2022-04-28 00:42:30.671764: total loss: 1.0706199488777433, mse:4.692759167491272, ic :0.1648271832862161, sharpe5:15.962365862131119, irr5:547.564697265625, ndcg5:0.8726569984729765, pnl5:7.203158378601074 
train 7, step: 0, loss: 0.9823423385620118, grad_norm: 0.2538092787358055, ic: 0.16068058230669285
train 7, step: 500, loss: 0.6489091774612937, grad_norm: 0.0014158632387528602, ic: 0.06646372787520313
train 7, step: 1000, loss: 1.0176823449697734, grad_norm: 1.034047580584828, ic: 0.18820508309738065
train 7, step: 1500, loss: 2.237874610631029, grad_norm: 0.7229582703574741, ic: 0.4343994582377257
train 7, step: 2000, loss: 0.9164340954412359, grad_norm: 0.05216442308957703, ic: -0.047114200334235835
Epoch 7: 2022-04-28 01:05:02.291479: train loss: 1.6278021323212786
Eval step 0: eval loss: 0.8304127571580281
Eval: 2022-04-28 01:06:27.564780: total loss: 1.0715254511278036, mse:4.685471315503824, ic :0.1651308455174889, sharpe5:16.570828793048857, irr5:547.1988525390625, ndcg5:0.8528731086320157, pnl5:4.807324409484863 
train 8, step: 0, loss: 3.5867898692255435, grad_norm: 1.0717708036129767, ic: 0.21276888560012003
train 8, step: 500, loss: 2.773529145492971, grad_norm: 0.8546485473845671, ic: -0.01971251561097201
train 8, step: 1000, loss: 3.0517903645833333, grad_norm: 0.8829424065426565, ic: 0.11122758447707587
train 8, step: 1500, loss: 0.7136051352015259, grad_norm: 0.011331995583369406, ic: 0.4596387931792598
train 8, step: 2000, loss: 1.0843944312916796, grad_norm: 0.36443440020600143, ic: 0.5059093511392199
Epoch 8: 2022-04-28 01:28:39.679823: train loss: 1.6272638388304865
Eval step 0: eval loss: 0.8244637267230308
Eval: 2022-04-28 01:30:06.889388: total loss: 1.0694256475591737, mse:4.68107841725739, ic :0.16954817804603858, sharpe5:16.719229402542112, irr5:549.9872436523438, ndcg5:0.8519412046820938, pnl5:5.355251312255859 
train 9, step: 0, loss: 5.420004033966308, grad_norm: 0.7939349673094009, ic: 0.1402811722872826
train 9, step: 500, loss: 1.349007784464713, grad_norm: 1.3559294768953045, ic: 0.32431180516856767
train 9, step: 1000, loss: 0.9283882228807471, grad_norm: 0.15028286805609362, ic: 0.07030805649205464
train 9, step: 1500, loss: 1.090363582560521, grad_norm: 0.009632764400632633, ic: 0.3899129404515153
train 9, step: 2000, loss: 1.069540626056457, grad_norm: 0.2633389329902506, ic: 0.26060890904922235
Epoch 9: 2022-04-28 01:52:49.897737: train loss: 1.6280233961563673
Eval step 0: eval loss: 0.8226345371772918
Eval: 2022-04-28 01:54:21.607506: total loss: 1.0710540364150263, mse:4.6912806122344675, ic :0.16677828857861954, sharpe5:17.609704949855804, irr5:583.661865234375, ndcg5:0.8475816558260539, pnl5:6.312846660614014 
train 10, step: 0, loss: 7.08305336643586, grad_norm: 1.6869713905782535, ic: 0.2678171068814747
train 10, step: 500, loss: 1.1342235906532085, grad_norm: 0.11875345481640552, ic: 0.03642549493115761
train 10, step: 1000, loss: 2.394907758279812, grad_norm: 0.7186538724249794, ic: 0.14720273275339638
train 10, step: 1500, loss: 1.0932209956181516, grad_norm: 0.33247406541036056, ic: 0.046218632214349895
train 10, step: 2000, loss: 2.7488943175341944, grad_norm: 0.5161918320899954, ic: 0.42542549709665856
Epoch 10: 2022-04-28 02:17:10.940514: train loss: 1.6276674810716532
Eval step 0: eval loss: 0.8225053921891464
Eval: 2022-04-28 02:18:37.346564: total loss: 1.0692784800833202, mse:4.683150138925228, ic :0.17122619231785108, sharpe5:17.92604899406433, irr5:595.7910766601562, ndcg5:0.8408640257402036, pnl5:6.129563808441162 
train 11, step: 0, loss: 1.2524651972157774, grad_norm: 0.2021969634854305, ic: 0.20018914000485405
train 11, step: 500, loss: 0.6629099902140441, grad_norm: 0.33073907757613513, ic: 0.5187378164904399
train 11, step: 1000, loss: 0.9298175204812449, grad_norm: 0.1569221091886907, ic: 0.06882952611149229
train 11, step: 1500, loss: 1.0537104690284058, grad_norm: 0.07059432819288625, ic: 0.17873029141010932
train 11, step: 2000, loss: 0.7883024049972848, grad_norm: 0.013692847952157163, ic: 0.10820513657607783
Epoch 11: 2022-04-28 02:41:28.758288: train loss: 1.6265248034881932
Eval step 0: eval loss: 0.8285303789144823
Eval: 2022-04-28 02:42:57.940058: total loss: 1.069952710408647, mse:4.672846949358008, ic :0.1740556333911379, sharpe5:16.760568248033522, irr5:558.4834594726562, ndcg5:0.8398287737098622, pnl5:4.660897254943848 
train 12, step: 0, loss: 0.9622580210367838, grad_norm: 0.29060460167837543, ic: 0.40073542171289034
train 12, step: 500, loss: 0.9280361016200861, grad_norm: 0.12555260412695618, ic: 0.17270363036216935
train 12, step: 1000, loss: 2.9433815342605496, grad_norm: 0.34346619601854256, ic: 0.23293690227891625
train 12, step: 1500, loss: 0.9352686141886425, grad_norm: 0.12703129149507922, ic: -0.10902468711866464
train 12, step: 2000, loss: 0.8722706590174188, grad_norm: 0.004930018647271609, ic: 0.22812065773554552
Epoch 12: 2022-04-28 03:05:24.587541: train loss: 1.6254032969926495
Eval step 0: eval loss: 0.8265042561248682
Eval: 2022-04-28 03:06:57.232668: total loss: 1.0677759739244643, mse:4.650695092261943, ic :0.18088948046656195, sharpe5:17.06389446258545, irr5:566.779541015625, ndcg5:0.8451526873276309, pnl5:5.217899799346924 
train 13, step: 0, loss: 2.0652028197597674, grad_norm: 1.2973629591853442, ic: 0.4117609287909864
train 13, step: 500, loss: 0.8309291199479877, grad_norm: 0.05544755865246263, ic: 0.5073000806819297
train 13, step: 1000, loss: 0.961927744206166, grad_norm: 0.41923842018643714, ic: 0.5045672065210592
train 13, step: 1500, loss: 2.4342465069403785, grad_norm: 0.6752181719800442, ic: -0.0893550056334102
train 13, step: 2000, loss: 1.4765861810767897, grad_norm: 0.18183838545745634, ic: 0.1813536509309757
Epoch 13: 2022-04-28 03:29:36.558386: train loss: 1.6237779674787858
Eval step 0: eval loss: 0.8236453796965555
Eval: 2022-04-28 03:31:00.130356: total loss: 1.0694755511592948, mse:4.642764565752156, ic :0.1769579549716048, sharpe5:17.138145847320555, irr5:559.2942504882812, ndcg5:0.8392005206689158, pnl5:4.888284683227539 
train 14, step: 0, loss: 4.547735776618565, grad_norm: 2.251234963028052, ic: 0.19615463857085688
train 14, step: 500, loss: 0.8287461773700305, grad_norm: 0.012310133645920925, ic: 0.08716060655697153
train 14, step: 1000, loss: 1.8369985941059226, grad_norm: 1.2889176243474576, ic: 0.4220770872713405
train 14, step: 1500, loss: 1.1299584117751669, grad_norm: 0.11175466442906981, ic: -0.06891238877492324
train 14, step: 2000, loss: 1.1674522877845852, grad_norm: 0.4599045955077152, ic: 0.08249385113361946
Epoch 14: 2022-04-28 03:53:21.055307: train loss: 1.620903541731722
Eval step 0: eval loss: 0.8284714018456928
Eval: 2022-04-28 03:54:43.631373: total loss: 1.0669613166612228, mse:4.593168676162332, ic :0.18607074194853582, sharpe5:17.677643226385115, irr5:581.1639404296875, ndcg5:0.8329937060218614, pnl5:5.536705493927002 
train 15, step: 0, loss: 3.465556222641051, grad_norm: 1.5144770849814275, ic: 0.09286931138292859
train 15, step: 500, loss: 1.2592560347178927, grad_norm: 0.031981179115028, ic: 0.0714687297586542
train 15, step: 1000, loss: 1.3187601229039634, grad_norm: 0.14492075473305355, ic: 0.06666249883276786
train 15, step: 1500, loss: 0.8503685177780511, grad_norm: 0.6175502075148558, ic: 0.058581809185325115
train 15, step: 2000, loss: 1.4568610199023753, grad_norm: 0.89901534224746, ic: 0.051544824563142036
Epoch 15: 2022-04-28 04:17:17.416323: train loss: 1.6193609763180772
Eval step 0: eval loss: 0.8294060308136854
Eval: 2022-04-28 04:18:40.348777: total loss: 1.0667595173344657, mse:4.57774012927297, ic :0.19450596247640325, sharpe5:18.039614943265914, irr5:601.0551147460938, ndcg5:0.8474895902329503, pnl5:5.535275459289551 
train 16, step: 0, loss: 0.7125262504329968, grad_norm: 1.370402477899582, ic: -0.09387804463538307
train 16, step: 500, loss: 1.6126195242191637, grad_norm: 1.019578528817586, ic: 0.17359222577889993
train 16, step: 1000, loss: 0.8773555871212121, grad_norm: 0.021540201688308093, ic: -0.08836083430580381
train 16, step: 1500, loss: 0.8444762654526202, grad_norm: 0.26957571110711664, ic: 0.1425585913697207
train 16, step: 2000, loss: 3.361800681255161, grad_norm: 1.947078868610355, ic: -0.017013484655782042
Epoch 16: 2022-04-28 04:41:31.285706: train loss: 1.6206689659026876
Eval step 0: eval loss: 0.8274657688603134
Eval: 2022-04-28 04:42:56.270805: total loss: 1.0668730619561737, mse:4.591634970786391, ic :0.1896998143911388, sharpe5:18.553451249599455, irr5:594.9976806640625, ndcg5:0.8446703509740814, pnl5:5.003251552581787 
train 17, step: 0, loss: 1.279201291031167, grad_norm: 0.691966906460849, ic: -0.11459729981299081
train 17, step: 500, loss: 1.7424897315379404, grad_norm: 1.852148770224097, ic: 0.18606349391336557
train 17, step: 1000, loss: 1.2862230383831523, grad_norm: 0.18788117251416786, ic: 0.15728500119556538
train 17, step: 1500, loss: 4.516216247244673, grad_norm: 1.8349720487261156, ic: 0.2048876004143421
train 17, step: 2000, loss: 1.2737519500174026, grad_norm: 1.3107814732182745, ic: 0.10489435512106611
Epoch 17: 2022-04-28 05:05:25.137632: train loss: 1.6188099102605142
Eval step 0: eval loss: 0.8307144599166886
Eval: 2022-04-28 05:06:52.804998: total loss: 1.0660316754166728, mse:4.579003876322804, ic :0.19496272218102462, sharpe5:18.28101518511772, irr5:601.5028076171875, ndcg5:0.8380113799479946, pnl5:5.1908159255981445 
train 18, step: 0, loss: 1.4200310755863985, grad_norm: 2.00962948504508, ic: 0.2216240157731147
train 18, step: 500, loss: 1.5126775783141646, grad_norm: 1.1155215509004321, ic: -0.06757169538728558
train 18, step: 1000, loss: 0.6478152424015411, grad_norm: 0.0499225560496157, ic: 0.5796057368638228
train 18, step: 1500, loss: 1.4219286869433354, grad_norm: 0.06915116104611622, ic: 0.2349281949876333
train 18, step: 2000, loss: 0.9138263289336187, grad_norm: 0.012907693234856774, ic: -0.02752290451618434
Epoch 18: 2022-04-28 05:29:58.181067: train loss: 1.6176857736109802
Eval step 0: eval loss: 0.8210033742343914
Eval: 2022-04-28 05:31:28.144472: total loss: 1.0645228817099215, mse:4.590385088515444, ic :0.1909179341682843, sharpe5:17.743369928598405, irr5:583.4658813476562, ndcg5:0.8604796361659208, pnl5:6.389886856079102 
train 19, step: 0, loss: 1.468499465215774, grad_norm: 1.323949241938099, ic: -0.047908257147802925
train 19, step: 500, loss: 0.8620560257523148, grad_norm: 0.036484182049481194, ic: 0.21144900484322954
train 19, step: 1000, loss: 0.9549241699589504, grad_norm: 0.15567839876179948, ic: 0.21136130433498723
train 19, step: 1500, loss: 3.934684576488932, grad_norm: 1.6313597456152533, ic: 0.15163221883658065
train 19, step: 2000, loss: 1.0029007662259615, grad_norm: 0.373127575007215, ic: 0.21794245587981018
Epoch 19: 2022-04-28 05:54:15.160965: train loss: 1.6195645955117708
Eval step 0: eval loss: 0.825085655027496
Eval: 2022-04-28 05:55:40.061876: total loss: 1.0651678108249458, mse:4.5839516292850195, ic :0.1943887071881859, sharpe5:18.229314669370652, irr5:607.265869140625, ndcg5:0.8460501217378587, pnl5:3.4376184940338135 
train 20, step: 0, loss: 2.324801213562253, grad_norm: 4.272179719865189, ic: 0.04031093258236068
train 20, step: 500, loss: 3.2459897017045454, grad_norm: 2.909121129309238, ic: 0.06206492693554808
train 20, step: 1000, loss: 0.9687723159790039, grad_norm: 0.09640099267886522, ic: 0.14632190030514858
train 20, step: 1500, loss: 1.7156049602794794, grad_norm: 3.5210862078375698, ic: 0.26250823071440915
train 20, step: 2000, loss: 1.0438452467054955, grad_norm: 0.13481009884619552, ic: -0.003928606001170199
Epoch 20: 2022-04-28 06:18:14.837006: train loss: 1.6168221868464197
Eval step 0: eval loss: 0.8253414367096944
Eval: 2022-04-28 06:19:38.629533: total loss: 1.0646828365711252, mse:4.581922662676146, ic :0.19365322963795886, sharpe5:18.253057404756547, irr5:597.50830078125, ndcg5:0.8546231939128294, pnl5:7.325346946716309 
train 21, step: 0, loss: 1.0121233232325038, grad_norm: 0.5050928583141052, ic: 0.06828935785398815
train 21, step: 500, loss: 0.7718578777482025, grad_norm: 0.011289402309067241, ic: 0.17382038495199595
train 21, step: 1000, loss: 0.9477267348975466, grad_norm: 1.2790953823053424, ic: 0.17019109650133843
train 21, step: 1500, loss: 0.9847079030552556, grad_norm: 0.38242945901361464, ic: 0.31767251090641524
train 21, step: 2000, loss: 0.9362749710167497, grad_norm: 0.28732552782176274, ic: 0.07970050564645888
Epoch 21: 2022-04-28 06:38:29.252175: train loss: 1.6196439334356438
Eval step 0: eval loss: 0.8219190945238408
Eval: 2022-04-28 06:39:19.250207: total loss: 1.0651201997182917, mse:4.596590199004017, ic :0.18849155580746385, sharpe5:17.41245862841606, irr5:586.65576171875, ndcg5:0.8462134490516927, pnl5:6.469971656799316 
train 22, step: 0, loss: 1.0520020393328477, grad_norm: 0.025954079597777898, ic: 0.17789498055660835
train 22, step: 500, loss: 3.2761371395452237, grad_norm: 2.012449577809846, ic: -0.24700498329579268
train 22, step: 1000, loss: 1.1838021868226156, grad_norm: 0.11003799444975457, ic: 0.47273913417383434
train 22, step: 1500, loss: 0.9693821534207818, grad_norm: 0.251332026272931, ic: 0.07063254627447163
train 22, step: 2000, loss: 1.7464690954506803, grad_norm: 0.7012146197674352, ic: 0.08808324470495649
Epoch 22: 2022-04-28 06:51:54.632504: train loss: 1.6165258765531147
Eval step 0: eval loss: 0.8211728448737157
Eval: 2022-04-28 06:52:41.476378: total loss: 1.0658875925621765, mse:4.59714603236401, ic :0.19065382002362355, sharpe5:18.072586129903794, irr5:598.93359375, ndcg5:0.8497614002301296, pnl5:6.382648468017578 
train 23, step: 0, loss: 0.9822336686104107, grad_norm: 0.038936585705389964, ic: 0.13869323712955273
train 23, step: 500, loss: 1.4240956448685245, grad_norm: 0.38962318986264854, ic: 0.04850919363491439
train 23, step: 1000, loss: 1.6476043701171876, grad_norm: 0.07620951902330124, ic: 0.26004975926290597
train 23, step: 1500, loss: 1.1363129107108596, grad_norm: 2.996306769133799, ic: 0.10227399199293818
train 23, step: 2000, loss: 1.8868649712519245, grad_norm: 2.394662102933326, ic: 0.41071897753113573
Epoch 23: 2022-04-28 07:05:00.342258: train loss: 1.615613730159329
Eval step 0: eval loss: 0.8227409145729057
Eval: 2022-04-28 07:05:51.403951: total loss: 1.0644724526858915, mse:4.580046364881269, ic :0.19724487830459864, sharpe5:18.328440116643904, irr5:612.1588134765625, ndcg5:0.8363808386073724, pnl5:6.204127788543701 
train 24, step: 0, loss: 2.1879622932674287, grad_norm: 0.09119778758942818, ic: 0.156530109803525
train 24, step: 500, loss: 1.2124994300218872, grad_norm: 1.026297557254337, ic: 0.1689252350255816
train 24, step: 1000, loss: 0.9201260398643232, grad_norm: 0.040468678084004686, ic: 0.43377803687257377
train 24, step: 1500, loss: 2.6019139175855317, grad_norm: 7.242371507436701, ic: 0.04961009814087671
train 24, step: 2000, loss: 0.9334455146571923, grad_norm: 0.13685043577546807, ic: 0.11545145229259023
Epoch 24: 2022-04-28 07:18:26.417344: train loss: 1.6156784311440284
Eval step 0: eval loss: 0.8209571958969968
Eval: 2022-04-28 07:19:14.881989: total loss: 1.0649640891300958, mse:4.603010763377608, ic :0.18963798342207905, sharpe5:17.58263444781303, irr5:587.2279052734375, ndcg5:0.8535801008266477, pnl5:4.9453444480896 
train 25, step: 0, loss: 0.8364777436127534, grad_norm: 0.059776325309454974, ic: 0.6070592930478335
train 25, step: 500, loss: 0.8688350804262651, grad_norm: 0.05446829491441657, ic: 0.1949780581914225
train 25, step: 1000, loss: 2.172555544316451, grad_norm: 1.9168563451869491, ic: 0.1888899357733075
train 25, step: 1500, loss: 1.1184805533237483, grad_norm: 0.4185482536175586, ic: 0.5470024568807851
train 25, step: 2000, loss: 1.0097683357911171, grad_norm: 0.6855577450610211, ic: 0.5944283667107051
Epoch 25: 2022-04-28 07:32:05.262398: train loss: 1.6153496886318515
Eval step 0: eval loss: 0.823445037745324
Eval: 2022-04-28 07:32:51.479651: total loss: 1.0650034264063515, mse:4.5802796538904, ic :0.19419523494796087, sharpe5:17.844990727901457, irr5:589.5274658203125, ndcg5:0.8371416722916536, pnl5:5.79065465927124 
train 26, step: 0, loss: 6.697418505391374, grad_norm: 0.9764342790352327, ic: 0.10756581857375662
train 26, step: 500, loss: 3.9286238943999217, grad_norm: 7.536748466201377, ic: 0.3700803347961745
train 26, step: 1000, loss: 1.2680265465561225, grad_norm: 1.9055448670761106, ic: 0.029765252689317966
train 26, step: 1500, loss: 0.8271171917367136, grad_norm: 0.17741290841314075, ic: 0.30868714446568135
train 26, step: 2000, loss: 0.9522788635301928, grad_norm: 1.0087027800393886, ic: 0.14245297734650253
Epoch 26: 2022-04-28 07:45:29.034550: train loss: 1.6156327212466657
Eval step 0: eval loss: 0.8207946069876185
Eval: 2022-04-28 07:46:12.512987: total loss: 1.0644993710156774, mse:4.5860497168498915, ic :0.19354048348115935, sharpe5:18.05945478916168, irr5:601.1006469726562, ndcg5:0.8543508527054074, pnl5:5.536442279815674 
train 27, step: 0, loss: 0.8305464920343137, grad_norm: 0.09184594975187138, ic: 0.10151372476957929
train 27, step: 500, loss: 0.9343984731554259, grad_norm: 1.5049220250748894, ic: 0.28363837845521805
train 27, step: 1000, loss: 0.7500390851580627, grad_norm: 0.6891211778688069, ic: 0.20438205880103927
train 27, step: 1500, loss: 0.6410232228475244, grad_norm: 0.10655680357183459, ic: 0.5070098257180586
train 27, step: 2000, loss: 1.3812128876589789, grad_norm: 0.0684819983636407, ic: 0.058035066917364944
Epoch 27: 2022-04-28 07:58:53.377104: train loss: 1.6174231568361106
Eval step 0: eval loss: 0.822619487412737
Eval: 2022-04-28 07:59:40.454438: total loss: 1.064654367935075, mse:4.588999346805775, ic :0.1938689731191174, sharpe5:17.661447086334228, irr5:595.1525268554688, ndcg5:0.8443125893830884, pnl5:4.575977325439453 
train 28, step: 0, loss: 1.5348397155526061, grad_norm: 2.2200027120281693, ic: 0.24328732312853016
train 28, step: 500, loss: 1.3840614519284518, grad_norm: 4.756212716964473, ic: 0.1841084261658571
train 28, step: 1000, loss: 0.9064511348238482, grad_norm: 0.2613787952592972, ic: 0.5861681926162259
train 28, step: 1500, loss: 1.032713705565268, grad_norm: 0.02840867473294462, ic: 0.02716002741671062
train 28, step: 2000, loss: 1.0509783972991757, grad_norm: 0.6286278909878946, ic: 0.07782739575517436
Epoch 28: 2022-04-28 08:12:11.927583: train loss: 1.6109704007184893
Eval step 0: eval loss: 0.8204904602500988
Eval: 2022-04-28 08:12:56.016557: total loss: 1.0710104459625818, mse:4.641339343247152, ic :0.18453897678782286, sharpe5:17.60251780629158, irr5:591.2507934570312, ndcg5:0.8550821582359702, pnl5:7.626522541046143 
train 29, step: 0, loss: 0.9133894936978771, grad_norm: 0.12458267669019663, ic: 0.07765394709930293
train 29, step: 500, loss: 1.102696327482751, grad_norm: 0.15687679435241256, ic: 0.616075326573197
train 29, step: 1000, loss: 1.0555495805952608, grad_norm: 2.7463586957573947, ic: 0.09548973555220017
train 29, step: 1500, loss: 2.3875298838797816, grad_norm: 1.7935583273074143, ic: -0.03949570385709784
train 29, step: 2000, loss: 4.059853636188271, grad_norm: 160.52642049532403, ic: 0.16359252421381637
Epoch 29: 2022-04-28 08:25:55.639634: train loss: 1.6110981134632139
Eval step 0: eval loss: 0.8292806161090621
Eval: 2022-04-28 08:26:44.692492: total loss: 1.0651551711430896, mse:4.580451828506267, ic :0.19399228201809116, sharpe5:17.910611486434934, irr5:586.771484375, ndcg5:0.8455694506614025, pnl5:7.342273235321045 
train 30, step: 0, loss: 1.0120395964522522, grad_norm: 0.12020664361648167, ic: 0.5091834080810866
train 30, step: 500, loss: 1.4245531365360953, grad_norm: 1.984478442387242, ic: 0.008382424460957289
train 30, step: 1000, loss: 0.9773444898200757, grad_norm: 0.04182784825842669, ic: -0.025808450590160046
train 30, step: 1500, loss: 1.4838498426620246, grad_norm: 5.517564627333239, ic: 0.19531948384562237
train 30, step: 2000, loss: 1.8486806319338178, grad_norm: 1.9849534191571327, ic: 0.047542852950264135
Epoch 30: 2022-04-28 08:39:20.502573: train loss: 1.6114260372000337
Eval step 0: eval loss: 0.8306531031842729
Eval: 2022-04-28 08:40:04.821309: total loss: 1.0687239596706564, mse:4.651561724435874, ic :0.19868499410187493, sharpe5:18.142773817777634, irr5:617.7659301757812, ndcg5:0.8458171562494489, pnl5:4.456900596618652 
train 31, step: 0, loss: 1.054866663701351, grad_norm: 0.45172501371682927, ic: 0.351925719508251
train 31, step: 500, loss: 1.5160381301440329, grad_norm: 1.7969267151827797, ic: 0.01651950095633121
train 31, step: 1000, loss: 4.601631110948477, grad_norm: 18.58425586040662, ic: 0.49703947084732747
train 31, step: 1500, loss: 0.7634113174621339, grad_norm: 0.10458244412281092, ic: 0.7157441297394308
train 31, step: 2000, loss: 1.2335923029659004, grad_norm: 6.502573128789222, ic: 0.21861884427151107
Epoch 31: 2022-04-28 08:52:29.203357: train loss: 1.6038708452028736
Eval step 0: eval loss: 0.8266961727805584
Eval: 2022-04-28 08:53:18.169998: total loss: 1.0654609718280523, mse:4.584308125209398, ic :0.19269235104967788, sharpe5:17.33066632390022, irr5:584.1140747070312, ndcg5:0.8289071730527686, pnl5:4.610098361968994 
train 32, step: 0, loss: 1.1255423232901403, grad_norm: 0.1696993911969607, ic: 0.17901999220270132
train 32, step: 500, loss: 1.5123879259965551, grad_norm: 4.162378585050729, ic: 0.0004318478390015149
train 32, step: 1000, loss: 1.0482126431647867, grad_norm: 0.3175622248579586, ic: 0.507499435189687
train 32, step: 1500, loss: 0.9736013405201183, grad_norm: 3.6555628877966617, ic: 0.056506606261872525
train 32, step: 2000, loss: 0.9522729928959748, grad_norm: 0.1298815969390116, ic: 0.540994422803901
Epoch 32: 2022-04-28 09:05:36.616061: train loss: 1.6055508216341063
Eval step 0: eval loss: 0.8209309552818757
Eval: 2022-04-28 09:06:22.123150: total loss: 1.0629486281145861, mse:4.58821453504961, ic :0.2008442605812478, sharpe5:18.47775070667267, irr5:618.3203735351562, ndcg5:0.832048441191956, pnl5:8.459007263183594 
train 33, step: 0, loss: 1.2499501700020248, grad_norm: 0.19806706793689557, ic: 0.23540422767724967
train 33, step: 500, loss: 0.9780551336301566, grad_norm: 0.04436160429453895, ic: 0.22068089651936562
train 33, step: 1000, loss: 1.0274745863478028, grad_norm: 4.273516625202178, ic: 0.20882112500698252
train 33, step: 1500, loss: 0.917720120431124, grad_norm: 1.2202867014838266, ic: 0.5294949096341
train 33, step: 2000, loss: 0.8105829544188292, grad_norm: 0.09124322897302828, ic: 0.25209182989628454
Epoch 33: 2022-04-28 09:18:49.027442: train loss: 1.609136268581695
Eval step 0: eval loss: 0.8257890064171166
Eval: 2022-04-28 09:19:38.660735: total loss: 1.0635954755468262, mse:4.573496783475896, ic :0.20195882137955884, sharpe5:18.35038370132446, irr5:618.22412109375, ndcg5:0.8517453971531788, pnl5:6.124120235443115 
train 34, step: 0, loss: 0.9991919301103834, grad_norm: 0.7394675354910895, ic: 0.6096538649699936
train 34, step: 500, loss: 0.7763110986178804, grad_norm: 0.12224844604564816, ic: 0.28117666197754143
train 34, step: 1000, loss: 3.188729703701037, grad_norm: 2.228608688844612, ic: 0.32684840128285025
train 34, step: 1500, loss: 0.8172669984728843, grad_norm: 0.8287132039913674, ic: 0.687102735946213
train 34, step: 2000, loss: 5.872441723954299, grad_norm: 237.1139334866158, ic: 0.41999318711986244
Epoch 34: 2022-04-28 09:32:04.894313: train loss: 1.6114117373621453
Eval step 0: eval loss: 0.8198911065924657
Eval: 2022-04-28 09:32:50.751922: total loss: 1.0656407193309907, mse:4.604976584390892, ic :0.195536070785506, sharpe5:18.145486732721327, irr5:609.3023071289062, ndcg5:0.8484393873114083, pnl5:6.37283182144165 
train 35, step: 0, loss: 1.1781152343749999, grad_norm: 0.9247818828068164, ic: 0.5595995129849815
train 35, step: 500, loss: 1.1724786641455438, grad_norm: 1.5459043637232714, ic: 0.007584610783010447
train 35, step: 1000, loss: 1.638308774134156, grad_norm: 5.100304897954166, ic: 0.11096173067846057
train 35, step: 1500, loss: 1.630078125, grad_norm: 2.4620265667247097, ic: 0.07163352648686723
train 35, step: 2000, loss: 0.790792862999248, grad_norm: 0.30690643184029703, ic: 0.5451553837838152
Epoch 35: 2022-04-28 09:45:31.155939: train loss: 1.609125727081417
Eval step 0: eval loss: 0.8257852118183614
Eval: 2022-04-28 09:46:20.098784: total loss: 1.0642251096048536, mse:4.580498816063281, ic :0.1969906659507406, sharpe5:18.021699110269545, irr5:603.5160522460938, ndcg5:0.8487219706048087, pnl5:6.0137176513671875 
train 36, step: 0, loss: 1.8412442050137363, grad_norm: 5.745549964626509, ic: 0.09190594061905367
train 36, step: 500, loss: 0.8477672579910364, grad_norm: 0.10836011931913823, ic: 0.051267048556562375
train 36, step: 1000, loss: 1.6571608664772726, grad_norm: 2.4835757514373933, ic: 0.2595762268837838
train 36, step: 1500, loss: 0.7631371134360786, grad_norm: 0.07009345849462095, ic: 0.3903978014347015
train 36, step: 2000, loss: 1.0857375722919975, grad_norm: 0.5715955702422664, ic: 0.7765131593515198
Epoch 36: 2022-04-28 09:58:54.419707: train loss: 1.6092393015034014
Eval step 0: eval loss: 0.8247247822543466
Eval: 2022-04-28 09:59:39.597583: total loss: 1.0634515221951804, mse:4.576588506381583, ic :0.19939944582656613, sharpe5:18.547385973930357, irr5:629.228515625, ndcg5:0.8629558305330919, pnl5:10.470444679260254 
train 37, step: 0, loss: 2.0205440784121365, grad_norm: 2.467117204670833, ic: 0.18168125588975154
train 37, step: 500, loss: 2.3596008201213294, grad_norm: 4.502876123163077, ic: 0.004485516673543546
train 37, step: 1000, loss: 1.0577773467227929, grad_norm: 0.40208189544085754, ic: 0.08989990242594197
train 37, step: 1500, loss: 2.0199626162063384, grad_norm: 5.120615229067391, ic: 0.6150550354506326
train 37, step: 2000, loss: 1.300423251434022, grad_norm: 0.2833712085354355, ic: 0.2835936470216619
Epoch 37: 2022-04-28 10:12:24.242976: train loss: 1.6033741742148235
Eval step 0: eval loss: 0.823075611046167
Eval: 2022-04-28 10:13:12.660837: total loss: 1.0654556671266067, mse:4.594084052754136, ic :0.1946879598896167, sharpe5:19.154051645994187, irr5:624.260986328125, ndcg5:0.854189485622774, pnl5:9.100626945495605 
train 38, step: 0, loss: 1.3387359060892245, grad_norm: 0.6230666374022182, ic: -0.08095480473473647
train 38, step: 500, loss: 0.9140799816743826, grad_norm: 0.1668722620623393, ic: 0.2753979751329161
train 38, step: 1000, loss: 0.9064855522789032, grad_norm: 0.3984484694429449, ic: 0.1467523203981672
train 38, step: 1500, loss: 0.9532339085931568, grad_norm: 0.12868125819622994, ic: 0.19493041486486345
train 38, step: 2000, loss: 2.326626596133875, grad_norm: 18.852096126884344, ic: 0.07463289150580459
Epoch 38: 2022-04-28 10:24:16.091088: train loss: 1.6077647400092447
Eval step 0: eval loss: 0.8218632045862421
Eval: 2022-04-28 10:24:49.772916: total loss: 1.0628216547326095, mse:4.5791717349299885, ic :0.2026547728133573, sharpe5:18.99091351389885, irr5:627.2026977539062, ndcg5:0.85407420133043, pnl5:9.472993850708008 
train 39, step: 0, loss: 0.968063494481078, grad_norm: 0.013315934828280458, ic: 0.09699579650861354
train 39, step: 500, loss: 0.8987240509103575, grad_norm: 0.9856039964967582, ic: 0.19590370036227692
train 39, step: 1000, loss: 0.939550930002856, grad_norm: 0.1725799872344458, ic: 0.16118058992646905
train 39, step: 1500, loss: 2.071895738411252, grad_norm: 0.5122575306678356, ic: 0.19537677091092948
train 39, step: 2000, loss: 0.6098093813252863, grad_norm: 0.1630508320528608, ic: 0.18351465194157324
Epoch 39: 2022-04-28 10:32:27.608024: train loss: 1.5999657266726992
Eval step 0: eval loss: 0.8271310723870521
Eval: 2022-04-28 10:32:53.419862: total loss: 1.0650235027141868, mse:4.603105022623995, ic :0.1899504178958011, sharpe5:17.95264274954796, irr5:603.7228393554688, ndcg5:0.852212497031313, pnl5:5.88012170791626 

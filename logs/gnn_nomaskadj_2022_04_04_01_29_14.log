Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='AdjTimeDataset', dout=0.3, epochs=40, gnn_layers=2, gpu=0, hidden_dim=128, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=3, mask_adj=False, mask_type='soft', model_type='GNNModel', normalize_adj=False, num_days=1, num_heads=1, print_inteval=500, relation_num=1, seed=10086, shuffle=True, side_info=False, sparse_adj_path=None, stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=False)
91965
GNNModel(
  (fc1): Linear(in_features=9, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
  (fc4): Linear(in_features=128, out_features=1, bias=True)
  (gnns): ModuleList(
    (0): GraphConv(128, 128)
    (1): GraphConv(128, 128)
  )
  (dropout): Dropout(p=0.3, inplace=False)
  (relu): LeakyReLU(negative_slope=0.01)
)
train 0, step: 0, loss: 2.0733489145874504, grad_norm: 0.4698135373283054, ic: 0.07554031498435583
train 0, step: 500, loss: 1.3655466306742798, grad_norm: 0.854948366385428, ic: -0.06311060091447826
train 0, step: 1000, loss: 1.505978248708572, grad_norm: 0.03238321741408945, ic: 0.1660913601614284
train 0, step: 1500, loss: 1.1874196831764028, grad_norm: 0.09313656264559277, ic: 0.03482176076333081
train 0, step: 2000, loss: 1.563946049387862, grad_norm: 0.05358140838556175, ic: -0.01552243715116544
Epoch 0: 2022-04-04 01:29:41.780546: train loss: 1.6475596320682724
Eval step 0: eval loss: 1.012454257380529
Eval: 2022-04-04 01:29:43.795379: total loss: 1.092251453640997, mse:4.889586517146819, ic :0.01657117548758459, sharpe5:5.628015359938145, irr5:151.8928680419922, ndcg5:0.8462615681434849, pnl5:2.3766205310821533 
train 1, step: 0, loss: 0.6365147958887686, grad_norm: 0.05024702644012698, ic: 0.06943159512205234
train 1, step: 500, loss: 1.2660734856735927, grad_norm: 0.2802818424574018, ic: 0.2272756784945188
train 1, step: 1000, loss: 0.8821403364087576, grad_norm: 0.06373510042768704, ic: 0.0736121938823897
train 1, step: 1500, loss: 1.8526064244712273, grad_norm: 0.5243728385198712, ic: 0.0784785680459744
train 1, step: 2000, loss: 1.3707639919123278, grad_norm: 0.22002823960086507, ic: 0.1450749202731625
Epoch 1: 2022-04-04 01:30:05.695082: train loss: 1.6460314507596296
Eval step 0: eval loss: 1.0050565650301144
Eval: 2022-04-04 01:30:07.909582: total loss: 1.0892223086659631, mse:4.878896022995382, ic :0.04950787568230149, sharpe5:1.6813724306970834, irr5:22.10674285888672, ndcg5:0.8421522898301295, pnl5:1.2542479038238525 
train 2, step: 0, loss: 1.3187509383083889, grad_norm: 0.49111498550161153, ic: 0.07736288651521397
train 2, step: 500, loss: 0.9585324925609352, grad_norm: 0.3634176098855157, ic: 0.08626941027320334
train 2, step: 1000, loss: 3.0688059477863168, grad_norm: 1.531103108218817, ic: 0.14273990552971297
train 2, step: 1500, loss: 2.278829890711737, grad_norm: 0.8761588459014734, ic: 0.10266948261391873
train 2, step: 2000, loss: 1.4616785057236306, grad_norm: 0.2847347714788946, ic: -0.10454317995885219
Epoch 2: 2022-04-04 01:30:29.858991: train loss: 1.6444680429573566
Eval step 0: eval loss: 0.9981923437294299
Eval: 2022-04-04 01:30:32.115566: total loss: 1.0892248361971417, mse:4.881206814832498, ic :0.04882070468579843, sharpe5:5.690436524748802, irr5:129.10536193847656, ndcg5:0.8400933761888061, pnl5:2.358086347579956 
train 3, step: 0, loss: 1.8287332034238715, grad_norm: 0.06146997238571362, ic: -0.11588017992909459
train 3, step: 500, loss: 0.7821977425361821, grad_norm: 0.023105671839166, ic: 0.07732355686056666
train 3, step: 1000, loss: 1.397147122039098, grad_norm: 0.4085674132815841, ic: 0.2271464325485384
train 3, step: 1500, loss: 2.628310531769625, grad_norm: 0.4442437098209155, ic: -0.06491703806145267
train 3, step: 2000, loss: 1.3596562241062973, grad_norm: 0.17050527815656377, ic: 0.0736795261105254
Epoch 3: 2022-04-04 01:30:54.023004: train loss: 1.6446151362563013
Eval step 0: eval loss: 1.006316286943786
Eval: 2022-04-04 01:30:56.213798: total loss: 1.092472672681565, mse:4.882562638372252, ic :0.05214983679412723, sharpe5:1.9647623149305582, irr5:21.460134506225586, ndcg5:0.8522564553689538, pnl5:1.3272511959075928 
train 4, step: 0, loss: 1.150323272658628, grad_norm: 0.1483675287082997, ic: 0.08773080559302429
train 4, step: 500, loss: 0.98618136885436, grad_norm: 0.009185875973424105, ic: 0.18483204115054785
train 4, step: 1000, loss: 1.3319061069794051, grad_norm: 0.06495407416281211, ic: 0.07053500300961087
train 4, step: 1500, loss: 1.0763167943709935, grad_norm: 0.11441219284297732, ic: 0.17403173314880802
train 4, step: 2000, loss: 4.181251844020457, grad_norm: 0.8953077230994713, ic: -0.029766492440171592
Epoch 4: 2022-04-04 01:31:18.861048: train loss: 1.6442765820795853
Eval step 0: eval loss: 1.003555466590146
Eval: 2022-04-04 01:31:21.092535: total loss: 1.0916308868628695, mse:4.881523329480685, ic :0.05019039003076186, sharpe5:5.027539825737476, irr5:70.25437927246094, ndcg5:0.8478080383915287, pnl5:1.5872248411178589 
train 5, step: 0, loss: 0.9829531086371859, grad_norm: 0.14040990122407676, ic: -0.12097309275481205
train 5, step: 500, loss: 0.7894257218540186, grad_norm: 0.02670686173531293, ic: 0.14929423909333436
train 5, step: 1000, loss: 1.1185172855891783, grad_norm: 0.04083996579978478, ic: -0.13535775925243093
train 5, step: 1500, loss: 1.7623882510797764, grad_norm: 0.34358992062666516, ic: -0.07772726375810532
train 5, step: 2000, loss: 2.1660274236175647, grad_norm: 0.8724587536177633, ic: 0.04462566406773947
Epoch 5: 2022-04-04 01:31:43.057039: train loss: 1.6443532875718339
Eval step 0: eval loss: 1.0033205182003686
Eval: 2022-04-04 01:31:45.315429: total loss: 1.0907248918422863, mse:4.90908497883905, ic :0.03999988354213838, sharpe5:2.6732778185606003, irr5:31.543079376220703, ndcg5:0.8590041737502084, pnl5:1.0435965061187744 
train 6, step: 0, loss: 0.7809413567868754, grad_norm: 0.05971904072172993, ic: -0.08635505922285518
train 6, step: 500, loss: 1.4275460048028599, grad_norm: 0.25590866852324007, ic: 0.062817321301234
train 6, step: 1000, loss: 1.2274192579937646, grad_norm: 0.18168899223820043, ic: 0.18930479391105512
train 6, step: 1500, loss: 1.0667606684846698, grad_norm: 0.31669843675689524, ic: 0.056197037517332175
train 6, step: 2000, loss: 2.3009298920826513, grad_norm: 1.159214436661697, ic: 0.09995856026700325
Epoch 6: 2022-04-04 01:32:07.825656: train loss: 1.6440371172324286
Eval step 0: eval loss: 1.0010223308320167
Eval: 2022-04-04 01:32:10.407414: total loss: 1.0896037537043266, mse:4.872722102786808, ic :0.06180530774718577, sharpe5:7.745204262435436, irr5:220.87294006347656, ndcg5:0.8628248837770577, pnl5:2.881392478942871 
train 7, step: 0, loss: 1.4533971946754016, grad_norm: 0.5433349798593532, ic: 0.19806588563750427
train 7, step: 500, loss: 1.319039109688524, grad_norm: 0.02350926632565672, ic: 0.19235378909418058
train 7, step: 1000, loss: 0.6427171731028337, grad_norm: 0.019120723045990072, ic: 0.293026664695497
train 7, step: 1500, loss: 1.0044504606257194, grad_norm: 0.13142121170867124, ic: 0.0995982952492438
train 7, step: 2000, loss: 1.576074373514263, grad_norm: 0.5697471368058288, ic: 0.419939821360797
Epoch 7: 2022-04-04 01:32:32.998067: train loss: 1.6403308130445984
Eval step 0: eval loss: 0.9959916711920747
Eval: 2022-04-04 01:32:35.405161: total loss: 1.0854326242674164, mse:4.729410551472041, ic :0.11940882940725711, sharpe5:7.766146111786365, irr5:218.9552764892578, ndcg5:0.8547945156827955, pnl5:3.7831122875213623 
train 8, step: 0, loss: 1.2032674153645833, grad_norm: 0.08750457395054069, ic: 0.05673790560073906
train 8, step: 500, loss: 5.220218670405564, grad_norm: 8.779790938004123, ic: 0.023141792025452704
train 8, step: 1000, loss: 1.8807980042223096, grad_norm: 0.5495501297151739, ic: 0.07496999756032084
train 8, step: 1500, loss: 1.0769512469951923, grad_norm: 0.322214512067561, ic: 0.6395434894288081
train 8, step: 2000, loss: 1.1276219685872395, grad_norm: 0.5411331493829932, ic: 0.006901992967793119
Epoch 8: 2022-04-04 01:32:58.685929: train loss: 1.6372498777616369
Eval step 0: eval loss: 1.0009837620129014
Eval: 2022-04-04 01:33:00.993474: total loss: 1.0876419829268995, mse:4.717435110777205, ic :0.1237541825216366, sharpe5:8.064321287870406, irr5:229.1262969970703, ndcg5:0.8435076030497695, pnl5:3.3351612091064453 
train 9, step: 0, loss: 1.1186088404312189, grad_norm: 0.027686923845297227, ic: 0.4434560714307107
train 9, step: 500, loss: 3.192515101788432, grad_norm: 0.9940745780699536, ic: 0.21252912303056373
train 9, step: 1000, loss: 0.8662661893720635, grad_norm: 0.10086731849568258, ic: 0.2574047566897761
train 9, step: 1500, loss: 2.1666008502583063, grad_norm: 1.184842807793454, ic: -0.02748552600267862
train 9, step: 2000, loss: 0.6046933009810189, grad_norm: 0.00725679718508986, ic: 0.07160582424815935
Epoch 9: 2022-04-04 01:33:23.649130: train loss: 1.634474486459072
Eval step 0: eval loss: 1.002467890172459
Eval: 2022-04-04 01:33:25.908869: total loss: 1.0844468543884838, mse:4.71540345247819, ic :0.13953488221545302, sharpe5:13.224379157423973, irr5:398.5719909667969, ndcg5:0.8541813936537034, pnl5:4.23874044418335 
train 10, step: 0, loss: 1.291567776461559, grad_norm: 0.061947548866436684, ic: 0.4045596989916518
train 10, step: 500, loss: 0.899436273929113, grad_norm: 0.00650944870331608, ic: 0.09160446316173147
train 10, step: 1000, loss: 1.5256002078346171, grad_norm: 0.5434468229301502, ic: 0.051078834055567415
train 10, step: 1500, loss: 3.063556854224036, grad_norm: 1.1209127408324555, ic: 0.10566231925574947
train 10, step: 2000, loss: 1.374192443662139, grad_norm: 0.2495775684501331, ic: 0.17706281146737662
Epoch 10: 2022-04-04 01:33:49.014846: train loss: 1.630701370111006
Eval step 0: eval loss: 1.0076026213426474
Eval: 2022-04-04 01:33:51.384333: total loss: 1.0845426381698922, mse:4.694879605838801, ic :0.1495669185251548, sharpe5:14.5900357568264, irr5:440.3070068359375, ndcg5:0.8302387615808225, pnl5:5.49606466293335 
train 11, step: 0, loss: 4.707873811938038, grad_norm: 1.209305932023172, ic: 0.4317971039741004
train 11, step: 500, loss: 0.9878895374303955, grad_norm: 0.059517602782871035, ic: 0.04058535027773384
train 11, step: 1000, loss: 1.035472832046148, grad_norm: 0.3624125400574825, ic: 0.058996305091432395
train 11, step: 1500, loss: 0.692079405161022, grad_norm: 0.0021991616265961333, ic: 0.09783577620027767
train 11, step: 2000, loss: 1.126560635725528, grad_norm: 0.05682360343773308, ic: -0.17908503179000027
Epoch 11: 2022-04-04 01:34:14.205240: train loss: 1.6294625862003485
Eval step 0: eval loss: 1.0007783187697472
Eval: 2022-04-04 01:34:16.564740: total loss: 1.0820535630909185, mse:4.701861157704044, ic :0.15238983820939347, sharpe5:14.569185662269591, irr5:466.7603759765625, ndcg5:0.8511311476207708, pnl5:4.829416751861572 
train 12, step: 0, loss: 1.374721976740732, grad_norm: 0.32875253439426827, ic: 0.1657700671548587
train 12, step: 500, loss: 0.8231443000197316, grad_norm: 0.4348579767931308, ic: 0.012272412744373436
train 12, step: 1000, loss: 1.182468706196405, grad_norm: 0.41825967828513494, ic: 0.6136926446836072
train 12, step: 1500, loss: 1.0875451324182912, grad_norm: 0.29605208012620665, ic: 0.061864722720856635
train 12, step: 2000, loss: 1.110922204442771, grad_norm: 0.07791876110220498, ic: 0.1311355266966
Epoch 12: 2022-04-04 01:34:39.884065: train loss: 1.628430082717398
Eval step 0: eval loss: 1.0055778226204581
Eval: 2022-04-04 01:34:42.198068: total loss: 1.084583911850138, mse:4.710501926273468, ic :0.15626647011212438, sharpe5:14.947100011110305, irr5:460.0808410644531, ndcg5:0.8635339899028002, pnl5:6.613853931427002 
train 13, step: 0, loss: 1.0785581677037095, grad_norm: 0.05313488744176796, ic: 0.44071611359807933
train 13, step: 500, loss: 1.1462969830927958, grad_norm: 0.01781848061441042, ic: -0.14533013920289806
train 13, step: 1000, loss: 1.3748453712013178, grad_norm: 0.5734544056440354, ic: 0.1323317600559189
train 13, step: 1500, loss: 0.7754465506682838, grad_norm: 0.015374717427957188, ic: 0.00833979819719655
train 13, step: 2000, loss: 1.0365449638776882, grad_norm: 0.02944870620439686, ic: 0.047343827655779956
Epoch 13: 2022-04-04 01:35:04.797430: train loss: 1.6287760180030049
Eval step 0: eval loss: 0.9975031832132042
Eval: 2022-04-04 01:35:07.140778: total loss: 1.0866810143109726, mse:4.7447358854707495, ic :0.1182184969585252, sharpe5:7.502622086405753, irr5:212.2588348388672, ndcg5:0.8610165053801206, pnl5:3.364952564239502 
train 14, step: 0, loss: 1.7606689970372087, grad_norm: 0.5848764009086929, ic: 0.156770958234471
train 14, step: 500, loss: 1.2705398324129775, grad_norm: 0.166675706709982, ic: 0.21603409142188995
train 14, step: 1000, loss: 1.063447911286157, grad_norm: 0.16425509168272498, ic: 0.1529402869828743
train 14, step: 1500, loss: 0.9736083796429945, grad_norm: 0.11439855613536001, ic: 0.18476817243548022
train 14, step: 2000, loss: 2.3096796381142948, grad_norm: 0.6811045967343505, ic: -0.06724028283085079
Epoch 14: 2022-04-04 01:35:30.358330: train loss: 1.6295688224609068
Eval step 0: eval loss: 1.0084207302774486
Eval: 2022-04-04 01:35:32.572565: total loss: 1.0847518911543699, mse:4.685823068101317, ic :0.1608534488438744, sharpe5:14.562674855589865, irr5:466.7519226074219, ndcg5:0.8469518950645157, pnl5:5.208624839782715 
train 15, step: 0, loss: 0.9782763554968077, grad_norm: 0.1934994169431167, ic: 0.12363895904431753
train 15, step: 500, loss: 1.231426568319089, grad_norm: 0.03414902965513385, ic: 0.078354179807209
train 15, step: 1000, loss: 1.7590688802083334, grad_norm: 0.06113823090280675, ic: -0.06044825416266601
train 15, step: 1500, loss: 5.381346523346868, grad_norm: 0.8949094052773638, ic: 0.024446551501655138
train 15, step: 2000, loss: 0.9317005111001523, grad_norm: 0.02368296160149848, ic: 0.013484881644030687
Epoch 15: 2022-04-04 01:35:55.145296: train loss: 1.6287430485711079
Eval step 0: eval loss: 1.008462384602093
Eval: 2022-04-04 01:35:57.705707: total loss: 1.083158001864528, mse:4.679896852430391, ic :0.16678015323345446, sharpe5:15.397667130231856, irr5:509.4557800292969, ndcg5:0.8529124517351436, pnl5:6.785895824432373 
train 16, step: 0, loss: 6.36116187590169, grad_norm: 2.411098891097833, ic: 0.16948010769801541
train 16, step: 500, loss: 1.3510248093377977, grad_norm: 0.8387074522213317, ic: -0.01178607226200834
train 16, step: 1000, loss: 0.8377418979149879, grad_norm: 0.2985963409704319, ic: -0.02910176158536467
train 16, step: 1500, loss: 1.2377810138915455, grad_norm: 0.3772534914116772, ic: 0.1420245253392225
train 16, step: 2000, loss: 0.9561160569936854, grad_norm: 0.30922567934500783, ic: 0.5434454833156556
Epoch 16: 2022-04-04 01:36:20.440938: train loss: 1.6260772382058766
Eval step 0: eval loss: 0.9966915024149222
Eval: 2022-04-04 01:36:22.703937: total loss: 1.0820687008100665, mse:4.719591826246794, ic :0.15995322274185744, sharpe5:14.729321426153183, irr5:482.1119384765625, ndcg5:0.8421594994299929, pnl5:5.1327104568481445 
train 17, step: 0, loss: 1.1846004556293137, grad_norm: 0.010511262143526663, ic: 0.0996216901516384
train 17, step: 500, loss: 1.042240410411144, grad_norm: 0.04037466172530402, ic: -0.021504280922071482
train 17, step: 1000, loss: 3.3814749639026402, grad_norm: 1.5042371810665722, ic: -0.01237979037190277
train 17, step: 1500, loss: 0.8850672453352549, grad_norm: 0.012649610205066743, ic: 0.05234326329580144
train 17, step: 2000, loss: 1.0140972367869128, grad_norm: 0.5962052103572569, ic: 0.5687088541756582
Epoch 17: 2022-04-04 01:36:45.744903: train loss: 1.627769947381082
Eval step 0: eval loss: 1.0079156073097681
Eval: 2022-04-04 01:36:48.231390: total loss: 1.0858101652784204, mse:4.716401687139393, ic :0.14897432563042678, sharpe5:14.081440824866295, irr5:434.6802673339844, ndcg5:0.8468339543315168, pnl5:5.084360122680664 
train 18, step: 0, loss: 0.8516288702260425, grad_norm: 0.0066151253858888395, ic: 0.038588938483568924
train 18, step: 500, loss: 2.524011240499178, grad_norm: 1.1586803594758446, ic: 0.07937217474797909
train 18, step: 1000, loss: 1.3699905505283274, grad_norm: 0.564963429248316, ic: 0.533602234526089
train 18, step: 1500, loss: 1.6855807906117446, grad_norm: 2.2864138785100323, ic: 0.3400567040718403
train 18, step: 2000, loss: 1.2385321605556758, grad_norm: 0.3505761729412232, ic: 0.22713059815261105
Epoch 18: 2022-04-04 01:37:11.088912: train loss: 1.6267662111174732
Eval step 0: eval loss: 1.002900568041568
Eval: 2022-04-04 01:37:13.376110: total loss: 1.0821106765343547, mse:4.68546921391501, ic :0.17109198630484473, sharpe5:15.453502287268638, irr5:528.9528198242188, ndcg5:0.841444324742431, pnl5:6.2785491943359375 
train 19, step: 0, loss: 2.2205775989862278, grad_norm: 0.737254745590652, ic: 0.24519593567587963
train 19, step: 500, loss: 1.0216354015261628, grad_norm: 0.061910058294110185, ic: 0.06002459260013863
train 19, step: 1000, loss: 0.9785682512256921, grad_norm: 0.4572286082629617, ic: 0.5615982813749917
train 19, step: 1500, loss: 1.5733429708598572, grad_norm: 0.08122484661205806, ic: 0.15657562564199812
train 19, step: 2000, loss: 1.6355733849332947, grad_norm: 2.206621076194967, ic: 0.6334681606875427
Epoch 19: 2022-04-04 01:37:36.165617: train loss: 1.6259111557675976
Eval step 0: eval loss: 0.9988789329910478
Eval: 2022-04-04 01:37:38.530767: total loss: 1.0802757283560092, mse:4.69738843882148, ic :0.1660298309750664, sharpe5:14.378848382234573, irr5:465.0487060546875, ndcg5:0.8458685458405162, pnl5:5.769900321960449 
train 20, step: 0, loss: 1.2605300104231607, grad_norm: 0.38101535261296493, ic: 0.4630343291250682
train 20, step: 500, loss: 1.2075877912426352, grad_norm: 0.42811320574398065, ic: 0.027535019352934113
train 20, step: 1000, loss: 1.556174315113817, grad_norm: 0.5030357446907565, ic: 0.19044894123058184
train 20, step: 1500, loss: 0.900655337573575, grad_norm: 0.7965079624895144, ic: 0.5693660153401643
train 20, step: 2000, loss: 1.3750391769717563, grad_norm: 0.24029474120300998, ic: -0.048165271884293634
Epoch 20: 2022-04-04 01:38:01.994385: train loss: 1.6251357019950587
Eval step 0: eval loss: 1.0045653911186807
Eval: 2022-04-04 01:38:04.304019: total loss: 1.080055210769332, mse:4.678749577968163, ic :0.16941865034320602, sharpe5:14.94051258444786, irr5:494.4095458984375, ndcg5:0.8533561846418188, pnl5:6.343118190765381 
train 21, step: 0, loss: 1.3914826951986152, grad_norm: 0.2997514268398959, ic: 0.30918049407733145
train 21, step: 500, loss: 1.1060085865770848, grad_norm: 0.10404691471483654, ic: 0.04303881915243897
train 21, step: 1000, loss: 0.9046186511400985, grad_norm: 0.7372491610846177, ic: 0.06781078994236459
train 21, step: 1500, loss: 0.7357648376835754, grad_norm: 0.17418911944626, ic: 0.6329647279887497
train 21, step: 2000, loss: 1.1375192874678781, grad_norm: 0.16393384793365823, ic: 0.2772596170005478
Epoch 21: 2022-04-04 01:38:26.990483: train loss: 1.6249403176324186
Eval step 0: eval loss: 1.0060473979931872
Eval: 2022-04-04 01:38:29.477263: total loss: 1.08114473017162, mse:4.691596345068738, ic :0.15625315131842915, sharpe5:12.890062524676322, irr5:411.37677001953125, ndcg5:0.8514678840063958, pnl5:4.406192302703857 
train 22, step: 0, loss: 1.043141192306404, grad_norm: 0.4767880082030351, ic: 0.08152924852183212
train 22, step: 500, loss: 1.027366241695374, grad_norm: 0.0019080811546695975, ic: -0.008322183237861613
train 22, step: 1000, loss: 0.9103895565345256, grad_norm: 0.017188421835884374, ic: 0.14152524740397043
train 22, step: 1500, loss: 1.0044289467119354, grad_norm: 0.055859768238463586, ic: 0.25480993792355155
train 22, step: 2000, loss: 1.0526398414789244, grad_norm: 0.11444965496532199, ic: 0.13544042109592058
Epoch 22: 2022-04-04 01:38:52.130013: train loss: 1.624060749511721
Eval step 0: eval loss: 1.0055370682349263
Eval: 2022-04-04 01:38:54.440755: total loss: 1.0810082544683173, mse:4.678886203260638, ic :0.1664442686951083, sharpe5:14.288337480425835, irr5:459.9820251464844, ndcg5:0.8411596301551095, pnl5:4.14499568939209 
train 23, step: 0, loss: 1.291622335532771, grad_norm: 1.0897577586559444, ic: 0.0042573823707043185
train 23, step: 500, loss: 0.9043604253412604, grad_norm: 0.13906639213693983, ic: 0.5939533154566463
train 23, step: 1000, loss: 2.2804649582755547, grad_norm: 0.9207569173980409, ic: 0.0989643486028185
train 23, step: 1500, loss: 0.7748542168121736, grad_norm: 0.33100825471967565, ic: 0.7157850677054578
train 23, step: 2000, loss: 1.4766455410289117, grad_norm: 0.38769293435438373, ic: 0.4080705014487107
Epoch 23: 2022-04-04 01:39:17.501427: train loss: 1.6238818298327606
Eval step 0: eval loss: 1.007184149655246
Eval: 2022-04-04 01:39:19.879632: total loss: 1.0846033318405743, mse:4.689521762788606, ic :0.1591269556224454, sharpe5:14.192895467877387, irr5:449.33648681640625, ndcg5:0.8396894998701204, pnl5:5.589457988739014 
train 24, step: 0, loss: 1.194551204350849, grad_norm: 0.49353720745654533, ic: 0.32838569731531175
train 24, step: 500, loss: 1.2429618224399315, grad_norm: 0.35573588025053465, ic: 0.02246806156049796
train 24, step: 1000, loss: 1.0362373910299163, grad_norm: 0.2781486908247589, ic: 0.11322343563479877
train 24, step: 1500, loss: 1.1979526790108268, grad_norm: 0.09186190851718345, ic: 0.06662577371419345
train 24, step: 2000, loss: 1.3529962315692468, grad_norm: 0.5399555935545444, ic: 0.45807994214117126
Epoch 24: 2022-04-04 01:39:42.780746: train loss: 1.624621200463072
Eval step 0: eval loss: 1.0121153660232358
Eval: 2022-04-04 01:39:45.177359: total loss: 1.0822853410578335, mse:4.688483268564009, ic :0.16600246308559913, sharpe5:15.26533874452114, irr5:507.755859375, ndcg5:0.8350202909945049, pnl5:6.32136344909668 
train 25, step: 0, loss: 1.2888342271237172, grad_norm: 0.4306393448648232, ic: 0.2072332528834936
train 25, step: 500, loss: 1.4737720241794339, grad_norm: 1.1683797335893986, ic: 0.0970489278071506
train 25, step: 1000, loss: 1.36264050370184, grad_norm: 0.24155464296667706, ic: 0.28006214622667547
train 25, step: 1500, loss: 2.875889331427015, grad_norm: 1.2680396119017547, ic: 0.21136561902971915
train 25, step: 2000, loss: 1.1980217076555082, grad_norm: 0.21191194205952057, ic: 0.14901020485526345
Epoch 25: 2022-04-04 01:40:08.337323: train loss: 1.6249282565985292
Eval step 0: eval loss: 1.0023575833497893
Eval: 2022-04-04 01:40:10.646977: total loss: 1.079312856514086, mse:4.674825478815776, ic :0.17394283286111142, sharpe5:15.032993849515915, irr5:504.69183349609375, ndcg5:0.8591219467753876, pnl5:4.562286853790283 
train 26, step: 0, loss: 1.6102089843749998, grad_norm: 0.43906152800655485, ic: 0.23571421492943978
train 26, step: 500, loss: 1.0315779950056492, grad_norm: 0.303147755684189, ic: -0.0206502570802944
train 26, step: 1000, loss: 1.8223725508690676, grad_norm: 0.7335284454436343, ic: 0.19155126109875417
train 26, step: 1500, loss: 0.924935145307545, grad_norm: 0.0068295593322117544, ic: -0.06616125819727467
train 26, step: 2000, loss: 0.996137772207185, grad_norm: 0.1576287856707429, ic: 0.1440051751495124
Epoch 26: 2022-04-04 01:40:33.223760: train loss: 1.6248755883557158
Eval step 0: eval loss: 0.9996783360485781
Eval: 2022-04-04 01:40:35.535640: total loss: 1.081094972664903, mse:4.693498790903989, ic :0.16199343522631618, sharpe5:14.272420388460159, irr5:455.6707458496094, ndcg5:0.835787643259098, pnl5:5.601189136505127 
train 27, step: 0, loss: 1.6338067112198795, grad_norm: 0.4358315262254655, ic: 0.6810572954350682
train 27, step: 500, loss: 1.4991779713015163, grad_norm: 0.3433578892454634, ic: 0.0911889395416828
train 27, step: 1000, loss: 2.586876881798757, grad_norm: 0.9220992204370935, ic: 0.40708174155725046
train 27, step: 1500, loss: 0.870376237476145, grad_norm: 0.7229474414169057, ic: 0.5510593715695673
train 27, step: 2000, loss: 1.3297295401905722, grad_norm: 1.6995351345216692, ic: 0.012183549382044991
Epoch 27: 2022-04-04 01:40:58.514789: train loss: 1.623554050900096
Eval step 0: eval loss: 1.0055256904332872
Eval: 2022-04-04 01:41:00.856582: total loss: 1.0791231847671277, mse:4.68471660525306, ic :0.1715935398162415, sharpe5:14.059005358815192, irr5:471.47369384765625, ndcg5:0.8456904658236356, pnl5:4.337751865386963 
train 28, step: 0, loss: 1.1552607512088626, grad_norm: 0.13053496414400123, ic: 0.12746502057909176
train 28, step: 500, loss: 2.9705321863416394, grad_norm: 1.354902822267574, ic: 0.06855934994507698
train 28, step: 1000, loss: 2.775052954988645, grad_norm: 2.1649499003662958, ic: -0.031509732648207986
train 28, step: 1500, loss: 1.028082510534443, grad_norm: 0.0028544110483226647, ic: 0.19249853960644497
train 28, step: 2000, loss: 1.7471111208893533, grad_norm: 0.4053693040926016, ic: 0.09339339576743826
Epoch 28: 2022-04-04 01:41:23.554107: train loss: 1.6236765417075083
Eval step 0: eval loss: 1.0018101632438126
Eval: 2022-04-04 01:41:25.854743: total loss: 1.0797943961600391, mse:4.688765607580852, ic :0.16727064343936102, sharpe5:15.020708166360855, irr5:489.7196350097656, ndcg5:0.8485541346018355, pnl5:4.455511093139648 
train 29, step: 0, loss: 1.5191580979909023, grad_norm: 0.10830371605472641, ic: 0.06796107222197784
train 29, step: 500, loss: 2.5955285664641683, grad_norm: 1.6675012342031181, ic: -0.0663762700472761
train 29, step: 1000, loss: 1.7121514449070068, grad_norm: 0.886482689289219, ic: 0.48242707901593235
train 29, step: 1500, loss: 3.9294689135466987, grad_norm: 1.2677506196865045, ic: 0.14051083251909594
train 29, step: 2000, loss: 0.9317895546833377, grad_norm: 0.21966674483956045, ic: 0.477560294261819
Epoch 29: 2022-04-04 01:41:48.287466: train loss: 1.62441843135485
Eval step 0: eval loss: 1.0021475118483412
Eval: 2022-04-04 01:41:50.566001: total loss: 1.0799281104892806, mse:4.68791079577039, ic :0.1677845902584899, sharpe5:14.753614690303802, irr5:471.4132995605469, ndcg5:0.8605369053747453, pnl5:4.633545875549316 
train 30, step: 0, loss: 1.2528259138732494, grad_norm: 0.04149391434907718, ic: 0.9808635585275827
train 30, step: 500, loss: 1.934866410267504, grad_norm: 0.3695920562724725, ic: 0.16482880004198633
train 30, step: 1000, loss: 3.430980331915069, grad_norm: 1.2550408744534174, ic: 0.41252903648241834
train 30, step: 1500, loss: 1.0717608990446892, grad_norm: 0.24624356563732264, ic: 0.1468050066064755
train 30, step: 2000, loss: 1.081548595094625, grad_norm: 0.0643946362375139, ic: 0.44186320395941925
Epoch 30: 2022-04-04 01:42:13.630984: train loss: 1.6244168144994797
Eval step 0: eval loss: 0.9982018573714784
Eval: 2022-04-04 01:42:15.930753: total loss: 1.079996886578082, mse:4.676789325493005, ic :0.169758991340651, sharpe5:15.775019599199295, irr5:532.105712890625, ndcg5:0.8497305232992355, pnl5:5.307575225830078 
train 31, step: 0, loss: 1.1753077115413648, grad_norm: 0.2744882532179285, ic: 0.19947490801218146
train 31, step: 500, loss: 0.8260819234228172, grad_norm: 0.09891721299949469, ic: 0.2099599046706218
train 31, step: 1000, loss: 5.13433548151751, grad_norm: 1.1249623696036395, ic: 0.03407287377724689
train 31, step: 1500, loss: 1.6750103391856646, grad_norm: 0.33874856272450354, ic: 0.30126514728007037
train 31, step: 2000, loss: 0.8967882879849138, grad_norm: 0.6571691355073039, ic: 0.15674252941256223
Epoch 31: 2022-04-04 01:42:38.739274: train loss: 1.623179847829258
Eval step 0: eval loss: 1.0080435915078658
Eval: 2022-04-04 01:42:41.089395: total loss: 1.0816303280632158, mse:4.6755299730536075, ic :0.16838747720388256, sharpe5:15.447585521936416, irr5:494.74615478515625, ndcg5:0.8627714695058912, pnl5:4.468444347381592 
train 32, step: 0, loss: 0.8640102476130117, grad_norm: 0.43349787050038024, ic: 0.11705190424408425
train 32, step: 500, loss: 1.1126366592035062, grad_norm: 0.37338211952408756, ic: 0.18563246955574225
train 32, step: 1000, loss: 1.3793457813334222, grad_norm: 0.03599317697838805, ic: 0.09148397729093079
train 32, step: 1500, loss: 2.082300711711494, grad_norm: 0.5363787370032229, ic: 0.43475243980856965
train 32, step: 2000, loss: 1.0880400842578355, grad_norm: 0.39581102992746753, ic: 0.4598995530231126
Epoch 32: 2022-04-04 01:43:03.425684: train loss: 1.6218435205744957
Eval step 0: eval loss: 1.008854629492496
Eval: 2022-04-04 01:43:05.718705: total loss: 1.0795363302598273, mse:4.668015444331278, ic :0.17744529978253473, sharpe5:16.093991425037384, irr5:537.7047729492188, ndcg5:0.8447658346532042, pnl5:4.491118431091309 
train 33, step: 0, loss: 1.1625594218511268, grad_norm: 0.017794130673238994, ic: 0.04520834818416212
train 33, step: 500, loss: 3.1928234290930053, grad_norm: 0.5377675629396965, ic: 0.5212894576803269
train 33, step: 1000, loss: 5.300089903495994, grad_norm: 3.2653816006424545, ic: 0.012992588113951082
train 33, step: 1500, loss: 1.3294539288776677, grad_norm: 2.188707670659113, ic: 4.2350538549291994e-05
train 33, step: 2000, loss: 1.847213011749031, grad_norm: 0.35475171166700137, ic: 0.07435951611636249
Epoch 33: 2022-04-04 01:43:28.765055: train loss: 1.6236917574660927
Eval step 0: eval loss: 1.01536748885104
Eval: 2022-04-04 01:43:31.080527: total loss: 1.0834075839519839, mse:4.672034829450912, ic :0.17603251351294122, sharpe5:15.751049841642379, irr5:536.6222534179688, ndcg5:0.8464540837414233, pnl5:4.795962810516357 
train 34, step: 0, loss: 0.7226133029169969, grad_norm: 0.27201489813057245, ic: 0.16659705389005716
train 34, step: 500, loss: 1.8217839174691473, grad_norm: 0.5685573903790466, ic: 0.8168259965795445
train 34, step: 1000, loss: 0.6878417968749999, grad_norm: 0.0677410512886731, ic: 0.4832989394352586
train 34, step: 1500, loss: 1.6502209785657052, grad_norm: 1.3536769587799056, ic: 0.6415544791098364
train 34, step: 2000, loss: 3.001757249407949, grad_norm: 0.49453400444562345, ic: 0.07787725727898394
Epoch 34: 2022-04-04 01:43:54.095062: train loss: 1.6231846737632885
Eval step 0: eval loss: 1.0117655468338598
Eval: 2022-04-04 01:43:56.457433: total loss: 1.0819114491286592, mse:4.68711960084255, ic :0.166981092775205, sharpe5:15.39524650633335, irr5:507.5740966796875, ndcg5:0.838463788746451, pnl5:3.7563271522521973 
train 35, step: 0, loss: 1.0518772752979133, grad_norm: 0.9082352792059296, ic: 0.007946396678946876
train 35, step: 500, loss: 3.292992794152462, grad_norm: 1.0042132216837933, ic: -0.05985036945537666
train 35, step: 1000, loss: 1.3456551004726685, grad_norm: 0.0675701967523974, ic: 0.5035498492541322
train 35, step: 1500, loss: 1.6467688058264232, grad_norm: 0.3278294964668008, ic: 0.07106446811057099
train 35, step: 2000, loss: 1.293498567106909, grad_norm: 0.11877135919683617, ic: -0.047103458467156
Epoch 35: 2022-04-04 01:44:19.618912: train loss: 1.62391425865211
Eval step 0: eval loss: 0.9997136907994338
Eval: 2022-04-04 01:44:21.951209: total loss: 1.0799417879959965, mse:4.67973897017156, ic :0.1699979326673497, sharpe5:14.970957203507423, irr5:498.23114013671875, ndcg5:0.8505771520241256, pnl5:4.183165073394775 
train 36, step: 0, loss: 9.010106304262036, grad_norm: 1.5961482054839664, ic: 0.05113393360055582
train 36, step: 500, loss: 0.8604058981122256, grad_norm: 0.0061401955393727775, ic: 0.07350836645573582
train 36, step: 1000, loss: 1.9478123441655586, grad_norm: 1.9774944541157111, ic: 0.070177452764658
train 36, step: 1500, loss: 1.0521673774940252, grad_norm: 0.16658181634354596, ic: 0.07709172048678012
train 36, step: 2000, loss: 2.1841406594871984, grad_norm: 1.4330788906834075, ic: 0.3846127861678074
Epoch 36: 2022-04-04 01:44:44.637367: train loss: 1.6227673197778736
Eval step 0: eval loss: 1.0167748650605581
Eval: 2022-04-04 01:44:46.964853: total loss: 1.0828324329405927, mse:4.67645301109978, ic :0.16945996434825641, sharpe5:15.306728670001029, irr5:513.8120727539062, ndcg5:0.8686446778645117, pnl5:4.527416229248047 
train 37, step: 0, loss: 1.2051242684170962, grad_norm: 0.24457288607470812, ic: 0.17239429085183583
train 37, step: 500, loss: 2.3399792936332986, grad_norm: 0.05605981707195116, ic: 0.1464757864946017
train 37, step: 1000, loss: 0.7513937489166502, grad_norm: 0.34098631672656843, ic: 0.16141105806176978
train 37, step: 1500, loss: 3.1290230533193206, grad_norm: 0.6273203295029112, ic: 0.19314041498329976
train 37, step: 2000, loss: 3.145101963521863, grad_norm: 1.7703307869102685, ic: -0.007407725239301128
Epoch 37: 2022-04-04 01:45:10.120222: train loss: 1.6230346430386982
Eval step 0: eval loss: 1.0078483690017772
Eval: 2022-04-04 01:45:12.442892: total loss: 1.0794770005299519, mse:4.6795976378752595, ic :0.1724772688294619, sharpe5:15.575984532237053, irr5:514.1392822265625, ndcg5:0.8446969002649937, pnl5:4.7821269035339355 
train 38, step: 0, loss: 1.342423595081676, grad_norm: 0.3846355859979733, ic: -0.22212857624629584
train 38, step: 500, loss: 1.6822462451550388, grad_norm: 0.9325094946794199, ic: 0.23374533465269867
train 38, step: 1000, loss: 1.8324938322368423, grad_norm: 0.6450572436195046, ic: 0.1457017486153968
train 38, step: 1500, loss: 1.0784613346434642, grad_norm: 0.24342434931035514, ic: 0.4829914467505028
train 38, step: 2000, loss: 0.7566507389188957, grad_norm: 0.01463068199647626, ic: 0.5620794347987891
Epoch 38: 2022-04-04 01:45:35.326606: train loss: 1.62199322213078
Eval step 0: eval loss: 0.9984218924845313
Eval: 2022-04-04 01:45:37.595540: total loss: 1.0790758047764182, mse:4.695289404951041, ic :0.17254305340200912, sharpe5:16.210162453651428, irr5:557.6787719726562, ndcg5:0.8440724922493722, pnl5:4.8792805671691895 
train 39, step: 0, loss: 0.8713199561241114, grad_norm: 0.032537080874321195, ic: 0.5389265291229279
train 39, step: 500, loss: 1.2367828295722234, grad_norm: 0.3631541946529906, ic: 0.05231661828077018
train 39, step: 1000, loss: 1.4044886733546402, grad_norm: 0.4154238316002366, ic: 0.08671202645844597
train 39, step: 1500, loss: 2.4480209604054193, grad_norm: 0.5051112692113204, ic: -0.06468721873465288
train 39, step: 2000, loss: 2.97241275765069, grad_norm: 2.761089394567125, ic: 0.19049982495406875
Epoch 39: 2022-04-04 01:46:00.497674: train loss: 1.6209571274715715
Eval step 0: eval loss: 0.9998243190289297
Eval: 2022-04-04 01:46:02.843004: total loss: 1.0804463966955664, mse:4.680305961170253, ic :0.168916928370706, sharpe5:14.666929112076758, irr5:517.4452514648438, ndcg5:0.8661585388069215, pnl5:3.730745553970337 

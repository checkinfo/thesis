Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='SparseAdjSeqTimeDataset', dout=0.3, epochs=40, gnn_layers=2, gpu=0, hidden_dim=128, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=3, mask_adj=True, mask_type='soft', model_type='RGCNModel', normalize_adj=True, num_days=1, num_heads=1, print_inteval=500, relation_num=1, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_250_0.8/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
load 2305 train graphs successful!
load 126 test graphs successful!
51130
RGCNModel(
  (fc1): Linear(in_features=9, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
  (fc4): Linear(in_features=128, out_features=1, bias=True)
  (gnns): ModuleList(
    (0): RGCN(
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
    )
    (1): RGCN(
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
    )
  )
  (dropout): Dropout(p=0.3, inplace=False)
  (relu): LeakyReLU(negative_slope=0.01)
)
train 0, step: 0, loss: 2.0733211230854742, grad_norm: 0.45761421270343544, ic: -0.025922579349852627
train 0, step: 500, loss: 1.3669734373519238, grad_norm: 0.8604767900675511, ic: -0.011458195388576193
train 0, step: 1000, loss: 1.506064057545264, grad_norm: 0.03263358857046033, ic: 0.18646924961357536
train 0, step: 1500, loss: 1.1907400707388547, grad_norm: 0.10494599264823598, ic: 0.03813156645530543
train 0, step: 2000, loss: 1.5586743238495617, grad_norm: 0.048934671653521555, ic: -0.0002559159788850761
Epoch 0: 2022-04-04 16:25:16.716478: train loss: 1.6475349532740848
Eval step 0: eval loss: 1.0109620940503226
Eval: 2022-04-04 16:25:22.196774: total loss: 1.0912625520595514, mse:4.887342216780407, ic :0.020003177597122005, sharpe5:6.6708577832579605, irr5:200.75082397460938, ndcg5:0.8300977956951525, pnl5:2.2274491786956787 
train 1, step: 0, loss: 0.642074736038057, grad_norm: 0.05652324999880529, ic: 0.055187222018361
train 1, step: 500, loss: 1.2611191982238608, grad_norm: 0.30247813470073515, ic: 0.23585833206443552
train 1, step: 1000, loss: 0.8767334389699778, grad_norm: 0.06249217631549574, ic: 0.07974463691019179
train 1, step: 1500, loss: 1.8638878799066312, grad_norm: 0.5701581403488876, ic: 0.08324806970063796
train 1, step: 2000, loss: 1.384212476371076, grad_norm: 0.222409363683185, ic: 0.1219203104768594
Epoch 1: 2022-04-04 16:25:56.364263: train loss: 1.6458996290570935
Eval step 0: eval loss: 1.0054963138493944
Eval: 2022-04-04 16:26:01.917434: total loss: 1.089089177087422, mse:4.880116576575845, ic :0.0482152144807778, sharpe5:6.542719375491142, irr5:197.42166137695312, ndcg5:0.8476912195081123, pnl5:2.284130811691284 
train 2, step: 0, loss: 1.3302215779171287, grad_norm: 0.4915386634675284, ic: 0.06027017103411789
train 2, step: 500, loss: 0.9456657444399659, grad_norm: 0.2731741428075054, ic: 0.0874783708760703
train 2, step: 1000, loss: 3.014988481025571, grad_norm: 1.0659386800636754, ic: 0.18112380537486542
train 2, step: 1500, loss: 2.286320225763283, grad_norm: 0.873391777492012, ic: 0.08304880937398953
train 2, step: 2000, loss: 1.4594397182261856, grad_norm: 0.2775683444983533, ic: -0.1038966851092185
Epoch 2: 2022-04-04 16:26:35.823587: train loss: 1.644566147243109
Eval step 0: eval loss: 0.9984938233321813
Eval: 2022-04-04 16:26:41.426181: total loss: 1.0890943257675958, mse:4.878872892219833, ic :0.04954604780509371, sharpe5:6.635564348995685, irr5:201.79957580566406, ndcg5:0.855455501304284, pnl5:2.5618770122528076 
train 3, step: 0, loss: 1.8306030180040167, grad_norm: 0.0645125526279971, ic: -0.149196544097364
train 3, step: 500, loss: 0.7809720650064683, grad_norm: 0.020420598564150245, ic: 0.0843914986447828
train 3, step: 1000, loss: 1.3697481895690637, grad_norm: 0.545299574536756, ic: 0.2324132547760622
train 3, step: 1500, loss: 2.621261608480762, grad_norm: 0.4021498014733504, ic: -0.060412644502533266
train 3, step: 2000, loss: 1.3555677009351326, grad_norm: 0.16383700327806838, ic: 0.0800692535826448
Epoch 3: 2022-04-04 16:27:16.259674: train loss: 1.6446124262889736
Eval step 0: eval loss: 1.0014579656439244
Eval: 2022-04-04 16:27:21.789390: total loss: 1.090671465096994, mse:4.877508769438183, ic :0.054151031520864396, sharpe5:6.502686853408814, irr5:194.42173767089844, ndcg5:0.8461597446211474, pnl5:2.805330753326416 
train 4, step: 0, loss: 1.1533370344606164, grad_norm: 0.15765505274487643, ic: 0.08892885302473963
train 4, step: 500, loss: 0.9912994139417132, grad_norm: 0.005745955788278337, ic: 0.1312848213110384
train 4, step: 1000, loss: 1.3307471373534039, grad_norm: 0.06173787730870982, ic: 0.04718629175564949
train 4, step: 1500, loss: 1.0531086457081331, grad_norm: 0.13633079911260515, ic: 0.6090502221362651
train 4, step: 2000, loss: 4.170133169010621, grad_norm: 0.8939912107987411, ic: -0.014944950485999114
Epoch 4: 2022-04-04 16:27:56.303073: train loss: 1.6410350222789238
Eval step 0: eval loss: 1.0082033307003686
Eval: 2022-04-04 16:28:01.749924: total loss: 1.0918077700953621, mse:4.731188716527619, ic :0.11296541496132813, sharpe5:6.473910374343395, irr5:195.44117736816406, ndcg5:0.8550842578782945, pnl5:3.081402063369751 
train 5, step: 0, loss: 1.0047589757473343, grad_norm: 0.19296939822623135, ic: -0.09143887390018371
train 5, step: 500, loss: 0.7874672936413902, grad_norm: 0.016670408890566785, ic: 0.15123572558444237
train 5, step: 1000, loss: 1.0925322346025965, grad_norm: 0.05090645319062904, ic: 0.4119860428299224
train 5, step: 1500, loss: 1.770631272230691, grad_norm: 0.3876367737080348, ic: -0.05149534921137487
train 5, step: 2000, loss: 2.17955732624137, grad_norm: 0.8397443217281825, ic: 0.041282317412118005
Epoch 5: 2022-04-04 16:28:36.817047: train loss: 1.6384754124582568
Eval step 0: eval loss: 1.0049678567461493
Eval: 2022-04-04 16:28:42.301862: total loss: 1.0865956668125256, mse:4.714691113327762, ic :0.1208287114004094, sharpe5:6.262506382763386, irr5:187.51644897460938, ndcg5:0.8434094905333878, pnl5:2.4537060260772705 
train 6, step: 0, loss: 0.7780793468728611, grad_norm: 0.009695948672291512, ic: -0.05660864592229147
train 6, step: 500, loss: 1.4191111960606269, grad_norm: 0.2443477839425472, ic: 0.04918261522895643
train 6, step: 1000, loss: 1.2252337934430588, grad_norm: 0.1886945331900287, ic: 0.2322307348617834
train 6, step: 1500, loss: 1.0574529223172169, grad_norm: 0.33148069913362094, ic: 0.08399380441661716
train 6, step: 2000, loss: 2.304569025866919, grad_norm: 1.2123229662366397, ic: 0.08349815291843869
Epoch 6: 2022-04-04 16:29:16.618445: train loss: 1.6377924207930157
Eval step 0: eval loss: 1.0023685111818719
Eval: 2022-04-04 16:29:22.155076: total loss: 1.0864350676659715, mse:4.720708534213577, ic :0.11389976610472871, sharpe5:6.186324836611748, irr5:182.91510009765625, ndcg5:0.8396160834026719, pnl5:2.486924171447754 
train 7, step: 0, loss: 1.4620572487644152, grad_norm: 0.5436708973326878, ic: 0.20343837426478534
train 7, step: 500, loss: 1.3467878611921582, grad_norm: 0.08774527135653769, ic: 0.18114715913191684
train 7, step: 1000, loss: 0.6408273752607788, grad_norm: 0.01680834643375357, ic: 0.28653447381103336
train 7, step: 1500, loss: 1.001106877008586, grad_norm: 0.13027036171047102, ic: 0.11477625432517842
train 7, step: 2000, loss: 1.580646496756141, grad_norm: 0.6231321931922038, ic: 0.4185597793791309
Epoch 7: 2022-04-04 16:29:56.765121: train loss: 1.637823456671682
Eval step 0: eval loss: 0.9949821966330963
Eval: 2022-04-04 16:30:02.339620: total loss: 1.0847516916606008, mse:4.729690875542141, ic :0.11696157491141097, sharpe5:6.909079241752624, irr5:201.505859375, ndcg5:0.8575248582138861, pnl5:2.758399248123169 
train 8, step: 0, loss: 1.2057671569534953, grad_norm: 0.0833594654944411, ic: 0.05460215598464435
train 8, step: 500, loss: 5.545058486603644, grad_norm: 1.1477839684188056, ic: 0.1463110058525141
train 8, step: 1000, loss: 1.8896419168548706, grad_norm: 0.5747735255441561, ic: 0.061783797117971
train 8, step: 1500, loss: 1.0705789040690912, grad_norm: 0.3510724406394001, ic: 0.6418919377557623
train 8, step: 2000, loss: 1.121924082438151, grad_norm: 0.4942052303732225, ic: 0.007221140836346788
Epoch 8: 2022-04-04 16:30:35.417975: train loss: 1.6377210157431819
Eval step 0: eval loss: 1.002264889621182
Eval: 2022-04-04 16:30:40.561804: total loss: 1.0888904216218036, mse:4.721036153297636, ic :0.1185323498182946, sharpe5:6.148506726622581, irr5:184.4726104736328, ndcg5:0.8458178219779405, pnl5:3.078761577606201 
train 9, step: 0, loss: 1.1207500737816287, grad_norm: 0.021743448794223647, ic: 0.4365214742514557
train 9, step: 500, loss: 3.2243834427321154, grad_norm: 1.3502190967572998, ic: 0.06563238597617842
train 9, step: 1000, loss: 0.8768260839308438, grad_norm: 0.12662185168555382, ic: 0.22840021572184516
train 9, step: 1500, loss: 2.1483882366161873, grad_norm: 0.9192093314884031, ic: -0.027866879561051994
train 9, step: 2000, loss: 0.6055388611944336, grad_norm: 0.00818206164801932, ic: 0.051962882145023995
Epoch 9: 2022-04-04 16:31:12.701029: train loss: 1.6376351281921027
Eval step 0: eval loss: 1.0009403720913967
Eval: 2022-04-04 16:31:17.875973: total loss: 1.0919728934105801, mse:4.794578934087303, ic :0.11281856115482419, sharpe5:8.189754821062088, irr5:248.81407165527344, ndcg5:0.8579255706055726, pnl5:2.573413372039795 
train 10, step: 0, loss: 1.3035188054758409, grad_norm: 0.021226540592896186, ic: 0.37777506874851907
train 10, step: 500, loss: 0.8993442815935367, grad_norm: 0.007257639066947012, ic: 0.09584617166649433
train 10, step: 1000, loss: 1.5336359105042674, grad_norm: 0.5224875751911513, ic: 0.044860822090826244
train 10, step: 1500, loss: 3.051414747860936, grad_norm: 1.2785065130712472, ic: 0.029958333226007293
train 10, step: 2000, loss: 1.3815632272273937, grad_norm: 0.13273493344287995, ic: 0.040302711478511194
Epoch 10: 2022-04-04 16:31:50.488016: train loss: 1.6381429857483483
Eval step 0: eval loss: 1.0039351766143365
Eval: 2022-04-04 16:31:55.579160: total loss: 1.0864735117396114, mse:4.715779389956506, ic :0.11826912895087544, sharpe5:6.329244752526283, irr5:186.73468017578125, ndcg5:0.8387042287913047, pnl5:2.8629651069641113 
train 11, step: 0, loss: 4.82186744099394, grad_norm: 0.8453089670669955, ic: 0.07943556431911954
train 11, step: 500, loss: 0.990950670842934, grad_norm: 0.061881118466204976, ic: 0.04382840756539916
train 11, step: 1000, loss: 1.0355538398050153, grad_norm: 0.31489063683370583, ic: 0.03306260458624512
train 11, step: 1500, loss: 0.6943457834218383, grad_norm: 0.0028507776851812343, ic: 0.0637754253443331
train 11, step: 2000, loss: 1.1381960883555036, grad_norm: 0.059912013573733915, ic: -0.18532473020404888
Epoch 11: 2022-04-04 16:32:28.667908: train loss: 1.6369143601436944
Eval step 0: eval loss: 0.9916821199068588
Eval: 2022-04-04 16:32:33.798815: total loss: 1.084476233660051, mse:4.7304188451155555, ic :0.11974960489621986, sharpe5:7.8308857405185694, irr5:226.37799072265625, ndcg5:0.8429540559980438, pnl5:3.1772193908691406 
train 12, step: 0, loss: 1.385443834660171, grad_norm: 0.25499633493789486, ic: 0.04315969934187516
train 12, step: 500, loss: 0.8148046913538378, grad_norm: 0.3672197329570059, ic: 0.01866321944838139
train 12, step: 1000, loss: 1.2206929793143964, grad_norm: 0.2643052126550532, ic: 0.5745415358605357
train 12, step: 1500, loss: 1.0888353633588972, grad_norm: 0.197348245639015, ic: -0.10395391809966201
train 12, step: 2000, loss: 1.115080228839465, grad_norm: 0.06036183630162282, ic: 0.10398016648978725
Epoch 12: 2022-04-04 16:33:06.329526: train loss: 1.6375889981476572
Eval step 0: eval loss: 1.0021052147100447
Eval: 2022-04-04 16:33:11.491921: total loss: 1.0869830939285565, mse:4.721719211590996, ic :0.12049659615486076, sharpe5:6.217199851870537, irr5:184.7861328125, ndcg5:0.8509519237540568, pnl5:2.31575608253479 
train 13, step: 0, loss: 1.0841118637791296, grad_norm: 0.04398326764776527, ic: 0.421506547613808
train 13, step: 500, loss: 1.145870202916269, grad_norm: 0.006834391473871513, ic: -0.1667904693390655
train 13, step: 1000, loss: 1.3946144230059991, grad_norm: 0.4075057651984592, ic: 0.061109298662305495
train 13, step: 1500, loss: 0.7761836639822346, grad_norm: 0.0025449855838750473, ic: -0.05359988553759315
train 13, step: 2000, loss: 1.0385829380580358, grad_norm: 0.026195093543824176, ic: 0.05671921660317259
Epoch 13: 2022-04-04 16:33:44.907742: train loss: 1.637910191441975
Eval step 0: eval loss: 0.9912651909722221
Eval: 2022-04-04 16:33:50.032856: total loss: 1.0854858127634512, mse:4.740556005246026, ic :0.11629925709009191, sharpe5:7.073571466505527, irr5:198.7862091064453, ndcg5:0.832015500504058, pnl5:2.9924702644348145 
train 14, step: 0, loss: 1.7623062133789062, grad_norm: 0.5324274307051844, ic: 0.15879471959986458
train 14, step: 500, loss: 1.280299627456833, grad_norm: 0.14643793197011507, ic: 0.19147254637552236
train 14, step: 1000, loss: 1.0744251598011363, grad_norm: 0.12735065913948015, ic: 0.12161802881783138
train 14, step: 1500, loss: 0.9769624470746727, grad_norm: 0.08318168345764014, ic: 0.20772941549635188
train 14, step: 2000, loss: 2.292577846209727, grad_norm: 0.45739747835412137, ic: -0.0653722552855394
Epoch 14: 2022-04-04 16:34:23.132752: train loss: 1.6372272950332005
Eval step 0: eval loss: 1.0016724725595707
Eval: 2022-04-04 16:34:28.347891: total loss: 1.0888912148548517, mse:4.728124992708216, ic :0.11499171143277595, sharpe5:6.8773335018754, irr5:197.92807006835938, ndcg5:0.8433054041973015, pnl5:3.027855634689331 
train 15, step: 0, loss: 0.9775061337165802, grad_norm: 0.14651345805897648, ic: 0.14863203406991526
train 15, step: 500, loss: 1.2217137254404602, grad_norm: 0.004578923686697203, ic: 0.07145049649516405
train 15, step: 1000, loss: 1.7654516927083335, grad_norm: 0.05447767577668011, ic: -0.11844210218701465
train 15, step: 1500, loss: 5.427459645990429, grad_norm: 0.8839002543078506, ic: -0.004893161965346907
train 15, step: 2000, loss: 0.9277812159338662, grad_norm: 0.01590016520221713, ic: -0.03389271226638909
Epoch 15: 2022-04-04 16:35:01.051677: train loss: 1.6385509076409728
Eval step 0: eval loss: 1.000479924672525
Eval: 2022-04-04 16:35:06.198741: total loss: 1.0859916842975172, mse:4.716681074077424, ic :0.11636215821001968, sharpe5:7.096087336242198, irr5:207.16261291503906, ndcg5:0.8556462988092656, pnl5:2.748094320297241 
train 16, step: 0, loss: 6.326518059563067, grad_norm: 0.9255007146000493, ic: -0.03143663003236844
train 16, step: 500, loss: 1.369724624875992, grad_norm: 0.750881794562213, ic: -0.010280385683077351
train 16, step: 1000, loss: 0.8240261523594883, grad_norm: 0.08863476383097199, ic: -0.012777701861664745
train 16, step: 1500, loss: 1.2154508326558913, grad_norm: 0.2833851342822279, ic: 0.11807508296868702
train 16, step: 2000, loss: 0.9674268410253728, grad_norm: 0.21431057751912905, ic: 0.5429800735062923
Epoch 16: 2022-04-04 16:35:39.142243: train loss: 1.6347954316502618
Eval step 0: eval loss: 1.0001509326454712
Eval: 2022-04-04 16:35:44.293999: total loss: 1.0822444787387284, mse:4.712378688725404, ic :0.13628600353501777, sharpe5:11.047712337970733, irr5:336.08270263671875, ndcg5:0.8394792992345261, pnl5:3.43117356300354 
train 17, step: 0, loss: 1.1799660899156441, grad_norm: 0.01069561556403641, ic: 0.15127408893413566
train 17, step: 500, loss: 1.0440707681229608, grad_norm: 0.02292792065372467, ic: -0.025494047707914972
train 17, step: 1000, loss: 3.3770288649958746, grad_norm: 0.8107104907114643, ic: -0.019291637277359525
train 17, step: 1500, loss: 0.8859462305951659, grad_norm: 0.07027716569478051, ic: 0.07566676568513525
train 17, step: 2000, loss: 1.0082963572252517, grad_norm: 0.6260470692399175, ic: 0.5715711831481135
Epoch 17: 2022-04-04 16:36:17.804322: train loss: 1.631000955455309
Eval step 0: eval loss: 1.0030669924960505
Eval: 2022-04-04 16:36:23.006717: total loss: 1.084122585473167, mse:4.712995153077611, ic :0.15031187151384917, sharpe5:12.45653720319271, irr5:427.7405090332031, ndcg5:0.8435519053189445, pnl5:4.137978553771973 
train 18, step: 0, loss: 0.8516202558014234, grad_norm: 0.012020362812424915, ic: 0.010047037368198983
train 18, step: 500, loss: 2.5249693470110928, grad_norm: 1.0384430721227786, ic: 0.0797702707953357
train 18, step: 1000, loss: 1.361028657542716, grad_norm: 0.3339215535176843, ic: 0.5289616934051221
train 18, step: 1500, loss: 1.7310057040363205, grad_norm: 0.9960167978513619, ic: 0.3290800060560267
train 18, step: 2000, loss: 1.2601993236839255, grad_norm: 0.3154267889955727, ic: 0.1826118904072832
Epoch 18: 2022-04-04 16:36:55.704716: train loss: 1.6295922981940874
Eval step 0: eval loss: 1.0018082348028567
Eval: 2022-04-04 16:37:00.788006: total loss: 1.0827245835677572, mse:4.691475512854571, ic :0.15594765026238983, sharpe5:13.652682968974112, irr5:451.286376953125, ndcg5:0.8500187299277848, pnl5:5.0915961265563965 
train 19, step: 0, loss: 2.2295224482354628, grad_norm: 1.1967541265536241, ic: 0.24113884828018678
train 19, step: 500, loss: 1.021662228606468, grad_norm: 0.060994057461161474, ic: 0.04137091776370272
train 19, step: 1000, loss: 0.9965875030899801, grad_norm: 0.3294524365621771, ic: 0.5320165000896857
train 19, step: 1500, loss: 1.5778947053132233, grad_norm: 0.0212332053589322, ic: 0.13274667536541507
train 19, step: 2000, loss: 1.7858261733855376, grad_norm: 1.7392372947247725, ic: 0.6243757892839376
Epoch 19: 2022-04-04 16:37:34.096254: train loss: 1.6285200523135495
Eval step 0: eval loss: 1.0040897732976237
Eval: 2022-04-04 16:37:39.275266: total loss: 1.0825358835128134, mse:4.696707506130902, ic :0.14913343438005308, sharpe5:11.610652593970299, irr5:358.3062744140625, ndcg5:0.8532548793850179, pnl5:3.2444865703582764 
train 20, step: 0, loss: 1.245418558096945, grad_norm: 0.32281998118008354, ic: 0.4572562613865153
train 20, step: 500, loss: 1.246082765633369, grad_norm: 0.5701962700071146, ic: 0.0060323454008709455
train 20, step: 1000, loss: 1.5671028714763102, grad_norm: 0.3022102064654824, ic: 0.14994479147388695
train 20, step: 1500, loss: 0.8577617659444703, grad_norm: 0.3684733681766391, ic: 0.569944612885025
train 20, step: 2000, loss: 1.354603304049616, grad_norm: 0.10127966432783682, ic: -0.03768309376272923
Epoch 20: 2022-04-04 16:38:11.984849: train loss: 1.62732544745906
Eval step 0: eval loss: 1.0049167530608214
Eval: 2022-04-04 16:38:17.147599: total loss: 1.0829875500454278, mse:4.701702057104552, ic :0.15563637448634668, sharpe5:13.343091888427734, irr5:450.353515625, ndcg5:0.8402392161825222, pnl5:3.6428842544555664 
train 21, step: 0, loss: 1.3788409085732507, grad_norm: 0.34195201178393425, ic: 0.3447672066717518
train 21, step: 500, loss: 1.110821164283665, grad_norm: 0.09524343652129909, ic: 0.05748510915975169
train 21, step: 1000, loss: 0.8881541042907765, grad_norm: 0.19907803483693945, ic: 0.08247735442165322
train 21, step: 1500, loss: 0.7355298461501941, grad_norm: 0.2707983596740223, ic: 0.6108733335496008
train 21, step: 2000, loss: 1.1645819710214758, grad_norm: 0.128482214000362, ic: 0.1535889930331435
Epoch 21: 2022-04-04 16:38:50.285581: train loss: 1.6292775834062125
Eval step 0: eval loss: 1.0048984971531068
Eval: 2022-04-04 16:38:55.379092: total loss: 1.0824634705709775, mse:4.693653736749524, ic :0.15236999947525362, sharpe5:11.91794318318367, irr5:388.8360900878906, ndcg5:0.8558105732084107, pnl5:3.7803432941436768 
train 22, step: 0, loss: 1.062957011362875, grad_norm: 0.235151749974999, ic: 0.1064738325711508
train 22, step: 500, loss: 1.0275131105437991, grad_norm: 0.007378493630895656, ic: 0.007753446816008881
train 22, step: 1000, loss: 0.9158440541017119, grad_norm: 0.05607603565061542, ic: 0.11489827110103033
train 22, step: 1500, loss: 1.0096859560577298, grad_norm: 0.05577426271906248, ic: 0.2258381981821491
train 22, step: 2000, loss: 1.0529988843341207, grad_norm: 0.1328454027210392, ic: 0.1129237095145345
Epoch 22: 2022-04-04 16:39:28.395357: train loss: 1.6279635325732191
Eval step 0: eval loss: 1.0111141837603672
Eval: 2022-04-04 16:39:33.550016: total loss: 1.0819217848421188, mse:4.681297589462933, ic :0.16037096733676742, sharpe5:12.927358483672142, irr5:443.0627746582031, ndcg5:0.84385572025541, pnl5:3.22770357131958 
train 23, step: 0, loss: 1.297671235711833, grad_norm: 0.8043110426802138, ic: -0.00349474892232033
train 23, step: 500, loss: 0.9037487323467549, grad_norm: 0.28091805954180016, ic: 0.589767708818129
train 23, step: 1000, loss: 2.294276894933637, grad_norm: 0.951764960812554, ic: 0.05438843776971868
train 23, step: 1500, loss: 0.7802809274539001, grad_norm: 0.5832721706714541, ic: 0.7145715183360966
train 23, step: 2000, loss: 1.4162028825201955, grad_norm: 0.7627314987270786, ic: 0.43836710358546666
Epoch 23: 2022-04-04 16:40:06.751730: train loss: 1.62560415962132
Eval step 0: eval loss: 1.015363117718207
Eval: 2022-04-04 16:40:11.821520: total loss: 1.0890863074119417, mse:4.705659877862268, ic :0.1495380448139926, sharpe5:11.555508908629417, irr5:369.52490234375, ndcg5:0.8409278885941657, pnl5:3.5857532024383545 
train 24, step: 0, loss: 1.1889143384684817, grad_norm: 0.5663317257139632, ic: 0.2623647796197652
train 24, step: 500, loss: 1.248570259612176, grad_norm: 0.7079591580220547, ic: -0.007812255520538347
train 24, step: 1000, loss: 1.0440857119676543, grad_norm: 0.6553904792214106, ic: 0.11162699513829763
train 24, step: 1500, loss: 1.197708922859252, grad_norm: 0.1233803697832172, ic: 0.1193038880490074
train 24, step: 2000, loss: 1.366898233856635, grad_norm: 0.43933818919179696, ic: 0.4417442486228975
Epoch 24: 2022-04-04 16:40:45.805244: train loss: 1.6267013392067449
Eval step 0: eval loss: 1.0170859868680884
Eval: 2022-04-04 16:40:50.930006: total loss: 1.0847488089704802, mse:4.693314188407515, ic :0.15461527474108275, sharpe5:12.755637021660805, irr5:437.383056640625, ndcg5:0.8341968048753764, pnl5:3.717517614364624 
train 25, step: 0, loss: 1.3366832841897094, grad_norm: 0.45528783270371875, ic: 0.17954020993282827
train 25, step: 500, loss: 1.4790383871499595, grad_norm: 0.7259104303818893, ic: 0.1272818457203736
train 25, step: 1000, loss: 1.3610118232011932, grad_norm: 0.2151870024384517, ic: 0.2679969707339423
train 25, step: 1500, loss: 2.8772501007057913, grad_norm: 1.0628939219246587, ic: 0.17801209576704366
train 25, step: 2000, loss: 1.2020149713830102, grad_norm: 0.15877557480973423, ic: 0.13770618757855818
Epoch 25: 2022-04-04 16:41:24.503200: train loss: 1.626894839720615
Eval step 0: eval loss: 1.0061392560640467
Eval: 2022-04-04 16:41:29.629664: total loss: 1.0814502143577538, mse:4.683950651967306, ic :0.15658791480605866, sharpe5:12.167489737272263, irr5:384.5746765136719, ndcg5:0.8365175962801571, pnl5:3.129068613052368 
train 26, step: 0, loss: 1.626413352272727, grad_norm: 0.41417853562971624, ic: 0.15833846143698932
train 26, step: 500, loss: 1.0107951481614625, grad_norm: 0.15085941081625098, ic: -0.06796490133169991
train 26, step: 1000, loss: 1.7960128847705037, grad_norm: 0.6610398481235782, ic: 0.19228185033646106
train 26, step: 1500, loss: 0.9240490387156448, grad_norm: 0.02222202939149248, ic: 0.03145730397732925
train 26, step: 2000, loss: 0.987110336183563, grad_norm: 0.26062901422259804, ic: 0.13908182784502893
Epoch 26: 2022-04-04 16:42:02.386780: train loss: 1.626520533959919
Eval step 0: eval loss: 1.0076034570003949
Eval: 2022-04-04 16:42:07.540620: total loss: 1.0820232260826224, mse:4.675456801306582, ic :0.17061206443270596, sharpe5:15.516675935983658, irr5:547.5215454101562, ndcg5:0.8682453533615, pnl5:5.0110273361206055 
train 27, step: 0, loss: 1.628065362034074, grad_norm: 1.017066493598999, ic: 0.6468202408503902
train 27, step: 500, loss: 1.5187036208750486, grad_norm: 0.2739719330489527, ic: 0.05886078234991262
train 27, step: 1000, loss: 2.6207227017773893, grad_norm: 0.712459334199637, ic: 0.3905304823468614
train 27, step: 1500, loss: 0.8681804966711485, grad_norm: 0.5142796367154511, ic: 0.5452152719564465
train 27, step: 2000, loss: 1.3418214390721006, grad_norm: 1.4587615028793404, ic: -0.023308964611589402
Epoch 27: 2022-04-04 16:42:40.771243: train loss: 1.6242325352105087
Eval step 0: eval loss: 1.0064496064951947
Eval: 2022-04-04 16:42:45.964741: total loss: 1.0792698219346029, mse:4.673552260108987, ic :0.17468721581527866, sharpe5:14.894802616238593, irr5:533.1363525390625, ndcg5:0.8508305503722193, pnl5:4.093541145324707 
train 28, step: 0, loss: 1.157436168221348, grad_norm: 0.5288336283550541, ic: 0.1746598847805269
train 28, step: 500, loss: 2.9291449205879325, grad_norm: 0.6223885051202666, ic: 0.1157560555258714
train 28, step: 1000, loss: 2.780492508392575, grad_norm: 1.8059506052497978, ic: -0.04451653912715618
train 28, step: 1500, loss: 1.0217692738867952, grad_norm: 0.007804920646024995, ic: 0.20455671576215229
train 28, step: 2000, loss: 1.7638996922692587, grad_norm: 0.46893588333458536, ic: 0.04147728417409261
Epoch 28: 2022-04-04 16:43:18.872495: train loss: 1.6254098933641876
Eval step 0: eval loss: 1.0119436062154423
Eval: 2022-04-04 16:43:24.043638: total loss: 1.0809024098236533, mse:4.684548225093246, ic :0.16040933844648533, sharpe5:13.721193530559539, irr5:458.09478759765625, ndcg5:0.8433782201978399, pnl5:3.533045530319214 
train 29, step: 0, loss: 1.5136415193802122, grad_norm: 0.18736352851713678, ic: 0.07290664287938216
train 29, step: 500, loss: 2.5471203472508237, grad_norm: 2.327980270199716, ic: -0.036981351669473916
train 29, step: 1000, loss: 1.705582963884083, grad_norm: 1.3293082493581485, ic: 0.482363044039713
train 29, step: 1500, loss: 3.984900760701825, grad_norm: 1.2617937321702963, ic: 0.13003698636318856
train 29, step: 2000, loss: 0.9385667007275572, grad_norm: 0.4144170014939866, ic: 0.4630173818462646
Epoch 29: 2022-04-04 16:43:57.276644: train loss: 1.625734013779819
Eval step 0: eval loss: 1.0130849218544298
Eval: 2022-04-04 16:44:02.432174: total loss: 1.0814630441790933, mse:4.680289514442907, ic :0.16532094280549334, sharpe5:14.599946220517158, irr5:505.919189453125, ndcg5:0.8384239823924262, pnl5:3.686105489730835 
train 30, step: 0, loss: 1.2501673499893546, grad_norm: 0.5465293880883263, ic: 0.9775748829959768
train 30, step: 500, loss: 1.9393801145915743, grad_norm: 0.47645986382543726, ic: 0.17938754070151194
train 30, step: 1000, loss: 3.4240178866490414, grad_norm: 0.9309127633002418, ic: 0.3928585144541082
train 30, step: 1500, loss: 1.0864888895635436, grad_norm: 0.26956525590638636, ic: 0.1477328435463387
train 30, step: 2000, loss: 1.1076145951082992, grad_norm: 4.451588100785118, ic: 0.4332152929744333
Epoch 30: 2022-04-04 16:44:35.194751: train loss: 1.6255626762765603
Eval step 0: eval loss: 1.0194561693654554
Eval: 2022-04-04 16:44:40.343539: total loss: 1.0836773826865407, mse:4.685966827741462, ic :0.1617867285019404, sharpe5:13.650518690943718, irr5:470.25848388671875, ndcg5:0.8512837228033815, pnl5:2.871342897415161 
train 31, step: 0, loss: 1.1611736991747181, grad_norm: 0.2519012242193267, ic: 0.16800705906131416
train 31, step: 500, loss: 0.834421897177222, grad_norm: 2.752403213865207, ic: 0.17540819925278095
train 31, step: 1000, loss: 5.133510913180934, grad_norm: 1.1683849072551031, ic: -0.022910332546377313
train 31, step: 1500, loss: 1.6769445970585395, grad_norm: 0.3329626816711387, ic: 0.2875096182801059
train 31, step: 2000, loss: 0.979846051095546, grad_norm: 0.4129724882201202, ic: 0.18791761956562975
Epoch 31: 2022-04-04 16:45:13.336061: train loss: 1.625832313648126
Eval step 0: eval loss: 1.0170488965203726
Eval: 2022-04-04 16:45:18.523759: total loss: 1.0843146898840408, mse:4.684374753317859, ic :0.15849851405087503, sharpe5:12.935182235240935, irr5:417.79345703125, ndcg5:0.8572733765843118, pnl5:3.1803882122039795 
train 32, step: 0, loss: 0.8861017350087661, grad_norm: 0.6653073476366025, ic: 0.11225504744189736
train 32, step: 500, loss: 1.097527480706936, grad_norm: 0.4454439625750892, ic: 0.11614518447920658
train 32, step: 1000, loss: 1.379190407267752, grad_norm: 0.030377828561438, ic: 0.06962135959768864
train 32, step: 1500, loss: 2.054377978062113, grad_norm: 0.6404030328303835, ic: 0.4451305502476235
train 32, step: 2000, loss: 1.0565061831795548, grad_norm: 0.3645649115584529, ic: 0.46722632572110345
Epoch 32: 2022-04-04 16:45:52.437437: train loss: 1.6238576582670792
Eval step 0: eval loss: 1.0145743853672986
Eval: 2022-04-04 16:45:57.532755: total loss: 1.081018006893627, mse:4.672980811834127, ic :0.16974311756061486, sharpe5:14.062413529157638, irr5:500.3774719238281, ndcg5:0.8549034874917307, pnl5:4.205524444580078 
train 33, step: 0, loss: 1.164069773861249, grad_norm: 0.054494826521730357, ic: 0.03968192416856974
train 33, step: 500, loss: 3.1560203088970025, grad_norm: 0.3874630068389962, ic: 0.5168582722100158
train 33, step: 1000, loss: 5.245162708257466, grad_norm: 2.349718675267274, ic: 0.034413294957891874
train 33, step: 1500, loss: 1.3281812714367378, grad_norm: 1.7215303354848321, ic: 0.009923047456149692
train 33, step: 2000, loss: 1.867810910247093, grad_norm: 0.37268753025051365, ic: 0.06278585865762772
Epoch 33: 2022-04-04 16:46:31.138918: train loss: 1.625774504916163
Eval step 0: eval loss: 1.0202218247062598
Eval: 2022-04-04 16:46:36.332317: total loss: 1.089484999292714, mse:4.694555568819182, ic :0.1669088923485307, sharpe5:14.773193460702895, irr5:516.5133056640625, ndcg5:0.8415075334487434, pnl5:2.863060474395752 
train 34, step: 0, loss: 0.7172495121056607, grad_norm: 0.3528425712393303, ic: 0.1558786783158656
train 34, step: 500, loss: 1.8077857303548055, grad_norm: 0.638092999177204, ic: 0.8770575095756507
train 34, step: 1000, loss: 0.695356866244612, grad_norm: 0.19231714165095481, ic: 0.45726479344013304
train 34, step: 1500, loss: 1.6588568271734776, grad_norm: 1.1030249383803934, ic: 0.6317081974968024
train 34, step: 2000, loss: 2.979243622580313, grad_norm: 0.4696652960466648, ic: 0.10099915732530501
Epoch 34: 2022-04-04 16:47:09.081764: train loss: 1.625188176379183
Eval step 0: eval loss: 1.0150274404291733
Eval: 2022-04-04 16:47:14.156586: total loss: 1.0834465234316863, mse:4.68526931733865, ic :0.1607727141060593, sharpe5:14.05012122452259, irr5:456.7047119140625, ndcg5:0.847277635809466, pnl5:3.963479995727539 
train 35, step: 0, loss: 1.055100549625445, grad_norm: 0.6495979757220551, ic: -0.01088387026051165
train 35, step: 500, loss: 3.3300836736505683, grad_norm: 1.4286387475741793, ic: -0.1261572983194304
train 35, step: 1000, loss: 1.3508177371608052, grad_norm: 0.09134374157480095, ic: 0.49807544171113893
train 35, step: 1500, loss: 1.6278650032312143, grad_norm: 0.3444274688063025, ic: 0.08109836128209538
train 35, step: 2000, loss: 1.2852620630653386, grad_norm: 0.06852067056102623, ic: -0.10666809358370544
Epoch 35: 2022-04-04 16:47:47.751857: train loss: 1.6255136192176898
Eval step 0: eval loss: 1.0099267141011716
Eval: 2022-04-04 16:47:52.890608: total loss: 1.0820279451996822, mse:4.683197806488247, ic :0.1619815400165988, sharpe5:12.801351719498633, irr5:415.5946960449219, ndcg5:0.8529608994679406, pnl5:2.905247211456299 
train 36, step: 0, loss: 8.96826133336622, grad_norm: 1.1867988901551885, ic: -0.06477368928240532
train 36, step: 500, loss: 0.8599724145119702, grad_norm: 0.020927866318563856, ic: 0.11430590438793439
train 36, step: 1000, loss: 1.981251075999715, grad_norm: 1.510584341216341, ic: 0.09215045967031356
train 36, step: 1500, loss: 1.0495714384324304, grad_norm: 0.1169175453082973, ic: 0.12520356336662836
train 36, step: 2000, loss: 2.1518609292230724, grad_norm: 1.2159275724681349, ic: 0.3844103789393119
Epoch 36: 2022-04-04 16:48:24.889525: train loss: 1.6247035887445445
Eval step 0: eval loss: 1.021824873391423
Eval: 2022-04-04 16:48:30.040938: total loss: 1.0885981156010585, mse:4.695634075692067, ic :0.16071042300858676, sharpe5:13.770930304527282, irr5:464.54345703125, ndcg5:0.8498356789312306, pnl5:3.915559768676758 
train 37, step: 0, loss: 1.178096950395547, grad_norm: 0.194964620607342, ic: 0.06708746340729298
train 37, step: 500, loss: 2.3359897724325727, grad_norm: 0.03062071213147653, ic: 0.15350972091973236
train 37, step: 1000, loss: 0.7705001710145107, grad_norm: 0.32420757053892396, ic: 0.15549655381819288
train 37, step: 1500, loss: 3.119105924809644, grad_norm: 0.6907876190745882, ic: 0.20228319564550085
train 37, step: 2000, loss: 3.134505332105513, grad_norm: 2.041646875679098, ic: 0.01980933727160248
Epoch 37: 2022-04-04 16:49:02.552961: train loss: 1.6234098801851407
Eval step 0: eval loss: 1.011999402440429
Eval: 2022-04-04 16:49:07.741334: total loss: 1.079513068168898, mse:4.669886544696259, ic :0.17366029240766945, sharpe5:16.37639754652977, irr5:562.4232177734375, ndcg5:0.8475682239235449, pnl5:4.298110008239746 
train 38, step: 0, loss: 1.3605565851384944, grad_norm: 1.6667392102472312, ic: -0.17970337864383035
train 38, step: 500, loss: 1.7204669331395348, grad_norm: 1.1775084084662282, ic: 0.19135681795278484
train 38, step: 1000, loss: 1.8123404359780049, grad_norm: 0.5725735371597096, ic: 0.15383058694132573
train 38, step: 1500, loss: 1.1016944536319915, grad_norm: 0.25918025231920166, ic: 0.4561286652238871
train 38, step: 2000, loss: 0.7600044909818672, grad_norm: 0.042994652859969215, ic: 0.5549633080403842
Epoch 38: 2022-04-04 16:49:40.624179: train loss: 1.6244986375847132
Eval step 0: eval loss: 1.0039755453116772
Eval: 2022-04-04 16:49:45.714286: total loss: 1.0796482535258738, mse:4.679828909506119, ic :0.17105661873557532, sharpe5:15.808252807259558, irr5:540.193359375, ndcg5:0.8631337282671967, pnl5:4.3519606590271 
train 39, step: 0, loss: 0.8643754473983017, grad_norm: 0.029193210107707795, ic: 0.541629766855527
train 39, step: 500, loss: 1.2566319322624298, grad_norm: 0.4162873813395418, ic: 0.004090812179160137
train 39, step: 1000, loss: 1.3895662249940814, grad_norm: 0.3118841241400567, ic: 0.07864861266860419
train 39, step: 1500, loss: 2.442338202086794, grad_norm: 0.5057521694892944, ic: -0.06232960507062407
train 39, step: 2000, loss: 2.8718320063562133, grad_norm: 1.3192894933417034, ic: 0.25006656021047197
Epoch 39: 2022-04-04 16:50:17.934063: train loss: 1.6227279655983085
Eval step 0: eval loss: 1.0100536697974263
Eval: 2022-04-04 16:50:23.098530: total loss: 1.0800686641635426, mse:4.677646453755375, ic :0.16803227139287585, sharpe5:15.10337734401226, irr5:517.0977172851562, ndcg5:0.8465589938695841, pnl5:3.3987605571746826 

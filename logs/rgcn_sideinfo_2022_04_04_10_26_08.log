Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path='./data/ann_type_2431_1931_25.npz', batch_size=1, dataset_type='AdjAnnTimeDataset', dout=0.3, epochs=40, gnn_layers=2, gpu=0, hidden_dim=128, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=3, mask_adj=True, mask_type='soft', model_type='RGCNModel', normalize_adj=True, num_days=1, num_heads=1, print_inteval=500, relation_num=1, seed=10086, shuffle=True, side_info=True, sparse_adj_path=None, stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
13663
RGCNModel(
  (fc1): Linear(in_features=9, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
  (fc4): Linear(in_features=128, out_features=1, bias=True)
  (gnns): ModuleList(
    (0): RGCN(
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
    )
    (1): RGCN(
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
    )
  )
  (dropout): Dropout(p=0.3, inplace=False)
  (relu): LeakyReLU(negative_slope=0.01)
  (type_embed): Embedding(89, 128)
  (fuse_type): Linear(in_features=256, out_features=128, bias=True)
)
train 0, step: 0, loss: 2.059895704668972, grad_norm: 1.9689148016934626, ic: -0.029290290707210835
train 0, step: 500, loss: 1.3425030133505496, grad_norm: 2.2757747110403557, ic: 0.02204279645323264
train 0, step: 1000, loss: 1.5125488680825492, grad_norm: 0.03922840120084158, ic: -0.03244043349240455
train 0, step: 1500, loss: 1.1886642186299001, grad_norm: 0.09845931721828201, ic: -0.061418301111955384
train 0, step: 2000, loss: 1.573258004537443, grad_norm: 0.1868797270440846, ic: -0.01334787899485712
Epoch 0: 2022-04-04 22:26:50.827800: train loss: 1.6516174640952332
Eval step 0: eval loss: 1.0131780012712281
Eval: 2022-04-04 22:26:53.356974: total loss: 1.0908431242328531, mse:4.888310540963268, ic :0.004401667407205187, sharpe5:-0.6882985880970954, irr5:-7.549280166625977, ndcg5:0.8518687116977772, pnl5:1.0413851737976074 
train 1, step: 0, loss: 0.6455265460628095, grad_norm: 0.055427470664159206, ic: -0.008621592332624271
train 1, step: 500, loss: 1.2725079329339815, grad_norm: 0.28623256011017467, ic: -0.0029135883971647576
train 1, step: 1000, loss: 0.8759120483060666, grad_norm: 0.12790825740675646, ic: 0.01130379392112709
train 1, step: 1500, loss: 1.8407600216749238, grad_norm: 0.5188377916874416, ic: -0.032434976208364115
train 1, step: 2000, loss: 1.383332934532925, grad_norm: 0.22186787142104633, ic: -0.00540098672025313
Epoch 1: 2022-04-04 22:27:24.631599: train loss: 1.6476655216833225
Eval step 0: eval loss: 1.013148817531431
Eval: 2022-04-04 22:27:27.036249: total loss: 1.0905792473508706, mse:4.888247408283314, ic :0.0015809681447659257, sharpe5:6.869484210312367, irr5:196.4402313232422, ndcg5:0.8616277071613113, pnl5:2.7900471687316895 
train 2, step: 0, loss: 1.329061233283675, grad_norm: 0.5011154585199413, ic: -0.04467820622461417
train 2, step: 500, loss: 0.9422180453634769, grad_norm: 0.250070581172876, ic: 0.03702493190926263
train 2, step: 1000, loss: 3.064803263567737, grad_norm: 4.989555493091052, ic: 0.05146925851682892
train 2, step: 1500, loss: 2.298042073503172, grad_norm: 0.8167731525876227, ic: 0.008373735972630907
train 2, step: 2000, loss: 1.462415818396106, grad_norm: 0.2677771824193294, ic: -0.00640649760581917
Epoch 2: 2022-04-04 22:27:57.578388: train loss: 1.6470177323492003
Eval step 0: eval loss: 1.013349825360387
Eval: 2022-04-04 22:28:00.138468: total loss: 1.0912669047401773, mse:4.888642179517723, ic :0.006669208499593599, sharpe5:8.625794413089752, irr5:239.6453857421875, ndcg5:0.8547411351167105, pnl5:3.312838554382324 
train 3, step: 0, loss: 1.8149057284692998, grad_norm: 0.052670614150579186, ic: -0.009854002392658653
train 3, step: 500, loss: 0.7576631099409767, grad_norm: 0.03456662160610012, ic: 0.5320614405742046
train 3, step: 1000, loss: 1.4003369289264649, grad_norm: 1.8483886283628597, ic: 0.011554973323206985
train 3, step: 1500, loss: 2.615049334155066, grad_norm: 0.6881756294801107, ic: 0.02226942500908839
train 3, step: 2000, loss: 1.355978670987216, grad_norm: 0.20747889345291412, ic: 0.06116095930947909
Epoch 3: 2022-04-04 22:28:30.557951: train loss: 1.6469346280291317
Eval step 0: eval loss: 1.0136734820341298
Eval: 2022-04-04 22:28:33.013668: total loss: 1.0908651899988477, mse:4.799065934362422, ic :0.09663879711818818, sharpe5:8.231332039833068, irr5:229.23385620117188, ndcg5:0.8586468309167374, pnl5:3.4661436080932617 
train 4, step: 0, loss: 1.1678467725872812, grad_norm: 0.15492724900048382, ic: 0.0017502177111120409
train 4, step: 500, loss: 0.9980532163149352, grad_norm: 0.0025091124073510036, ic: 0.05698395074654597
train 4, step: 1000, loss: 1.3386483734386918, grad_norm: 0.061862920578586306, ic: 0.10558808058230043
train 4, step: 1500, loss: 1.054088338216146, grad_norm: 0.23185852358833042, ic: 0.5893207426417358
train 4, step: 2000, loss: 4.187488859043076, grad_norm: 0.9103471775816626, ic: 0.03662602193131408
Epoch 4: 2022-04-04 22:29:04.652472: train loss: 1.6403354990215822
Eval step 0: eval loss: 1.0137794820053316
Eval: 2022-04-04 22:29:07.064380: total loss: 1.090485650177357, mse:4.757328629262843, ic :0.09377519731156875, sharpe5:7.031682565212249, irr5:201.12734985351562, ndcg5:0.8478034799551306, pnl5:2.839740753173828 
train 5, step: 0, loss: 0.9709457780964394, grad_norm: 0.13162860517160313, ic: -0.014587826653697195
train 5, step: 500, loss: 0.791135381183353, grad_norm: 0.00540193509632532, ic: 0.1097268959195527
train 5, step: 1000, loss: 1.0853170983167748, grad_norm: 0.04243807094871398, ic: 0.4237902052204816
train 5, step: 1500, loss: 1.7656214272103659, grad_norm: 0.3661269741412328, ic: -0.05768529529365418
train 5, step: 2000, loss: 2.1919845119158254, grad_norm: 0.9251989007572615, ic: 0.06233170129268892
Epoch 5: 2022-04-04 22:29:37.174648: train loss: 1.6404392409603048
Eval step 0: eval loss: 1.0024006518644681
Eval: 2022-04-04 22:29:39.641999: total loss: 1.0885421634856134, mse:4.7703735454932055, ic :0.11639006570494813, sharpe5:6.956046818196773, irr5:204.11659240722656, ndcg5:0.8475034809251609, pnl5:3.946286916732788 
train 6, step: 0, loss: 0.7808296469937115, grad_norm: 0.0256277951262991, ic: -0.07157645444046838
train 6, step: 500, loss: 1.448554501896016, grad_norm: 0.2566270192388303, ic: 0.1094764402641574
train 6, step: 1000, loss: 1.23260682143634, grad_norm: 0.16719849756628835, ic: 0.19899083647580407
train 6, step: 1500, loss: 1.0781796322228774, grad_norm: 0.3743068358531809, ic: 0.04990140832053377
train 6, step: 2000, loss: 2.2596461519281914, grad_norm: 1.1574663444497801, ic: 0.10490264406601277
Epoch 6: 2022-04-04 22:30:10.494382: train loss: 1.639136607144867
Eval step 0: eval loss: 1.0005188148984663
Eval: 2022-04-04 22:30:12.927136: total loss: 1.0882448859778062, mse:4.75341414713871, ic :0.11555139456773184, sharpe5:8.172323302030563, irr5:231.6308135986328, ndcg5:0.848318234674361, pnl5:3.0065083503723145 
train 7, step: 0, loss: 1.4584403878578047, grad_norm: 0.7169807544408922, ic: 0.16646856982443692
train 7, step: 500, loss: 1.322014586052672, grad_norm: 0.02327149525194103, ic: 0.17426485725569973
train 7, step: 1000, loss: 0.6484221350997479, grad_norm: 0.06651613025833417, ic: 0.27959845890267554
train 7, step: 1500, loss: 1.000267186900422, grad_norm: 0.12532322241924773, ic: 0.03594054935473325
train 7, step: 2000, loss: 1.5792601958696515, grad_norm: 0.6262745995186823, ic: 0.4206145285136618
Epoch 7: 2022-04-04 22:30:43.924636: train loss: 1.6402264647855722
Eval step 0: eval loss: 0.9950243652086623
Eval: 2022-04-04 22:30:46.369799: total loss: 1.0886118377861733, mse:4.784933876090305, ic :0.11176084208663727, sharpe5:7.78801213055849, irr5:221.62254333496094, ndcg5:0.8429560119249966, pnl5:3.131033182144165 
train 8, step: 0, loss: 1.2034247761465737, grad_norm: 0.17950724364094123, ic: 0.07186737825407791
train 8, step: 500, loss: 5.473576943328761, grad_norm: 4.956076750924226, ic: 0.08394328105812826
train 8, step: 1000, loss: 1.8808501693833466, grad_norm: 0.5487539092654644, ic: 0.06942605531342128
train 8, step: 1500, loss: 1.079091566667959, grad_norm: 0.8158663167475173, ic: 0.6425326162891851
train 8, step: 2000, loss: 1.1248917212853065, grad_norm: 0.694212241725019, ic: 0.013419287089501762
Epoch 8: 2022-04-04 22:31:16.526563: train loss: 1.6422160683734486
Eval step 0: eval loss: 1.0072536378110188
Eval: 2022-04-04 22:31:18.961475: total loss: 1.0933475779643163, mse:4.773643979669763, ic :0.11871912275860493, sharpe5:6.986627177596092, irr5:191.7029571533203, ndcg5:0.8532270414240591, pnl5:3.2715089321136475 
train 9, step: 0, loss: 1.1189626094195475, grad_norm: 0.07433865898144111, ic: 0.44016029964878034
train 9, step: 500, loss: 3.181046066400304, grad_norm: 1.8253947474175125, ic: 0.0900690779007971
train 9, step: 1000, loss: 0.8680532719814507, grad_norm: 0.11378497139017772, ic: 0.20291912669718706
train 9, step: 1500, loss: 2.1568279049964545, grad_norm: 4.196851933402341, ic: -0.053395346814551985
train 9, step: 2000, loss: 0.6056897443265638, grad_norm: 0.0057438194495306304, ic: 0.09691842737435552
Epoch 9: 2022-04-04 22:31:49.717941: train loss: 1.6391278397165407
Eval step 0: eval loss: 1.0008746765361702
Eval: 2022-04-04 22:31:52.258959: total loss: 1.0929194530160606, mse:4.782642165018117, ic :0.11040232120971907, sharpe5:8.270686333179473, irr5:231.27627563476562, ndcg5:0.8292231549279669, pnl5:2.775758743286133 
train 10, step: 0, loss: 1.2847485234249865, grad_norm: 0.1589747765945609, ic: 0.39429795949827395
train 10, step: 500, loss: 0.899235075400398, grad_norm: 0.007243646654926358, ic: 0.08489587567753215
train 10, step: 1000, loss: 1.5435700555526646, grad_norm: 0.6723302356005101, ic: 0.06286477880409196
train 10, step: 1500, loss: 3.131835361243607, grad_norm: 1.720925361309134, ic: 0.044659483479307864
train 10, step: 2000, loss: 1.3896035423394757, grad_norm: 0.21052623438742998, ic: 0.020717283082038924
Epoch 10: 2022-04-04 22:32:22.781267: train loss: 1.640695124529142
Eval step 0: eval loss: 1.005249730532517
Eval: 2022-04-04 22:32:25.197996: total loss: 1.0890271481876626, mse:4.730246532885744, ic :0.12246033078496743, sharpe5:7.985677024126052, irr5:223.1983642578125, ndcg5:0.8483177630909418, pnl5:3.2345266342163086 
train 11, step: 0, loss: 4.847474146672205, grad_norm: 2.7115832475426873, ic: 0.06109950748999217
train 11, step: 500, loss: 0.990514142905146, grad_norm: 0.09806505468351222, ic: 0.03489408574924182
train 11, step: 1000, loss: 1.031983166773932, grad_norm: 0.522697703706459, ic: 0.04255658706661602
train 11, step: 1500, loss: 0.6931108371671887, grad_norm: 0.0032708657904225893, ic: 0.11550377639530872
train 11, step: 2000, loss: 1.115836991806712, grad_norm: 0.08920726601414174, ic: -0.18341849447591216
Epoch 11: 2022-04-04 22:32:55.925421: train loss: 1.6364166617240956
Eval step 0: eval loss: 1.0021364554535281
Eval: 2022-04-04 22:32:58.348642: total loss: 1.0887008378758736, mse:4.787601478755828, ic :0.11485732104888127, sharpe5:8.223883820772171, irr5:228.1763153076172, ndcg5:0.8689972500639287, pnl5:4.373335361480713 
train 12, step: 0, loss: 1.3980481746078897, grad_norm: 0.4545097040652313, ic: 0.06761691126624103
train 12, step: 500, loss: 0.8081983462411207, grad_norm: 0.540541609745694, ic: 0.035351853062818975
train 12, step: 1000, loss: 1.2229994318416062, grad_norm: 1.0525350774171953, ic: 0.5734401611010234
train 12, step: 1500, loss: 1.082907393802561, grad_norm: 0.26698656596567455, ic: 0.08534573677081181
train 12, step: 2000, loss: 1.1197119672887978, grad_norm: 0.07716417438404476, ic: 0.0878629547999197
Epoch 12: 2022-04-04 22:33:29.314140: train loss: 1.636855328686509
Eval step 0: eval loss: 1.0069715068991902
Eval: 2022-04-04 22:33:31.698616: total loss: 1.0876799621159328, mse:4.705303154306458, ic :0.14534650088679182, sharpe5:13.391917735934257, irr5:413.2370300292969, ndcg5:0.849090853753409, pnl5:4.886874675750732 
train 13, step: 0, loss: 1.0768658257619292, grad_norm: 0.14974981767329548, ic: 0.44118231828453947
train 13, step: 500, loss: 1.1455625111820134, grad_norm: 0.01405418130175987, ic: -0.17136752571717082
train 13, step: 1000, loss: 1.3940131955030488, grad_norm: 0.5393481639464243, ic: 0.0749902586713595
train 13, step: 1500, loss: 0.7755872009370243, grad_norm: 0.004781411693320366, ic: -0.046993365114466334
train 13, step: 2000, loss: 1.0365494641657067, grad_norm: 0.04649907266544221, ic: 0.0722764676801363
Epoch 13: 2022-04-04 22:34:02.068859: train loss: 1.6321041735379265
Eval step 0: eval loss: 0.9996506307801802
Eval: 2022-04-04 22:34:04.483250: total loss: 1.0848870698079127, mse:4.734596945732107, ic :0.144603472801021, sharpe5:13.534213340878486, irr5:420.61279296875, ndcg5:0.847028561319993, pnl5:6.153614521026611 
train 14, step: 0, loss: 1.760229337013374, grad_norm: 1.1612835039378273, ic: 0.19675182461123658
train 14, step: 500, loss: 1.2656122637881153, grad_norm: 0.31323938851711874, ic: 0.23767621919429735
train 14, step: 1000, loss: 1.0763110956869835, grad_norm: 0.1696425345633117, ic: 0.15440525221943519
train 14, step: 1500, loss: 0.9867556999975943, grad_norm: 0.07482917181492427, ic: 0.1719610130644797
train 14, step: 2000, loss: 2.3125764681892336, grad_norm: 0.6014002273217247, ic: -0.062288740229118476
Epoch 14: 2022-04-04 22:34:35.511651: train loss: 1.6306068722972562
Eval step 0: eval loss: 1.0053669154612623
Eval: 2022-04-04 22:34:37.909191: total loss: 1.0867919370049777, mse:4.724246885995196, ic :0.15468960279696983, sharpe5:14.669993911385536, irr5:476.229736328125, ndcg5:0.8496654158299647, pnl5:6.247546672821045 
train 15, step: 0, loss: 0.9767210063036214, grad_norm: 0.16064969980365973, ic: 0.14445145648582902
train 15, step: 500, loss: 1.2214189475506112, grad_norm: 0.014420572261075465, ic: 0.12697686610567718
train 15, step: 1000, loss: 1.7950135416666668, grad_norm: 2.107572861703567, ic: 0.06577991352299631
train 15, step: 1500, loss: 5.425341683584686, grad_norm: 1.0577934897161685, ic: 0.03951377145577301
train 15, step: 2000, loss: 0.9273350442102712, grad_norm: 0.037977771218303265, ic: 0.06558155848586521
Epoch 15: 2022-04-04 22:35:08.986198: train loss: 1.6302665167347974
Eval step 0: eval loss: 1.009245910162421
Eval: 2022-04-04 22:35:11.401703: total loss: 1.0854383775507166, mse:4.70071072136454, ic :0.15888776301000695, sharpe5:14.13713125526905, irr5:469.868896484375, ndcg5:0.8633482426992507, pnl5:5.495785236358643 
train 16, step: 0, loss: 6.324437731863149, grad_norm: 1.7958531199564607, ic: 0.16222712560216682
train 16, step: 500, loss: 1.3893824017237104, grad_norm: 0.7324038560556299, ic: -0.014953502999419686
train 16, step: 1000, loss: 0.8166710471645849, grad_norm: 0.1659705853657823, ic: 0.008097903641800684
train 16, step: 1500, loss: 1.2145478672532517, grad_norm: 0.27566498325581235, ic: 0.09030460627860215
train 16, step: 2000, loss: 0.9705002936225654, grad_norm: 0.48135858991729447, ic: 0.5378650976168391
Epoch 16: 2022-04-04 22:35:42.822531: train loss: 1.6288744861417026
Eval step 0: eval loss: 1.00135614396146
Eval: 2022-04-04 22:35:45.253468: total loss: 1.086782975789939, mse:4.756534052126957, ic :0.1197564144574366, sharpe5:9.644810859560966, irr5:280.23052978515625, ndcg5:0.8512023343411329, pnl5:4.240363121032715 
train 17, step: 0, loss: 1.1878755721577838, grad_norm: 0.039533510178050256, ic: 0.13560685204608983
train 17, step: 500, loss: 1.030661055547767, grad_norm: 0.061506701209465366, ic: -0.019777939388992357
train 17, step: 1000, loss: 3.3776291447504128, grad_norm: 1.5675374418015642, ic: -0.01195242942267919
train 17, step: 1500, loss: 0.8863458232200647, grad_norm: 0.03991716190166065, ic: 0.07980266670271641
train 17, step: 2000, loss: 0.9877285746119966, grad_norm: 1.3730112860562356, ic: 0.5777558776130691
Epoch 17: 2022-04-04 22:36:16.170369: train loss: 1.6288211809924444
Eval step 0: eval loss: 1.0006397281463928
Eval: 2022-04-04 22:36:18.589333: total loss: 1.0839353526075486, mse:4.704056404723166, ic :0.15892484994544587, sharpe5:14.80015518128872, irr5:485.03466796875, ndcg5:0.8520767818108246, pnl5:6.603172302246094 
train 18, step: 0, loss: 0.8541274449303328, grad_norm: 0.008026413636178578, ic: 0.012297206110416067
train 18, step: 500, loss: 2.4994148248125514, grad_norm: 1.0531251155061938, ic: 0.106209837154433
train 18, step: 1000, loss: 1.3614642465714928, grad_norm: 0.38340454526998896, ic: 0.5336198850358803
train 18, step: 1500, loss: 1.7743679786916757, grad_norm: 0.6665637561637956, ic: 0.3456991935764804
train 18, step: 2000, loss: 1.265632475131788, grad_norm: 0.6094613241448855, ic: 0.17762675677916667
Epoch 18: 2022-04-04 22:36:49.289202: train loss: 1.628663148112004
Eval step 0: eval loss: 1.0016672657689902
Eval: 2022-04-04 22:36:51.731040: total loss: 1.0871288217948538, mse:4.718188444105643, ic :0.1245391869421805, sharpe5:8.062508894205093, irr5:226.63275146484375, ndcg5:0.859642170305888, pnl5:4.0474419593811035 
train 19, step: 0, loss: 2.245089168300497, grad_norm: 0.8422103351908471, ic: 0.08554783882776568
train 19, step: 500, loss: 1.0141903899436773, grad_norm: 0.08862397613190394, ic: 0.05131720879589608
train 19, step: 1000, loss: 0.9875594499320204, grad_norm: 0.3220958790618932, ic: 0.5546912186416099
train 19, step: 1500, loss: 1.5818259156780476, grad_norm: 0.08672834663185343, ic: 0.14279145918703806
train 19, step: 2000, loss: 1.4053825738350736, grad_norm: 18.721648103852555, ic: 0.6421495250854179
Epoch 19: 2022-04-04 22:37:22.974239: train loss: 1.6307726957095456
Eval step 0: eval loss: 1.0003437124596826
Eval: 2022-04-04 22:37:25.397577: total loss: 1.0853285748175507, mse:4.721501139695185, ic :0.1217339804545135, sharpe5:8.281744204759597, irr5:229.3269805908203, ndcg5:0.8525213955810372, pnl5:3.6874215602874756 
train 20, step: 0, loss: 1.2414036320331983, grad_norm: 0.5079894857363818, ic: 0.4670618187616288
train 20, step: 500, loss: 1.2223156038681708, grad_norm: 0.4557394205624973, ic: 2.896401364242164e-05
train 20, step: 1000, loss: 1.5600647974291955, grad_norm: 0.35278522345257135, ic: 0.1477266575574617
train 20, step: 1500, loss: 0.8608998956881196, grad_norm: 1.1719519949160127, ic: 0.5765857961896267
train 20, step: 2000, loss: 1.3336247757932498, grad_norm: 0.3558581359340533, ic: -0.011054089667279325
Epoch 20: 2022-04-04 22:37:55.824175: train loss: 1.630746764187023
Eval step 0: eval loss: 1.021005478829318
Eval: 2022-04-04 22:37:58.237848: total loss: 1.1210844218140792, mse:5.021901113155039, ic :0.1300875734928219, sharpe5:14.203434026241302, irr5:463.9953308105469, ndcg5:0.8623933050899164, pnl5:6.391502380371094 
train 21, step: 0, loss: 1.280623633381924, grad_norm: 1.8588896273636342, ic: 0.3234777588055647
train 21, step: 500, loss: 1.1099354773873853, grad_norm: 0.08352200283816306, ic: 0.07515388128768015
train 21, step: 1000, loss: 0.9271711664505443, grad_norm: 0.14637660721528928, ic: 0.09806668332243587
train 21, step: 1500, loss: 0.7323359889327313, grad_norm: 0.18172425065257505, ic: 0.6305997666400506
train 21, step: 2000, loss: 1.138220250694062, grad_norm: 0.23279698976973195, ic: 0.25492316311161467
Epoch 21: 2022-04-04 22:38:29.194704: train loss: 1.6278060731575645
Eval step 0: eval loss: 1.006206558653403
Eval: 2022-04-04 22:38:31.618590: total loss: 1.0840712974195135, mse:4.693313750856762, ic :0.1509295376905289, sharpe5:13.010021039843558, irr5:395.98736572265625, ndcg5:0.852662585069106, pnl5:5.994630813598633 
train 22, step: 0, loss: 1.0555443472417605, grad_norm: 0.22904062272728393, ic: 0.07135618159528778
train 22, step: 500, loss: 1.027581162340059, grad_norm: 0.0032346988284460594, ic: -0.0386424218102323
train 22, step: 1000, loss: 0.9178484542368018, grad_norm: 0.014214214081384147, ic: 0.14403045696505656
train 22, step: 1500, loss: 0.9970336153499805, grad_norm: 0.045671226739095065, ic: 0.2805529997340951
train 22, step: 2000, loss: 1.0541099370912064, grad_norm: 0.19887094374413283, ic: 0.11867389646331888
Epoch 22: 2022-04-04 22:39:02.351671: train loss: 1.627356073034963
Eval step 0: eval loss: 1.0147998843963928
Eval: 2022-04-04 22:39:04.798656: total loss: 1.0845696604395185, mse:4.686407436314962, ic :0.16542405559221385, sharpe5:14.842984805703162, irr5:496.26513671875, ndcg5:0.8626394465471677, pnl5:5.202576160430908 
train 23, step: 0, loss: 1.285423961501668, grad_norm: 0.9664129928081533, ic: -0.011619479282947098
train 23, step: 500, loss: 0.9186054271656079, grad_norm: 0.423718274806774, ic: 0.5814863731606199
train 23, step: 1000, loss: 2.2894401248019016, grad_norm: 1.155864541773411, ic: 0.11839535810977365
train 23, step: 1500, loss: 0.7668335917101827, grad_norm: 0.583524411621259, ic: 0.7168318727803403
train 23, step: 2000, loss: 1.4723865050577523, grad_norm: 1.0272756883250325, ic: 0.40013768379625464
Epoch 23: 2022-04-04 22:39:35.489545: train loss: 1.6271963810623098
Eval step 0: eval loss: 1.0049829628669693
Eval: 2022-04-04 22:39:37.926605: total loss: 1.0869670669621556, mse:4.697477700951286, ic :0.1552378384050129, sharpe5:14.309447704553603, irr5:451.5592041015625, ndcg5:0.8502432892428432, pnl5:6.198301315307617 
train 24, step: 0, loss: 1.1627965327076015, grad_norm: 0.2479140180770927, ic: 0.3189570665865875
train 24, step: 500, loss: 1.2752842906774409, grad_norm: 0.6536530807740761, ic: 0.009221104874549631
train 24, step: 1000, loss: 1.065211412383289, grad_norm: 0.44630658849073895, ic: 0.11489905877601514
train 24, step: 1500, loss: 1.1918253260334646, grad_norm: 0.08455409997070518, ic: 0.07837873105857203
train 24, step: 2000, loss: 1.3661656834189047, grad_norm: 0.5766503529354293, ic: 0.447953795275236
Epoch 24: 2022-04-04 22:40:08.991082: train loss: 1.6296544134584596
Eval step 0: eval loss: 1.0053046268183912
Eval: 2022-04-04 22:40:11.441001: total loss: 1.0871047753902754, mse:4.763060592569512, ic :0.13223796933122267, sharpe5:13.03657601237297, irr5:379.1171875, ndcg5:0.8371911802006956, pnl5:6.113757133483887 
train 25, step: 0, loss: 1.3144539601446694, grad_norm: 1.42468544028704, ic: 0.14775423308746116
train 25, step: 500, loss: 1.4966618921849635, grad_norm: 0.2733899002979844, ic: 0.11171221825329822
train 25, step: 1000, loss: 1.3773897422189476, grad_norm: 0.2930926157513952, ic: 0.25990805977068027
train 25, step: 1500, loss: 2.9076098827841323, grad_norm: 1.8689977371028328, ic: 0.18750613818652812
train 25, step: 2000, loss: 1.2024055191233187, grad_norm: 0.12897631014822078, ic: 0.1376956776764905
Epoch 25: 2022-04-04 22:40:41.625446: train loss: 1.6290736217547428
Eval step 0: eval loss: 1.0074103557793574
Eval: 2022-04-04 22:40:44.039211: total loss: 1.082982137322668, mse:4.684872320579461, ic :0.17130455661758964, sharpe5:15.532737754583358, irr5:507.6219177246094, ndcg5:0.8509610409791794, pnl5:6.513256072998047 
train 26, step: 0, loss: 1.6198160511363635, grad_norm: 0.19318504476302928, ic: 0.20768339387907328
train 26, step: 500, loss: 1.0291085035563887, grad_norm: 0.155637185787054, ic: -0.1011023961566998
train 26, step: 1000, loss: 1.8412100024068485, grad_norm: 1.0534494575615443, ic: 0.18552422397324983
train 26, step: 1500, loss: 0.9244346054109408, grad_norm: 0.011483351192706532, ic: -0.06954202077418056
train 26, step: 2000, loss: 0.9939776082677165, grad_norm: 0.09887155358408019, ic: 0.13386117228127703
Epoch 26: 2022-04-04 22:41:14.436957: train loss: 1.6274507678278816
Eval step 0: eval loss: 1.0017513457946616
Eval: 2022-04-04 22:41:16.853881: total loss: 1.0840866727470762, mse:4.701683494323979, ic :0.16024619230042336, sharpe5:14.194961369633674, irr5:442.9292297363281, ndcg5:0.8505074858896775, pnl5:7.86594820022583 
train 27, step: 0, loss: 1.690199518778238, grad_norm: 0.7012223267005705, ic: 0.672446064598518
train 27, step: 500, loss: 1.5428943307737168, grad_norm: 1.7894312539819015, ic: 0.059187265821173424
train 27, step: 1000, loss: 2.5594083108731547, grad_norm: 1.2521097154385314, ic: 0.40310126053809414
train 27, step: 1500, loss: 0.8349783882178174, grad_norm: 0.6487004505455314, ic: 0.5431925823820078
train 27, step: 2000, loss: 1.3736943539386521, grad_norm: 0.7435057016354121, ic: -0.02001762310851558
Epoch 27: 2022-04-04 22:41:47.858911: train loss: 1.6261994599943335
Eval step 0: eval loss: 1.0040802596555751
Eval: 2022-04-04 22:41:50.270750: total loss: 1.082553422364904, mse:4.689024713679715, ic :0.15675597841302097, sharpe5:13.86826795220375, irr5:423.9103698730469, ndcg5:0.8582738653813712, pnl5:5.498909950256348 
train 28, step: 0, loss: 1.1825075215610565, grad_norm: 0.14544007159283626, ic: 0.05425821299146594
train 28, step: 500, loss: 2.942832079515033, grad_norm: 0.9365355311521558, ic: 0.09605940703307243
train 28, step: 1000, loss: 2.814364416716035, grad_norm: 4.641553246654491, ic: -0.0744549834630716
train 28, step: 1500, loss: 1.0265000267177904, grad_norm: 0.015726804915998503, ic: 0.19595622600552864
train 28, step: 2000, loss: 1.768883461175963, grad_norm: 0.3050100679399494, ic: 0.10006120971051886
Epoch 28: 2022-04-04 22:42:22.140560: train loss: 1.625765679319223
Eval step 0: eval loss: 1.0099443914765995
Eval: 2022-04-04 22:42:24.539441: total loss: 1.083407847044476, mse:4.697649310176741, ic :0.15886530240175534, sharpe5:14.870159359574318, irr5:458.4337463378906, ndcg5:0.8542678858381749, pnl5:7.14905309677124 
train 29, step: 0, loss: 1.51587339781558, grad_norm: 0.15225609826540848, ic: 0.07210708156192916
train 29, step: 500, loss: 2.53698831020902, grad_norm: 1.0378771911359093, ic: -0.044006234225365176
train 29, step: 1000, loss: 1.6717256433823529, grad_norm: 0.9403049754467682, ic: 0.48295195805545776
train 29, step: 1500, loss: 3.937978321675389, grad_norm: 2.842712572916841, ic: 0.16045152794949155
train 29, step: 2000, loss: 0.9439775957728422, grad_norm: 0.1899998899341371, ic: 0.4674474688621058
Epoch 29: 2022-04-04 22:42:54.960310: train loss: 1.6265181415699883
Eval step 0: eval loss: 1.0036945071830567
Eval: 2022-04-04 22:42:57.383293: total loss: 1.0833828802374568, mse:4.7003158806417105, ic :0.15951251209117073, sharpe5:15.344231786727905, irr5:487.8353271484375, ndcg5:0.8329943335493056, pnl5:4.4790239334106445 
train 30, step: 0, loss: 1.2641183880582891, grad_norm: 0.07765295896383001, ic: 0.9544448110179443
train 30, step: 500, loss: 1.9334741906274724, grad_norm: 0.2595845863309912, ic: 0.16525678731277807
train 30, step: 1000, loss: 3.4300612142680103, grad_norm: 0.7644641620074626, ic: 0.4238955346775087
train 30, step: 1500, loss: 1.0978162696324483, grad_norm: 0.4040691817789982, ic: 0.12913034346101288
train 30, step: 2000, loss: 1.0958356645866758, grad_norm: 0.16760741611448415, ic: 0.442191108605506
Epoch 30: 2022-04-04 22:43:27.487310: train loss: 1.6271548786643384
Eval step 0: eval loss: 1.001932040712217
Eval: 2022-04-04 22:43:29.923874: total loss: 1.0837985379990267, mse:4.684104560365931, ic :0.16818307388955867, sharpe5:14.949183885455131, irr5:480.5882263183594, ndcg5:0.8397175364406659, pnl5:6.612580299377441 
train 31, step: 0, loss: 1.1889689717315821, grad_norm: 0.3054769577352686, ic: 0.18430800633297784
train 31, step: 500, loss: 0.816977313466621, grad_norm: 0.23418631518352678, ic: 0.23639263339987687
train 31, step: 1000, loss: 5.015777754134241, grad_norm: 0.5230433370434071, ic: 0.06730150236481337
train 31, step: 1500, loss: 1.6801221986089645, grad_norm: 0.47193288446139814, ic: 0.24602412817220157
train 31, step: 2000, loss: 0.9942732653855364, grad_norm: 0.813528766526571, ic: 0.1336261046600068
Epoch 31: 2022-04-04 22:44:00.739028: train loss: 1.6266526695190628
Eval step 0: eval loss: 1.0039111353837544
Eval: 2022-04-04 22:44:03.166078: total loss: 1.0857456563998344, mse:4.7035496561006145, ic :0.1582002099897376, sharpe5:14.410211495161056, irr5:461.4474792480469, ndcg5:0.8551823129312859, pnl5:6.4212164878845215 
train 32, step: 0, loss: 0.8564636369290182, grad_norm: 0.41104964439547775, ic: 0.11251669792516494
train 32, step: 500, loss: 1.135156677990425, grad_norm: 0.3486036042945835, ic: 0.14900379396589952
train 32, step: 1000, loss: 1.3968921015750133, grad_norm: 0.42964403582569916, ic: 0.061529395619653385
train 32, step: 1500, loss: 2.085366641773897, grad_norm: 0.4060129828990395, ic: 0.4501558871036337
train 32, step: 2000, loss: 1.0615579060943907, grad_norm: 0.5383368553911827, ic: 0.47213805754551014
Epoch 32: 2022-04-04 22:44:33.958825: train loss: 1.6252139663171472
Eval step 0: eval loss: 0.9977888496001184
Eval: 2022-04-04 22:44:36.449500: total loss: 1.0817619236485863, mse:4.702344690001954, ic :0.1691608019954191, sharpe5:15.409520525336264, irr5:504.1043395996094, ndcg5:0.8528537277030043, pnl5:7.1302490234375 
train 33, step: 0, loss: 1.1621369783708937, grad_norm: 0.021984006812342215, ic: -0.038188406788479276
train 33, step: 500, loss: 3.134267960943505, grad_norm: 0.6449779136821028, ic: 0.5255667940300061
train 33, step: 1000, loss: 5.2533425749954485, grad_norm: 1.7792275375569249, ic: 0.015285136262487802
train 33, step: 1500, loss: 1.2751577982088416, grad_norm: 1.911606190367214, ic: 0.07324648944835115
train 33, step: 2000, loss: 1.8616146590358527, grad_norm: 0.8336262588264628, ic: 0.07612147924388704
Epoch 33: 2022-04-04 22:45:06.441190: train loss: 1.6254049914597113
Eval step 0: eval loss: 1.0105784628628554
Eval: 2022-04-04 22:45:08.892250: total loss: 1.086948697764305, mse:4.689570862015249, ic :0.17010388014540972, sharpe5:14.85910432577133, irr5:478.37481689453125, ndcg5:0.850230505893007, pnl5:6.084629058837891 
train 34, step: 0, loss: 0.7258068634855388, grad_norm: 0.2430048616468308, ic: 0.19419254701269686
train 34, step: 500, loss: 1.812373273303104, grad_norm: 1.3520592964592772, ic: 0.7709390386252537
train 34, step: 1000, loss: 0.6871324420797413, grad_norm: 0.08437999125143512, ic: 0.48996472122759893
train 34, step: 1500, loss: 1.6470496544471154, grad_norm: 1.3072327032725177, ic: 0.6495322834289037
train 34, step: 2000, loss: 2.986629580351627, grad_norm: 0.6992858078863038, ic: 0.10511093149786574
Epoch 34: 2022-04-04 22:45:39.261955: train loss: 1.626022819414841
Eval step 0: eval loss: 1.0058043501513954
Eval: 2022-04-04 22:45:41.693608: total loss: 1.0820972607843389, mse:4.681665142776626, ic :0.1649200656149628, sharpe5:14.593388117551802, irr5:480.9250183105469, ndcg5:0.85209726032308, pnl5:8.135371208190918 
train 35, step: 0, loss: 1.049624575844294, grad_norm: 0.612963453407082, ic: 0.006355898478519015
train 35, step: 500, loss: 3.3095311020359848, grad_norm: 1.6255875518828584, ic: -0.06306275202154088
train 35, step: 1000, loss: 1.327087593676528, grad_norm: 0.040141382752649245, ic: 0.5127741022163361
train 35, step: 1500, loss: 1.663043547809173, grad_norm: 0.5467080684743368, ic: 0.06121290188782124
train 35, step: 2000, loss: 1.2790276437103059, grad_norm: 0.13445723595150272, ic: 0.08617821601963391
Epoch 35: 2022-04-04 22:46:12.510455: train loss: 1.6268404975798094
Eval step 0: eval loss: 1.0023844529604395
Eval: 2022-04-04 22:46:14.936045: total loss: 1.084983442316957, mse:4.693360162401512, ic :0.1604386456586423, sharpe5:14.993622529506682, irr5:447.3771667480469, ndcg5:0.8365616741261969, pnl5:5.438394069671631 
train 36, step: 0, loss: 9.040629470451854, grad_norm: 1.244738329282759, ic: -0.0630946832535112
train 36, step: 500, loss: 0.8583001159159728, grad_norm: 0.012893282295280367, ic: 0.1597773785059338
train 36, step: 1000, loss: 1.9766348517049772, grad_norm: 2.1225844805400604, ic: 0.0847056519644623
train 36, step: 1500, loss: 1.0585114267996814, grad_norm: 0.1883607986151228, ic: 0.0730400577537573
train 36, step: 2000, loss: 2.1830942604105354, grad_norm: 1.5424369312857753, ic: 0.35888414542627645
Epoch 36: 2022-04-04 22:46:45.400009: train loss: 1.6253215062920598
Eval step 0: eval loss: 1.0099467698871116
Eval: 2022-04-04 22:46:47.850432: total loss: 1.0856167934984076, mse:4.689613098208186, ic :0.16565328573203025, sharpe5:14.874419808983802, irr5:497.58758544921875, ndcg5:0.8480400138510402, pnl5:5.630728721618652 
train 37, step: 0, loss: 1.1951593877523625, grad_norm: 0.18449510944337827, ic: 0.15727604704051815
train 37, step: 500, loss: 2.3418552256224068, grad_norm: 0.08063741063862646, ic: 0.14978344613862454
train 37, step: 1000, loss: 0.7211576966589491, grad_norm: 0.4431930321225135, ic: 0.18493320241404115
train 37, step: 1500, loss: 3.1366790926395938, grad_norm: 2.0089671239023668, ic: 0.19573715295018937
train 37, step: 2000, loss: 3.1583657616444865, grad_norm: 1.8654404076991289, ic: 0.02050427830963461
Epoch 37: 2022-04-04 22:47:18.440259: train loss: 1.6258303810820047
Eval step 0: eval loss: 1.0091346391192733
Eval: 2022-04-04 22:47:20.873385: total loss: 1.0818562323164707, mse:4.68256502548204, ic :0.16587240902952938, sharpe5:15.510709982514381, irr5:504.8367919921875, ndcg5:0.8524541114558738, pnl5:7.4076104164123535 
train 38, step: 0, loss: 1.3424910111860795, grad_norm: 0.6597767378435746, ic: -0.23965293441283983
train 38, step: 500, loss: 1.740288691557655, grad_norm: 1.0755385756683684, ic: 0.18392353096651287
train 38, step: 1000, loss: 1.8253748220247448, grad_norm: 0.5955891452388582, ic: 0.13170497061417188
train 38, step: 1500, loss: 1.0808340857733312, grad_norm: 0.14090594564955808, ic: 0.47863119536632964
train 38, step: 2000, loss: 0.7564221710498114, grad_norm: 0.0629345858737081, ic: 0.5618802629901187
Epoch 38: 2022-04-04 22:47:51.766015: train loss: 1.6243431670711905
Eval step 0: eval loss: 1.0005991023235912
Eval: 2022-04-04 22:47:54.197488: total loss: 1.0802883468244928, mse:4.689471817747843, ic :0.167583049310415, sharpe5:14.5609712433815, irr5:479.8928527832031, ndcg5:0.8508751142676461, pnl5:4.796478271484375 
train 39, step: 0, loss: 0.8681199976241607, grad_norm: 0.05483597216364099, ic: 0.5396614309480408
train 39, step: 500, loss: 1.2525573094176021, grad_norm: 0.6017621927343931, ic: 0.026742244606366924
train 39, step: 1000, loss: 1.3834088874585702, grad_norm: 0.30178334566551546, ic: 0.08938998019752975
train 39, step: 1500, loss: 2.459135442081084, grad_norm: 0.3490682969158945, ic: -0.07818281589118681
train 39, step: 2000, loss: 2.8269420265201806, grad_norm: 1.7618174483412963, ic: 0.2687198793821905
Epoch 39: 2022-04-04 22:48:24.990177: train loss: 1.6270598061291093
Eval step 0: eval loss: 1.0044539915128028
Eval: 2022-04-04 22:48:27.432589: total loss: 1.0816373730426938, mse:4.6868651525829526, ic :0.1633264411196182, sharpe5:14.817737102508545, irr5:465.81658935546875, ndcg5:0.8589102853380813, pnl5:5.332361698150635 

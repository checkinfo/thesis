Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='AdjTimeDataset', dout=0.3, epochs=40, gnn_layers=2, gpu=0, hidden_dim=128, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=3, mask_adj=True, mask_type='soft', model_type='GNNModel', normalize_adj=False, num_days=1, num_heads=1, print_inteval=500, relation_num=1, seed=10086, shuffle=True, side_info=False, sparse_adj_path=None, stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=False)
61293
GNNModel(
  (fc1): Linear(in_features=9, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
  (fc4): Linear(in_features=128, out_features=1, bias=True)
  (gnns): ModuleList(
    (0): GraphConv(128, 128)
    (1): GraphConv(128, 128)
  )
  (dropout): Dropout(p=0.3, inplace=False)
  (relu): LeakyReLU(negative_slope=0.01)
)
train 0, step: 0, loss: 2.073332509881423, grad_norm: 0.4717636941742139, ic: 0.06189800533425492
train 0, step: 500, loss: 1.3650571463052028, grad_norm: 0.8584379162562451, ic: -0.045492285115052905
train 0, step: 1000, loss: 1.5060294942652925, grad_norm: 0.03218015448422127, ic: 0.23227565369522796
train 0, step: 1500, loss: 1.1881914190106169, grad_norm: 0.09577819652584414, ic: 0.04192799896928863
train 0, step: 2000, loss: 1.55973694964153, grad_norm: 0.050215591960850646, ic: -0.025572001440086586
Epoch 0: 2022-04-04 01:14:11.326289: train loss: 1.6474781071088211
Eval step 0: eval loss: 1.0094022424425684
Eval: 2022-04-04 01:14:13.430309: total loss: 1.0905765018516989, mse:4.885819782246167, ic :0.025259621192121048, sharpe5:6.717529757916927, irr5:202.28819274902344, ndcg5:0.8516645807386475, pnl5:2.366215467453003 
train 1, step: 0, loss: 0.6448176922184407, grad_norm: 0.06145966924723124, ic: 0.0643958297564614
train 1, step: 500, loss: 1.262099687918901, grad_norm: 0.2920312914169077, ic: 0.2697854457592092
train 1, step: 1000, loss: 0.8780180483017431, grad_norm: 0.06270647019775791, ic: 0.09910563208024355
train 1, step: 1500, loss: 1.8571282363519437, grad_norm: 0.5483185422459214, ic: 0.08787208620425592
train 1, step: 2000, loss: 1.3744353547030532, grad_norm: 0.24446108547926937, ic: 0.12514817924814337
Epoch 1: 2022-04-04 01:14:33.587560: train loss: 1.645648373927245
Eval step 0: eval loss: 1.0014495447850842
Eval: 2022-04-04 01:14:35.719235: total loss: 1.0882545093239435, mse:4.87623494127656, ic :0.05472350438388757, sharpe5:7.143103627860546, irr5:214.27586364746094, ndcg5:0.8512562123557302, pnl5:3.195934534072876 
train 2, step: 0, loss: 1.3301705122875092, grad_norm: 0.520663262930618, ic: 0.07600604197093407
train 2, step: 500, loss: 0.9550633061456753, grad_norm: 0.3039070249327639, ic: 0.08178085458989207
train 2, step: 1000, loss: 3.1414565126836234, grad_norm: 3.9057770695302123, ic: 0.16214896631570586
train 2, step: 1500, loss: 2.2924092207325537, grad_norm: 0.8823137777225885, ic: 0.07549996256990522
train 2, step: 2000, loss: 1.460756640305601, grad_norm: 0.2775293621186482, ic: -0.10593605204214872
Epoch 2: 2022-04-04 01:14:55.966469: train loss: 1.6443341041066233
Eval step 0: eval loss: 0.9977658368713795
Eval: 2022-04-04 01:14:58.128932: total loss: 1.0884726046264697, mse:4.873100571031851, ic :0.0600150488270967, sharpe5:7.332347417771816, irr5:215.32510375976562, ndcg5:0.8350704424890026, pnl5:2.7016758918762207 
train 3, step: 0, loss: 1.8304405066469012, grad_norm: 0.06793794013957909, ic: -0.11087577122928205
train 3, step: 500, loss: 0.7782157710422057, grad_norm: 0.01969013993489798, ic: 0.14354949038714915
train 3, step: 1000, loss: 1.3804732835093225, grad_norm: 0.49466213646001495, ic: 0.24209387518138176
train 3, step: 1500, loss: 2.6081308835436, grad_norm: 0.48212806779171113, ic: -0.05873893623969756
train 3, step: 2000, loss: 1.34139228589607, grad_norm: 0.17720095765564187, ic: 0.06709604503921994
Epoch 3: 2022-04-04 01:15:18.484711: train loss: 1.6435501599377438
Eval step 0: eval loss: 1.0012235315050684
Eval: 2022-04-04 01:15:20.558184: total loss: 1.0867168979908968, mse:4.712024395019815, ic :0.1271844572807905, sharpe5:10.751703804731369, irr5:302.3879699707031, ndcg5:0.8430118974928218, pnl5:3.4880259037017822 
train 4, step: 0, loss: 1.1637240660970796, grad_norm: 0.1523754805506952, ic: 0.08759448729412089
train 4, step: 500, loss: 0.9873504355577459, grad_norm: 0.006988973537210765, ic: 0.1566585797829278
train 4, step: 1000, loss: 1.327616606478833, grad_norm: 0.06222972254998935, ic: 0.07069809374399218
train 4, step: 1500, loss: 1.052061736278045, grad_norm: 0.13275436492243858, ic: 0.6077970371507657
train 4, step: 2000, loss: 4.187118134097168, grad_norm: 0.8936194565281821, ic: -0.02319319250743901
Epoch 4: 2022-04-04 01:15:40.718823: train loss: 1.6378916219426565
Eval step 0: eval loss: 1.0179816834106765
Eval: 2022-04-04 01:15:43.276232: total loss: 1.1013340935752547, mse:4.754017985516083, ic :0.12544370739681698, sharpe5:11.682154172658919, irr5:354.8931884765625, ndcg5:0.8531983008507736, pnl5:4.046365737915039 
train 5, step: 0, loss: 0.9872517872655655, grad_norm: 0.16934594027575672, ic: -0.08108987665047232
train 5, step: 500, loss: 0.7879542249827212, grad_norm: 0.01826035994364995, ic: 0.15266893347172403
train 5, step: 1000, loss: 1.101200695653895, grad_norm: 0.07469496003571102, ic: 0.3919445009137291
train 5, step: 1500, loss: 1.7510067327235772, grad_norm: 0.33436268178734624, ic: -0.01405196785555677
train 5, step: 2000, loss: 2.177409718534254, grad_norm: 0.8244109439617227, ic: 0.029121991597175143
Epoch 5: 2022-04-04 01:16:03.826080: train loss: 1.6348755355368891
Eval step 0: eval loss: 1.0071592727669167
Eval: 2022-04-04 01:16:05.999668: total loss: 1.0859766088709852, mse:4.716213738272434, ic :0.14569577683352872, sharpe5:14.112488944530487, irr5:437.4449462890625, ndcg5:0.8383559496060341, pnl5:5.31718111038208 
train 6, step: 0, loss: 0.7635006757732289, grad_norm: 0.021264811460914166, ic: 0.19970711513885275
train 6, step: 500, loss: 1.4212598298725327, grad_norm: 0.24609143768771174, ic: 0.0898735936958921
train 6, step: 1000, loss: 1.2246926433802205, grad_norm: 0.19605986981514278, ic: 0.18742468235059723
train 6, step: 1500, loss: 1.0573409861438678, grad_norm: 0.337909664855196, ic: 0.08835409844994761
train 6, step: 2000, loss: 2.278305727994579, grad_norm: 1.056493764632604, ic: 0.08784655408010879
Epoch 6: 2022-04-04 01:16:27.480129: train loss: 1.631524406239285
Eval step 0: eval loss: 1.008803140118977
Eval: 2022-04-04 01:16:29.673358: total loss: 1.0836809617938388, mse:4.684036200431236, ic :0.1629261535176085, sharpe5:15.388862453699112, irr5:500.88616943359375, ndcg5:0.8559865149387493, pnl5:6.640773296356201 
train 7, step: 0, loss: 1.4480228832565383, grad_norm: 0.5607260316712793, ic: 0.2069080432093081
train 7, step: 500, loss: 1.3492828544098077, grad_norm: 0.28227379525023727, ic: 0.17802222637335044
train 7, step: 1000, loss: 0.6321277857158379, grad_norm: 0.07866629561744586, ic: 0.2719361042196987
train 7, step: 1500, loss: 1.0055657691984843, grad_norm: 0.14121070290379176, ic: 0.10562323586850567
train 7, step: 2000, loss: 1.5760469028575674, grad_norm: 0.6481568615856972, ic: 0.41485129560135087
Epoch 7: 2022-04-04 01:16:50.818395: train loss: 1.6306054626779902
Eval step 0: eval loss: 1.0026186942552
Eval: 2022-04-04 01:16:52.997548: total loss: 1.0828712490014756, mse:4.697916447022331, ic :0.15505656163795445, sharpe5:15.070881958007812, irr5:487.2771911621094, ndcg5:0.8465468110027485, pnl5:7.390270233154297 
train 8, step: 0, loss: 1.1953874199311314, grad_norm: 0.09504784429642664, ic: 0.15303103709931165
train 8, step: 500, loss: 5.502670622918299, grad_norm: 1.3132192948691694, ic: 0.1338432816425075
train 8, step: 1000, loss: 1.9010710734976435, grad_norm: 0.6127608592245377, ic: 0.06559118360748886
train 8, step: 1500, loss: 1.0697696960297767, grad_norm: 0.31619320091695846, ic: 0.6395159866493466
train 8, step: 2000, loss: 1.1278329506898537, grad_norm: 0.5525322178269927, ic: 0.022698521174879558
Epoch 8: 2022-04-04 01:17:14.433789: train loss: 1.6330376491467695
Eval step 0: eval loss: 1.0065619060401856
Eval: 2022-04-04 01:17:16.895635: total loss: 1.0874184473817001, mse:4.698244381829854, ic :0.15636879203262724, sharpe5:14.399431725740431, irr5:474.24346923828125, ndcg5:0.8516969214038012, pnl5:6.657073974609375 
train 9, step: 0, loss: 1.0954695991847827, grad_norm: 0.08080417564557045, ic: 0.47973027854401956
train 9, step: 500, loss: 3.142778788527397, grad_norm: 1.2291948671499178, ic: 0.20806492828801987
train 9, step: 1000, loss: 0.8818531439653484, grad_norm: 0.14701368543197993, ic: 0.20882011553103197
train 9, step: 1500, loss: 2.1542863892195094, grad_norm: 1.0833699337579266, ic: -0.010354630132881168
train 9, step: 2000, loss: 0.6039348515256195, grad_norm: 0.026452055285529373, ic: 0.06995830241847643
Epoch 9: 2022-04-04 01:17:38.376594: train loss: 1.628553634116819
Eval step 0: eval loss: 1.002570868919497
Eval: 2022-04-04 01:17:40.570546: total loss: 1.0901482317021385, mse:4.765005936852291, ic :0.13611943753216002, sharpe5:12.299745286703109, irr5:376.0946960449219, ndcg5:0.8649605920725615, pnl5:4.187508583068848 
train 10, step: 0, loss: 1.2889504012613453, grad_norm: 0.2642589291394018, ic: 0.39721143642252266
train 10, step: 500, loss: 0.8940547222979056, grad_norm: 0.005827119306907601, ic: 0.10998081931363488
train 10, step: 1000, loss: 1.5193393526228143, grad_norm: 0.6518880573208878, ic: 0.04237832740941908
train 10, step: 1500, loss: 3.0231854838709675, grad_norm: 1.5655571668678738, ic: 0.11307715679189458
train 10, step: 2000, loss: 1.3790906540890957, grad_norm: 0.27174058881921853, ic: 0.16012690385836498
Epoch 10: 2022-04-04 01:18:01.921342: train loss: 1.6286018402233846
Eval step 0: eval loss: 1.0069558865274486
Eval: 2022-04-04 01:18:04.129528: total loss: 1.0840799461400425, mse:4.683472027406871, ic :0.15984287947524906, sharpe5:15.095330353975296, irr5:490.13134765625, ndcg5:0.837385442874604, pnl5:7.036530017852783 
train 11, step: 0, loss: 4.665232237099296, grad_norm: 1.2449702568332721, ic: 0.4425255261773964
train 11, step: 500, loss: 0.9862624957997311, grad_norm: 0.06942223659709101, ic: 0.054176782949143805
train 11, step: 1000, loss: 1.0409215815098207, grad_norm: 0.49986825824618586, ic: 0.06512106669609186
train 11, step: 1500, loss: 0.6938445973228269, grad_norm: 0.00646411194902791, ic: 0.08240659487552221
train 11, step: 2000, loss: 1.1239825821232736, grad_norm: 0.06261575440606716, ic: -0.17912977260150986
Epoch 11: 2022-04-04 01:18:24.876559: train loss: 1.626960284965389
Eval step 0: eval loss: 0.9978204760317929
Eval: 2022-04-04 01:18:27.064472: total loss: 1.082699589261646, mse:4.703149688472929, ic :0.15016467719812987, sharpe5:14.443161871433258, irr5:457.093505859375, ndcg5:0.84833437305187, pnl5:5.985483169555664 
train 12, step: 0, loss: 1.3750162450986216, grad_norm: 0.42816679010134123, ic: 0.1732601015406266
train 12, step: 500, loss: 0.8209208282976519, grad_norm: 0.8447618647719429, ic: 0.0026798065664420615
train 12, step: 1000, loss: 1.1665729935376814, grad_norm: 0.3413507857247284, ic: 0.6158471606213805
train 12, step: 1500, loss: 1.0861073531871177, grad_norm: 0.28958249034784544, ic: 0.07572058352287449
train 12, step: 2000, loss: 1.1136727434290734, grad_norm: 0.10071020643853212, ic: 0.1278588099583592
Epoch 12: 2022-04-04 01:18:48.619195: train loss: 1.6272825679406895
Eval step 0: eval loss: 1.0038124634881844
Eval: 2022-04-04 01:18:51.127323: total loss: 1.085123585141025, mse:4.696579826724155, ic :0.15349706075551917, sharpe5:13.75476916372776, irr5:423.3572692871094, ndcg5:0.8455697611807123, pnl5:4.81536865234375 
train 13, step: 0, loss: 1.0743287448725825, grad_norm: 0.044468728856015056, ic: 0.44047410360863365
train 13, step: 500, loss: 1.147599035364981, grad_norm: 0.010679908462523958, ic: -0.1495319508492463
train 13, step: 1000, loss: 1.3879216852195613, grad_norm: 0.9438395817523197, ic: 0.07629040582998212
train 13, step: 1500, loss: 0.774814739256326, grad_norm: 0.027483190889290028, ic: 0.012351290442351157
train 13, step: 2000, loss: 1.0380650299119143, grad_norm: 0.04630287522307618, ic: 0.057379498122572786
Epoch 13: 2022-04-04 01:19:12.391805: train loss: 1.6270273538064615
Eval step 0: eval loss: 0.9961688306345444
Eval: 2022-04-04 01:19:14.676267: total loss: 1.0821100299429838, mse:4.705087658744176, ic :0.15461111958785356, sharpe5:14.716716020107269, irr5:474.425537109375, ndcg5:0.8542340142348244, pnl5:6.575608730316162 
train 14, step: 0, loss: 1.7551985918465307, grad_norm: 0.5414280007178052, ic: 0.18388986619661263
train 14, step: 500, loss: 1.2620416398787655, grad_norm: 0.1624473220415136, ic: 0.2340326579252504
train 14, step: 1000, loss: 1.0658411956030476, grad_norm: 0.17849411061733678, ic: 0.14727168151996206
train 14, step: 1500, loss: 0.9734803890612971, grad_norm: 0.14232726947128418, ic: 0.16756929810430563
train 14, step: 2000, loss: 2.3052721630301796, grad_norm: 0.776291047541841, ic: -0.07136434974572749
Epoch 14: 2022-04-04 01:19:35.960527: train loss: 1.6266037900845587
Eval step 0: eval loss: 1.0098377486917456
Eval: 2022-04-04 01:19:38.184396: total loss: 1.0852420370205125, mse:4.680222428793567, ic :0.16670816739047167, sharpe5:15.563379126191139, irr5:516.2363891601562, ndcg5:0.8440751241626635, pnl5:5.8398356437683105 
train 15, step: 0, loss: 0.9669511921388668, grad_norm: 0.18885933046846304, ic: 0.14092837761714705
train 15, step: 500, loss: 1.2406263242157658, grad_norm: 0.13637070722419525, ic: 0.07485535672723789
train 15, step: 1000, loss: 1.75530078125, grad_norm: 0.04002502012161646, ic: 0.005223294193612612
train 15, step: 1500, loss: 5.382558163246809, grad_norm: 0.9780717746645435, ic: 0.008724165039509225
train 15, step: 2000, loss: 0.9274757021949405, grad_norm: 0.023022215005033188, ic: 0.04886154509095539
Epoch 15: 2022-04-04 01:19:59.366744: train loss: 1.6267737090309753
Eval step 0: eval loss: 1.0145410876201288
Eval: 2022-04-04 01:20:01.570751: total loss: 1.086385998407609, mse:4.6925889254502495, ic :0.1607220077710441, sharpe5:15.102295204997063, irr5:506.0001525878906, ndcg5:0.8426118218856853, pnl5:6.42425012588501 
train 16, step: 0, loss: 6.391222369641385, grad_norm: 5.096419944010192, ic: 0.15991109171827472
train 16, step: 500, loss: 1.3691892593625992, grad_norm: 0.8108032416777595, ic: 0.0016933573052050482
train 16, step: 1000, loss: 0.8426323828439766, grad_norm: 0.257417025934309, ic: -0.021839195200254742
train 16, step: 1500, loss: 1.2380320659190895, grad_norm: 0.4381774012730349, ic: 0.14373499950063337
train 16, step: 2000, loss: 0.9517415859898053, grad_norm: 0.34532488381211074, ic: 0.5457701472464441
Epoch 16: 2022-04-04 01:20:22.736627: train loss: 1.6248700535804297
Eval step 0: eval loss: 0.9954252238020009
Eval: 2022-04-04 01:20:24.938083: total loss: 1.080398844867948, mse:4.694218303561168, ic :0.16099452830141756, sharpe5:14.856680864095686, irr5:489.88385009765625, ndcg5:0.8444710548894944, pnl5:5.938793182373047 
train 17, step: 0, loss: 1.1797262554519747, grad_norm: 0.014347599289930998, ic: 0.1216991349217102
train 17, step: 500, loss: 1.0367227526317802, grad_norm: 0.03755273315974579, ic: -0.015201568952845109
train 17, step: 1000, loss: 3.3776033609220297, grad_norm: 1.9463721565799383, ic: -0.011431263041523705
train 17, step: 1500, loss: 0.881030826506877, grad_norm: 0.03006520973818995, ic: 0.08867392019966641
train 17, step: 2000, loss: 1.016702495805369, grad_norm: 0.7931868273693272, ic: 0.5784158479699194
Epoch 17: 2022-04-04 01:20:46.440927: train loss: 1.6257476372720627
Eval step 0: eval loss: 1.0058161779225907
Eval: 2022-04-04 01:20:48.677664: total loss: 1.0855916923978766, mse:4.718522808676355, ic :0.1538593647347344, sharpe5:14.283293804526329, irr5:468.1818542480469, ndcg5:0.8471479579480108, pnl5:4.401979923248291 
train 18, step: 0, loss: 0.8475004072273457, grad_norm: 0.004209831632059984, ic: 0.04130093625226728
train 18, step: 500, loss: 2.5348069904863393, grad_norm: 1.341515993913948, ic: 0.08928540127298068
train 18, step: 1000, loss: 1.3698085867243706, grad_norm: 0.8921381776386403, ic: 0.5335519949199158
train 18, step: 1500, loss: 1.6714001814355781, grad_norm: 1.6730757850252118, ic: 0.3289564702751127
train 18, step: 2000, loss: 1.2455335382365684, grad_norm: 0.3519009929056654, ic: 0.22909317386444417
Epoch 18: 2022-04-04 01:21:10.012894: train loss: 1.6258185139931263
Eval step 0: eval loss: 1.0013162895150407
Eval: 2022-04-04 01:21:12.432342: total loss: 1.0815406700830559, mse:4.680475428044174, ic :0.17015702406320743, sharpe5:14.785067666172981, irr5:502.1464538574219, ndcg5:0.8491037503038544, pnl5:8.218332290649414 
train 19, step: 0, loss: 2.238944744644223, grad_norm: 0.9894484009618241, ic: 0.25015135564275415
train 19, step: 500, loss: 1.020799006972202, grad_norm: 0.06791470045340772, ic: 0.0770228683193539
train 19, step: 1000, loss: 0.9775048635001236, grad_norm: 0.2584880476071777, ic: 0.5607346512365633
train 19, step: 1500, loss: 1.5709166350188077, grad_norm: 0.11306368758714676, ic: 0.16251091092065573
train 19, step: 2000, loss: 1.6094208825768563, grad_norm: 2.343423419680806, ic: 0.6422131039731185
Epoch 19: 2022-04-04 01:21:34.406705: train loss: 1.6244909560325287
Eval step 0: eval loss: 1.0014460093099986
Eval: 2022-04-04 01:21:36.822849: total loss: 1.080873204366568, mse:4.686522708268387, ic :0.1602742436862422, sharpe5:14.502049530744552, irr5:461.5847473144531, ndcg5:0.8439593817838382, pnl5:4.4269208908081055 
train 20, step: 0, loss: 1.256527717571306, grad_norm: 0.40287900488952516, ic: 0.46517413297219123
train 20, step: 500, loss: 1.243909691768211, grad_norm: 0.7005674903663343, ic: 0.022112496955125252
train 20, step: 1000, loss: 1.5789305735921786, grad_norm: 0.5667868701945233, ic: 0.1823707116909447
train 20, step: 1500, loss: 0.8924382811289886, grad_norm: 0.8025624604403814, ic: 0.5649957294496124
train 20, step: 2000, loss: 1.3616520011241915, grad_norm: 0.15266484567984212, ic: -0.044605829586353604
Epoch 20: 2022-04-04 01:21:59.265615: train loss: 1.6241084484650303
Eval step 0: eval loss: 1.0061359134330567
Eval: 2022-04-04 01:22:01.895549: total loss: 1.0830432123188014, mse:4.695239597871735, ic :0.16097116841285683, sharpe5:15.348703177571297, irr5:488.1688537597656, ndcg5:0.8408439647488747, pnl5:5.929572582244873 
train 21, step: 0, loss: 1.390359078899417, grad_norm: 0.3495501463342603, ic: 0.27397713839878785
train 21, step: 500, loss: 1.119822051931905, grad_norm: 0.1940736159770252, ic: 0.0204970436088898
train 21, step: 1000, loss: 0.9167552687833812, grad_norm: 0.31962083014256026, ic: 0.08434727167007205
train 21, step: 1500, loss: 0.7423281157684842, grad_norm: 0.18557762512337117, ic: 0.6337836050294984
train 21, step: 2000, loss: 1.1225932789268998, grad_norm: 0.12078729056528797, ic: 0.30274339895230684
Epoch 21: 2022-04-04 01:22:23.316560: train loss: 1.6236665240089856
Eval step 0: eval loss: 1.0053141404604395
Eval: 2022-04-04 01:22:25.638774: total loss: 1.0820296253869413, mse:4.690211743923203, ic :0.15544409642878015, sharpe5:13.365167902708054, irr5:417.80609130859375, ndcg5:0.8626896797063404, pnl5:4.883441925048828 
train 22, step: 0, loss: 1.0299820649534432, grad_norm: 0.5138642778917211, ic: 0.08131819050103085
train 22, step: 500, loss: 1.028489000215305, grad_norm: 0.0016585617220428554, ic: -0.01263227490763217
train 22, step: 1000, loss: 0.9068084226460883, grad_norm: 0.03228427491295153, ic: 0.1328048998427413
train 22, step: 1500, loss: 1.0049188441576615, grad_norm: 0.02987706785152529, ic: 0.25675132560538294
train 22, step: 2000, loss: 1.0437776787336484, grad_norm: 0.14147234375912845, ic: 0.12846855959820272
Epoch 22: 2022-04-04 01:22:47.043500: train loss: 1.6229762085560646
Eval step 0: eval loss: 1.009672352739106
Eval: 2022-04-04 01:22:49.217989: total loss: 1.081958295799625, mse:4.681912007625815, ic :0.16310519318070651, sharpe5:14.082430263161658, irr5:449.4993896484375, ndcg5:0.8547266773630652, pnl5:4.681098937988281 
train 23, step: 0, loss: 1.2959173133646489, grad_norm: 1.238072869080143, ic: 0.006180342153098355
train 23, step: 500, loss: 0.9010613410027474, grad_norm: 0.13967937649241616, ic: 0.5924518795349478
train 23, step: 1000, loss: 2.272855779826169, grad_norm: 1.1460505659785285, ic: 0.10487528562819536
train 23, step: 1500, loss: 0.7785787159095545, grad_norm: 0.4080620783246909, ic: 0.7191850834573562
train 23, step: 2000, loss: 1.4477815865929706, grad_norm: 0.46295557403425985, ic: 0.40463737470323985
Epoch 23: 2022-04-04 01:23:10.382552: train loss: 1.6229698062962687
Eval step 0: eval loss: 1.0062959740323854
Eval: 2022-04-04 01:23:12.558726: total loss: 1.0913878422925194, mse:4.711481140449382, ic :0.14626075940433192, sharpe5:12.778318428397178, irr5:383.58013916015625, ndcg5:0.8372159443484477, pnl5:4.722503662109375 
train 24, step: 0, loss: 1.190246915556694, grad_norm: 0.43064877525255396, ic: 0.2898283910603646
train 24, step: 500, loss: 1.2384840487342679, grad_norm: 0.31948969044282916, ic: 0.011880832473804562
train 24, step: 1000, loss: 1.0363687654820886, grad_norm: 0.5213863718143228, ic: 0.11663058393369281
train 24, step: 1500, loss: 1.201523668184055, grad_norm: 0.08983218774397767, ic: 0.07887215806183935
train 24, step: 2000, loss: 1.3663573704499077, grad_norm: 0.4251526475847818, ic: 0.4596315772812402
Epoch 24: 2022-04-04 01:23:33.658297: train loss: 1.6237222596903689
Eval step 0: eval loss: 1.0188340543131253
Eval: 2022-04-04 01:23:35.846761: total loss: 1.0858492831656785, mse:4.7110099753206445, ic :0.16131602328686073, sharpe5:15.038991964459418, irr5:504.2085266113281, ndcg5:0.8564979305352061, pnl5:5.491052150726318 
train 25, step: 0, loss: 1.3042535031535063, grad_norm: 0.701292716769818, ic: 0.19462123005362256
train 25, step: 500, loss: 1.470615139255276, grad_norm: 0.7534084981852427, ic: 0.12736098931254192
train 25, step: 1000, loss: 1.3609827621837263, grad_norm: 0.24892789045570074, ic: 0.27975683164562737
train 25, step: 1500, loss: 2.869703017202251, grad_norm: 1.2927499897168222, ic: 0.25908336162550655
train 25, step: 2000, loss: 1.1903368792956388, grad_norm: 0.3101041225290892, ic: 0.15272901751539014
Epoch 25: 2022-04-04 01:23:56.100189: train loss: 1.6241764396323028
Eval step 0: eval loss: 1.0053508451199644
Eval: 2022-04-04 01:23:58.225328: total loss: 1.080882546698149, mse:4.678182961992765, ic :0.168540780827748, sharpe5:15.143755128979683, irr5:498.4474792480469, ndcg5:0.8516848107941962, pnl5:5.35529899597168 
train 26, step: 0, loss: 1.6084467329545453, grad_norm: 0.4729368297058447, ic: 0.22063686993640585
train 26, step: 500, loss: 1.0088111294422761, grad_norm: 0.2016561474979433, ic: -0.04670025007639839
train 26, step: 1000, loss: 1.8063017553731266, grad_norm: 0.8021986199361192, ic: 0.18450731792475975
train 26, step: 1500, loss: 0.9279396105518302, grad_norm: 0.05011566216044026, ic: -0.04290356250962839
train 26, step: 2000, loss: 1.0020471287524606, grad_norm: 0.15684453678259958, ic: 0.14641834146975827
Epoch 26: 2022-04-04 01:24:18.647338: train loss: 1.6231734988549975
Eval step 0: eval loss: 1.003409997860716
Eval: 2022-04-04 01:24:20.774828: total loss: 1.083563424346198, mse:4.6854484793670315, ic :0.16393972442439456, sharpe5:14.86330801963806, irr5:500.0060729980469, ndcg5:0.8460361912562275, pnl5:5.266932964324951 
train 27, step: 0, loss: 1.6234798201595446, grad_norm: 0.560138060581286, ic: 0.657057551306324
train 27, step: 500, loss: 1.5125162886979977, grad_norm: 0.617717221541835, ic: 0.07085659823807225
train 27, step: 1000, loss: 2.5814202344964063, grad_norm: 0.7375308618756744, ic: 0.39774762320191215
train 27, step: 1500, loss: 0.8328639711463394, grad_norm: 0.5565410246956888, ic: 0.54916313184884
train 27, step: 2000, loss: 1.3579456897741455, grad_norm: 1.7101539382816076, ic: -0.010767256347164337
Epoch 27: 2022-04-04 01:24:41.821438: train loss: 1.6212693550687436
Eval step 0: eval loss: 1.0106102821386256
Eval: 2022-04-04 01:24:43.929549: total loss: 1.0798880778409936, mse:4.680168899090698, ic :0.16895523744648144, sharpe5:15.443799927234648, irr5:503.3085021972656, ndcg5:0.8518473198625964, pnl5:4.750184535980225 
train 28, step: 0, loss: 1.1577216097719398, grad_norm: 0.16993247684515667, ic: 0.13653468743759095
train 28, step: 500, loss: 2.936182766809102, grad_norm: 0.6984527112811771, ic: 0.11795718662321342
train 28, step: 1000, loss: 2.782058016760466, grad_norm: 3.0632646582926393, ic: -0.02677442104470227
train 28, step: 1500, loss: 1.0216281875959659, grad_norm: 0.012076344034586541, ic: 0.20967137569393499
train 28, step: 2000, loss: 1.7605356615643168, grad_norm: 0.4246223602897088, ic: 0.06552693639362774
Epoch 28: 2022-04-04 01:25:04.507323: train loss: 1.6221122708205318
Eval step 0: eval loss: 1.010053605516061
Eval: 2022-04-04 01:25:06.776436: total loss: 1.0806949362744556, mse:4.681034815652195, ic :0.1679227565193365, sharpe5:15.523514032959937, irr5:524.4912109375, ndcg5:0.8477609045886016, pnl5:5.087677001953125 
train 29, step: 0, loss: 1.5131284353677028, grad_norm: 0.17162141591595348, ic: 0.08319760043322792
train 29, step: 500, loss: 2.573148271790054, grad_norm: 2.2792008414301246, ic: -0.11757901738483262
train 29, step: 1000, loss: 1.708468891922578, grad_norm: 1.2417466258567929, ic: 0.480135045418498
train 29, step: 1500, loss: 3.977359790157005, grad_norm: 1.4280463937823478, ic: 0.11936994029994874
train 29, step: 2000, loss: 0.9074128221563665, grad_norm: 0.3460889408586197, ic: 0.4799679526780479
Epoch 29: 2022-04-04 01:25:27.445999: train loss: 1.622734480747591
Eval step 0: eval loss: 1.0041906950409754
Eval: 2022-04-04 01:25:29.609751: total loss: 1.0812676074032375, mse:4.682117236521346, ic :0.1673056241714491, sharpe5:15.604132443666458, irr5:515.53759765625, ndcg5:0.8595980359345365, pnl5:4.610010623931885 
train 30, step: 0, loss: 1.2467881923909443, grad_norm: 0.0436355024150658, ic: 0.980086992261355
train 30, step: 500, loss: 1.9408279612094541, grad_norm: 0.32596633144943815, ic: 0.15603318521105436
train 30, step: 1000, loss: 3.418743287343027, grad_norm: 1.0905046252613695, ic: 0.41124676175929764
train 30, step: 1500, loss: 1.0772757082748634, grad_norm: 0.2446503160726406, ic: 0.15675088626501002
train 30, step: 2000, loss: 1.0939929298926123, grad_norm: 0.09376195692490821, ic: 0.44260188335443573
Epoch 30: 2022-04-04 01:25:50.710111: train loss: 1.6215247645626845
Eval step 0: eval loss: 1.0144706352438784
Eval: 2022-04-04 01:25:52.901666: total loss: 1.0822591713959109, mse:4.67882410926476, ic :0.1688146568401814, sharpe5:15.365895377397537, irr5:518.303955078125, ndcg5:0.8433585281524549, pnl5:4.294898509979248 
train 31, step: 0, loss: 1.1525535890637582, grad_norm: 0.29355745329750893, ic: 0.21126560659289303
train 31, step: 500, loss: 0.8279039925117463, grad_norm: 0.08371177366855294, ic: 0.18136242792278032
train 31, step: 1000, loss: 5.16160019455253, grad_norm: 1.6797526612729794, ic: 0.015033955482169948
train 31, step: 1500, loss: 1.7061607207544436, grad_norm: 0.6155144355705235, ic: 0.284192171611515
train 31, step: 2000, loss: 0.919516470605843, grad_norm: 0.7654967236406074, ic: 0.18315903110567183
Epoch 31: 2022-04-04 01:26:13.231268: train loss: 1.6226174911167766
Eval step 0: eval loss: 1.0072021484375
Eval: 2022-04-04 01:26:15.383501: total loss: 1.0815121236426832, mse:4.666605206198038, ic :0.17648461995253242, sharpe5:16.39766195654869, irr5:541.4976806640625, ndcg5:0.8514312947407078, pnl5:5.049685001373291 
train 32, step: 0, loss: 0.8874559843513078, grad_norm: 0.4207046724893213, ic: 0.11168444293744861
train 32, step: 500, loss: 1.0921066098096894, grad_norm: 0.3121401115380999, ic: 0.15091568861852456
train 32, step: 1000, loss: 1.381680824129071, grad_norm: 0.07335226078753422, ic: 0.070341849599028
train 32, step: 1500, loss: 2.051326976102941, grad_norm: 0.5864265265225633, ic: 0.43252541120393595
train 32, step: 2000, loss: 1.079887761103178, grad_norm: 0.5921874193034293, ic: 0.46712756937254823
Epoch 32: 2022-04-04 01:26:35.719471: train loss: 1.6214010970237425
Eval step 0: eval loss: 1.0066468217236044
Eval: 2022-04-04 01:26:37.912122: total loss: 1.0819252466114286, mse:4.687231642009941, ic :0.16856431905110145, sharpe5:15.729443006515503, irr5:516.0513916015625, ndcg5:0.8453781405874023, pnl5:5.321126461029053 
train 33, step: 0, loss: 1.160938563102798, grad_norm: 0.025996189286968962, ic: 0.013252273217722113
train 33, step: 500, loss: 3.161037107873751, grad_norm: 0.8740993574138762, ic: 0.5242550325924789
train 33, step: 1000, loss: 5.204326676870903, grad_norm: 3.9235414447748855, ic: 0.05985931540598867
train 33, step: 1500, loss: 1.325883223370808, grad_norm: 1.4204658069283393, ic: 0.009615024982370442
train 33, step: 2000, loss: 1.8724645333696706, grad_norm: 0.40502184649919587, ic: 0.07562570293267672
Epoch 33: 2022-04-04 01:26:58.982728: train loss: 1.6222537868805156
Eval step 0: eval loss: 1.0169767085472616
Eval: 2022-04-04 01:27:01.164516: total loss: 1.0870950409616704, mse:4.68429439914757, ic :0.17278722104023309, sharpe5:16.49641281723976, irr5:537.278564453125, ndcg5:0.8588586770037144, pnl5:4.944645881652832 
train 34, step: 0, loss: 0.7288219131493908, grad_norm: 0.549882688033705, ic: 0.16141765424462667
train 34, step: 500, loss: 1.831780900862472, grad_norm: 0.6252050544672745, ic: 0.8203400231901367
train 34, step: 1000, loss: 0.6844471056707974, grad_norm: 0.02785556512784915, ic: 0.4849212367622256
train 34, step: 1500, loss: 1.6383820362580128, grad_norm: 0.9235248434500412, ic: 0.6461336550215454
train 34, step: 2000, loss: 2.9863866463524507, grad_norm: 0.5555068680562593, ic: 0.08242388102310587
Epoch 34: 2022-04-04 01:27:21.800675: train loss: 1.621396357985003
Eval step 0: eval loss: 1.0108412450837612
Eval: 2022-04-04 01:27:23.916535: total loss: 1.08271533770563, mse:4.682531312023109, ic :0.1656947609546678, sharpe5:16.08698400735855, irr5:521.0550537109375, ndcg5:0.8587345781923412, pnl5:5.078327655792236 
train 35, step: 0, loss: 1.0504209301139735, grad_norm: 0.6306757403178511, ic: -0.009008034558520853
train 35, step: 500, loss: 3.291662967566288, grad_norm: 2.244427852484804, ic: -0.05570862637532054
train 35, step: 1000, loss: 1.344350593590811, grad_norm: 0.1233415168080158, ic: 0.5072910887925695
train 35, step: 1500, loss: 1.6177215701141483, grad_norm: 0.42828722616582343, ic: 0.10501958797462604
train 35, step: 2000, loss: 1.2964613329363932, grad_norm: 0.19196211922638237, ic: -0.004569558822240083
Epoch 35: 2022-04-04 01:27:44.478726: train loss: 1.622173503266156
Eval step 0: eval loss: 1.0049516578421207
Eval: 2022-04-04 01:27:46.607321: total loss: 1.081269715953226, mse:4.680051440037012, ic :0.16786187597483157, sharpe5:15.308603494763373, irr5:498.00750732421875, ndcg5:0.8537630330324102, pnl5:5.5080366134643555 
train 36, step: 0, loss: 8.960071928028809, grad_norm: 1.4764814487210713, ic: -0.14598979974776727
train 36, step: 500, loss: 0.8601480811766654, grad_norm: 0.010351553657670005, ic: 0.10746548000149769
train 36, step: 1000, loss: 1.9735051766717324, grad_norm: 2.0476773298222595, ic: 0.07730879839862448
train 36, step: 1500, loss: 1.054667060648718, grad_norm: 0.15471069563638168, ic: 0.08583673146418107
train 36, step: 2000, loss: 2.167352578722778, grad_norm: 1.2133578225957369, ic: 0.38356070795743036
Epoch 36: 2022-04-04 01:28:07.438904: train loss: 1.6261134566936368
Eval step 0: eval loss: 1.016790871120491
Eval: 2022-04-04 01:28:09.984920: total loss: 1.0893388251600162, mse:4.694454412659528, ic :0.16550247710242688, sharpe5:16.29444443464279, irr5:539.0734252929688, ndcg5:0.8534750105625842, pnl5:3.8716256618499756 
train 37, step: 0, loss: 1.1745314625393757, grad_norm: 0.182402785555545, ic: 0.19933169832935327
train 37, step: 500, loss: 2.3333161793309127, grad_norm: 0.060776901728354336, ic: 0.16941059967351493
train 37, step: 1000, loss: 0.7704346863856973, grad_norm: 0.4277504252402444, ic: 0.16241340518133313
train 37, step: 1500, loss: 3.1351045715022208, grad_norm: 1.12642441456489, ic: 0.19484912351047012
train 37, step: 2000, loss: 3.115021610622623, grad_norm: 2.3455329791014674, ic: 0.005992228074584872
Epoch 37: 2022-04-04 01:28:29.752904: train loss: 1.623020614253494
Eval step 0: eval loss: 1.0073876644574447
Eval: 2022-04-04 01:28:31.714650: total loss: 1.0807701995154413, mse:4.679909964010416, ic :0.16649849066362923, sharpe5:15.575020633935928, irr5:519.1114501953125, ndcg5:0.856381949048772, pnl5:4.745607376098633 
train 38, step: 0, loss: 1.3451319839015152, grad_norm: 0.5457894726517184, ic: -0.2756364391044031
train 38, step: 500, loss: 1.6558601320251938, grad_norm: 1.0409777547426677, ic: 0.22738427978063241
train 38, step: 1000, loss: 1.817487142822074, grad_norm: 0.7371154121732142, ic: 0.14169785913788016
train 38, step: 1500, loss: 1.083048552900958, grad_norm: 0.33797607868455426, ic: 0.4879790116286379
train 38, step: 2000, loss: 0.75374482917524, grad_norm: 0.06884453919422448, ic: 0.5745214770573532
Epoch 38: 2022-04-04 01:28:50.933462: train loss: 1.62108231853557
Eval step 0: eval loss: 0.9985384345996248
Eval: 2022-04-04 01:28:52.921917: total loss: 1.079402412531102, mse:4.684128934608454, ic :0.172221053293057, sharpe5:16.944690796136854, irr5:554.1759643554688, ndcg5:0.8369655006977795, pnl5:4.391843795776367 
train 39, step: 0, loss: 0.8669859779201224, grad_norm: 0.0365038545978907, ic: 0.5390922282114722
train 39, step: 500, loss: 1.2259432403393142, grad_norm: 0.46980435544941007, ic: 0.04400912967623126
train 39, step: 1000, loss: 1.395105165423769, grad_norm: 0.3254582542282237, ic: 0.06303757668222724
train 39, step: 1500, loss: 2.433132234997924, grad_norm: 0.5165684129505475, ic: -0.08596092544497712
train 39, step: 2000, loss: 2.9981915701340944, grad_norm: 2.9029368427198667, ic: 0.12620331564868015
Epoch 39: 2022-04-04 01:29:12.185636: train loss: 1.619653895368826
Eval step 0: eval loss: 1.0018144700952802
Eval: 2022-04-04 01:29:14.152699: total loss: 1.0784032235615226, mse:4.674712747761966, ic :0.1740413779305375, sharpe5:16.44489770293236, irr5:540.4671630859375, ndcg5:0.8447848923079372, pnl5:4.628396987915039 

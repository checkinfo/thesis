Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='SparseAdjSeqTimeDataset', dout=0.3, epochs=40, gnn_layers=2, gpu=0, hidden_dim=128, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=3, mask_adj=True, mask_type='soft', model_type='GNNModel', normalize_adj=False, num_days=1, num_heads=1, print_inteval=500, relation_num=1, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_750_0.6/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=False)
load 2305 train graphs successful!
load 126 test graphs successful!
83626
GNNModel(
  (fc1): Linear(in_features=9, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
  (fc4): Linear(in_features=128, out_features=1, bias=True)
  (gnns): ModuleList(
    (0): GraphConv(128, 128)
    (1): GraphConv(128, 128)
  )
  (dropout): Dropout(p=0.3, inplace=False)
  (relu): LeakyReLU(negative_slope=0.01)
)
train 0, step: 0, loss: 2.0732400645380435, grad_norm: 0.47024670035103555, ic: 0.002346018420535941
train 0, step: 500, loss: 1.3679106671128696, grad_norm: 0.8457309880940476, ic: -0.009301255093751876
train 0, step: 1000, loss: 1.5063150908474836, grad_norm: 0.03268249318841363, ic: 0.208088902422712
train 0, step: 1500, loss: 1.194700459532331, grad_norm: 0.10818587657658316, ic: 0.056289404465165845
train 0, step: 2000, loss: 1.560321900902725, grad_norm: 0.04972792566915567, ic: -7.067361544736521e-05
Epoch 0: 2022-04-04 01:30:36.599707: train loss: 1.647971294011024
Eval step 0: eval loss: 1.0097158712233412
Eval: 2022-04-04 01:30:42.450768: total loss: 1.0912550270354315, mse:4.8861015095239, ic :0.02811125398529869, sharpe5:6.704881312251091, irr5:203.4989471435547, ndcg5:0.8496234872399057, pnl5:2.6199140548706055 
train 1, step: 0, loss: 0.6407828000512453, grad_norm: 0.05583248099939666, ic: 0.052271624966354624
train 1, step: 500, loss: 1.2575679666554962, grad_norm: 0.3026247259791642, ic: 0.269485928291548
train 1, step: 1000, loss: 0.8753112894299944, grad_norm: 0.062525975315155, ic: 0.10183278949150981
train 1, step: 1500, loss: 1.8590504716082317, grad_norm: 0.5581719623267046, ic: 0.09421640443832917
train 1, step: 2000, loss: 1.3854154204153906, grad_norm: 0.23109225150172763, ic: 0.1348186427018041
Epoch 1: 2022-04-04 01:31:27.407893: train loss: 1.6452669009752634
Eval step 0: eval loss: 1.0011087892682002
Eval: 2022-04-04 01:31:33.272423: total loss: 1.0883128106324613, mse:4.875310839773438, ic :0.057293353365585956, sharpe5:7.816309498250484, irr5:221.87371826171875, ndcg5:0.8516118854816429, pnl5:3.0779786109924316 
train 2, step: 0, loss: 1.3277561726256466, grad_norm: 0.5347760366317986, ic: 0.06688080185722209
train 2, step: 500, loss: 0.9535541910683801, grad_norm: 0.33632478530624477, ic: 0.0668576563591767
train 2, step: 1000, loss: 3.0343064068450762, grad_norm: 1.2931610120551682, ic: 0.1491534527874585
train 2, step: 1500, loss: 2.2967948459803726, grad_norm: 0.8685757572984762, ic: 0.07191089459097577
train 2, step: 2000, loss: 1.4569857356398201, grad_norm: 0.28131101538492054, ic: -0.10814102326025035
Epoch 2: 2022-04-04 01:32:18.756741: train loss: 1.6448461549924076
Eval step 0: eval loss: 0.9956116397610584
Eval: 2022-04-04 01:32:24.838866: total loss: 1.0884932998830408, mse:4.8742879965518915, ic :0.05789229452360564, sharpe5:7.471659100055694, irr5:224.2184600830078, ndcg5:0.84813689500063, pnl5:2.591583251953125 
train 3, step: 0, loss: 1.8329691460046862, grad_norm: 0.06787034779150329, ic: -0.1569774921050838
train 3, step: 500, loss: 0.7784674917124839, grad_norm: 0.020127986811873434, ic: 0.11340478187805628
train 3, step: 1000, loss: 1.3618051653764744, grad_norm: 0.4965224844972124, ic: 0.2215705142369556
train 3, step: 1500, loss: 2.621696832100735, grad_norm: 0.4216496582405348, ic: -0.05872540792909553
train 3, step: 2000, loss: 1.3519587661280776, grad_norm: 0.16858221008743024, ic: 0.08436964100930205
Epoch 3: 2022-04-04 01:33:11.091216: train loss: 1.6447634539504488
Eval step 0: eval loss: 0.995882071464422
Eval: 2022-04-04 01:33:17.489473: total loss: 1.0904684188845444, mse:4.870049992371992, ic :0.0693657289563917, sharpe5:7.240931265056133, irr5:220.15208435058594, ndcg5:0.8496911223869064, pnl5:2.7606592178344727 
train 4, step: 0, loss: 1.1526579370600265, grad_norm: 0.15645150492573406, ic: 0.08638306216741794
train 4, step: 500, loss: 0.9930550522765925, grad_norm: 0.004983229082666005, ic: 0.10001238868308082
train 4, step: 1000, loss: 1.3325498858814837, grad_norm: 0.06325396065240149, ic: 0.04649919020687497
train 4, step: 1500, loss: 1.0544266920823318, grad_norm: 0.1422595531425126, ic: 0.6079015244678199
train 4, step: 2000, loss: 4.169365595495672, grad_norm: 0.9185740212813586, ic: -0.001562250424176917
Epoch 4: 2022-04-04 01:34:03.799782: train loss: 1.6402421823558548
Eval step 0: eval loss: 0.9987762756508359
Eval: 2022-04-04 01:34:09.919407: total loss: 1.0934137434721536, mse:4.735417326393836, ic :0.12258867550039805, sharpe5:7.53995540946722, irr5:217.30442810058594, ndcg5:0.8648801205270492, pnl5:3.864840269088745 
train 5, step: 0, loss: 1.0052515336419459, grad_norm: 0.20049564674705517, ic: -0.1484079424265254
train 5, step: 500, loss: 0.7894833822385959, grad_norm: 0.03400210209608247, ic: 0.1455768468409389
train 5, step: 1000, loss: 1.0972955279745884, grad_norm: 0.06669314047268907, ic: 0.4076490243104474
train 5, step: 1500, loss: 1.7648741187118901, grad_norm: 0.3616526740678972, ic: -0.06467676138191007
train 5, step: 2000, loss: 2.1766784635554965, grad_norm: 0.8483247010374774, ic: 0.04400196751518597
Epoch 5: 2022-04-04 01:34:56.268321: train loss: 1.6397770334833561
Eval step 0: eval loss: 0.99771582596926
Eval: 2022-04-04 01:35:02.458176: total loss: 1.0850075548843636, mse:4.714393757321639, ic :0.12342960390339348, sharpe5:7.616434449255466, irr5:225.53805541992188, ndcg5:0.84846914205217, pnl5:3.1281633377075195 
train 6, step: 0, loss: 0.7798172404389117, grad_norm: 0.008823562094450284, ic: -0.07740474308589651
train 6, step: 500, loss: 1.4081114830329404, grad_norm: 0.27050687899496884, ic: 0.02918406259062964
train 6, step: 1000, loss: 1.2259776387579757, grad_norm: 0.1811030556889539, ic: 0.22578209957098253
train 6, step: 1500, loss: 1.0583087043042452, grad_norm: 0.35365922729689336, ic: 0.08501664450909904
train 6, step: 2000, loss: 2.295362606766571, grad_norm: 1.2402356633388523, ic: 0.08832284970541805
Epoch 6: 2022-04-04 01:35:48.174281: train loss: 1.6381074081542426
Eval step 0: eval loss: 0.9965315060969588
Eval: 2022-04-04 01:35:54.364556: total loss: 1.085007015271889, mse:4.712059567803044, ic :0.12727528000071653, sharpe5:7.817005226612091, irr5:222.40765380859375, ndcg5:0.8542532711143108, pnl5:2.9757962226867676 
train 7, step: 0, loss: 1.4573329064559308, grad_norm: 0.5511379998348579, ic: 0.20792357122571964
train 7, step: 500, loss: 1.3373697516763925, grad_norm: 0.1074898056839687, ic: 0.18697892116595335
train 7, step: 1000, loss: 0.6410948603474877, grad_norm: 0.020141703319684286, ic: 0.2967399179059132
train 7, step: 1500, loss: 1.0017725958425268, grad_norm: 0.1293340026823141, ic: 0.10632316358979252
train 7, step: 2000, loss: 1.5750364211899102, grad_norm: 0.5950738144376426, ic: 0.4206935292193348
Epoch 7: 2022-04-04 01:36:40.501973: train loss: 1.6376092260236836
Eval step 0: eval loss: 0.990866839352126
Eval: 2022-04-04 01:36:46.626106: total loss: 1.0838503401116986, mse:4.722219891627265, ic :0.12318481158752119, sharpe5:7.686458019018173, irr5:227.22299194335938, ndcg5:0.839200263371885, pnl5:3.142883777618408 
train 8, step: 0, loss: 1.2098406027843602, grad_norm: 0.08905124240156811, ic: 0.0506339292949411
train 8, step: 500, loss: 5.523230860599529, grad_norm: 1.3868143471857224, ic: 0.13882073000939824
train 8, step: 1000, loss: 1.8885353250196388, grad_norm: 0.5839947048991508, ic: 0.06022631600520112
train 8, step: 1500, loss: 1.0788321293908965, grad_norm: 0.3892338179671355, ic: 0.6415335080364123
train 8, step: 2000, loss: 1.1333185831705728, grad_norm: 0.554766791026803, ic: -0.0006837491676173219
Epoch 8: 2022-04-04 01:37:32.673759: train loss: 1.637377758400093
Eval step 0: eval loss: 0.9990352652711952
Eval: 2022-04-04 01:37:38.998684: total loss: 1.08845625295184, mse:4.717000999690865, ic :0.1264557170100646, sharpe5:7.203201126158237, irr5:217.61215209960938, ndcg5:0.8488444521198518, pnl5:2.460355758666992 
train 9, step: 0, loss: 1.1219855680350144, grad_norm: 0.031287511750512524, ic: 0.4365193868564937
train 9, step: 500, loss: 3.167722751379376, grad_norm: 2.0201265542699427, ic: 0.08076908816964685
train 9, step: 1000, loss: 0.8852735980936766, grad_norm: 0.16929080489933002, ic: 0.22031812895188319
train 9, step: 1500, loss: 2.151779496302674, grad_norm: 1.0061131127284344, ic: -0.019146008962507663
train 9, step: 2000, loss: 0.60535810877262, grad_norm: 0.007318083716296931, ic: 0.05889957023965566
Epoch 9: 2022-04-04 01:38:25.692531: train loss: 1.6371772995528127
Eval step 0: eval loss: 0.9852694751966494
Eval: 2022-04-04 01:38:32.129958: total loss: 1.088369354796137, mse:4.767449301479707, ic :0.12834595200138682, sharpe5:11.991062294840813, irr5:396.15081787109375, ndcg5:0.8410364667184914, pnl5:6.186117649078369 
train 10, step: 0, loss: 1.3138016488420983, grad_norm: 0.0902239496391243, ic: 0.3723886060427959
train 10, step: 500, loss: 0.8983771589509097, grad_norm: 0.0061368460470184035, ic: 0.08933785765456834
train 10, step: 1000, loss: 1.5280913163184326, grad_norm: 0.5324191525818445, ic: 0.04794660471479084
train 10, step: 1500, loss: 2.979066141940401, grad_norm: 2.318197640873982, ic: 0.03915503098935643
train 10, step: 2000, loss: 1.3815915185992116, grad_norm: 0.13562419521872776, ic: 0.04571511439281113
Epoch 10: 2022-04-04 01:39:18.193652: train loss: 1.637494881136282
Eval step 0: eval loss: 1.0000050139464849
Eval: 2022-04-04 01:39:24.378699: total loss: 1.0854523767690514, mse:4.71106114130486, ic :0.1273441357264416, sharpe5:7.520843453407287, irr5:220.7274169921875, ndcg5:0.8531938926096153, pnl5:2.7413361072540283 
train 11, step: 0, loss: 4.800739255521892, grad_norm: 1.361282978698901, ic: 0.13440388780566961
train 11, step: 500, loss: 0.9923436037406393, grad_norm: 0.062489893771787694, ic: 0.03624242235687861
train 11, step: 1000, loss: 1.037472885678871, grad_norm: 0.3203589837939597, ic: 0.03349538898614499
train 11, step: 1500, loss: 0.694000507017179, grad_norm: 0.004037068851381614, ic: 0.08202838712219455
train 11, step: 2000, loss: 1.1382653045034523, grad_norm: 0.07560301114617124, ic: -0.18542787757201143
Epoch 11: 2022-04-04 01:40:11.062240: train loss: 1.6365500657667227
Eval step 0: eval loss: 0.9859880765781331
Eval: 2022-04-04 01:40:17.292274: total loss: 1.0834025164125507, mse:4.724285693843437, ic :0.12967638448204147, sharpe5:11.998705374598503, irr5:397.0036926269531, ndcg5:0.8396700837264763, pnl5:5.251870155334473 
train 12, step: 0, loss: 1.3871979339947718, grad_norm: 0.26559105914784054, ic: 0.050981772938621855
train 12, step: 500, loss: 0.8189490121842936, grad_norm: 0.3742190739754581, ic: 0.028371667287714723
train 12, step: 1000, loss: 1.2242157868156331, grad_norm: 0.32573675704849875, ic: 0.574797576379668
train 12, step: 1500, loss: 1.0913616028765292, grad_norm: 0.20030905570192065, ic: -0.09436690109269325
train 12, step: 2000, loss: 1.1155992552800487, grad_norm: 0.06085444893765768, ic: 0.10898782892351429
Epoch 12: 2022-04-04 01:41:03.505509: train loss: 1.6370006355598476
Eval step 0: eval loss: 1.002049418485058
Eval: 2022-04-04 01:41:09.587994: total loss: 1.0858628368571148, mse:4.705844756097192, ic :0.15614987886715387, sharpe5:15.263886748552322, irr5:494.74993896484375, ndcg5:0.857496591747444, pnl5:10.741338729858398 
train 13, step: 0, loss: 1.0827142864220038, grad_norm: 0.05628764369176377, ic: 0.44382162597752095
train 13, step: 500, loss: 1.143528409768607, grad_norm: 0.07910989368800268, ic: -0.044011950825612677
train 13, step: 1000, loss: 1.3839296690597955, grad_norm: 0.43168983122612153, ic: 0.05598250784025206
train 13, step: 1500, loss: 0.7762966301161767, grad_norm: 0.0032289243678716387, ic: -0.04957587262799429
train 13, step: 2000, loss: 1.0361480009720623, grad_norm: 0.029772183646069622, ic: 0.06336660406948881
Epoch 13: 2022-04-04 01:41:55.611495: train loss: 1.632204082579279
Eval step 0: eval loss: 0.9923000566704515
Eval: 2022-04-04 01:42:01.852313: total loss: 1.0815002556237547, mse:4.700939623903496, ic :0.15374236015015733, sharpe5:13.56817112803459, irr5:444.0216064453125, ndcg5:0.8444871690930627, pnl5:4.075947284698486 
train 14, step: 0, loss: 1.7621941000728283, grad_norm: 0.4978557863958752, ic: 0.19335424247760077
train 14, step: 500, loss: 1.275887875413299, grad_norm: 0.5960629287828348, ic: 0.22234376178931028
train 14, step: 1000, loss: 1.0653899389850205, grad_norm: 0.14022488325783222, ic: 0.1661340778661261
train 14, step: 1500, loss: 0.9635771882818513, grad_norm: 0.1562570848449717, ic: 0.19605173962830624
train 14, step: 2000, loss: 2.297945554649266, grad_norm: 0.5927690278333614, ic: -0.07327595637631744
Epoch 14: 2022-04-04 01:42:48.020150: train loss: 1.6291080986004038
Eval step 0: eval loss: 1.0053268681707477
Eval: 2022-04-04 01:42:54.166036: total loss: 1.0846476463905492, mse:4.684489252691502, ic :0.16568251953631663, sharpe5:15.028969881534575, irr5:495.9036560058594, ndcg5:0.8527352864562404, pnl5:8.2212553024292 
train 15, step: 0, loss: 0.9635525130312251, grad_norm: 0.13819005716005492, ic: 0.13865316298362443
train 15, step: 500, loss: 1.2235209069423223, grad_norm: 0.009384581814636781, ic: 0.07269100087607319
train 15, step: 1000, loss: 1.7574296875000002, grad_norm: 0.07016633950946295, ic: -0.018066685297261152
train 15, step: 1500, loss: 5.401227840414733, grad_norm: 0.90930444795646, ic: -0.004416588384930149
train 15, step: 2000, loss: 0.9281612831360742, grad_norm: 0.241269806859209, ic: 0.05736785976002911
Epoch 15: 2022-04-04 01:43:40.578601: train loss: 1.6289842887702985
Eval step 0: eval loss: 1.010738587743549
Eval: 2022-04-04 01:43:46.864689: total loss: 1.0848493621992454, mse:4.682434518146288, ic :0.16320427406537472, sharpe5:15.400683687329291, irr5:518.044677734375, ndcg5:0.8671149936435015, pnl5:8.212434768676758 
train 16, step: 0, loss: 6.371677433274939, grad_norm: 3.9724456157049657, ic: 0.15675723435339795
train 16, step: 500, loss: 1.3596534365699404, grad_norm: 1.014159710681435, ic: -0.014376870099695911
train 16, step: 1000, loss: 0.8499019109463134, grad_norm: 0.804181686232201, ic: -0.06737382184919966
train 16, step: 1500, loss: 1.2346516428964232, grad_norm: 0.42351390383355697, ic: 0.13981411146292635
train 16, step: 2000, loss: 0.9537116507531954, grad_norm: 0.35650621474211563, ic: 0.5459347043627517
Epoch 16: 2022-04-04 01:44:33.076969: train loss: 1.6267730446482997
Eval step 0: eval loss: 0.9974292596432331
Eval: 2022-04-04 01:44:39.286767: total loss: 1.0794071743996134, mse:4.688702986672258, ic :0.15933989081795882, sharpe5:14.038545931577682, irr5:477.78985595703125, ndcg5:0.8509161480880719, pnl5:6.037115097045898 
train 17, step: 0, loss: 1.1806563862993673, grad_norm: 0.023489047335093455, ic: 0.14893153594141514
train 17, step: 500, loss: 1.0436561671594617, grad_norm: 0.03387933416632982, ic: -0.02275446246606945
train 17, step: 1000, loss: 3.3627234732750617, grad_norm: 0.7704785359080317, ic: -0.021350037646855648
train 17, step: 1500, loss: 0.8862126915200244, grad_norm: 0.0033530246993025196, ic: 0.014899429122545445
train 17, step: 2000, loss: 1.0201679818582214, grad_norm: 0.6643764639236684, ic: 0.5632407863980446
Epoch 17: 2022-04-04 01:45:25.453278: train loss: 1.6301055912062303
Eval step 0: eval loss: 1.0051103042514151
Eval: 2022-04-04 01:45:31.643990: total loss: 1.084145032072322, mse:4.712387300156503, ic :0.15585591881276678, sharpe5:14.380309837460517, irr5:486.0035400390625, ndcg5:0.8388935305291264, pnl5:6.005449295043945 
train 18, step: 0, loss: 0.8525049963662791, grad_norm: 0.19800201182768187, ic: 0.0226261355972949
train 18, step: 500, loss: 2.540519319407354, grad_norm: 1.141300927619296, ic: 0.09523457234898029
train 18, step: 1000, loss: 1.3593814108869156, grad_norm: 0.4613810422551578, ic: 0.5349191162500833
train 18, step: 1500, loss: 1.7390500470158405, grad_norm: 0.8342183196505886, ic: 0.33151119960410247
train 18, step: 2000, loss: 1.2536343244511843, grad_norm: 0.487363319826657, ic: 0.22799584420632674
Epoch 18: 2022-04-04 01:46:17.736204: train loss: 1.6280716505551402
Eval step 0: eval loss: 1.0038231341948063
Eval: 2022-04-04 01:46:24.017356: total loss: 1.0811931874463452, mse:4.6815578677133445, ic :0.16724223208748518, sharpe5:15.528368523716926, irr5:510.8092346191406, ndcg5:0.8520624238040632, pnl5:4.733776092529297 
train 19, step: 0, loss: 2.2359003652209255, grad_norm: 0.9291900786282532, ic: 0.2500927998301474
train 19, step: 500, loss: 1.0204375510992005, grad_norm: 0.05851105604202276, ic: 0.05685491967174401
train 19, step: 1000, loss: 0.9950888626812787, grad_norm: 0.5727631583873504, ic: 0.536124392559774
train 19, step: 1500, loss: 1.5808382387514466, grad_norm: 0.149377622188609, ic: 0.1334715598944702
train 19, step: 2000, loss: 1.645628277866396, grad_norm: 2.6291153378283436, ic: 0.622057746810446
Epoch 19: 2022-04-04 01:47:10.832479: train loss: 1.626750479334604
Eval step 0: eval loss: 1.0045956033603212
Eval: 2022-04-04 01:47:17.112954: total loss: 1.0801478770371509, mse:4.686477391302788, ic :0.1599641013898884, sharpe5:13.814524236917496, irr5:455.57330322265625, ndcg5:0.8404486535610766, pnl5:5.709939002990723 
train 20, step: 0, loss: 1.2481093561262857, grad_norm: 0.3602766724393562, ic: 0.4614577248350648
train 20, step: 500, loss: 1.2507683825990894, grad_norm: 0.6417243515832822, ic: -0.006918228215317153
train 20, step: 1000, loss: 1.5740075664207254, grad_norm: 0.3947697319478263, ic: 0.14511525333558073
train 20, step: 1500, loss: 0.8676102837960812, grad_norm: 0.5166193030595103, ic: 0.5877834808168184
train 20, step: 2000, loss: 1.359678646201748, grad_norm: 0.1631340954792211, ic: -0.037884126536231744
Epoch 20: 2022-04-04 01:48:04.007719: train loss: 1.625748087631631
Eval step 0: eval loss: 1.000313757343503
Eval: 2022-04-04 01:48:10.482581: total loss: 1.0816975849280595, mse:4.690288182147529, ic :0.16773526628947863, sharpe5:15.618836858868598, irr5:539.97509765625, ndcg5:0.8579250147817107, pnl5:6.460017681121826 
train 21, step: 0, loss: 1.3836123986424926, grad_norm: 0.3835219539226288, ic: 0.3262509031680701
train 21, step: 500, loss: 1.117995573713657, grad_norm: 0.21324563690535203, ic: 0.02953436189774933
train 21, step: 1000, loss: 0.8663038192661257, grad_norm: 0.21728193302510537, ic: 0.11368603726272512
train 21, step: 1500, loss: 0.7412432478055369, grad_norm: 0.2205892243799905, ic: 0.6243572538331366
train 21, step: 2000, loss: 1.1648754058255322, grad_norm: 0.046215447493155884, ic: 0.15491921574924578
Epoch 21: 2022-04-04 01:48:57.088890: train loss: 1.6267872643200751
Eval step 0: eval loss: 1.003562151852126
Eval: 2022-04-04 01:49:03.293055: total loss: 1.0810883354646406, mse:4.687463354034361, ic :0.15753137453591354, sharpe5:12.371260108351708, irr5:398.4889221191406, ndcg5:0.857064703739314, pnl5:4.7322821617126465 
train 22, step: 0, loss: 1.0538845573335343, grad_norm: 0.23123543537963342, ic: 0.10496832066131578
train 22, step: 500, loss: 1.0279094065268208, grad_norm: 0.006085256242956572, ic: 0.004708307464209912
train 22, step: 1000, loss: 0.908667496533091, grad_norm: 0.06980925311503657, ic: 0.12593990078002382
train 22, step: 1500, loss: 1.008163499683606, grad_norm: 0.03636725885856901, ic: 0.22767798328433916
train 22, step: 2000, loss: 1.0536047647165698, grad_norm: 0.10804812609559478, ic: 0.10415842708766952
Epoch 22: 2022-04-04 01:49:50.160631: train loss: 1.625591018291668
Eval step 0: eval loss: 1.0106582360370588
Eval: 2022-04-04 01:49:56.473789: total loss: 1.0813408298137739, mse:4.6791044825290085, ic :0.16450844251587707, sharpe5:14.00476503252983, irr5:447.1809387207031, ndcg5:0.8560971661455654, pnl5:4.125718116760254 
train 23, step: 0, loss: 1.306704438836833, grad_norm: 0.9178802919271676, ic: -0.024111233810189685
train 23, step: 500, loss: 0.8993050711495536, grad_norm: 0.16801727051501072, ic: 0.5931393212733673
train 23, step: 1000, loss: 2.2881776353258716, grad_norm: 1.190589645309757, ic: 0.0573525855876166
train 23, step: 1500, loss: 0.7841360226623695, grad_norm: 0.2981011766838779, ic: 0.7106927522308567
train 23, step: 2000, loss: 1.4483393455038265, grad_norm: 0.4554229536115573, ic: 0.4304779049009088
Epoch 23: 2022-04-04 01:50:43.427268: train loss: 1.624343274695402
Eval step 0: eval loss: 1.0136398628801342
Eval: 2022-04-04 01:50:49.870965: total loss: 1.0883726977988577, mse:4.696307278194793, ic :0.15838345400470408, sharpe5:12.416030772328376, irr5:405.13018798828125, ndcg5:0.84756383074379, pnl5:4.022620677947998 
train 24, step: 0, loss: 1.1965621721921351, grad_norm: 0.31661915048241557, ic: 0.2797939371154825
train 24, step: 500, loss: 1.2447896181946034, grad_norm: 1.4574525995739362, ic: -0.0015171054272666799
train 24, step: 1000, loss: 1.0364630164169684, grad_norm: 0.3583884894742007, ic: 0.14431097939930587
train 24, step: 1500, loss: 1.2002697081077756, grad_norm: 0.07526387750545123, ic: 0.04799469381397321
train 24, step: 2000, loss: 1.350449146754871, grad_norm: 0.40435109394915575, ic: 0.460870781123429
Epoch 24: 2022-04-04 01:51:36.891758: train loss: 1.6254959696903166
Eval step 0: eval loss: 1.0123271088401788
Eval: 2022-04-04 01:51:43.204225: total loss: 1.082187787320751, mse:4.680900862715976, ic :0.16678217924165165, sharpe5:15.208526446223258, irr5:518.669189453125, ndcg5:0.8425196554128477, pnl5:5.718117713928223 
train 25, step: 0, loss: 1.3293589262489311, grad_norm: 0.48437681150397044, ic: 0.2180912978331535
train 25, step: 500, loss: 1.4656120399376016, grad_norm: 0.7186528050027914, ic: 0.13909285356224213
train 25, step: 1000, loss: 1.3570303234168344, grad_norm: 0.24136178154932098, ic: 0.2740319110597759
train 25, step: 1500, loss: 2.8844202466866378, grad_norm: 0.9780846925506336, ic: 0.1802574363787946
train 25, step: 2000, loss: 1.204282543327235, grad_norm: 0.34713279961369486, ic: 0.14333748029773974
Epoch 25: 2022-04-04 01:52:30.482260: train loss: 1.6255140024189012
Eval step 0: eval loss: 1.0051434734358544
Eval: 2022-04-04 01:52:36.926666: total loss: 1.0797100194795777, mse:4.676738320207016, ic :0.16694097316985965, sharpe5:13.538423656225204, irr5:473.8771667480469, ndcg5:0.8520060253814848, pnl5:3.759763240814209 
train 26, step: 0, loss: 1.6122800071022727, grad_norm: 0.4761460150020921, ic: 0.19212626110213465
train 26, step: 500, loss: 1.0058954845419064, grad_norm: 0.21540241789088854, ic: -0.058765581594118245
train 26, step: 1000, loss: 1.7961114761136554, grad_norm: 0.6872623362616521, ic: 0.20086292766963412
train 26, step: 1500, loss: 0.9248923045636231, grad_norm: 0.021251072555149412, ic: -0.03141039980860026
train 26, step: 2000, loss: 1.0010953647883858, grad_norm: 0.1492325481529453, ic: 0.16736843578881316
Epoch 26: 2022-04-04 01:53:23.376436: train loss: 1.6258172311320829
Eval step 0: eval loss: 1.0044478205017442
Eval: 2022-04-04 01:53:29.676282: total loss: 1.0819538378374416, mse:4.6856236044976365, ic :0.16263016861313426, sharpe5:14.128779677152632, irr5:465.4725646972656, ndcg5:0.8408302472945374, pnl5:4.589924335479736 
train 27, step: 0, loss: 1.6344536471079631, grad_norm: 0.8047661332087003, ic: 0.634596933187848
train 27, step: 500, loss: 1.5209873608816096, grad_norm: 0.3551766052185413, ic: 0.06795735352033717
train 27, step: 1000, loss: 2.3228423052641802, grad_norm: 1.1141882939370455, ic: 0.4361045920668356
train 27, step: 1500, loss: 0.8408820677101405, grad_norm: 0.8078130693956651, ic: 0.5477368564349329
train 27, step: 2000, loss: 1.350911645845334, grad_norm: 3.1906417498349393, ic: -0.004682021923261715
Epoch 27: 2022-04-04 01:54:16.498633: train loss: 1.6227076268097533
Eval step 0: eval loss: 1.008175046899684
Eval: 2022-04-04 01:54:22.798440: total loss: 1.0788623784039584, mse:4.679462256911148, ic :0.16733152661506787, sharpe5:14.01026369869709, irr5:485.25360107421875, ndcg5:0.8422157933502463, pnl5:4.479457378387451 
train 28, step: 0, loss: 1.1580826052341946, grad_norm: 0.23342080250060138, ic: 0.13530981274018766
train 28, step: 500, loss: 2.932983599541804, grad_norm: 0.8683914963720532, ic: 0.13524837268420598
train 28, step: 1000, loss: 2.791059786297887, grad_norm: 3.107562630329925, ic: -0.03959612300626765
train 28, step: 1500, loss: 1.0241875747007607, grad_norm: 0.013866526076452456, ic: 0.19916099293158546
train 28, step: 2000, loss: 1.762966422147529, grad_norm: 0.5067551555311175, ic: 0.03538914748574839
Epoch 28: 2022-04-04 01:55:09.449239: train loss: 1.6243585299126393
Eval step 0: eval loss: 1.0079471051787123
Eval: 2022-04-04 01:55:15.702725: total loss: 1.079593119912907, mse:4.681930319596563, ic :0.1648571979465698, sharpe5:14.235932250022888, irr5:472.6312561035156, ndcg5:0.8444723204837042, pnl5:3.412748336791992 
train 29, step: 0, loss: 1.513605240712661, grad_norm: 0.2393419589784101, ic: 0.07558164491135756
train 29, step: 500, loss: 2.5505865810337727, grad_norm: 3.732982853162496, ic: -0.04542197473007515
train 29, step: 1000, loss: 1.7002368755406574, grad_norm: 1.3906021916520757, ic: 0.4818549728919127
train 29, step: 1500, loss: 3.9654486631105743, grad_norm: 1.414699166088439, ic: 0.13100931806170488
train 29, step: 2000, loss: 0.9267290671200719, grad_norm: 0.27258723375138044, ic: 0.4643943526557178
Epoch 29: 2022-04-04 01:56:02.803491: train loss: 1.6243664716241348
Eval step 0: eval loss: 1.0052499233766126
Eval: 2022-04-04 01:56:09.053010: total loss: 1.0812640599674135, mse:4.683892470833802, ic :0.16149301229255045, sharpe5:14.017807456254959, irr5:475.5378112792969, ndcg5:0.8606456189251351, pnl5:4.727794170379639 
train 30, step: 0, loss: 1.2432895518901401, grad_norm: 0.0785706189225732, ic: 0.9869332031112226
train 30, step: 500, loss: 1.9496531426152097, grad_norm: 0.5211504579977633, ic: 0.16487446907598402
train 30, step: 1000, loss: 3.419992874256444, grad_norm: 1.0181475254867656, ic: 0.3917313819686693
train 30, step: 1500, loss: 1.0834107077801167, grad_norm: 0.25122322218462495, ic: 0.15807960659257178
train 30, step: 2000, loss: 1.0945012950563375, grad_norm: 0.3731910233082866, ic: 0.4410348130766574
Epoch 30: 2022-04-04 01:56:56.427323: train loss: 1.623164664993484
Eval step 0: eval loss: 1.0183486014431937
Eval: 2022-04-04 01:57:02.729134: total loss: 1.0830538187375682, mse:4.690890107851902, ic :0.15995229658628246, sharpe5:13.576162308454514, irr5:460.3872985839844, ndcg5:0.8585152971569542, pnl5:2.352508306503296 
train 31, step: 0, loss: 1.1589153983934681, grad_norm: 0.269044454538351, ic: 0.1905896842297073
train 31, step: 500, loss: 0.8247863721735513, grad_norm: 0.1832101979642959, ic: 0.20863462597553145
train 31, step: 1000, loss: 5.246221045111868, grad_norm: 3.5185172677246026, ic: -0.09618589874623276
train 31, step: 1500, loss: 1.6989617797285548, grad_norm: 0.6624245517623137, ic: 0.28569111650982815
train 31, step: 2000, loss: 0.941847293312979, grad_norm: 0.3761819293928231, ic: 0.16407261468360235
Epoch 31: 2022-04-04 01:57:49.066433: train loss: 1.6264664460771483
Eval step 0: eval loss: 1.0117460052988414
Eval: 2022-04-04 01:57:55.364686: total loss: 1.0824473458606947, mse:4.675775885706547, ic :0.1654957965041677, sharpe5:13.028104301691055, irr5:440.5704345703125, ndcg5:0.8377459464024677, pnl5:4.857163906097412 
train 32, step: 0, loss: 0.8829275366932808, grad_norm: 0.519875948891198, ic: 0.11235085207073041
train 32, step: 500, loss: 1.1061026410358707, grad_norm: 0.39295447218437135, ic: 0.2164351071938277
train 32, step: 1000, loss: 1.3800350582287773, grad_norm: 0.045757957873705415, ic: 0.06768456741714676
train 32, step: 1500, loss: 2.0900637033184988, grad_norm: 0.6321827836217659, ic: 0.4203684821589376
train 32, step: 2000, loss: 1.0695766455678823, grad_norm: 0.5307970055315621, ic: 0.4658941144121418
Epoch 32: 2022-04-04 01:58:41.766781: train loss: 1.620199990555638
Eval step 0: eval loss: 1.0129089837578988
Eval: 2022-04-04 01:58:47.969787: total loss: 1.0801521583205664, mse:4.669504447641319, ic :0.17397262754152285, sharpe5:16.01801467180252, irr5:556.373779296875, ndcg5:0.8673538544843592, pnl5:6.500247955322266 
train 33, step: 0, loss: 1.1631377870750572, grad_norm: 0.016922820978807613, ic: 0.03568204363618456
train 33, step: 500, loss: 3.1547108444225596, grad_norm: 1.5699832654142978, ic: 0.5221503310129356
train 33, step: 1000, loss: 5.237040809359068, grad_norm: 3.4880974260487747, ic: 0.04141029736359658
train 33, step: 1500, loss: 1.3034815346322408, grad_norm: 0.931834130196078, ic: -0.008913834191679713
train 33, step: 2000, loss: 1.869123402676841, grad_norm: 0.40870240201018637, ic: 0.06296092966366526
Epoch 33: 2022-04-04 01:59:33.423605: train loss: 1.6242039460999331
Eval step 0: eval loss: 1.018411275774256
Eval: 2022-04-04 01:59:39.427639: total loss: 1.0895653460504175, mse:4.696747606267991, ic :0.16544630709374733, sharpe5:13.958577371835707, irr5:462.747802734375, ndcg5:0.8394523484798375, pnl5:4.140790939331055 
train 34, step: 0, loss: 0.7167030491655111, grad_norm: 0.443401180251296, ic: 0.1463768502653362
train 34, step: 500, loss: 1.8189970257572925, grad_norm: 0.7506250950093538, ic: 0.8735237543397832
train 34, step: 1000, loss: 0.6997334236934266, grad_norm: 0.02541654336581483, ic: 0.4388351927634994
train 34, step: 1500, loss: 1.6499596228966347, grad_norm: 0.8547860150448017, ic: 0.6326666534644941
train 34, step: 2000, loss: 2.978442624137665, grad_norm: 0.6155439169695569, ic: 0.09621083541316634
Epoch 34: 2022-04-04 02:00:24.752600: train loss: 1.623769518837424
Eval step 0: eval loss: 1.0109026980688849
Eval: 2022-04-04 02:00:30.755852: total loss: 1.0818211939515918, mse:4.679953209779596, ic :0.16597882047619533, sharpe5:14.245425560474395, irr5:468.2685546875, ndcg5:0.8490229450676209, pnl5:4.955117225646973 
train 35, step: 0, loss: 1.0466977855827235, grad_norm: 0.540223776625088, ic: -0.01732962689669426
train 35, step: 500, loss: 3.30238739938447, grad_norm: 1.6268999284344767, ic: -0.0950660576336703
train 35, step: 1000, loss: 1.3553606469803094, grad_norm: 0.12390594609377557, ic: 0.4953859683613391
train 35, step: 1500, loss: 1.62562184876638, grad_norm: 0.3458291380774038, ic: 0.06469514137066291
train 35, step: 2000, loss: 1.2903253967895978, grad_norm: 0.08537879334710423, ic: -0.10918212709225036
Epoch 35: 2022-04-04 02:01:16.438896: train loss: 1.6229169561339891
Eval step 0: eval loss: 1.005782815894056
Eval: 2022-04-04 02:01:22.698329: total loss: 1.0820292080676397, mse:4.681040557499164, ic :0.16755830984494752, sharpe5:15.400853008031845, irr5:528.8414916992188, ndcg5:0.8558747463506761, pnl5:4.847207546234131 
train 36, step: 0, loss: 9.000294433208365, grad_norm: 1.4602789499554103, ic: -0.1950204359652013
train 36, step: 500, loss: 0.8578449165523278, grad_norm: 0.01133874017376128, ic: 0.10659508190358144
train 36, step: 1000, loss: 1.9875380681278496, grad_norm: 3.918681685876349, ic: 0.09255281929256282
train 36, step: 1500, loss: 1.0505431916733052, grad_norm: 0.17789571534977844, ic: 0.12591306077312944
train 36, step: 2000, loss: 2.1451886622185845, grad_norm: 1.4218149062719854, ic: 0.4037842865800589
Epoch 36: 2022-04-04 02:02:07.791143: train loss: 1.6240731381665099
Eval step 0: eval loss: 1.0209023715195498
Eval: 2022-04-04 02:02:13.677698: total loss: 1.0893837272722473, mse:4.700506030724888, ic :0.16069228854142445, sharpe5:13.496013076901436, irr5:449.6705627441406, ndcg5:0.8394095287676575, pnl5:3.8328800201416016 
train 37, step: 0, loss: 1.171355536986326, grad_norm: 0.25456171876122174, ic: 0.18934958957939124
train 37, step: 500, loss: 2.3310794054719914, grad_norm: 0.03935785499742678, ic: 0.1903018148708335
train 37, step: 1000, loss: 0.7673481549778378, grad_norm: 0.4580532332820697, ic: 0.15469248548397904
train 37, step: 1500, loss: 3.136241622382614, grad_norm: 0.7477044432634073, ic: 0.20540025314109492
train 37, step: 2000, loss: 3.1215586383079845, grad_norm: 2.0303772123403308, ic: 0.028282815728049308
Epoch 37: 2022-04-04 02:02:58.475287: train loss: 1.6232407284632047
Eval step 0: eval loss: 1.0089871133861572
Eval: 2022-04-04 02:03:04.473567: total loss: 1.0797368859363403, mse:4.677994943515465, ic :0.16813711197816392, sharpe5:15.358296756148338, irr5:539.8989868164062, ndcg5:0.8489571512313729, pnl5:4.317719459533691 
train 38, step: 0, loss: 1.3538112755977747, grad_norm: 1.2127720649199518, ic: -0.22287789178622086
train 38, step: 500, loss: 1.6571260674055233, grad_norm: 1.0429468072939354, ic: 0.2022100808221265
train 38, step: 1000, loss: 1.8147081972947763, grad_norm: 0.5361038147171496, ic: 0.13894396419793967
train 38, step: 1500, loss: 1.0930560551703492, grad_norm: 0.2637742948549334, ic: 0.4623868263442336
train 38, step: 2000, loss: 0.7542115095057441, grad_norm: 0.057299850061772045, ic: 0.5700665162935455
Epoch 38: 2022-04-04 02:03:50.509389: train loss: 1.621365215923514
Eval step 0: eval loss: 1.0008519209328923
Eval: 2022-04-04 02:03:56.632497: total loss: 1.0786714575775787, mse:4.6826365166244805, ic :0.16942218660732097, sharpe5:14.926611260175704, irr5:529.205078125, ndcg5:0.837534199585394, pnl5:4.287811756134033 
train 39, step: 0, loss: 0.8625276152744865, grad_norm: 0.020384376188200062, ic: 0.542784415446478
train 39, step: 500, loss: 1.245698856944166, grad_norm: 0.423308654511843, ic: 0.04473253202338444
train 39, step: 1000, loss: 1.3835070985736269, grad_norm: 0.2399125350950458, ic: 0.07145485227582667
train 39, step: 1500, loss: 2.4629080636160716, grad_norm: 0.5799531756616293, ic: -0.07865736419676224
train 39, step: 2000, loss: 2.8986527275292087, grad_norm: 1.522392383477778, ic: 0.2249237835517232
Epoch 39: 2022-04-04 02:04:41.949056: train loss: 1.6206205525582402
Eval step 0: eval loss: 1.0043146937944312
Eval: 2022-04-04 02:04:47.883385: total loss: 1.078744437395512, mse:4.676862311067329, ic :0.17003197810611387, sharpe5:15.533061261177062, irr5:516.1030883789062, ndcg5:0.8579600821954044, pnl5:3.510615348815918 

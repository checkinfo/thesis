Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='AdjSeqTimeDataset', dout=0.3, epochs=40, glstm_layers=1, gnn_layers=2, gpu=0, graph_attn=False, hidden_dim=128, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=3, mask_adj=True, mask_type='soft', model_type='RGCNModel', normalize_adj=True, num_days=1, num_heads=1, print_inteval=500, relation_num=1, seed=10086, shuffle=True, side_info=False, sparse_adj_path=None, stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
31534
RGCNModel(
  (fc1): Linear(in_features=9, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
  (fc4): Linear(in_features=128, out_features=1, bias=True)
  (gnns): ModuleList(
    (0): RGCN(
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
    )
    (1): RGCN(
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
    )
  )
  (dropout): Dropout(p=0.3, inplace=False)
  (relu): LeakyReLU(negative_slope=0.01)
)
train 0, step: 0, loss: 2.071792011487154, grad_norm: 0.44913541836739124, ic: -0.17499346925576897
train 0, step: 500, loss: 1.3691432163333965, grad_norm: 0.8467663164997322, ic: -0.023560161016210883
train 0, step: 1000, loss: 1.5065592314724836, grad_norm: 0.03249118936143402, ic: 0.05120011125090921
train 0, step: 1500, loss: 1.1918874003170639, grad_norm: 0.10480280380835652, ic: 0.14549377715813042
train 0, step: 2000, loss: 1.5542671389696074, grad_norm: 0.04471814372915003, ic: -0.14506929687421016
Epoch 0: 2022-04-20 15:08:34.729735: train loss: 1.6476345974149738
Eval step 0: eval loss: 1.0136012940610188
Eval: 2022-04-20 15:08:37.777187: total loss: 1.0917328038914478, mse:4.889281111743499, ic :-0.0026971041000657197, sharpe5:0.7952277451381087, irr5:10.200479507446289, ndcg5:0.8418033418116868, pnl5:1.2525767087936401 
train 1, step: 0, loss: 0.6401989625232054, grad_norm: 0.04972472197142556, ic: 0.0802889893847287
train 1, step: 500, loss: 1.2688721357657509, grad_norm: 0.28706842515586384, ic: 0.07460427265572891
train 1, step: 1000, loss: 0.8860891455105147, grad_norm: 0.0687734837578249, ic: -0.048994101929939256
train 1, step: 1500, loss: 1.8412068064619855, grad_norm: 0.5290794605828252, ic: 0.02710441309174611
train 1, step: 2000, loss: 1.3869066223798814, grad_norm: 0.23061971290604952, ic: 0.08791052273420416
Epoch 1: 2022-04-20 15:09:11.302727: train loss: 1.6467842363387437
Eval step 0: eval loss: 1.0130658302889677
Eval: 2022-04-20 15:09:14.384081: total loss: 1.0903488922346567, mse:4.888372622878113, ic :0.006081609728103627, sharpe5:4.9156216791272165, irr5:103.26846313476562, ndcg5:0.8433102365601333, pnl5:1.8157120943069458 
train 2, step: 0, loss: 1.3330173760278086, grad_norm: 0.5001022187870449, ic: 0.24502227164317897
train 2, step: 500, loss: 0.9525983749644348, grad_norm: 0.271555368156735, ic: 0.018330447312268516
train 2, step: 1000, loss: 2.984755423694233, grad_norm: 0.8835109014754007, ic: 0.024968786041099297
train 2, step: 1500, loss: 2.290277007645222, grad_norm: 0.8315498101631933, ic: -0.016043988273158134
train 2, step: 2000, loss: 1.4639238808258381, grad_norm: 0.2694764866355738, ic: -0.01552272774282877
Epoch 2: 2022-04-20 15:09:47.771142: train loss: 1.6464646611918485
Eval step 0: eval loss: 1.0134189921093337
Eval: 2022-04-20 15:09:50.804286: total loss: 1.0913926379638974, mse:4.888800519110098, ic :0.004153095543395765, sharpe5:8.350738134384155, irr5:232.1598358154297, ndcg5:0.8427034382335575, pnl5:3.461965322494507 
train 3, step: 0, loss: 1.8160890726616297, grad_norm: 0.0534143705670539, ic: 0.08739529721570066
train 3, step: 500, loss: 0.78601105802272, grad_norm: 0.023139259328138068, ic: 0.08295016286901319
train 3, step: 1000, loss: 1.4264043288325245, grad_norm: 0.3644349356861651, ic: 0.17718572149396467
train 3, step: 1500, loss: 2.648744139114463, grad_norm: 0.35524338353504614, ic: -0.03670758030882463
train 3, step: 2000, loss: 1.3613083348129735, grad_norm: 0.15716316842378, ic: 0.04050301485248495
Epoch 3: 2022-04-20 15:10:23.846753: train loss: 1.6463702598093424
Eval step 0: eval loss: 1.0063527987592154
Eval: 2022-04-20 15:10:27.010319: total loss: 1.0906245425410952, mse:4.879288902882031, ic :0.048855527033427916, sharpe5:0.049068119034636766, irr5:-0.3885537385940552, ndcg5:0.8558775971139481, pnl5:1.1818445920944214 
train 4, step: 0, loss: 1.1691379866462137, grad_norm: 0.14649399517772965, ic: 0.13963674821401895
train 4, step: 500, loss: 0.9970823911951144, grad_norm: 0.002382403642395733, ic: 0.09469773443491376
train 4, step: 1000, loss: 1.3373917289402175, grad_norm: 0.06157572558184838, ic: 0.04068264968336605
train 4, step: 1500, loss: 1.0825181227463943, grad_norm: 0.09158292303657281, ic: 0.17629963397907492
train 4, step: 2000, loss: 4.18210239845594, grad_norm: 0.8616938515146854, ic: -0.008763432214855826
Epoch 4: 2022-04-20 15:11:03.355452: train loss: 1.6455594712300128
Eval step 0: eval loss: 1.00730416296406
Eval: 2022-04-20 15:11:06.638128: total loss: 1.0913125011069573, mse:4.881573387794612, ic :0.049179986396245844, sharpe5:1.7324964047223328, irr5:20.7265625, ndcg5:0.8561057325983651, pnl5:1.1731631755828857 
train 5, step: 0, loss: 0.9723459143540556, grad_norm: 0.12661381104369904, ic: -0.13274645401170804
train 5, step: 500, loss: 0.7879271303872927, grad_norm: 0.011649458260792153, ic: 0.14336033325658093
train 5, step: 1000, loss: 1.1197836008005462, grad_norm: 0.04364131790289161, ic: -0.12386888065738284
train 5, step: 1500, loss: 1.752465026359248, grad_norm: 0.32025895571840757, ic: -0.10546489018347877
train 5, step: 2000, loss: 2.180307770180563, grad_norm: 0.7999099974671766, ic: 0.022794121924948285
Epoch 5: 2022-04-20 15:11:42.460775: train loss: 1.6448404718061773
Eval step 0: eval loss: 0.9991631851879278
Eval: 2022-04-20 15:11:45.822560: total loss: 1.0895508739059336, mse:4.877332777555016, ic :0.054420953115320546, sharpe5:1.9603963948041199, irr5:19.76949691772461, ndcg5:0.8516467250841916, pnl5:1.130238652229309 
train 6, step: 0, loss: 0.785863104786961, grad_norm: 0.017610685912963088, ic: -0.09673018031243295
train 6, step: 500, loss: 1.4366118670904147, grad_norm: 0.24078946056985182, ic: 0.09292637693087522
train 6, step: 1000, loss: 1.2321799057726701, grad_norm: 0.17077757243511926, ic: 0.17757760708131298
train 6, step: 1500, loss: 1.0685934736143867, grad_norm: 0.33616848831672885, ic: 0.04136125598637823
train 6, step: 2000, loss: 2.279871464556056, grad_norm: 1.0311639415757725, ic: 0.09946381610569048
Epoch 6: 2022-04-20 15:12:22.270623: train loss: 1.6452623831239157
Eval step 0: eval loss: 1.0027714267788967
Eval: 2022-04-20 15:12:25.571606: total loss: 1.0900265006728038, mse:4.880060804194896, ic :0.048191306558974745, sharpe5:1.2304900818318127, irr5:12.949002265930176, ndcg5:0.842350188840952, pnl5:1.0432206392288208 
train 7, step: 0, loss: 1.4542477653289745, grad_norm: 0.5519282952818886, ic: 0.19931999966325376
train 7, step: 500, loss: 1.3210301254734849, grad_norm: 0.02399860815345437, ic: 0.1055486734166555
train 7, step: 1000, loss: 0.6420234605897949, grad_norm: 0.021344691004845606, ic: 0.28027392499418247
train 7, step: 1500, loss: 1.0016197971627974, grad_norm: 0.12567026190225453, ic: 0.09492908572572512
train 7, step: 2000, loss: 1.594983084266046, grad_norm: 0.561809321842963, ic: 0.10729989035970242
Epoch 7: 2022-04-20 15:13:02.098080: train loss: 1.6446400156986698
Eval step 0: eval loss: 0.9949585410907056
Eval: 2022-04-20 15:13:05.366499: total loss: 1.0884853385422493, mse:4.879477176339465, ic :0.05395412877426836, sharpe5:2.057896150499582, irr5:21.1513729095459, ndcg5:0.8544400631736359, pnl5:0.9859513640403748 
train 8, step: 0, loss: 1.2055457719317733, grad_norm: 0.08645456920471975, ic: 0.05786418695506567
train 8, step: 500, loss: 5.547203327047414, grad_norm: 1.099073545281484, ic: 0.13378002017313056
train 8, step: 1000, loss: 1.8746229532845642, grad_norm: 0.5334151923626985, ic: 0.07027982749078374
train 8, step: 1500, loss: 1.1158947057227047, grad_norm: 0.29949826333916124, ic: 0.08422997464037825
train 8, step: 2000, loss: 1.1241545065855367, grad_norm: 0.48876684374722024, ic: 0.016355242313363674
Epoch 8: 2022-04-20 15:13:41.405317: train loss: 1.643942132298476
Eval step 0: eval loss: 1.0120553915095114
Eval: 2022-04-20 15:13:44.680999: total loss: 1.0927505731875273, mse:4.884631370484563, ic :0.05156849545442377, sharpe5:1.8687558212131261, irr5:18.921024322509766, ndcg5:0.8338362208277362, pnl5:1.2381004095077515 
train 9, step: 0, loss: 1.150959039363195, grad_norm: 0.014477870131118245, ic: 0.061435681288712844
train 9, step: 500, loss: 3.193908598506469, grad_norm: 0.6730691262643864, ic: 0.078391953822473
train 9, step: 1000, loss: 0.8623589834573219, grad_norm: 0.07834218181652697, ic: 0.25610587073866037
train 9, step: 1500, loss: 2.1751402324756888, grad_norm: 1.192845933747422, ic: 0.030895478316931634
train 9, step: 2000, loss: 0.6058887928888425, grad_norm: 0.005636876594352183, ic: 0.06413194517276401
Epoch 9: 2022-04-20 15:14:20.150683: train loss: 1.6443766856723088
Eval step 0: eval loss: 0.9939081835834649
Eval: 2022-04-20 15:14:23.519533: total loss: 1.0888525384425491, mse:4.89656035956089, ic :0.050075399290528615, sharpe5:1.4645157685875891, irr5:15.044301986694336, ndcg5:0.8529211659717416, pnl5:1.1937482357025146 
train 10, step: 0, loss: 1.3087413032234383, grad_norm: 0.05213137944300094, ic: 0.18548487774952277
train 10, step: 500, loss: 0.8976634316954132, grad_norm: 0.005789566743763923, ic: 0.09768715433255226
train 10, step: 1000, loss: 1.5320444226165695, grad_norm: 0.5225818518802418, ic: 0.04155640814866589
train 10, step: 1500, loss: 3.1007307699400077, grad_norm: 0.8583314364844276, ic: 0.02348122325778167
train 10, step: 2000, loss: 1.3857193688853533, grad_norm: 0.13187827448616088, ic: 0.026089974344831623
Epoch 10: 2022-04-20 15:14:59.225679: train loss: 1.644186998906472
Eval step 0: eval loss: 1.0037218910446286
Eval: 2022-04-20 15:15:02.514339: total loss: 1.0898970901906224, mse:4.877866397166835, ic :0.051664272757392424, sharpe5:2.1556384178996084, irr5:22.222753524780273, ndcg5:0.8632068781241746, pnl5:1.1734848022460938 
train 11, step: 0, loss: 4.837210314454652, grad_norm: 1.1648379181227995, ic: 0.09025295111146138
train 11, step: 500, loss: 0.9918461344026017, grad_norm: 0.05827917609355912, ic: 0.03577206882194214
train 11, step: 1000, loss: 1.0394545030630244, grad_norm: 0.32846133198288885, ic: 0.047242952104955084
train 11, step: 1500, loss: 0.692933323799677, grad_norm: 0.0008906803728966053, ic: 0.09089634614688986
train 11, step: 2000, loss: 1.0923012207427905, grad_norm: 0.032338779135386776, ic: 0.016187891151642785
Epoch 11: 2022-04-20 15:15:38.335942: train loss: 1.6433413323238082
Eval step 0: eval loss: 0.9916491435665152
Eval: 2022-04-20 15:15:41.644844: total loss: 1.087933183376305, mse:4.886016668124615, ic :0.053864426990305844, sharpe5:2.901198146045208, irr5:28.17377471923828, ndcg5:0.8532097858767106, pnl5:1.1697311401367188 
train 12, step: 0, loss: 1.388285798627614, grad_norm: 0.26176182980222923, ic: 0.055818197443065
train 12, step: 500, loss: 0.8110900734387332, grad_norm: 0.32936287186871044, ic: 0.01422132362191875
train 12, step: 1000, loss: 1.2739256202073714, grad_norm: 0.2545737286935162, ic: -0.07631321468498518
train 12, step: 1500, loss: 1.0867633411279147, grad_norm: 0.20049142003064585, ic: -0.07155340642786917
train 12, step: 2000, loss: 1.1172599858137908, grad_norm: 0.05840672768797681, ic: 0.08486188726966208
Epoch 12: 2022-04-20 15:16:17.404179: train loss: 1.6437265604371556
Eval step 0: eval loss: 1.0006412708991574
Eval: 2022-04-20 15:16:20.619946: total loss: 1.0909870581213037, mse:4.8816111494951535, ic :0.052646172568510737, sharpe5:2.510098775178194, irr5:25.886913299560547, ndcg5:0.8452613256076075, pnl5:1.0988985300064087 
train 13, step: 0, loss: 1.1077067315313887, grad_norm: 0.03959607505908498, ic: -0.12008176009545972
train 13, step: 500, loss: 1.1460641176645991, grad_norm: 0.006470043889457084, ic: -0.1960291655442335
train 13, step: 1000, loss: 1.3855631638473642, grad_norm: 0.4038446288469733, ic: 0.0763476323638862
train 13, step: 1500, loss: 0.7768840354327197, grad_norm: 0.004123265364561671, ic: -0.049293326807273
train 13, step: 2000, loss: 1.042779550391225, grad_norm: 0.02638675291644606, ic: 0.05835095901027697
Epoch 13: 2022-04-20 15:16:57.975514: train loss: 1.6439099426060642
Eval step 0: eval loss: 0.9932368290053974
Eval: 2022-04-20 15:17:01.264716: total loss: 1.0891134576322201, mse:4.8975063814472115, ic :0.048985752481969264, sharpe5:3.3643295234441757, irr5:35.74906921386719, ndcg5:0.8358437628431599, pnl5:1.365548849105835 
train 14, step: 0, loss: 1.77417819782839, grad_norm: 0.5161026401696817, ic: 0.16697333855566768
train 14, step: 500, loss: 1.28031962869099, grad_norm: 0.15407555424934954, ic: 0.16932224377433355
train 14, step: 1000, loss: 1.07649954803719, grad_norm: 0.12291252061986536, ic: 0.10358862465078468
train 14, step: 1500, loss: 0.9849973800459487, grad_norm: 0.07162654934324614, ic: 0.17900352629679972
train 14, step: 2000, loss: 2.3009744118321778, grad_norm: 0.46266708534425277, ic: -0.04874634174404094
Epoch 14: 2022-04-20 15:17:37.805390: train loss: 1.6438166442176212
Eval step 0: eval loss: 1.0025847536943786
Eval: 2022-04-20 15:17:41.153411: total loss: 1.0922155471777522, mse:4.833641688891044, ic :0.09059848766403553, sharpe5:6.380743786096573, irr5:187.06289672851562, ndcg5:0.8269548865319434, pnl5:1.8815548419952393 
train 15, step: 0, loss: 0.9786709163632283, grad_norm: 0.13958996831166373, ic: 0.13737236737113057
train 15, step: 500, loss: 1.2254736589237967, grad_norm: 0.004834647479348206, ic: 0.03967744322545233
train 15, step: 1000, loss: 1.7602221354166667, grad_norm: 0.09760814640302022, ic: 0.0037961117203500726
train 15, step: 1500, loss: 5.425724604843388, grad_norm: 0.8353008573170467, ic: 0.02983146018612131
train 15, step: 2000, loss: 0.9352988140659606, grad_norm: 0.01791859307474108, ic: -0.10578272348090584
Epoch 15: 2022-04-20 15:18:16.728522: train loss: 1.6356493294092993
Eval step 0: eval loss: 1.0032285958481437
Eval: 2022-04-20 15:18:20.042109: total loss: 1.0867055356499782, mse:4.716250509824472, ic :0.12263875166914125, sharpe5:9.481522325277329, irr5:271.80548095703125, ndcg5:0.8385150312014055, pnl5:3.8815505504608154 
train 16, step: 0, loss: 6.34341709926319, grad_norm: 0.9428990867983522, ic: -0.04193403837096348
train 16, step: 500, loss: 1.3661871047247023, grad_norm: 0.7043536079931649, ic: -0.02126917188550191
train 16, step: 1000, loss: 0.8346768608984689, grad_norm: 0.2893314914485844, ic: 0.0006252917189294629
train 16, step: 1500, loss: 1.2284169974177506, grad_norm: 0.3177498378693167, ic: 0.111628784728938
train 16, step: 2000, loss: 0.9694048555900031, grad_norm: 0.5314880480908453, ic: 0.5478336668473135
Epoch 16: 2022-04-20 15:18:57.078761: train loss: 1.6293371592312524
Eval step 0: eval loss: 1.0028186093009477
Eval: 2022-04-20 15:19:00.424824: total loss: 1.0817720971748241, mse:4.699445758933336, ic :0.1597300636550255, sharpe5:14.873685770630836, irr5:480.0174865722656, ndcg5:0.8489728968830038, pnl5:7.000675201416016 
train 17, step: 0, loss: 1.1852828885879985, grad_norm: 0.009859848924063191, ic: 0.12260521263727148
train 17, step: 500, loss: 1.0470374949021208, grad_norm: 0.04164613479926797, ic: -0.025873199964828023
train 17, step: 1000, loss: 3.3932702596431517, grad_norm: 1.7125557262895674, ic: -0.016350973379927823
train 17, step: 1500, loss: 0.8833374220962278, grad_norm: 0.04224047733991533, ic: 0.08844834766485812
train 17, step: 2000, loss: 0.9986631252621644, grad_norm: 0.5704361109751301, ic: 0.5812364850954624
Epoch 17: 2022-04-20 15:19:36.718726: train loss: 1.6292301739336927
Eval step 0: eval loss: 1.0049469653024616
Eval: 2022-04-20 15:19:39.923994: total loss: 1.0838238287529631, mse:4.7069742336802785, ic :0.16158418309090777, sharpe5:14.97464063823223, irr5:501.7210693359375, ndcg5:0.8382561654106997, pnl5:5.692437171936035 
train 18, step: 0, loss: 0.8533290443940457, grad_norm: 0.02971160045213782, ic: 0.015567135679056673
train 18, step: 500, loss: 2.5111040853533275, grad_norm: 1.1041857069788177, ic: 0.05045963961485249
train 18, step: 1000, loss: 1.370804645346223, grad_norm: 0.5428727063162344, ic: 0.5342722749625887
train 18, step: 1500, loss: 1.7599748144220575, grad_norm: 1.1146133559790892, ic: 0.3133747364931608
train 18, step: 2000, loss: 1.2545409310008664, grad_norm: 0.390904243540535, ic: 0.2260031021924513
Epoch 18: 2022-04-20 15:20:16.618743: train loss: 1.6283564818200125
Eval step 0: eval loss: 0.9957498446962216
Eval: 2022-04-20 15:20:19.937284: total loss: 1.0851026584039372, mse:4.722712169570256, ic :0.12727111011899495, sharpe5:9.637229264974593, irr5:283.0611877441406, ndcg5:0.8396084750917929, pnl5:4.0743608474731445 
train 19, step: 0, loss: 2.260307516318382, grad_norm: 0.681583578514231, ic: 0.060588982615728974
train 19, step: 500, loss: 1.01690673828125, grad_norm: 0.055544582982968244, ic: 0.0772019330487109
train 19, step: 1000, loss: 0.9748036253192979, grad_norm: 0.4284066689571613, ic: 0.5652827684104026
train 19, step: 1500, loss: 1.5786016016830633, grad_norm: 0.05504439674357135, ic: 0.15198075383602982
train 19, step: 2000, loss: 1.791456701952823, grad_norm: 1.6110160618678633, ic: 0.6409850599709301
Epoch 19: 2022-04-20 15:20:56.096606: train loss: 1.628140303353751
Eval step 0: eval loss: 1.0022934305473274
Eval: 2022-04-20 15:20:59.409975: total loss: 1.0849081860413874, mse:4.7235284682410175, ic :0.12246535951926193, sharpe5:7.76038920789957, irr5:227.45278930664062, ndcg5:0.8462393081608058, pnl5:3.30865478515625 
train 20, step: 0, loss: 1.2612134976280003, grad_norm: 0.3639143161464731, ic: 0.4509265628254492
train 20, step: 500, loss: 1.2276797670058919, grad_norm: 0.5269880827165914, ic: 0.05828936317830351
train 20, step: 1000, loss: 1.558303081781035, grad_norm: 0.27719663837331443, ic: 0.18547955465132693
train 20, step: 1500, loss: 0.8591055982322646, grad_norm: 0.3588693677835989, ic: 0.5648199633802411
train 20, step: 2000, loss: 1.3522976849863582, grad_norm: 0.1366903409177384, ic: -0.04048333877553695
Epoch 20: 2022-04-20 15:21:36.334354: train loss: 1.629180773164869
Eval step 0: eval loss: 1.004042397931477
Eval: 2022-04-20 15:21:39.778505: total loss: 1.0892573005914805, mse:4.736449441080079, ic :0.15276928561685577, sharpe5:14.7327050024271, irr5:469.9570617675781, ndcg5:0.8521916412394732, pnl5:5.478250980377197 
train 21, step: 0, loss: 1.3767733293094022, grad_norm: 0.36525286387138756, ic: 0.2730310881024829
train 21, step: 500, loss: 1.1202404719778118, grad_norm: 0.207121264948548, ic: 0.07029136395650114
train 21, step: 1000, loss: 0.9149888100541803, grad_norm: 0.32212268668821453, ic: 0.08715767829497714
train 21, step: 1500, loss: 0.7321497101304018, grad_norm: 0.16141346362088727, ic: 0.6308082948903192
train 21, step: 2000, loss: 1.1236448582048457, grad_norm: 0.2624126818684889, ic: 0.2935106646238717
Epoch 21: 2022-04-20 15:22:18.123548: train loss: 1.6254940250766392
Eval step 0: eval loss: 0.9964850306699249
Eval: 2022-04-20 15:22:21.712561: total loss: 1.0821494719224083, mse:4.697971830741349, ic :0.15073697792935248, sharpe5:12.571459609866142, irr5:378.0498046875, ndcg5:0.8456415977000922, pnl5:5.615236282348633 
train 22, step: 0, loss: 1.0612714466941318, grad_norm: 0.25279531441217556, ic: 0.08104014039534259
train 22, step: 500, loss: 1.0312934454970473, grad_norm: 0.004619147934935266, ic: -0.04711696331138835
train 22, step: 1000, loss: 0.9126570569529456, grad_norm: 0.0138468963719023, ic: 0.1254125606903181
train 22, step: 1500, loss: 0.999485289196359, grad_norm: 0.348638845771015, ic: 0.2698895920790996
train 22, step: 2000, loss: 1.059089838072311, grad_norm: 0.13210225272913526, ic: 0.005374748990149544
Epoch 22: 2022-04-20 15:23:00.176240: train loss: 1.6284149924146998
Eval step 0: eval loss: 1.0075438038934965
Eval: 2022-04-20 15:23:03.567641: total loss: 1.0837527179363393, mse:4.69441228142286, ic :0.15116560866745696, sharpe5:13.669166670441626, irr5:425.2591857910156, ndcg5:0.8359872509180767, pnl5:4.997410297393799 
train 23, step: 0, loss: 1.276643043410273, grad_norm: 0.9014666685023082, ic: 0.005000357931887078
train 23, step: 500, loss: 0.9072228735619849, grad_norm: 0.21173981426035576, ic: 0.598110041249067
train 23, step: 1000, loss: 2.2701681049425515, grad_norm: 1.031276867329665, ic: 0.11657556198191227
train 23, step: 1500, loss: 0.7668806828033208, grad_norm: 0.280166315068499, ic: 0.7163371600930587
train 23, step: 2000, loss: 1.4931521599525228, grad_norm: 0.4779245419236164, ic: 0.4009717432131934
Epoch 23: 2022-04-20 15:23:41.053847: train loss: 1.6246586703205455
Eval step 0: eval loss: 0.9984913806403041
Eval: 2022-04-20 15:23:44.385574: total loss: 1.0843541063289472, mse:4.691597953141623, ic :0.15690557482230305, sharpe5:13.460092493891715, irr5:411.58740234375, ndcg5:0.8388990326153936, pnl5:4.565724849700928 
train 24, step: 0, loss: 1.1738325084772638, grad_norm: 0.3418880524584692, ic: 0.3254290422210878
train 24, step: 500, loss: 1.2527017484267735, grad_norm: 0.3018573435061891, ic: 0.019271664594573277
train 24, step: 1000, loss: 1.0338486462104612, grad_norm: 0.37197814706970067, ic: 0.10227336834147599
train 24, step: 1500, loss: 1.1985142024483268, grad_norm: 0.08281150715331809, ic: 0.07415594181692275
train 24, step: 2000, loss: 1.3595272182727751, grad_norm: 0.4065135794968323, ic: 0.4444200707798076
Epoch 24: 2022-04-20 15:24:20.902995: train loss: 1.6272331175491395
Eval step 0: eval loss: 0.9985222999769615
Eval: 2022-04-20 15:24:24.269934: total loss: 1.0859038630306979, mse:4.724801919842885, ic :0.12280545986253034, sharpe5:7.740296326875686, irr5:227.10595703125, ndcg5:0.8457286229507871, pnl5:2.8846521377563477 
train 25, step: 0, loss: 1.343149670173532, grad_norm: 0.39491123167905995, ic: 0.17877075761668362
train 25, step: 500, loss: 1.484576733081372, grad_norm: 0.29719967818437104, ic: 0.12231580461141969
train 25, step: 1000, loss: 1.3705237609617595, grad_norm: 0.18590436096987323, ic: 0.25536723482567614
train 25, step: 1500, loss: 2.8901654411764706, grad_norm: 0.9676739739613234, ic: 0.07755563262415374
train 25, step: 2000, loss: 1.2067316755463806, grad_norm: 0.14116634251645815, ic: 0.1448932689632808
Epoch 25: 2022-04-20 15:25:02.040804: train loss: 1.632674468337266
Eval step 0: eval loss: 0.9958625299294035
Eval: 2022-04-20 15:25:05.434079: total loss: 1.083871306499643, mse:4.714096841667796, ic :0.12693826145232906, sharpe5:7.409455971121788, irr5:210.7498016357422, ndcg5:0.8412415492561005, pnl5:3.200028896331787 
train 26, step: 0, loss: 1.6273089488636363, grad_norm: 0.1635445119269558, ic: 0.017044878967608347
train 26, step: 500, loss: 1.0200269537669473, grad_norm: 0.19219472498010365, ic: -0.040491297986175706
train 26, step: 1000, loss: 1.8277192508846796, grad_norm: 0.7112846953890767, ic: 0.17521199775803145
train 26, step: 1500, loss: 0.9188889227256211, grad_norm: 0.03815691098893423, ic: 0.057202657999957204
train 26, step: 2000, loss: 0.9918297474778544, grad_norm: 0.10026754738786012, ic: 0.12839927667524303
Epoch 26: 2022-04-20 15:25:41.636122: train loss: 1.6254788462644225
Eval step 0: eval loss: 0.9965313775342285
Eval: 2022-04-20 15:25:44.974865: total loss: 1.081459826554934, mse:4.68462592227672, ic :0.1667767883370278, sharpe5:15.107217802405357, irr5:503.57794189453125, ndcg5:0.8464071657985573, pnl5:5.0094146728515625 
train 27, step: 0, loss: 1.6255239463714233, grad_norm: 0.34008998649836836, ic: 0.6491954546007581
train 27, step: 500, loss: 1.5292921288758747, grad_norm: 0.9774654508896744, ic: 0.053083358706658396
train 27, step: 1000, loss: 2.5719755775908117, grad_norm: 1.2359756963299893, ic: 0.39005380478976703
train 27, step: 1500, loss: 0.8503550119816967, grad_norm: 0.507125652508161, ic: 0.552003480908358
train 27, step: 2000, loss: 1.352846957205261, grad_norm: 1.218758458251765, ic: -0.014491390192497858
Epoch 27: 2022-04-20 15:26:21.881705: train loss: 1.62390255765706
Eval step 0: eval loss: 0.9970135520545352
Eval: 2022-04-20 15:26:25.198560: total loss: 1.0822189187176372, mse:4.699075760092464, ic :0.15121156074337766, sharpe5:12.254211260676383, irr5:373.5060729980469, ndcg5:0.8509898599141645, pnl5:4.948797702789307 
train 28, step: 0, loss: 1.1743725078485854, grad_norm: 0.1034521943507658, ic: 0.12666310328954852
train 28, step: 500, loss: 2.954533132336285, grad_norm: 1.0403511755650297, ic: 0.11289849242152902
train 28, step: 1000, loss: 2.7951515523178316, grad_norm: 3.9661510953278256, ic: -0.047482846781276754
train 28, step: 1500, loss: 1.0254616452488134, grad_norm: 0.021377128221038138, ic: 0.19897014415010447
train 28, step: 2000, loss: 1.7679393679596658, grad_norm: 0.3867505662211859, ic: 0.09307392221182018
Epoch 28: 2022-04-20 15:27:02.187192: train loss: 1.6250266168988845
Eval step 0: eval loss: 1.0047345796718667
Eval: 2022-04-20 15:27:05.642648: total loss: 1.080593380933112, mse:4.694681115116222, ic :0.16188095016293466, sharpe5:14.32476886332035, irr5:461.8576965332031, ndcg5:0.8550662268522414, pnl5:4.871065616607666 
train 29, step: 0, loss: 1.5148559292669637, grad_norm: 0.18524237831316773, ic: 0.07608070464698433
train 29, step: 500, loss: 2.5188450821149093, grad_norm: 1.772382963067933, ic: -0.0852980998069393
train 29, step: 1000, loss: 1.6943658426146193, grad_norm: 1.5627633516096282, ic: 0.4825669487711775
train 29, step: 1500, loss: 3.9356899783615136, grad_norm: 1.3497096589008, ic: 0.13606443326703366
train 29, step: 2000, loss: 0.93625419344366, grad_norm: 0.3367627380100806, ic: 0.46785946827665476
Epoch 29: 2022-04-20 15:27:41.680308: train loss: 1.6244704648333694
Eval step 0: eval loss: 1.002898575319247
Eval: 2022-04-20 15:27:45.248709: total loss: 1.0800495080770243, mse:4.688343620909181, ic :0.16601871008830457, sharpe5:14.677391050457954, irr5:488.80340576171875, ndcg5:0.849084200681698, pnl5:6.423588752746582 
train 30, step: 0, loss: 1.2441961619097748, grad_norm: 0.10355166871858354, ic: 0.989516424359245
train 30, step: 500, loss: 1.9439693402640428, grad_norm: 0.2734828783446154, ic: 0.15903638595337646
train 30, step: 1000, loss: 3.4120393439152346, grad_norm: 1.7066006056641008, ic: 0.44033284880282764
train 30, step: 1500, loss: 1.0779034884139322, grad_norm: 0.22690125946042672, ic: 0.1400355572648826
train 30, step: 2000, loss: 1.0881593363705149, grad_norm: 0.07226050994150289, ic: 0.4379127692530477
Epoch 30: 2022-04-20 15:28:21.175567: train loss: 1.624222320487579
Eval step 0: eval loss: 0.9944295054551737
Eval: 2022-04-20 15:28:24.710976: total loss: 1.081333835576216, mse:4.695150692594063, ic :0.15854038381557534, sharpe5:13.627076759934425, irr5:445.78851318359375, ndcg5:0.858495581283034, pnl5:4.311809539794922 
train 31, step: 0, loss: 1.1691863079961755, grad_norm: 0.42526842213158667, ic: 0.18398116379397622
train 31, step: 500, loss: 0.8243101354492952, grad_norm: 0.08756249595953869, ic: 0.22629755745470373
train 31, step: 1000, loss: 5.089134697227627, grad_norm: 0.9217889617500862, ic: 0.013321865051193638
train 31, step: 1500, loss: 1.686631357467156, grad_norm: 0.2779544714650359, ic: 0.2571917302910628
train 31, step: 2000, loss: 0.9594952930435824, grad_norm: 0.5151856708221341, ic: 0.13705685185618274
Epoch 31: 2022-04-20 15:29:00.639798: train loss: 1.6245276768236827
Eval step 0: eval loss: 1.0034738292563519
Eval: 2022-04-20 15:29:04.057452: total loss: 1.0838370948458662, mse:4.689761263027521, ic :0.15960556877207566, sharpe5:13.55950361073017, irr5:414.97467041015625, ndcg5:0.847822611164664, pnl5:4.511768341064453 
train 32, step: 0, loss: 0.877377178200815, grad_norm: 0.696771377608299, ic: 0.1106907164445685
train 32, step: 500, loss: 1.1083383327577172, grad_norm: 0.44399176855458455, ic: 0.13063683406129967
train 32, step: 1000, loss: 1.3833808145355044, grad_norm: 0.12788353390177376, ic: 0.09329373523201204
train 32, step: 1500, loss: 2.063950482536765, grad_norm: 0.5565214038470588, ic: 0.4510501445690016
train 32, step: 2000, loss: 1.0755801879668279, grad_norm: 0.3462251567273122, ic: 0.4664895993335014
Epoch 32: 2022-04-20 15:29:43.324048: train loss: 1.6224204051025473
Eval step 0: eval loss: 1.0058744168394549
Eval: 2022-04-20 15:29:46.700373: total loss: 1.081454491369421, mse:4.680872562414121, ic :0.17138467464945153, sharpe5:15.639713439345359, irr5:531.6936645507812, ndcg5:0.833789569023333, pnl5:7.458869934082031 
train 33, step: 0, loss: 1.165048201453877, grad_norm: 0.013623096028266468, ic: 0.022872714808001987
train 33, step: 500, loss: 3.1541797775749423, grad_norm: 0.19849277338604326, ic: 0.5186468970544058
train 33, step: 1000, loss: 5.269092045816643, grad_norm: 1.986168132890563, ic: -0.0016031137603830271
train 33, step: 1500, loss: 1.3136659203506098, grad_norm: 1.0670158346258876, ic: 0.0651885323226874
train 33, step: 2000, loss: 1.8584419664486433, grad_norm: 0.26962570284701615, ic: 0.08041027306896148
Epoch 33: 2022-04-20 15:30:22.978147: train loss: 1.6245750231769964
Eval step 0: eval loss: 1.0082347000065823
Eval: 2022-04-20 15:30:26.243935: total loss: 1.0837206569491982, mse:4.684037453881986, ic :0.16569176387077314, sharpe5:14.308449752926826, irr5:460.8901062011719, ndcg5:0.848122812825587, pnl5:5.546926021575928 
train 34, step: 0, loss: 0.7150477970080973, grad_norm: 0.28550614475314845, ic: 0.16357633339669247
train 34, step: 500, loss: 1.8326473535667538, grad_norm: 0.4274072047566608, ic: 0.8422622285357272
train 34, step: 1000, loss: 0.6879674872036637, grad_norm: 0.039387966901853484, ic: 0.47968350239671487
train 34, step: 1500, loss: 1.6576522435897436, grad_norm: 1.3257685006250546, ic: 0.6415219615901931
train 34, step: 2000, loss: 3.011164908746911, grad_norm: 0.46546141991692735, ic: 0.07428984808640604
Epoch 34: 2022-04-20 15:31:02.898040: train loss: 1.6231211089634183
Eval step 0: eval loss: 1.0007513205963665
Eval: 2022-04-20 15:31:06.203701: total loss: 1.080109353358259, mse:4.6871445816032935, ic :0.16778693931535232, sharpe5:14.13715301156044, irr5:480.5686950683594, ndcg5:0.8510752489419923, pnl5:5.63698148727417 
train 35, step: 0, loss: 1.0565679043154173, grad_norm: 0.7801333193008447, ic: 0.02319874755529125
train 35, step: 500, loss: 3.304090465198864, grad_norm: 1.4521304134723043, ic: -0.04852728432751342
train 35, step: 1000, loss: 1.340244113838411, grad_norm: 0.045063636470411006, ic: 0.504920968429633
train 35, step: 1500, loss: 1.6561842159986693, grad_norm: 0.3637812128841021, ic: 0.03739645056662828
train 35, step: 2000, loss: 1.2927308115617782, grad_norm: 0.09217829826987675, ic: -0.0631304189894284
Epoch 35: 2022-04-20 15:31:43.280781: train loss: 1.623344636590816
Eval step 0: eval loss: 0.9953962971876644
Eval: 2022-04-20 15:31:46.667165: total loss: 1.081655382828691, mse:4.688830618268057, ic :0.16128280868119313, sharpe5:13.585296167135239, irr5:414.2096862792969, ndcg5:0.8482290508856836, pnl5:5.700888156890869 
train 36, step: 0, loss: 8.995765403018943, grad_norm: 1.0312620906381553, ic: -0.10197838276093382
train 36, step: 500, loss: 0.8622838034041446, grad_norm: 0.016815118064282306, ic: 0.07762307815824965
train 36, step: 1000, loss: 1.9749536949088147, grad_norm: 3.4487104755153566, ic: 0.061350447658307904
train 36, step: 1500, loss: 1.0473571989516945, grad_norm: 0.15915838257281906, ic: 0.05284768177094301
train 36, step: 2000, loss: 2.1915219258111387, grad_norm: 1.39925517973088, ic: 0.3808088370116536
Epoch 36: 2022-04-20 15:32:23.809761: train loss: 1.6225691797429018
Eval step 0: eval loss: 1.0082303931551144
Eval: 2022-04-20 15:32:27.183750: total loss: 1.0810153287892068, mse:4.6804330492803405, ic :0.16648649000443974, sharpe5:14.064458620548248, irr5:442.7567443847656, ndcg5:0.846177752590164, pnl5:5.314974784851074 
train 37, step: 0, loss: 1.2149016390141754, grad_norm: 0.2375409439134549, ic: 0.13470827874018892
train 37, step: 500, loss: 2.3417182637448133, grad_norm: 0.050858817945688084, ic: 0.15692978114298717
train 37, step: 1000, loss: 0.750256521766046, grad_norm: 0.46347788682122265, ic: 0.1564079322772785
train 37, step: 1500, loss: 3.1072564294495555, grad_norm: 1.2103932260129115, ic: 0.21526169548395085
train 37, step: 2000, loss: 3.1511640773526612, grad_norm: 2.494506413730135, ic: 0.00219865063825192
Epoch 37: 2022-04-20 15:33:07.715875: train loss: 1.6224745270283667
Eval step 0: eval loss: 1.0043449060360716
Eval: 2022-04-20 15:33:11.493997: total loss: 1.079975733854013, mse:4.684250804625389, ic :0.17097839281029695, sharpe5:15.202247391343116, irr5:489.86248779296875, ndcg5:0.8454537865094428, pnl5:5.762602806091309 
train 38, step: 0, loss: 1.3432190866181344, grad_norm: 0.45954819722219686, ic: -0.2528924788018895
train 38, step: 500, loss: 1.7011873940164728, grad_norm: 0.78879066706963, ic: 0.2350118337611541
train 38, step: 1000, loss: 1.849282383825118, grad_norm: 1.0332805837899872, ic: 0.12787870506735483
train 38, step: 1500, loss: 1.0684176941295194, grad_norm: 0.3168997504403239, ic: 0.489283027980424
train 38, step: 2000, loss: 0.7456396283436213, grad_norm: 0.09618481718724588, ic: 0.5859956443209582
Epoch 38: 2022-04-20 15:33:49.472784: train loss: 1.6222126372396768
Eval step 0: eval loss: 0.992823628389942
Eval: 2022-04-20 15:33:52.304885: total loss: 1.0787336350648205, mse:4.70177331485088, ic :0.1690409158873785, sharpe5:14.937255762219428, irr5:484.5931091308594, ndcg5:0.8527117604004856, pnl5:5.6312971115112305 
train 39, step: 0, loss: 0.8641716111892772, grad_norm: 0.04857470369960423, ic: 0.5358592387543243
train 39, step: 500, loss: 1.2478358215968324, grad_norm: 0.7238231208133911, ic: 0.020306164805782838
train 39, step: 1000, loss: 1.405853271484375, grad_norm: 0.3831995208495404, ic: 0.07523431116146989
train 39, step: 1500, loss: 2.466930706239618, grad_norm: 0.8147430153320645, ic: -0.008157998128457319
train 39, step: 2000, loss: 2.905069619622942, grad_norm: 1.5968812165228459, ic: 0.19294071533630208
Epoch 39: 2022-04-20 15:34:18.136567: train loss: 1.6208285282268948
Eval step 0: eval loss: 0.9964800810048051
Eval: 2022-04-20 15:34:20.843214: total loss: 1.0787529600699917, mse:4.688968878099128, ic :0.16979506388335783, sharpe5:15.317007098793983, irr5:498.51397705078125, ndcg5:0.8517367231499692, pnl5:7.089662075042725 

Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='RGCNSeqTimeDataset', dout=0.3, epochs=40, glstm_layers=1, gnn_layers=1, gpu=0, graph_attn=False, hidden_dim=128, inner_prod=False, input_dim=9, input_graph=True, label_cnt=3, lr=0.0004, lstm_layers=1, market=None, mask_adj=True, mask_type='soft', model_type='BiGLSTM', normalize_adj=True, num_days=8, num_heads=1, print_inteval=500, rank_loss=False, relation_num=2, rsr_data_path=None, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_250_0.8/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
load 2305 train graphs successful!
load 126 test graphs successful!
97384
BiGLSTM(
  (input_to_hidden): Linear(in_features=9, out_features=128, bias=True)
  (forward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
            (1): Linear(in_features=128, out_features=128, bias=False)
          )
          (lin_out): Linear(in_features=256, out_features=128, bias=True)
        )
      )
    )
  )
  (backward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
            (1): Linear(in_features=128, out_features=128, bias=False)
          )
          (lin_out): Linear(in_features=256, out_features=128, bias=True)
        )
      )
    )
  )
  (fc0): ModuleList(
    (0): Linear(in_features=256, out_features=128, bias=True)
  )
  (w_out): Linear(in_features=128, out_features=1, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
)
train 0, step: 0, loss: 4.896541258429437, grad_norm: 4.674170520939608, ic: 0.0028186852262038816
train 0, step: 500, loss: 0.8633343280484645, grad_norm: 0.025482812156072218, ic: 0.021884228649856216
train 0, step: 1000, loss: 1.9471540025489211, grad_norm: 0.5376003946874215, ic: 0.035304587792827004
train 0, step: 1500, loss: 0.9561921010375494, grad_norm: 0.05267460808336257, ic: 0.029052276638809115
train 0, step: 2000, loss: 1.0015019306267998, grad_norm: 0.16096783579994547, ic: 0.05518588650340017
Epoch 0: 2022-04-27 19:31:49.263516: train loss: 1.6487654152302516
Eval step 0: eval loss: 0.8362164994813619
Eval: 2022-04-27 19:32:20.450311: total loss: 1.0793043931754809, mse:4.822931978376922, ic :0.007298727268656565, sharpe5:7.360212497413158, irr5:207.47164916992188, ndcg5:0.8472883308549928, pnl5:2.6518890857696533 
train 1, step: 0, loss: 2.7732366746471775, grad_norm: 0.9103974531377398, ic: 0.058312287223272724
train 1, step: 500, loss: 1.7595162604723884, grad_norm: 0.7853305054939421, ic: 0.1259770376606321
train 1, step: 1000, loss: 0.8774328492949068, grad_norm: 0.1797726855930911, ic: 0.045524744190531846
train 1, step: 1500, loss: 1.7135245487607758, grad_norm: 0.2145837329673844, ic: -0.03586496464273077
train 1, step: 2000, loss: 2.1804115234375, grad_norm: 0.8943486890193866, ic: -0.021130690671116184
Epoch 1: 2022-04-27 19:40:33.482586: train loss: 1.6468329636376138
Eval step 0: eval loss: 0.8345574237272787
Eval: 2022-04-27 19:41:04.685224: total loss: 1.0789313579856477, mse:4.82349971610974, ic :0.007778413528430472, sharpe5:7.440480915606021, irr5:209.22793579101562, ndcg5:0.842997851282507, pnl5:2.621349334716797 
train 2, step: 0, loss: 2.142094105113636, grad_norm: 0.009125605198641591, ic: 0.1306214029741363
train 2, step: 500, loss: 3.301114412167449, grad_norm: 0.28106918591145413, ic: 0.05388989558690037
train 2, step: 1000, loss: 2.072712000119732, grad_norm: 0.00018470265034538057, ic: 0.19946611051283217
train 2, step: 1500, loss: 1.4854986059756679, grad_norm: 0.061851025880755035, ic: -0.031000493798515563
train 2, step: 2000, loss: 3.2327411358173075, grad_norm: 0.7794635864948607, ic: 0.21546433880864177
Epoch 2: 2022-04-27 19:49:01.058287: train loss: 1.6465795890306423
Eval step 0: eval loss: 0.8359016120999078
Eval: 2022-04-27 19:49:32.369289: total loss: 1.079398734197116, mse:4.82277934559633, ic :0.011051371469133788, sharpe5:7.577805680930614, irr5:212.95953369140625, ndcg5:0.8513172999499379, pnl5:2.5682358741760254 
train 3, step: 0, loss: 1.5224428750635162, grad_norm: 0.528721700831941, ic: 0.001079488415270567
train 3, step: 500, loss: 1.5014469681443323, grad_norm: 0.3506641051583485, ic: 0.07563162571416461
train 3, step: 1000, loss: 3.6789223292674156, grad_norm: 0.7095471775933293, ic: -0.012242403643394016
train 3, step: 1500, loss: 1.9776801126483226, grad_norm: 1.2710691456559373, ic: -0.02613103659892406
train 3, step: 2000, loss: 0.898411304370777, grad_norm: 0.0009567082651257739, ic: 0.010360026273316739
Epoch 3: 2022-04-27 19:57:33.179550: train loss: 1.646173592649506
Eval step 0: eval loss: 0.8342968827178279
Eval: 2022-04-27 19:58:04.782849: total loss: 1.078852967798225, mse:4.823305963040486, ic :0.016001939122309534, sharpe5:7.415442261993885, irr5:208.8971405029297, ndcg5:0.8367782568001798, pnl5:2.3892922401428223 
train 4, step: 0, loss: 1.4354642657844388, grad_norm: 0.045404358347404986, ic: 0.11069833622665023
train 4, step: 500, loss: 1.6584303487942913, grad_norm: 0.6216990929015215, ic: 0.11346638422297911
train 4, step: 1000, loss: 2.964016053734756, grad_norm: 0.6971503776093257, ic: 0.05307667756368558
train 4, step: 1500, loss: 2.1491186214398734, grad_norm: 0.4579071148652513, ic: 0.0004804502362785717
train 4, step: 2000, loss: 1.0791905997885887, grad_norm: 0.4247971966505087, ic: 0.24478038146064435
Epoch 4: 2022-04-27 20:06:15.184253: train loss: 1.6454469428388159
Eval step 0: eval loss: 0.9185891347388698
Eval: 2022-04-27 20:06:47.020025: total loss: 1.1305620223389767, mse:4.9669983973686005, ic :0.09994917585572777, sharpe5:7.528638827204704, irr5:284.53802490234375, ndcg5:0.841290613951834, pnl5:2.0504324436187744 
train 5, step: 0, loss: 1.4635355494966442, grad_norm: 1.3581082532064435, ic: 0.269505257372998
train 5, step: 500, loss: 0.8877394552934179, grad_norm: 0.01142807543049091, ic: 0.840192924993514
train 5, step: 1000, loss: 0.9846679687500001, grad_norm: 0.15673236001903879, ic: -0.011246205151449359
train 5, step: 1500, loss: 1.5412408849181662, grad_norm: 0.1929916824764013, ic: 0.02686387108346354
train 5, step: 2000, loss: 1.1067718010214254, grad_norm: 0.02626716970323288, ic: 0.10121300259179575
Epoch 5: 2022-04-27 20:14:46.518746: train loss: 1.64004656725384
Eval step 0: eval loss: 0.8346079111852936
Eval: 2022-04-27 20:15:17.969860: total loss: 1.0751579097807977, mse:4.710284886690631, ic :0.1405735795823287, sharpe5:11.774350714087486, irr5:401.3888854980469, ndcg5:0.8402253966122849, pnl5:3.1085143089294434 
train 6, step: 0, loss: 1.3419040515662382, grad_norm: 0.4840145304528901, ic: 0.05793064376873656
train 6, step: 500, loss: 1.0081783370621171, grad_norm: 0.048660359127356737, ic: 0.0368382171265609
train 6, step: 1000, loss: 1.1222442742989542, grad_norm: 0.1145698524409024, ic: 0.5839585326058596
train 6, step: 1500, loss: 1.5640811636428202, grad_norm: 0.7884027860324314, ic: 0.15822299843168455
train 6, step: 2000, loss: 0.7977155161629302, grad_norm: 0.04256535617983391, ic: 0.3543998587452869
Epoch 6: 2022-04-27 20:23:19.959728: train loss: 1.6363880148836518
Eval step 0: eval loss: 0.829748187853991
Eval: 2022-04-27 20:23:51.154108: total loss: 1.0721846845667256, mse:4.70423444237, ic :0.1472219275188015, sharpe5:12.842731239795684, irr5:415.837646484375, ndcg5:0.8550926660104078, pnl5:3.8147592544555664 
train 7, step: 0, loss: 0.993637752532959, grad_norm: 0.04987415447966641, ic: 0.0683966709641875
train 7, step: 500, loss: 0.6498393142839333, grad_norm: 0.0017689631180999243, ic: 0.059711605728315
train 7, step: 1000, loss: 1.0239840737754664, grad_norm: 0.25756135017776693, ic: 0.17228394611116743
train 7, step: 1500, loss: 2.238660675408628, grad_norm: 0.7366541600134576, ic: 0.43680760324835216
train 7, step: 2000, loss: 0.9155510084309371, grad_norm: 0.05611958660341645, ic: -0.036575168755805715
Epoch 7: 2022-04-27 20:31:47.715190: train loss: 1.636199613277502
Eval step 0: eval loss: 0.8407362524902857
Eval: 2022-04-27 20:32:19.970072: total loss: 1.0777171635005591, mse:4.726228438624179, ic :0.13153764969218987, sharpe5:6.760351341962814, irr5:276.1095275878906, ndcg5:0.8475903144461849, pnl5:2.3698830604553223 
train 8, step: 0, loss: 3.5702799479166667, grad_norm: 1.9967010734697532, ic: -0.04108928272882195
train 8, step: 500, loss: 2.735965438889153, grad_norm: 0.95958457194184, ic: 0.057351225729558454
train 8, step: 1000, loss: 3.0717150701992755, grad_norm: 0.8906599481335931, ic: 0.11259892489512333
train 8, step: 1500, loss: 0.7196261668175863, grad_norm: 0.05135917471241608, ic: 0.4435554618377559
train 8, step: 2000, loss: 1.0981707324461074, grad_norm: 0.7592278478231351, ic: 0.2146622983253861
Epoch 8: 2022-04-27 20:40:26.285056: train loss: 1.633182709609078
Eval step 0: eval loss: 0.8265832352311643
Eval: 2022-04-27 20:40:58.370268: total loss: 1.0701978282318634, mse:4.680821035768089, ic :0.16678007648643775, sharpe5:16.066149047613145, irr5:521.4979248046875, ndcg5:0.8500461059824854, pnl5:7.142244815826416 
train 9, step: 0, loss: 5.432163171600878, grad_norm: 0.9320191075787742, ic: 0.0851723884238927
train 9, step: 500, loss: 1.3523219559018285, grad_norm: 1.8291194919931255, ic: 0.31241942505007325
train 9, step: 1000, loss: 0.9246008360914408, grad_norm: 3.6666334640827323, ic: 0.03549904265541756
train 9, step: 1500, loss: 1.089230521964746, grad_norm: 0.031208326263504498, ic: 0.4310858802747203
train 9, step: 2000, loss: 1.0673402240745435, grad_norm: 0.29095477134638237, ic: 0.2544129889887853
Epoch 9: 2022-04-27 20:48:51.521890: train loss: 1.6271035999115269
Eval step 0: eval loss: 0.8285210532056769
Eval: 2022-04-27 20:49:22.933306: total loss: 1.0703210257611369, mse:4.641448217727754, ic :0.17145418028834986, sharpe5:16.11620932817459, irr5:526.4058837890625, ndcg5:0.8347575415658467, pnl5:4.900467395782471 
train 10, step: 0, loss: 7.070178685313411, grad_norm: 2.3444051727813138, ic: 0.24731621328279213
train 10, step: 500, loss: 1.129017109773597, grad_norm: 0.12850216810253562, ic: 0.052633075946003166
train 10, step: 1000, loss: 2.4048319623514187, grad_norm: 0.721390057112054, ic: 0.15945390425380257
train 10, step: 1500, loss: 1.0902890292080967, grad_norm: 0.43846124265455483, ic: 0.014206714429231874
train 10, step: 2000, loss: 2.750006678618921, grad_norm: 0.3906121827156326, ic: 0.4362661011492742
Epoch 10: 2022-04-27 20:57:18.195837: train loss: 1.6261899975244507
Eval step 0: eval loss: 0.8269833402965292
Eval: 2022-04-27 20:57:49.467418: total loss: 1.0703139266784985, mse:4.671632441296244, ic :0.17132865386164067, sharpe5:17.18412918806076, irr5:558.6795043945312, ndcg5:0.8400638126420712, pnl5:9.463105201721191 
train 11, step: 0, loss: 1.2549269957221578, grad_norm: 0.08916886075920741, ic: 0.19912364798850118
train 11, step: 500, loss: 0.6570779349057728, grad_norm: 0.03374457839449197, ic: 0.5737447347091535
train 11, step: 1000, loss: 0.9279754965735779, grad_norm: 0.11712552066134786, ic: 0.06188506785422057
train 11, step: 1500, loss: 1.0595214576051946, grad_norm: 0.06065062977116606, ic: 0.17989784428040034
train 11, step: 2000, loss: 0.7891158696034508, grad_norm: 0.011837188152959886, ic: 0.12680829510296165
Epoch 11: 2022-04-27 21:05:57.534140: train loss: 1.6250933845075883
Eval step 0: eval loss: 0.8317964993990384
Eval: 2022-04-27 21:06:29.088795: total loss: 1.0687418884045272, mse:4.588586238878385, ic :0.1829898801950856, sharpe5:17.69384882569313, irr5:571.5859985351562, ndcg5:0.8495150053368025, pnl5:4.824222564697266 
train 12, step: 0, loss: 0.9569260279337565, grad_norm: 0.08540933488710263, ic: 0.411029771397432
train 12, step: 500, loss: 0.9372525601773649, grad_norm: 0.12673058974869778, ic: 0.18280980464770188
train 12, step: 1000, loss: 2.96631772958549, grad_norm: 0.31379740268336054, ic: 0.37239132030178235
train 12, step: 1500, loss: 0.9486386138613861, grad_norm: 0.24419759273789712, ic: -0.11008353482898192
train 12, step: 2000, loss: 0.8749069720956855, grad_norm: 0.0036202818460001757, ic: 0.1882095428629548
Epoch 12: 2022-04-27 21:14:38.427014: train loss: 1.6245589377434182
Eval step 0: eval loss: 0.8323370046183483
Eval: 2022-04-27 21:15:09.845619: total loss: 1.0708907708008026, mse:4.674410406684998, ic :0.16945871269722917, sharpe5:16.70781586289406, irr5:540.364501953125, ndcg5:0.8403840007403084, pnl5:7.918980598449707 
train 13, step: 0, loss: 2.0821653082101372, grad_norm: 0.6562565493232747, ic: 0.388137271212258
train 13, step: 500, loss: 0.8151027788732094, grad_norm: 0.04129359576777182, ic: 0.5946219108536757
train 13, step: 1000, loss: 0.9435204422713925, grad_norm: 0.353026369559589, ic: 0.589647478321585
train 13, step: 1500, loss: 2.3685235076356363, grad_norm: 0.19519149711496492, ic: -0.11414807097493494
train 13, step: 2000, loss: 1.4741671402882024, grad_norm: 0.11467597629455024, ic: 0.16445729322382024
Epoch 13: 2022-04-27 21:23:08.541495: train loss: 1.624877065720128
Eval step 0: eval loss: 0.8268423613054859
Eval: 2022-04-27 21:23:39.780929: total loss: 1.0688896866380622, mse:4.611408619621509, ic :0.17675616727620477, sharpe5:16.942780026197433, irr5:543.5309448242188, ndcg5:0.8597259295694899, pnl5:7.56303596496582 
train 14, step: 0, loss: 4.579319041902301, grad_norm: 1.3600672336297843, ic: 0.17769943135288682
train 14, step: 500, loss: 0.8271377983443234, grad_norm: 0.0019711616987474613, ic: 0.0810938245107419
train 14, step: 1000, loss: 1.8256494845055051, grad_norm: 0.39590197063399624, ic: 0.4586982836062136
train 14, step: 1500, loss: 1.1289522419544742, grad_norm: 0.06263480145372044, ic: -0.07079822585660467
train 14, step: 2000, loss: 1.1527708544808584, grad_norm: 0.17250367517697704, ic: 0.10081524942235874
Epoch 14: 2022-04-27 21:31:31.963989: train loss: 1.6218248578330563
Eval step 0: eval loss: 0.8325203030327977
Eval: 2022-04-27 21:32:03.194564: total loss: 1.0685541682096527, mse:4.590852850166321, ic :0.182579021535706, sharpe5:16.911140702962875, irr5:538.4793090820312, ndcg5:0.8513199140147503, pnl5:6.671511650085449 
train 15, step: 0, loss: 3.3831240880350197, grad_norm: 0.6032391009978164, ic: 0.055818803333384015
train 15, step: 500, loss: 1.2552515602270367, grad_norm: 0.04624044020878602, ic: 0.013811494146851601
train 15, step: 1000, loss: 1.3148019682101117, grad_norm: 0.11885319575800467, ic: 0.06961653534269216
train 15, step: 1500, loss: 0.8528677872785433, grad_norm: 0.1839180125971242, ic: 0.04554610535235871
train 15, step: 2000, loss: 1.4659765860884661, grad_norm: 0.5244083988398927, ic: 0.04606022258971744
Epoch 15: 2022-04-27 21:40:08.375853: train loss: 1.6217445597952258
Eval step 0: eval loss: 0.8335353260422155
Eval: 2022-04-27 21:40:40.567679: total loss: 1.0692456254991025, mse:4.588674930098776, ic :0.18561332798565264, sharpe5:17.77430926680565, irr5:573.9371337890625, ndcg5:0.8484520312526124, pnl5:11.446809768676758 
train 16, step: 0, loss: 0.6994070263014648, grad_norm: 0.37769078401397166, ic: -0.10164919448430808
train 16, step: 500, loss: 1.5966711574411065, grad_norm: 0.44214715804996296, ic: 0.18244573921555424
train 16, step: 1000, loss: 0.877154541015625, grad_norm: 0.003316819699187257, ic: -0.085620797048588
train 16, step: 1500, loss: 0.868709098268814, grad_norm: 0.2170456671019575, ic: 0.14096659697915956
train 16, step: 2000, loss: 3.347919139657308, grad_norm: 0.9305702023830362, ic: 0.0217729933287598
Epoch 16: 2022-04-27 21:48:47.416405: train loss: 1.6220126832044883
Eval step 0: eval loss: 0.8302567927176633
Eval: 2022-04-27 21:49:18.007070: total loss: 1.0705397949371345, mse:4.684809406161427, ic :0.17156570742422073, sharpe5:17.49809328317642, irr5:567.5872802734375, ndcg5:0.8467447554581906, pnl5:15.217159271240234 
train 17, step: 0, loss: 1.274495140500663, grad_norm: 0.24255339015222488, ic: -0.1198542928842126
train 17, step: 500, loss: 1.7381629509654473, grad_norm: 0.5673423662590125, ic: 0.19390695798076713
train 17, step: 1000, loss: 1.2859691890906682, grad_norm: 0.09796706782193432, ic: 0.16895586340709245
train 17, step: 1500, loss: 4.5053441862601025, grad_norm: 1.36551608968264, ic: 0.22684630400376396
train 17, step: 2000, loss: 1.313674477612868, grad_norm: 1.07849907791964, ic: 0.046565550041862365
Epoch 17: 2022-04-27 21:57:14.147819: train loss: 1.6249350249644188
Eval step 0: eval loss: 0.836468486564805
Eval: 2022-04-27 21:57:45.840331: total loss: 1.072402962607094, mse:4.587943158085513, ic :0.1865121814404026, sharpe5:18.436067544221878, irr5:603.0657958984375, ndcg5:0.8559446201008185, pnl5:6.731804370880127 
train 18, step: 0, loss: 1.4385082566015932, grad_norm: 0.996909382018692, ic: 0.21726770545932936
train 18, step: 500, loss: 1.4906812764830508, grad_norm: 1.0395443410286844, ic: 0.03245469805320077
train 18, step: 1000, loss: 0.6582515517979451, grad_norm: 0.039411285520086534, ic: 0.573483393328117
train 18, step: 1500, loss: 1.4311868353616402, grad_norm: 0.03594879396328708, ic: 0.21327661611368348
train 18, step: 2000, loss: 0.9142712635599125, grad_norm: 0.008861208032757953, ic: -0.047482799519527046
Epoch 18: 2022-04-27 22:17:37.615268: train loss: 1.6217362208571366
Eval step 0: eval loss: 0.8235999088267254
Eval: 2022-04-27 22:18:55.702785: total loss: 1.0663232455553913, mse:4.586126932964815, ic :0.19305097737795723, sharpe5:17.873676871061324, irr5:588.46875, ndcg5:0.8481018499056154, pnl5:6.028214931488037 
train 19, step: 0, loss: 1.4700203062996031, grad_norm: 0.7358220289138395, ic: -0.0047670657060058415
train 19, step: 500, loss: 0.8668284946017795, grad_norm: 0.05429742057934991, ic: 0.22299729528059045
train 19, step: 1000, loss: 0.9573928265292806, grad_norm: 0.01899282882760247, ic: 0.2072277780717433
train 19, step: 1500, loss: 3.943940645862614, grad_norm: 0.8785103899217115, ic: 0.16533484574753
train 19, step: 2000, loss: 1.0189239032451922, grad_norm: 0.09309772882261744, ic: 0.23504716169894768
Epoch 19: 2022-04-27 22:41:34.996173: train loss: 1.6226497409597465
Eval step 0: eval loss: 0.8301787140246312
Eval: 2022-04-27 22:42:44.337284: total loss: 1.0676904814333286, mse:4.583237825217814, ic :0.18991721402432749, sharpe5:17.973848512172697, irr5:597.8084106445312, ndcg5:0.8577606512159086, pnl5:8.156356811523438 
train 20, step: 0, loss: 2.310163197875494, grad_norm: 0.7634705376573698, ic: 0.04303612721582999
train 20, step: 500, loss: 3.1883707386363636, grad_norm: 0.5129058161965733, ic: 0.03446672900101999
train 20, step: 1000, loss: 0.981002426147461, grad_norm: 0.08465225750229757, ic: 0.1865009339209514
train 20, step: 1500, loss: 1.8783609527541156, grad_norm: 0.43575696529936914, ic: 0.24189020838802638
train 20, step: 2000, loss: 1.0484248747833402, grad_norm: 0.17374521470060728, ic: -0.019163564651233755
Epoch 20: 2022-04-27 23:05:26.758805: train loss: 1.622046296174825
Eval step 0: eval loss: 0.828344379260241
Eval: 2022-04-27 23:06:42.528725: total loss: 1.0661344516581577, mse:4.579406922271298, ic :0.194208699600181, sharpe5:17.66624482154846, irr5:584.6956787109375, ndcg5:0.8554844557305795, pnl5:9.69839096069336 
train 21, step: 0, loss: 1.0114565455758964, grad_norm: 0.3574770536029148, ic: 0.10466355193077663
train 21, step: 500, loss: 0.7726961659119193, grad_norm: 0.012687176450553408, ic: 0.18404798931613556
train 21, step: 1000, loss: 0.9234451829341419, grad_norm: 0.4365453235701692, ic: 0.15809438161814504
train 21, step: 1500, loss: 0.9967961156857451, grad_norm: 0.18397685285914733, ic: 0.3158350246183056
train 21, step: 2000, loss: 0.9413857021733112, grad_norm: 0.04559086464114237, ic: 0.06242246035600252
Epoch 21: 2022-04-27 23:28:26.384487: train loss: 1.6209127466605537
Eval step 0: eval loss: 0.8234163531513434
Eval: 2022-04-27 23:29:45.213602: total loss: 1.0663963429663559, mse:4.596878239617621, ic :0.1885088730353535, sharpe5:18.20960157752037, irr5:594.1211547851562, ndcg5:0.8423933837735188, pnl5:7.937729358673096 
train 22, step: 0, loss: 1.044748252394509, grad_norm: 0.04274620234609118, ic: 0.21225853230861294
train 22, step: 500, loss: 3.260239218114837, grad_norm: 0.9756471615374279, ic: -0.22588946222294118
train 22, step: 1000, loss: 1.1974411804552023, grad_norm: 0.1018450491884459, ic: 0.46337074984370746
train 22, step: 1500, loss: 0.9759789737654321, grad_norm: 0.0706489466262952, ic: 0.13207517187541523
train 22, step: 2000, loss: 1.7709592788938493, grad_norm: 0.6942153480376654, ic: 0.1154480653689577
Epoch 22: 2022-04-27 23:51:47.151132: train loss: 1.6208298976163742
Eval step 0: eval loss: 0.8299655733420047
Eval: 2022-04-27 23:52:59.141502: total loss: 1.0678747472975334, mse:4.5910835151570595, ic :0.18980593853837227, sharpe5:17.76637105822563, irr5:581.336669921875, ndcg5:0.8627390953143457, pnl5:8.81373405456543 
train 23, step: 0, loss: 0.996048017606268, grad_norm: 0.07654983014958754, ic: 0.11109090659199165
train 23, step: 500, loss: 1.4300501657243427, grad_norm: 0.09918133545628875, ic: 0.05877796851196654
train 23, step: 1000, loss: 1.656365966796875, grad_norm: 0.09161697117258687, ic: 0.2595754427443316
train 23, step: 1500, loss: 1.0995870781969492, grad_norm: 0.18413289433390684, ic: 0.10434400639127867
train 23, step: 2000, loss: 1.9587738765396459, grad_norm: 0.6941651563791561, ic: 0.43157425600847255
Epoch 23: 2022-04-28 00:15:05.235076: train loss: 1.620552109902188
Eval step 0: eval loss: 0.8303600829820863
Eval: 2022-04-28 00:16:22.560128: total loss: 1.068339741996267, mse:4.596310241023152, ic :0.181244913796311, sharpe5:14.621999532580375, irr5:494.298095703125, ndcg5:0.8558350780533316, pnl5:4.521299839019775 
train 24, step: 0, loss: 2.192027033358321, grad_norm: 0.03408769678591868, ic: 0.16321738992281898
train 24, step: 500, loss: 1.2290747735286967, grad_norm: 0.08859197867324041, ic: 0.2373811224334505
train 24, step: 1000, loss: 0.9005571219826132, grad_norm: 0.053218471637435746, ic: 0.5356208398865632
train 24, step: 1500, loss: 2.6119303251236605, grad_norm: 0.8051231954064952, ic: 0.050721376328878784
train 24, step: 2000, loss: 0.9288181842782192, grad_norm: 0.029329458309862506, ic: 0.10876199722186183
Epoch 24: 2022-04-28 00:38:38.889223: train loss: 1.619645453569668
Eval step 0: eval loss: 0.8245269485972075
Eval: 2022-04-28 00:40:04.880192: total loss: 1.0677639504312177, mse:4.615226897063643, ic :0.18874760234818352, sharpe5:18.19948584794998, irr5:594.054443359375, ndcg5:0.8280781824487821, pnl5:12.558968544006348 
train 25, step: 0, loss: 0.8446534852723818, grad_norm: 0.22416506899851152, ic: 0.6126359978364669
train 25, step: 500, loss: 0.8658886128682024, grad_norm: 0.007690315255443216, ic: 0.2179457791289831
train 25, step: 1000, loss: 2.102018241562738, grad_norm: 0.36473143644525235, ic: 0.23289212129714
train 25, step: 1500, loss: 1.138810959172023, grad_norm: 0.41146620158074515, ic: 0.5312736534522613
train 25, step: 2000, loss: 1.02333787842644, grad_norm: 0.4770227773781691, ic: 0.602092136031893
Epoch 25: 2022-04-28 01:02:32.469657: train loss: 1.619918839780661
Eval step 0: eval loss: 0.8281652613359457
Eval: 2022-04-28 01:03:54.128405: total loss: 1.0685309045602036, mse:4.590044128730861, ic :0.19392941597256294, sharpe5:18.46321182847023, irr5:599.3442993164062, ndcg5:0.8469521348983479, pnl5:4.904018402099609 
train 26, step: 0, loss: 6.6828067279852235, grad_norm: 1.649622214195522, ic: 0.14340851327807944
train 26, step: 500, loss: 3.866381969556294, grad_norm: 0.934220158166967, ic: 0.3652231775236426
train 26, step: 1000, loss: 1.2671988830087324, grad_norm: 1.0735109968550458, ic: 0.008324702885629151
train 26, step: 1500, loss: 0.8351481472851139, grad_norm: 0.1971737242604588, ic: 0.3082685492117125
train 26, step: 2000, loss: 0.9525503763338414, grad_norm: 0.09889603117479832, ic: 0.21265655314336623
Epoch 26: 2022-04-28 01:26:01.631216: train loss: 1.619539494481859
Eval step 0: eval loss: 0.8274975405854846
Eval: 2022-04-28 01:27:23.391297: total loss: 1.0667649958128207, mse:4.591195851240765, ic :0.19130419625632727, sharpe5:18.23533264875412, irr5:594.7465209960938, ndcg5:0.8496540451731944, pnl5:4.9365363121032715 
train 27, step: 0, loss: 0.8303175742953431, grad_norm: 0.02055087744168374, ic: 0.11350225629988833
train 27, step: 500, loss: 0.9483648355624578, grad_norm: 1.0058379159316986, ic: 0.292067746744267
train 27, step: 1000, loss: 0.7462271493438225, grad_norm: 0.20346737261537068, ic: 0.20316946834592953
train 27, step: 1500, loss: 0.6439927591981773, grad_norm: 0.08655840684307389, ic: 0.5104369126966141
train 27, step: 2000, loss: 1.384476437927107, grad_norm: 0.017577455423324645, ic: -0.030546663438626637
Epoch 27: 2022-04-28 01:49:53.747173: train loss: 1.6176650524632747
Eval step 0: eval loss: 0.8297506318328504
Eval: 2022-04-28 01:51:15.548479: total loss: 1.0717582899390363, mse:4.699382534626763, ic :0.167261772343111, sharpe5:18.247921028137206, irr5:598.7562866210938, ndcg5:0.8510011526189657, pnl5:6.110631942749023 
train 28, step: 0, loss: 1.5214723093629343, grad_norm: 0.2723037999848734, ic: 0.23105474107715443
train 28, step: 500, loss: 1.3707714134118223, grad_norm: 1.5798517394929055, ic: 0.2114547557728337
train 28, step: 1000, loss: 0.903552047605437, grad_norm: 0.2512785050476572, ic: 0.577360734888221
train 28, step: 1500, loss: 1.037732910535645, grad_norm: 0.030919665385610338, ic: 0.02164576301292918
train 28, step: 2000, loss: 1.0475681047498082, grad_norm: 0.13987027078252828, ic: 0.08912659120515047
Epoch 28: 2022-04-28 02:13:51.858474: train loss: 1.6173385350103913
Eval step 0: eval loss: 0.8268004920887118
Eval: 2022-04-28 02:15:17.819436: total loss: 1.0744371416041933, mse:4.65768440502656, ic :0.17882857370452934, sharpe5:17.594210686683653, irr5:569.1580810546875, ndcg5:0.8345985667654975, pnl5:9.31712532043457 
train 29, step: 0, loss: 0.9043143665004264, grad_norm: 0.03173919397366973, ic: 0.1252241100999572
train 29, step: 500, loss: 1.1212862813325748, grad_norm: 0.26838772075597406, ic: 0.6009984212664812
train 29, step: 1000, loss: 1.058880235813987, grad_norm: 0.5308291885061222, ic: 0.10424359448543134
train 29, step: 1500, loss: 2.3178274495633295, grad_norm: 0.16602505633521436, ic: -0.04878063036287135
train 29, step: 2000, loss: 4.330240131896219, grad_norm: 5.8033938906639255, ic: 0.20468157431112075
Epoch 29: 2022-04-28 02:37:19.397636: train loss: 1.6152405102371281
Eval step 0: eval loss: 0.835697990071786
Eval: 2022-04-28 02:38:47.042882: total loss: 1.069099409780404, mse:4.593389708442892, ic :0.18668880527868573, sharpe5:17.247078652381894, irr5:565.4640502929688, ndcg5:0.8351392216098494, pnl5:4.504879474639893 
train 30, step: 0, loss: 1.018809939358718, grad_norm: 0.09556754838966247, ic: 0.5049317909916698
train 30, step: 500, loss: 1.4135064241629922, grad_norm: 0.93628768945005, ic: 0.039760996930004774
train 30, step: 1000, loss: 0.985904208096591, grad_norm: 0.05979183384156254, ic: -0.07489704599252392
train 30, step: 1500, loss: 1.5013046550699651, grad_norm: 1.5186537874703039, ic: 0.15127329697140732
train 30, step: 2000, loss: 1.836872594084736, grad_norm: 0.24997371605467714, ic: 0.07497844002035804
Epoch 30: 2022-04-28 03:01:12.399818: train loss: 1.6162519621866671
Eval step 0: eval loss: 0.8384084912572444
Eval: 2022-04-28 03:02:35.868960: total loss: 1.0737200281980674, mse:4.65353830025602, ic :0.19004392887747693, sharpe5:18.08802174568176, irr5:588.6204223632812, ndcg5:0.8584824951077336, pnl5:6.397682189941406 
train 31, step: 0, loss: 1.0391277258773792, grad_norm: 0.5301049229789985, ic: 0.37390655624310387
train 31, step: 500, loss: 1.5144027898341048, grad_norm: 0.7525782776025902, ic: 0.05209490678537846
train 31, step: 1000, loss: 4.428096488339188, grad_norm: 2.395235896705941, ic: 0.47557600924878063
train 31, step: 1500, loss: 0.7702727743217377, grad_norm: 0.10047077258275516, ic: 0.7090848044634365
train 31, step: 2000, loss: 1.226338580748955, grad_norm: 0.5460092379494655, ic: 0.19793810189081204
Epoch 31: 2022-04-28 03:25:08.994454: train loss: 1.6163995434585785
Eval step 0: eval loss: 0.8293989561380399
Eval: 2022-04-28 03:26:31.092298: total loss: 1.0657829246209451, mse:4.582747116083713, ic :0.1947318844780301, sharpe5:18.536534314155578, irr5:609.9613037109375, ndcg5:0.8438659877781969, pnl5:8.6494779586792 
train 32, step: 0, loss: 1.12474158770947, grad_norm: 0.037812537800281466, ic: 0.19898934744058436
train 32, step: 500, loss: 1.4807982437253937, grad_norm: 0.44058570603190855, ic: 0.1232642055363086
train 32, step: 1000, loss: 1.064395333986789, grad_norm: 0.410657469268365, ic: 0.5024406277054232
train 32, step: 1500, loss: 0.9888023068030131, grad_norm: 1.4967866896037627, ic: 0.09574558708683857
train 32, step: 2000, loss: 0.9468249368638186, grad_norm: 0.2964014247428722, ic: 0.5512443476005796
Epoch 32: 2022-04-28 03:47:58.930818: train loss: 1.6163281763410893
Eval step 0: eval loss: 0.8222681976093256
Eval: 2022-04-28 03:49:26.748500: total loss: 1.0659614705076894, mse:4.60205073074601, ic :0.19222261351708086, sharpe5:18.29056335926056, irr5:595.4798583984375, ndcg5:0.839443234453546, pnl5:10.628334045410156 
train 33, step: 0, loss: 1.2589761666722912, grad_norm: 0.25000338933481986, ic: 0.20587300124435365
train 33, step: 500, loss: 0.9897994353991596, grad_norm: 0.06663257377605564, ic: 0.21185440995241744
train 33, step: 1000, loss: 1.0649929557710343, grad_norm: 1.2118796383376016, ic: 0.22184650744030543
train 33, step: 1500, loss: 0.8956452321044633, grad_norm: 0.3166813856311882, ic: 0.5503214968954565
train 33, step: 2000, loss: 0.8121621302681755, grad_norm: 0.21369497528609863, ic: 0.25629042911074773
Epoch 33: 2022-04-28 04:11:12.496490: train loss: 1.6182956531766302
Eval step 0: eval loss: 0.8242886606584233
Eval: 2022-04-28 04:12:39.868130: total loss: 1.0657985762394167, mse:4.584742639913132, ic :0.19624621882606266, sharpe5:17.896747999191284, irr5:598.509033203125, ndcg5:0.8525974166923358, pnl5:6.1897406578063965 
train 34, step: 0, loss: 1.0134417966039209, grad_norm: 1.2557658665123888, ic: 0.5974864057694853
train 34, step: 500, loss: 0.7769858917329654, grad_norm: 0.05153349890804722, ic: 0.29440278372282047
train 34, step: 1000, loss: 3.16454590593798, grad_norm: 3.1030126798463478, ic: 0.3383264383669319
train 34, step: 1500, loss: 0.8026830152618444, grad_norm: 0.19523117606795384, ic: 0.6869238807400423
train 34, step: 2000, loss: 6.428117133036406, grad_norm: 16.704014415738172, ic: 0.42436957352565685
Epoch 34: 2022-04-28 04:34:09.733973: train loss: 1.615851432734275
Eval step 0: eval loss: 0.8233209736605966
Eval: 2022-04-28 04:35:37.294018: total loss: 1.0692677683176763, mse:4.616253782230198, ic :0.1893185476643493, sharpe5:17.6857819712162, irr5:586.2034301757812, ndcg5:0.8582219623725814, pnl5:6.5833611488342285 
train 35, step: 0, loss: 1.1838854262408087, grad_norm: 1.3810637528464749, ic: 0.5515965516634156
train 35, step: 500, loss: 1.176607694961161, grad_norm: 0.47801595490755405, ic: 0.11482062057360956
train 35, step: 1000, loss: 1.7046079858346603, grad_norm: 3.49168270816478, ic: 0.09039687335826618
train 35, step: 1500, loss: 1.6294145397673874, grad_norm: 1.411812256333438, ic: 0.03230998128844244
train 35, step: 2000, loss: 0.7933987704190341, grad_norm: 0.15771679364597865, ic: 0.5509952597959636
Epoch 35: 2022-04-28 04:57:59.401570: train loss: 1.6170629024203913
Eval step 0: eval loss: 0.828750529957521
Eval: 2022-04-28 04:59:29.255518: total loss: 1.065583800635858, mse:4.579318996790949, ic :0.19825231888125464, sharpe5:18.953594852685928, irr5:616.2282104492188, ndcg5:0.8357511383940133, pnl5:5.804353713989258 
train 36, step: 0, loss: 1.8362077027325354, grad_norm: 0.6938709634128282, ic: 0.12575173582876278
train 36, step: 500, loss: 0.8538223879838949, grad_norm: 0.41131303877926884, ic: -0.09092967841795588
train 36, step: 1000, loss: 1.8496548295454545, grad_norm: 5.163647401876178, ic: 0.19186478247632296
train 36, step: 1500, loss: 0.7593695905163661, grad_norm: 0.0660114248747556, ic: 0.4092397116269916
train 36, step: 2000, loss: 1.1068343086030579, grad_norm: 0.3459748152598853, ic: 0.7785384178800017
Epoch 36: 2022-04-28 05:22:02.981642: train loss: 1.6151890592112492
Eval step 0: eval loss: 0.8282807714946654
Eval: 2022-04-28 05:23:25.283999: total loss: 1.0663201449013457, mse:4.589840643542726, ic :0.19358467701096965, sharpe5:18.276344203948973, irr5:610.5865478515625, ndcg5:0.8503315053339207, pnl5:6.689792156219482 
train 37, step: 0, loss: 2.018276898090544, grad_norm: 1.3541682169043443, ic: 0.177056260867387
train 37, step: 500, loss: 2.32789201098593, grad_norm: 1.133827335192775, ic: 0.029763916293323457
train 37, step: 1000, loss: 1.0682182602323533, grad_norm: 0.2798263965135367, ic: 0.0880921975001949
train 37, step: 1500, loss: 2.0196569613422293, grad_norm: 0.9365484133684474, ic: 0.6130016696920375
train 37, step: 2000, loss: 1.3148815877413829, grad_norm: 0.1651271339549879, ic: 0.13894521793049025
Epoch 37: 2022-04-28 05:45:30.460074: train loss: 1.6163927651737662
Eval step 0: eval loss: 0.8260446594688488
Eval: 2022-04-28 05:47:02.074769: total loss: 1.067573222725362, mse:4.602342352172282, ic :0.18921933469708566, sharpe5:18.667866640090942, irr5:611.4944458007812, ndcg5:0.8607050308737237, pnl5:5.139689922332764 
train 38, step: 0, loss: 1.3310712488686167, grad_norm: 0.3059343022832307, ic: -0.07129395467694502
train 38, step: 500, loss: 0.9179459936824845, grad_norm: 0.060311513721280616, ic: 0.25559593775844397
train 38, step: 1000, loss: 0.9065089048604249, grad_norm: 0.12282932505124027, ic: 0.010296817721551159
train 38, step: 1500, loss: 0.9502094937891515, grad_norm: 0.04896778121308203, ic: 0.22367884295937918
train 38, step: 2000, loss: 2.3060147841531347, grad_norm: 2.6316016763813814, ic: 0.06954389020570187
Epoch 38: 2022-04-28 06:09:19.155382: train loss: 1.6103666726663697
Eval step 0: eval loss: 0.82571022025652
Eval: 2022-04-28 06:10:48.230414: total loss: 1.0652355072292683, mse:4.592652336861777, ic :0.19366069749541395, sharpe5:18.691524242162703, irr5:604.3970947265625, ndcg5:0.8394689910712098, pnl5:7.8684611320495605 
train 39, step: 0, loss: 0.9700365912294534, grad_norm: 0.043103982025127816, ic: 0.10949373699011956
train 39, step: 500, loss: 0.8965941538359915, grad_norm: 0.08844946909004701, ic: 0.20714116572718913
train 39, step: 1000, loss: 0.9420131616527038, grad_norm: 0.07593019345799128, ic: 0.19581095283345956
train 39, step: 1500, loss: 2.08223360427397, grad_norm: 0.5021905517477185, ic: 0.1916794380115474
train 39, step: 2000, loss: 0.6223362445078001, grad_norm: 0.03638301499408181, ic: 0.0586213428647141
Epoch 39: 2022-04-28 06:33:17.936476: train loss: 1.617379924279199
Eval step 0: eval loss: 0.8311766291820336
Eval: 2022-04-28 06:34:27.419214: total loss: 1.0667898274085488, mse:4.586804292674473, ic :0.19163415684604185, sharpe5:18.683718463182448, irr5:603.0604858398438, ndcg5:0.8445272926682325, pnl5:7.508288383483887 

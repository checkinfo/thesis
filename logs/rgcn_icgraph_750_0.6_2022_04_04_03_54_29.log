Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='SparseAdjSeqTimeDataset', dout=0.3, epochs=40, gnn_layers=2, gpu=0, hidden_dim=128, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=3, mask_adj=True, mask_type='soft', model_type='RGCNModel', normalize_adj=True, num_days=1, num_heads=1, print_inteval=500, relation_num=1, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_750_0.6/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
load 2305 train graphs successful!
load 126 test graphs successful!
49476
RGCNModel(
  (fc1): Linear(in_features=9, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
  (fc4): Linear(in_features=128, out_features=1, bias=True)
  (gnns): ModuleList(
    (0): RGCN(
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
    )
    (1): RGCN(
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
    )
  )
  (dropout): Dropout(p=0.3, inplace=False)
  (relu): LeakyReLU(negative_slope=0.01)
)
train 0, step: 0, loss: 2.0732919806077077, grad_norm: 0.45755339180915433, ic: -0.024089561706094127
train 0, step: 500, loss: 1.3683365712661106, grad_norm: 0.8462877506446979, ic: -0.024794269143195376
train 0, step: 1000, loss: 1.5063902110397913, grad_norm: 0.032457418570981375, ic: 0.2097476751187315
train 0, step: 1500, loss: 1.1904186157883359, grad_norm: 0.11000738294699151, ic: 0.04783926094429791
train 0, step: 2000, loss: 1.5604984934737043, grad_norm: 0.051155551253504024, ic: -0.04482089927176977
Epoch 0: 2022-04-04 15:56:41.953703: train loss: 1.6477097939982295
Eval step 0: eval loss: 1.0100999523803647
Eval: 2022-04-04 15:56:47.207625: total loss: 1.0912458423179454, mse:4.886454115969969, ic :0.02375586960160513, sharpe5:6.853039764761925, irr5:207.22213745117188, ndcg5:0.8495089665371893, pnl5:2.4178669452667236 
train 1, step: 0, loss: 0.6423571747128326, grad_norm: 0.056923737064594346, ic: 0.06519948910465678
train 1, step: 500, loss: 1.2666880916973862, grad_norm: 0.3077624516687147, ic: 0.22785553741010045
train 1, step: 1000, loss: 0.8785707761915467, grad_norm: 0.06332840372983627, ic: 0.066338026104409
train 1, step: 1500, loss: 1.864627745093369, grad_norm: 0.5702038476308364, ic: 0.09194536512000262
train 1, step: 2000, loss: 1.3721250852435873, grad_norm: 0.235314780260496, ic: 0.11728509769240128
Epoch 1: 2022-04-04 15:57:21.901007: train loss: 1.6459319766058207
Eval step 0: eval loss: 1.0036491245392312
Eval: 2022-04-04 15:57:27.165405: total loss: 1.0888040081480914, mse:4.876823345537814, ic :0.05632948645383391, sharpe5:7.483048518598079, irr5:228.8574981689453, ndcg5:0.8460927839707517, pnl5:2.865901231765747 
train 2, step: 0, loss: 1.3299338600852273, grad_norm: 0.5121328045905956, ic: 0.028606383655095213
train 2, step: 500, loss: 0.9501899406653073, grad_norm: 0.27524054728386654, ic: 0.0851849249853089
train 2, step: 1000, loss: 3.0705537183759524, grad_norm: 1.5426510702294507, ic: 0.190770453703263
train 2, step: 1500, loss: 2.292013484461737, grad_norm: 0.8849037986708905, ic: 0.0797948622554854
train 2, step: 2000, loss: 1.4589090167940004, grad_norm: 0.2739396194278241, ic: -0.1045547367422596
Epoch 2: 2022-04-04 15:58:01.645129: train loss: 1.644610430003253
Eval step 0: eval loss: 0.9957926560854397
Eval: 2022-04-04 15:58:07.017051: total loss: 1.0883752566139588, mse:4.874097349954171, ic :0.05872835573392796, sharpe5:7.284216352701187, irr5:219.4567413330078, ndcg5:0.8353857380584836, pnl5:2.9111180305480957 
train 3, step: 0, loss: 1.8320764543085308, grad_norm: 0.06744494943745691, ic: -0.15933979609939755
train 3, step: 500, loss: 0.7771847269667691, grad_norm: 0.017422984134372755, ic: 0.11467610626710066
train 3, step: 1000, loss: 1.3873186967870053, grad_norm: 0.476927559094104, ic: 0.20262541721005925
train 3, step: 1500, loss: 2.6237662684889793, grad_norm: 0.3953490932524509, ic: -0.059016966603150374
train 3, step: 2000, loss: 1.3524969852331914, grad_norm: 0.16697220582237673, ic: 0.08285313369006253
Epoch 3: 2022-04-04 15:58:41.806283: train loss: 1.6447589287642026
Eval step 0: eval loss: 0.9979896003036136
Eval: 2022-04-04 15:58:46.984709: total loss: 1.0898741872649007, mse:4.861158324155775, ic :0.08538299382530776, sharpe5:7.548578941226006, irr5:225.74557495117188, ndcg5:0.8495124311631882, pnl5:2.6554794311523438 
train 4, step: 0, loss: 1.1574786925061833, grad_norm: 0.15152558240790875, ic: 0.08826638918442876
train 4, step: 500, loss: 0.9821378746811226, grad_norm: 0.014468636366738799, ic: 0.2050339529498193
train 4, step: 1000, loss: 1.3318094563429634, grad_norm: 0.06921805035326914, ic: 0.08111712600791034
train 4, step: 1500, loss: 1.0509386111528445, grad_norm: 0.12481216937679189, ic: 0.6090321572163501
train 4, step: 2000, loss: 4.179956419649882, grad_norm: 0.8752536364802772, ic: -0.02194970304488949
Epoch 4: 2022-04-04 15:59:21.355911: train loss: 1.6395965811815574
Eval step 0: eval loss: 1.0020503184241705
Eval: 2022-04-04 15:59:26.653741: total loss: 1.0872513289151975, mse:4.716242633552347, ic :0.12574177923468985, sharpe5:7.492487438321113, irr5:220.4446563720703, ndcg5:0.8437257235032039, pnl5:2.7203712463378906 
train 5, step: 0, loss: 0.9814655800766375, grad_norm: 0.13742671570509124, ic: -0.15233854907591923
train 5, step: 500, loss: 0.7884829070707444, grad_norm: 0.0176203481477573, ic: 0.14433339353658675
train 5, step: 1000, loss: 1.0965188082597768, grad_norm: 0.056662761393246885, ic: 0.40457267781003564
train 5, step: 1500, loss: 1.7600786410696139, grad_norm: 0.35496725015088226, ic: -0.07684638037992912
train 5, step: 2000, loss: 2.1801822640069037, grad_norm: 0.840096168125616, ic: 0.019566434448613737
Epoch 5: 2022-04-04 16:00:01.275804: train loss: 1.638192687959651
Eval step 0: eval loss: 1.003978502254476
Eval: 2022-04-04 16:00:06.467500: total loss: 1.0849621584705205, mse:4.71933643799552, ic :0.11765613724339563, sharpe5:10.471263316869734, irr5:305.68719482421875, ndcg5:0.830705052829353, pnl5:3.326749086380005 
train 6, step: 0, loss: 0.7727763484717232, grad_norm: 0.001929980768944182, ic: -0.03023907270507594
train 6, step: 500, loss: 1.421616314447414, grad_norm: 0.2366276398996613, ic: 0.056772012400936905
train 6, step: 1000, loss: 1.2253968370855086, grad_norm: 0.18881062500631057, ic: 0.2190969732071232
train 6, step: 1500, loss: 1.0567369914504716, grad_norm: 0.32769159770086137, ic: 0.08639124531098819
train 6, step: 2000, loss: 2.3078773111446402, grad_norm: 1.1628144718148525, ic: 0.06036821258797709
Epoch 6: 2022-04-04 16:00:41.095022: train loss: 1.6374896114765747
Eval step 0: eval loss: 1.0029733988283307
Eval: 2022-04-04 16:00:46.305917: total loss: 1.0835553379798746, mse:4.690390846408942, ic :0.1524758619399121, sharpe5:12.785606786012648, irr5:391.4393615722656, ndcg5:0.8632442914083518, pnl5:6.166667461395264 
train 7, step: 0, loss: 1.4579498944604614, grad_norm: 0.5568305013158547, ic: 0.205919823392208
train 7, step: 500, loss: 1.346506929514742, grad_norm: 0.10219562919960054, ic: 0.18081732403891573
train 7, step: 1000, loss: 0.6317325003123914, grad_norm: 0.04515225146156798, ic: 0.24312568947235325
train 7, step: 1500, loss: 1.0041659421767075, grad_norm: 0.15466812410827183, ic: 0.09240548656679551
train 7, step: 2000, loss: 1.5740162667558109, grad_norm: 0.6292701418837232, ic: 0.42262226249906754
Epoch 7: 2022-04-04 16:01:21.620789: train loss: 1.6319368481846737
Eval step 0: eval loss: 0.9938895419875592
Eval: 2022-04-04 16:01:26.817935: total loss: 1.0822654122824356, mse:4.705439588808393, ic :0.1445773302576817, sharpe5:12.366913579702377, irr5:377.3019714355469, ndcg5:0.8443857906305915, pnl5:4.143606185913086 
train 8, step: 0, loss: 1.2027871371445498, grad_norm: 0.1269120458635409, ic: 0.0865371980267886
train 8, step: 500, loss: 5.49849344570435, grad_norm: 1.3587079346409126, ic: 0.1455677567897803
train 8, step: 1000, loss: 1.8775215718283584, grad_norm: 0.583992084231677, ic: 0.060871866080464965
train 8, step: 1500, loss: 1.0743424105585064, grad_norm: 0.364359150278567, ic: 0.6475805709722788
train 8, step: 2000, loss: 1.1295367509890826, grad_norm: 0.5165186842377061, ic: 0.0031799564264070185
Epoch 8: 2022-04-04 16:02:01.901732: train loss: 1.629749328419951
Eval step 0: eval loss: 1.0062200577400935
Eval: 2022-04-04 16:02:07.204258: total loss: 1.0857358513920445, mse:4.686105271049615, ic :0.16683887982988768, sharpe5:15.503457570075987, irr5:528.4415283203125, ndcg5:0.8561195420393275, pnl5:5.707472801208496 
train 9, step: 0, loss: 1.0982632953102727, grad_norm: 0.03631519703459355, ic: 0.47550998910615605
train 9, step: 500, loss: 3.150040950223554, grad_norm: 2.310231380645062, ic: 0.14724703762942157
train 9, step: 1000, loss: 0.8715975170688136, grad_norm: 0.14107315599181788, ic: 0.2453736824028372
train 9, step: 1500, loss: 2.162455603601094, grad_norm: 1.093222733783043, ic: -0.033859054589350845
train 9, step: 2000, loss: 0.6069161139727577, grad_norm: 0.020082678251402798, ic: 0.05118480576314371
Epoch 9: 2022-04-04 16:02:42.540297: train loss: 1.6283928893342041
Eval step 0: eval loss: 0.9927461050635202
Eval: 2022-04-04 16:02:47.992032: total loss: 1.0817587494214853, mse:4.715897160343077, ic :0.1634345969811377, sharpe5:14.507038342952727, irr5:509.5732421875, ndcg5:0.8648989682433748, pnl5:4.85975456237793 
train 10, step: 0, loss: 1.3076549882374533, grad_norm: 0.9321297288307924, ic: 0.382817321453811
train 10, step: 500, loss: 0.899270983877464, grad_norm: 0.0069587329310208945, ic: 0.0997017997547226
train 10, step: 1000, loss: 1.531603912429746, grad_norm: 0.5088515926614241, ic: 0.05021828874537718
train 10, step: 1500, loss: 3.024907914228462, grad_norm: 1.828569666742063, ic: 0.031519782250546316
train 10, step: 2000, loss: 1.3612379636445668, grad_norm: 0.24179235857982526, ic: 0.21054531277256866
Epoch 10: 2022-04-04 16:03:23.072000: train loss: 1.635569025549277
Eval step 0: eval loss: 1.0077327911071616
Eval: 2022-04-04 16:03:28.509694: total loss: 1.0832643775446922, mse:4.682164189768037, ic :0.16214024343119496, sharpe5:13.602073105573654, irr5:447.4609680175781, ndcg5:0.8434981787913756, pnl5:5.304184913635254 
train 11, step: 0, loss: 4.713811831142494, grad_norm: 1.3615103998501787, ic: 0.3855917378005394
train 11, step: 500, loss: 0.9931149343557988, grad_norm: 0.06610275204963088, ic: 0.035887524705867035
train 11, step: 1000, loss: 1.0312416198870138, grad_norm: 0.35693835487442016, ic: 0.06229106562367316
train 11, step: 1500, loss: 0.6962450904218872, grad_norm: 0.004975893398591604, ic: 0.07488196989179118
train 11, step: 2000, loss: 1.130850846935926, grad_norm: 0.0623732171058702, ic: -0.1813499368479578
Epoch 11: 2022-04-04 16:04:02.698254: train loss: 1.6319378994675375
Eval step 0: eval loss: 0.992762432530279
Eval: 2022-04-04 16:04:07.949205: total loss: 1.0810854127494993, mse:4.697703286606189, ic :0.15241135987244603, sharpe5:13.192903479337692, irr5:419.6283264160156, ndcg5:0.8435337928574902, pnl5:4.847923755645752 
train 12, step: 0, loss: 1.3834946084838402, grad_norm: 0.3198983443616271, ic: 0.15037246151678352
train 12, step: 500, loss: 0.8123186769312352, grad_norm: 0.3638835058985288, ic: 0.024202428498551937
train 12, step: 1000, loss: 1.1933070361456959, grad_norm: 0.5040353955373658, ic: 0.6087401496959479
train 12, step: 1500, loss: 1.080109295859614, grad_norm: 0.2115669250685981, ic: 0.09840391885562086
train 12, step: 2000, loss: 1.1142122199736444, grad_norm: 0.07567729787318153, ic: 0.14075299254044246
Epoch 12: 2022-04-04 16:04:42.436499: train loss: 1.6279142721174829
Eval step 0: eval loss: 1.0075209197274881
Eval: 2022-04-04 16:04:47.735460: total loss: 1.0834494334554354, mse:4.68772051052133, ic :0.1665838579619965, sharpe5:15.22868601500988, irr5:512.6017456054688, ndcg5:0.8608424087789398, pnl5:4.959496021270752 
train 13, step: 0, loss: 1.0709918209020293, grad_norm: 0.04919802499226278, ic: 0.4484291050163277
train 13, step: 500, loss: 1.1444473848998091, grad_norm: 0.027811239373714634, ic: -0.11107501728751921
train 13, step: 1000, loss: 1.3938744137551633, grad_norm: 0.42345327646431097, ic: 0.05163036736295022
train 13, step: 1500, loss: 0.7761514742080479, grad_norm: 0.005625543782542672, ic: -0.0448022337945891
train 13, step: 2000, loss: 1.0361615018361174, grad_norm: 0.029592818969534893, ic: 0.05774151024220864
Epoch 13: 2022-04-04 16:05:22.787041: train loss: 1.6288245512272763
Eval step 0: eval loss: 0.9949076302494734
Eval: 2022-04-04 16:05:28.109262: total loss: 1.081009676635183, mse:4.701728897357238, ic :0.1543614158946326, sharpe5:13.212996833324432, irr5:434.29681396484375, ndcg5:0.8515962969975734, pnl5:5.725496292114258 
train 14, step: 0, loss: 1.7603260622186176, grad_norm: 0.5406719325039053, ic: 0.1973350446008444
train 14, step: 500, loss: 1.2699219467533063, grad_norm: 0.17463584576972863, ic: 0.2367319991397456
train 14, step: 1000, loss: 1.063092091457903, grad_norm: 0.18096019054724058, ic: 0.16887132619125683
train 14, step: 1500, loss: 0.969012465267754, grad_norm: 0.27688628865296133, ic: 0.1425595312467546
train 14, step: 2000, loss: 2.2939345591608893, grad_norm: 0.6220910937428652, ic: -0.07981474085753536
Epoch 14: 2022-04-04 16:06:03.122513: train loss: 1.6272143367071963
Eval step 0: eval loss: 1.010813154127172
Eval: 2022-04-04 16:06:08.396988: total loss: 1.085835531427071, mse:4.69159220868202, ic :0.16272719915976216, sharpe5:14.591099923253058, irr5:490.5585632324219, ndcg5:0.8426749945744544, pnl5:6.138150215148926 
train 15, step: 0, loss: 0.9698794183023245, grad_norm: 0.21433299122780067, ic: 0.13340212967228948
train 15, step: 500, loss: 1.223405084690126, grad_norm: 0.01822186474926632, ic: 0.06412028113209803
train 15, step: 1000, loss: 1.7591986979166667, grad_norm: 0.056017296633356264, ic: -0.04516482074744201
train 15, step: 1500, loss: 5.404899579466357, grad_norm: 0.8985284481402942, ic: -0.029352254064144864
train 15, step: 2000, loss: 0.9299884175145349, grad_norm: 0.023723970331301344, ic: -0.04050744085061225
Epoch 15: 2022-04-04 16:06:43.608105: train loss: 1.629277497738468
Eval step 0: eval loss: 1.006991112715574
Eval: 2022-04-04 16:06:48.904837: total loss: 1.0829570846177807, mse:4.679781823836952, ic :0.16530641567556068, sharpe5:15.646841935515402, irr5:524.54052734375, ndcg5:0.8526894755936538, pnl5:6.056038856506348 
train 16, step: 0, loss: 6.340861774139531, grad_norm: 1.4030213467340165, ic: 0.1474336499516905
train 16, step: 500, loss: 1.3604703388516866, grad_norm: 0.7906511661711901, ic: -0.014886100755105682
train 16, step: 1000, loss: 0.8521987214192184, grad_norm: 1.0204767399563357, ic: -0.04230490566407771
train 16, step: 1500, loss: 1.2451233517238907, grad_norm: 0.43011429912811167, ic: 0.13544757480741998
train 16, step: 2000, loss: 0.9556115789523737, grad_norm: 0.32911907993815004, ic: 0.5446547320155553
Epoch 16: 2022-04-04 16:07:23.889196: train loss: 1.626044637964117
Eval step 0: eval loss: 1.0012888413721037
Eval: 2022-04-04 16:07:29.647534: total loss: 1.0790406281456846, mse:4.690572775970281, ic :0.16062473556904755, sharpe5:13.77887986421585, irr5:474.480224609375, ndcg5:0.8461029966210537, pnl5:4.073288440704346 
train 17, step: 0, loss: 1.1810812920880465, grad_norm: 0.01953611745319723, ic: 0.13905809043039374
train 17, step: 500, loss: 1.0434552390268148, grad_norm: 0.03208591096109473, ic: -0.022463774046473615
train 17, step: 1000, loss: 3.3732714763175538, grad_norm: 0.8225681296770755, ic: -0.022051626644137085
train 17, step: 1500, loss: 0.8880345613053702, grad_norm: 0.005496018597463823, ic: 0.015014916145857947
train 17, step: 2000, loss: 1.0441128519557465, grad_norm: 0.5375920880374844, ic: 0.5181447080854085
Epoch 17: 2022-04-04 16:08:04.384094: train loss: 1.6314502095422172
Eval step 0: eval loss: 0.9996342390320563
Eval: 2022-04-04 16:08:09.876862: total loss: 1.08199969926558, mse:4.69505492585006, ic :0.163425244013243, sharpe5:15.523362684845923, irr5:520.6498413085938, ndcg5:0.8438983727819914, pnl5:5.936347961425781 
train 18, step: 0, loss: 0.8546161177450882, grad_norm: 0.14340614944358157, ic: 0.009782237660131103
train 18, step: 500, loss: 2.536540649714975, grad_norm: 1.0762954010075279, ic: 0.11439371449708048
train 18, step: 1000, loss: 1.3524061024617806, grad_norm: 0.35674133427073773, ic: 0.5351123312794643
train 18, step: 1500, loss: 1.7385986587022801, grad_norm: 1.115318601724797, ic: 0.3333198880320209
train 18, step: 2000, loss: 1.2502899786972848, grad_norm: 0.35194128054960383, ic: 0.23441573880290922
Epoch 18: 2022-04-04 16:08:46.307517: train loss: 1.6279351475821904
Eval step 0: eval loss: 1.0031645716084123
Eval: 2022-04-04 16:08:51.694952: total loss: 1.0807038759967373, mse:4.682765380810448, ic :0.16894369017507305, sharpe5:16.10227773427963, irr5:538.135986328125, ndcg5:0.8462681872343238, pnl5:5.0936479568481445 
train 19, step: 0, loss: 2.240484493054227, grad_norm: 0.8755097833054681, ic: 0.2452497536602665
train 19, step: 500, loss: 1.0209188771802324, grad_norm: 0.053169901843024024, ic: 0.047756177531058236
train 19, step: 1000, loss: 1.0038315754779168, grad_norm: 0.31976142963692256, ic: 0.5212562367819187
train 19, step: 1500, loss: 1.5770612175081982, grad_norm: 0.05970220720815133, ic: 0.14112935071546373
train 19, step: 2000, loss: 1.703555692007444, grad_norm: 1.9115952462922083, ic: 0.6214554826574535
Epoch 19: 2022-04-04 16:09:27.407056: train loss: 1.6265658111133943
Eval step 0: eval loss: 1.0045643626168377
Eval: 2022-04-04 16:09:32.886190: total loss: 1.0804120038273632, mse:4.689083227297363, ic :0.15675021396633576, sharpe5:12.361835850477219, irr5:393.2538757324219, ndcg5:0.8485628915109747, pnl5:3.4787843227386475 
train 20, step: 0, loss: 1.243169541965399, grad_norm: 0.3361063818235931, ic: 0.45670610975968956
train 20, step: 500, loss: 1.266306815328736, grad_norm: 0.7030917586141987, ic: -0.019458398663383274
train 20, step: 1000, loss: 1.5638848421370435, grad_norm: 0.4988845588258372, ic: 0.16507276495089784
train 20, step: 1500, loss: 0.86534026002943, grad_norm: 0.6383758880577588, ic: 0.5875605605154278
train 20, step: 2000, loss: 1.364093703421837, grad_norm: 0.11736834792848909, ic: -0.05007429778482559
Epoch 20: 2022-04-04 16:10:08.253590: train loss: 1.6269312632860091
Eval step 0: eval loss: 0.9932242298578198
Eval: 2022-04-04 16:10:13.719585: total loss: 1.0845004727488003, mse:4.718305652281949, ic :0.1283990088314812, sharpe5:7.463644271492957, irr5:218.2080535888672, ndcg5:0.8364660937877687, pnl5:2.7284860610961914 
train 21, step: 0, loss: 1.4021356254555393, grad_norm: 0.28369140748570654, ic: 0.31988889306054125
train 21, step: 500, loss: 1.103394395263485, grad_norm: 0.10270286904186685, ic: 0.07315860942915715
train 21, step: 1000, loss: 0.909160629686216, grad_norm: 0.17181515460302255, ic: 0.115114597271479
train 21, step: 1500, loss: 0.7391122512765869, grad_norm: 0.2310122093498, ic: 0.6285635686417362
train 21, step: 2000, loss: 1.1328967482332966, grad_norm: 0.13764395322313744, ic: 0.28198433420324487
Epoch 21: 2022-04-04 16:10:48.985032: train loss: 1.6261724989791309
Eval step 0: eval loss: 1.0043596264687005
Eval: 2022-04-04 16:10:54.481999: total loss: 1.0809742230784374, mse:4.686737557039096, ic :0.1589536497215194, sharpe5:12.382521353960037, irr5:394.4719543457031, ndcg5:0.8581141624989227, pnl5:5.259321689605713 
train 22, step: 0, loss: 1.0483907390892953, grad_norm: 0.28227144552805494, ic: 0.11962030288260338
train 22, step: 500, loss: 1.0261411171259842, grad_norm: 0.0005078409649324612, ic: 0.011209858336924797
train 22, step: 1000, loss: 0.912932765876052, grad_norm: 0.01999349652283461, ic: 0.1144615527445169
train 22, step: 1500, loss: 1.0104662933824962, grad_norm: 0.038731818259525, ic: 0.22395759813702393
train 22, step: 2000, loss: 1.061654166288154, grad_norm: 0.11380456492378, ic: 0.12391653251496035
Epoch 22: 2022-04-04 16:11:30.405172: train loss: 1.625235705397912
Eval step 0: eval loss: 1.0074902575162914
Eval: 2022-04-04 16:11:36.347917: total loss: 1.080754326173475, mse:4.675684230313741, ic :0.16938795330237968, sharpe5:15.27681187748909, irr5:513.9765625, ndcg5:0.8451273277689106, pnl5:3.7562291622161865 
train 23, step: 0, loss: 1.2981280891262756, grad_norm: 0.8737738885069032, ic: -0.0005659073893326191
train 23, step: 500, loss: 0.9039326762105083, grad_norm: 0.17465538577868372, ic: 0.5902139739508344
train 23, step: 1000, loss: 2.2869611882181062, grad_norm: 1.2392777433100925, ic: 0.07606300738998727
train 23, step: 1500, loss: 0.7837329993982539, grad_norm: 0.31557487264936024, ic: 0.7085972566878909
train 23, step: 2000, loss: 1.437487820649093, grad_norm: 0.4213924199996796, ic: 0.426738395676417
Epoch 23: 2022-04-04 16:12:12.049525: train loss: 1.624606620411158
Eval step 0: eval loss: 1.0096778166551474
Eval: 2022-04-04 16:12:17.606566: total loss: 1.08694201616387, mse:4.692475184882298, ic :0.15999510539243897, sharpe5:12.590455690026282, irr5:404.0348815917969, ndcg5:0.8533268319381982, pnl5:4.302393913269043 
train 24, step: 0, loss: 1.186983702612705, grad_norm: 0.637969912218601, ic: 0.28130760563793356
train 24, step: 500, loss: 1.2525818196987033, grad_norm: 0.9903304258646073, ic: 0.009733265863045596
train 24, step: 1000, loss: 1.036897798863853, grad_norm: 0.35710070971722824, ic: 0.1510858062542841
train 24, step: 1500, loss: 1.2008864034817914, grad_norm: 0.08998091969945249, ic: 0.04268781758544259
train 24, step: 2000, loss: 1.3540630451059767, grad_norm: 0.39943331668327103, ic: 0.45936420928353233
Epoch 24: 2022-04-04 16:12:53.087763: train loss: 1.6250896097091507
Eval step 0: eval loss: 1.0104585781167719
Eval: 2022-04-04 16:12:58.459755: total loss: 1.0826097144063416, mse:4.684565668915699, ic :0.16566600934312922, sharpe5:14.740786045789719, irr5:478.0863342285156, ndcg5:0.84533638567028, pnl5:6.191659450531006 
train 25, step: 0, loss: 1.3374424306941277, grad_norm: 0.4565056379428993, ic: 0.20169559671122994
train 25, step: 500, loss: 1.4916805911373783, grad_norm: 0.8745948984605967, ic: 0.1068443806766026
train 25, step: 1000, loss: 1.3608356320083381, grad_norm: 0.2799918413886426, ic: 0.2792184116678855
train 25, step: 1500, loss: 2.884246848334241, grad_norm: 0.9436370893780955, ic: 0.1788288744465014
train 25, step: 2000, loss: 1.2031284766861154, grad_norm: 0.21897854725148314, ic: 0.1574692619007887
Epoch 25: 2022-04-04 16:13:33.893323: train loss: 1.627273257268386
Eval step 0: eval loss: 1.003600913515337
Eval: 2022-04-04 16:13:39.449435: total loss: 1.0799375590571307, mse:4.675433823079261, ic :0.1681561566007813, sharpe5:14.374363748431206, irr5:495.7161865234375, ndcg5:0.8454299781692183, pnl5:4.615851402282715 
train 26, step: 0, loss: 1.620203125, grad_norm: 0.43626176034163877, ic: 0.18561049541680869
train 26, step: 500, loss: 1.0133095759295399, grad_norm: 0.2091326592656178, ic: -0.05906521286655986
train 26, step: 1000, loss: 1.8037751743338886, grad_norm: 0.6870742297925301, ic: 0.19943893244555133
train 26, step: 1500, loss: 0.9276605650436047, grad_norm: 0.018197577225754505, ic: -0.054616364146052476
train 26, step: 2000, loss: 0.9899037278543307, grad_norm: 0.34910583853645566, ic: 0.14051104487873806
Epoch 26: 2022-04-04 16:14:15.429846: train loss: 1.6254680707907798
Eval step 0: eval loss: 1.0034171973736177
Eval: 2022-04-04 16:14:20.973001: total loss: 1.0810278523730308, mse:4.6825328292649715, ic :0.16910452049807606, sharpe5:15.64579101204872, irr5:530.7281494140625, ndcg5:0.8416163901683831, pnl5:5.2100090980529785 
train 27, step: 0, loss: 1.6237594420651356, grad_norm: 0.4794364245251926, ic: 0.6483625525082282
train 27, step: 500, loss: 1.5483941394099923, grad_norm: 0.4213414217913166, ic: 0.12005871151833733
train 27, step: 1000, loss: 2.5835850618565463, grad_norm: 0.838397281830277, ic: 0.40691319173392737
train 27, step: 1500, loss: 0.8845668901262144, grad_norm: 0.6936095483281877, ic: 0.5429813945173618
train 27, step: 2000, loss: 1.3449199811287922, grad_norm: 1.4638743356691557, ic: -0.0039405869642003865
Epoch 27: 2022-04-04 16:14:56.629319: train loss: 1.624685746421266
Eval step 0: eval loss: 1.004502266818062
Eval: 2022-04-04 16:15:02.149222: total loss: 1.0784135658393086, mse:4.682284424567317, ic :0.17160628716726026, sharpe5:14.175413814783095, irr5:493.6776428222656, ndcg5:0.8544117131726485, pnl5:6.624697208404541 
train 28, step: 0, loss: 1.1562414719931797, grad_norm: 0.10587786015373772, ic: 0.15088282823218874
train 28, step: 500, loss: 2.937284013977554, grad_norm: 0.7377343366471649, ic: 0.13679205814802758
train 28, step: 1000, loss: 2.77650931359844, grad_norm: 2.244996345040085, ic: -0.040586247851462844
train 28, step: 1500, loss: 1.0268258883392658, grad_norm: 0.005755155018909674, ic: 0.1944621793619103
train 28, step: 2000, loss: 1.7685287830441496, grad_norm: 0.38666171293099466, ic: 0.07128106115453384
Epoch 28: 2022-04-04 16:15:37.442454: train loss: 1.625145209102279
Eval step 0: eval loss: 1.0107389091503751
Eval: 2022-04-04 16:15:43.015821: total loss: 1.080209904379941, mse:4.679499414263861, ic :0.16543703514949487, sharpe5:14.003319658040999, irr5:467.377685546875, ndcg5:0.8457366323971434, pnl5:5.641910076141357 
train 29, step: 0, loss: 1.5168632871730476, grad_norm: 0.13579470316541284, ic: 0.08654787242761725
train 29, step: 500, loss: 2.569453784622117, grad_norm: 1.3058049596494936, ic: -0.01362119417491172
train 29, step: 1000, loss: 1.7070621688473182, grad_norm: 0.8820099156798965, ic: 0.48161354920826804
train 29, step: 1500, loss: 3.9817150072966987, grad_norm: 1.1333796992165308, ic: 0.12480800016167848
train 29, step: 2000, loss: 0.9330886897725759, grad_norm: 0.21297180032829444, ic: 0.465196364862272
Epoch 29: 2022-04-04 16:16:18.387340: train loss: 1.626078390393056
Eval step 0: eval loss: 1.0082739116393495
Eval: 2022-04-04 16:16:23.917216: total loss: 1.0806586219484096, mse:4.68054659132042, ic :0.16600981015763286, sharpe5:13.97236045539379, irr5:463.5959777832031, ndcg5:0.8403249202384513, pnl5:4.7574639320373535 
train 30, step: 0, loss: 1.2437412397686411, grad_norm: 0.03542599944903916, ic: 0.9874744947113341
train 30, step: 500, loss: 1.9414348360858387, grad_norm: 1.2786441211312163, ic: 0.17589649874265406
train 30, step: 1000, loss: 3.4387515232567742, grad_norm: 0.7526327659172255, ic: 0.37610812271893523
train 30, step: 1500, loss: 1.0844730779091105, grad_norm: 0.23688428256185154, ic: 0.17484224606958856
train 30, step: 2000, loss: 1.108021401190563, grad_norm: 4.460130754991931, ic: 0.43599664399369076
Epoch 30: 2022-04-04 16:16:59.283392: train loss: 1.6258830980036578
Eval step 0: eval loss: 1.011124468778798
Eval: 2022-04-04 16:17:04.670833: total loss: 1.0818087450414433, mse:4.681348617259177, ic :0.16581399662978807, sharpe5:13.707047211527824, irr5:458.9127197265625, ndcg5:0.8585084012009927, pnl5:3.6285407543182373 
train 31, step: 0, loss: 1.1636982547680152, grad_norm: 0.28927414341597385, ic: 0.20930805484258042
train 31, step: 500, loss: 0.8189682926903876, grad_norm: 0.11777665748667589, ic: 0.23286257820175285
train 31, step: 1000, loss: 5.153825693093386, grad_norm: 1.9673746743917198, ic: -0.002042093713675558
train 31, step: 1500, loss: 1.6476352697546368, grad_norm: 0.40309839445075935, ic: 0.29679752211859517
train 31, step: 2000, loss: 0.9736793021132664, grad_norm: 0.5911027102959613, ic: 0.27232724463374497
Epoch 31: 2022-04-04 16:17:39.536237: train loss: 1.625124341035936
Eval step 0: eval loss: 1.009342910742496
Eval: 2022-04-04 16:17:44.898722: total loss: 1.0811852459001638, mse:4.675919822164905, ic :0.16734289334855854, sharpe5:13.391146806478499, irr5:444.5735778808594, ndcg5:0.850310911193988, pnl5:3.7077577114105225 
train 32, step: 0, loss: 0.8824066786805819, grad_norm: 0.8713028369432446, ic: 0.11369246493404223
train 32, step: 500, loss: 1.096220249082984, grad_norm: 0.4423198604412768, ic: 0.1891533459961957
train 32, step: 1000, loss: 1.3742615821459556, grad_norm: 0.024991291544927265, ic: 0.08625386856786278
train 32, step: 1500, loss: 2.0614960378168536, grad_norm: 0.6027901687873456, ic: 0.43629109324653437
train 32, step: 2000, loss: 1.0559897263565465, grad_norm: 0.4015436532152472, ic: 0.4658338362323058
Epoch 32: 2022-04-04 16:18:20.407891: train loss: 1.6227271275965167
Eval step 0: eval loss: 1.0135865093470247
Eval: 2022-04-04 16:18:25.895181: total loss: 1.0836526849938515, mse:4.69253839607766, ic :0.1597222127332422, sharpe5:15.30707677066326, irr5:509.0839538574219, ndcg5:0.8472743047166714, pnl5:6.277557849884033 
train 33, step: 0, loss: 1.1640047753831646, grad_norm: 0.036958804850710514, ic: 0.04757509600452772
train 33, step: 500, loss: 3.1826535927892006, grad_norm: 0.3525897065512904, ic: 0.5128643276809624
train 33, step: 1000, loss: 5.181873207620175, grad_norm: 2.926444271065203, ic: 0.07620071270822165
train 33, step: 1500, loss: 1.3197554425495426, grad_norm: 1.4236090211832892, ic: -0.001292265344369388
train 33, step: 2000, loss: 1.860276617005814, grad_norm: 0.37290940854128873, ic: 0.05013314128705222
Epoch 33: 2022-04-04 16:19:01.198501: train loss: 1.6262148696553118
Eval step 0: eval loss: 1.0167784648170088
Eval: 2022-04-04 16:19:06.774342: total loss: 1.0876939895428714, mse:4.691629304501089, ic :0.16669656632806834, sharpe5:13.90407124042511, irr5:472.4505920410156, ndcg5:0.8417420427757377, pnl5:4.720400810241699 
train 34, step: 0, loss: 0.7184445340357568, grad_norm: 0.43201288406775773, ic: 0.1617609259903601
train 34, step: 500, loss: 1.8115164985742334, grad_norm: 0.7454334548122123, ic: 0.8682182989882192
train 34, step: 1000, loss: 0.7005329842403016, grad_norm: 0.09532413964468134, ic: 0.4441952107992539
train 34, step: 1500, loss: 1.6243937174479166, grad_norm: 0.7529577989951065, ic: 0.6375874268601563
train 34, step: 2000, loss: 2.9847751975648684, grad_norm: 0.5778433920152419, ic: 0.09707774485560619
Epoch 34: 2022-04-04 16:19:41.842111: train loss: 1.6248578758857857
Eval step 0: eval loss: 1.004638029061348
Eval: 2022-04-04 16:19:47.362025: total loss: 1.0808800057321082, mse:4.678697102984182, ic :0.16664766653068755, sharpe5:13.884143423438072, irr5:453.2212829589844, ndcg5:0.8470006637303907, pnl5:4.095518589019775 
train 35, step: 0, loss: 1.0431062722507911, grad_norm: 0.5739361638365954, ic: -0.007558933249488042
train 35, step: 500, loss: 3.296518406723485, grad_norm: 2.856096735178914, ic: -0.09702820559071354
train 35, step: 1000, loss: 1.3603690694492065, grad_norm: 0.13110748283392432, ic: 0.4906514922239051
train 35, step: 1500, loss: 1.6352006192094084, grad_norm: 0.37997531843231214, ic: 0.10480513285733672
train 35, step: 2000, loss: 1.3069074130039933, grad_norm: 0.31683031816669127, ic: -0.08930423105378153
Epoch 35: 2022-04-04 16:20:22.259661: train loss: 1.6255413611251799
Eval step 0: eval loss: 1.0048866051005463
Eval: 2022-04-04 16:20:27.770548: total loss: 1.0799077758098692, mse:4.674632606169915, ic :0.1706424581710116, sharpe5:16.931506483554838, irr5:564.4425048828125, ndcg5:0.8362606063636976, pnl5:7.189673900604248 
train 36, step: 0, loss: 8.972493618044593, grad_norm: 1.0441907505821844, ic: -0.250929849432058
train 36, step: 500, loss: 0.857271435583838, grad_norm: 0.012948224734843725, ic: 0.15011143487297549
train 36, step: 1000, loss: 1.96607929450038, grad_norm: 3.2358351933646237, ic: 0.101234743967437
train 36, step: 1500, loss: 1.0556122922400057, grad_norm: 0.18393162129481413, ic: 0.10633213475605059
train 36, step: 2000, loss: 2.1402411862216746, grad_norm: 1.1101338187449148, ic: 0.39124831783250236
Epoch 36: 2022-04-04 16:21:03.288773: train loss: 1.624405103007244
Eval step 0: eval loss: 1.0158864965936019
Eval: 2022-04-04 16:21:08.699725: total loss: 1.085494946605065, mse:4.685314047629553, ic :0.16465613323521427, sharpe5:13.307203466892242, irr5:446.1729431152344, ndcg5:0.8526941337673667, pnl5:3.4697229862213135 
train 37, step: 0, loss: 1.1854204700028637, grad_norm: 0.18256463108635662, ic: 0.18255347712850029
train 37, step: 500, loss: 2.3354820409751036, grad_norm: 0.04903838554095949, ic: 0.15937563095528134
train 37, step: 1000, loss: 0.7666776871718998, grad_norm: 0.37247495519763846, ic: 0.16171051693682584
train 37, step: 1500, loss: 3.1329903384755706, grad_norm: 0.8230386059608477, ic: 0.19159168409370406
train 37, step: 2000, loss: 3.1172008673954372, grad_norm: 2.0018058800309704, ic: 0.03345964693778841
Epoch 37: 2022-04-04 16:21:44.135606: train loss: 1.6237088630608882
Eval step 0: eval loss: 1.007841298051606
Eval: 2022-04-04 16:21:49.612403: total loss: 1.079160332243627, mse:4.676637102361839, ic :0.17092949377392636, sharpe5:15.47863837122917, irr5:535.3262939453125, ndcg5:0.8539187942163601, pnl5:4.720868110656738 
train 38, step: 0, loss: 1.3580813321200285, grad_norm: 0.8639671335482453, ic: -0.22011481167289332
train 38, step: 500, loss: 1.7366112524224806, grad_norm: 1.0134466902860497, ic: 0.20066971261728403
train 38, step: 1000, loss: 1.806998493347408, grad_norm: 0.5474454057734727, ic: 0.15219568942560138
train 38, step: 1500, loss: 1.0815901974370363, grad_norm: 0.24977257437939257, ic: 0.4775323457447551
train 38, step: 2000, loss: 0.7557113500943072, grad_norm: 0.07279509395689139, ic: 0.5620489614076516
Epoch 38: 2022-04-04 16:22:24.323024: train loss: 1.623668783851612
Eval step 0: eval loss: 1.0001069641916798
Eval: 2022-04-04 16:22:29.877658: total loss: 1.0785406719652932, mse:4.682155468102979, ic :0.1701613172215992, sharpe5:14.371823937892913, irr5:485.5633239746094, ndcg5:0.8547596537905846, pnl5:5.06779670715332 
train 39, step: 0, loss: 0.8637404117915679, grad_norm: 0.014657628441719283, ic: 0.5422435320427893
train 39, step: 500, loss: 1.2515603855503208, grad_norm: 0.36491979489726317, ic: 0.00604592439540437
train 39, step: 1000, loss: 1.391366669625947, grad_norm: 0.289885108746025, ic: 0.07053777657027059
train 39, step: 1500, loss: 2.443761274268065, grad_norm: 0.44900577977553047, ic: -0.08014569229711405
train 39, step: 2000, loss: 2.861963953797132, grad_norm: 1.3155735762833007, ic: 0.24471918255992572
Epoch 39: 2022-04-04 16:23:04.869558: train loss: 1.622384136297309
Eval step 0: eval loss: 1.0046668271129542
Eval: 2022-04-04 16:23:10.353195: total loss: 1.07885427439384, mse:4.673888487614813, ic :0.16902178379244007, sharpe5:14.400739941000937, irr5:479.59210205078125, ndcg5:0.8398131308732505, pnl5:3.5614519119262695 

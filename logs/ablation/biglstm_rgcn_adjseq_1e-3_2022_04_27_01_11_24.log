Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='AdjSeqTimeDataset', dout=0.3, epochs=40, glstm_layers=1, gnn_layers=1, gpu=0, graph_attn=False, hidden_dim=128, inner_prod=False, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=1, market=None, mask_adj=True, mask_type='soft', model_type='BiGLSTM', normalize_adj=True, num_days=8, num_heads=1, print_inteval=500, rank_loss=False, relation_num=1, rsr_data_path=None, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_250_0.8/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
60372
BiGLSTM(
  (input_to_hidden): Linear(in_features=9, out_features=128, bias=True)
  (forward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
  )
  (backward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
  )
  (fc0): ModuleList(
    (0): Linear(in_features=256, out_features=128, bias=True)
  )
  (w_out): Linear(in_features=128, out_features=1, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
)
train 0, step: 0, loss: 4.812299953577013, grad_norm: 4.549985491803066, ic: 0.030745341308215185
train 0, step: 500, loss: 0.8653877218055294, grad_norm: 0.025175104626869973, ic: 0.02156855683918323
train 0, step: 1000, loss: 1.9484716832594184, grad_norm: 0.4450790031194197, ic: -0.01547978703204727
train 0, step: 1500, loss: 0.9561092090229742, grad_norm: 0.05549752089793229, ic: 0.04748588312054783
train 0, step: 2000, loss: 1.0006172064828562, grad_norm: 0.13089823512399426, ic: 0.04805605567523909
Epoch 0: 2022-04-27 13:14:45.715415: train loss: 1.6491513772704847
Eval step 0: eval loss: 0.8362126405673735
Eval: 2022-04-27 13:14:58.143896: total loss: 1.0792875600626, mse:4.823188533149541, ic :0.007426920197480774, sharpe5:8.02547874033451, irr5:222.53952026367188, ndcg5:0.8489515143489167, pnl5:2.961297035217285 
train 1, step: 0, loss: 2.767485587827621, grad_norm: 0.7407368126646081, ic: 0.047811715847062085
train 1, step: 500, loss: 1.7484864510403557, grad_norm: 0.6563307832858541, ic: 0.12206385263587943
train 1, step: 1000, loss: 0.8748460416595358, grad_norm: 0.14972334120674047, ic: 0.059984916307627284
train 1, step: 1500, loss: 1.7078447714619254, grad_norm: 0.17991329031845452, ic: -0.008247488485735189
train 1, step: 2000, loss: 2.172283984375, grad_norm: 0.8433973477558704, ic: -0.00016121102555078162
Epoch 1: 2022-04-27 13:18:19.082113: train loss: 1.646838599590013
Eval step 0: eval loss: 0.836276184017716
Eval: 2022-04-27 13:18:31.461937: total loss: 1.0793042446948689, mse:4.823086114277456, ic :0.011733274596496852, sharpe5:8.256044349074363, irr5:231.76327514648438, ndcg5:0.8581002144983035, pnl5:2.626349687576294 
train 2, step: 0, loss: 2.140472833806818, grad_norm: 0.006539642812426213, ic: 0.09108260951863134
train 2, step: 500, loss: 3.289609237455986, grad_norm: 0.25545810464527885, ic: 0.009853321056486904
train 2, step: 1000, loss: 2.074038403975096, grad_norm: 2.4121973600642145e-05, ic: 0.2449479125718167
train 2, step: 1500, loss: 1.480745691197519, grad_norm: 0.05131374524207997, ic: -0.031325106989037815
train 2, step: 2000, loss: 3.2154304387019232, grad_norm: 0.7287111040010456, ic: 0.13225995477980265
Epoch 2: 2022-04-27 13:21:49.926622: train loss: 1.6466298319959163
Eval step 0: eval loss: 0.8366750670936511
Eval: 2022-04-27 13:22:02.374721: total loss: 1.0794268638951898, mse:4.822866736037648, ic :0.017803361366753048, sharpe5:10.701007862091064, irr5:309.3243408203125, ndcg5:0.8525822236137341, pnl5:2.3788421154022217 
train 3, step: 0, loss: 1.5232241250635163, grad_norm: 0.49262345884291553, ic: -0.001572502626938606
train 3, step: 500, loss: 1.4944155460796789, grad_norm: 0.3246793248157869, ic: 0.040895489194045925
train 3, step: 1000, loss: 3.686845022848302, grad_norm: 0.679356174723667, ic: 0.006375179823532524
train 3, step: 1500, loss: 1.9505633215272096, grad_norm: 0.9348595201348723, ic: -0.01915965056709454
train 3, step: 2000, loss: 0.8984885715793919, grad_norm: 0.002731181913770434, ic: 0.010242591701795048
Epoch 3: 2022-04-27 13:25:25.716231: train loss: 1.6478470647014565
Eval step 0: eval loss: 0.834288200161354
Eval: 2022-04-27 13:25:38.262438: total loss: 1.0788071187922637, mse:4.82468487149392, ic :0.02382780284580782, sharpe5:11.498360806703566, irr5:401.0376281738281, ndcg5:0.8352768957568866, pnl5:3.7493903636932373 
train 4, step: 0, loss: 1.4429917689732144, grad_norm: 0.06061811484339054, ic: 0.05586866762600883
train 4, step: 500, loss: 1.640524460199311, grad_norm: 0.5886356856970588, ic: -0.042641538409617555
train 4, step: 1000, loss: 2.9206500169707508, grad_norm: 0.8450046855577986, ic: -0.0038926848432814104
train 4, step: 1500, loss: 2.161884600804325, grad_norm: 0.47085084256352716, ic: -0.04929778398287519
train 4, step: 2000, loss: 1.0796805896432737, grad_norm: 0.4022787270475568, ic: 0.19766625930062837
Epoch 4: 2022-04-27 13:28:55.547332: train loss: 1.6441390196828474
Eval step 0: eval loss: 0.9167967978217202
Eval: 2022-04-27 13:29:08.028399: total loss: 1.1300402558633167, mse:4.904832889765489, ic :0.12706312783589227, sharpe5:11.535258530974387, irr5:401.9967346191406, ndcg5:0.8591225216827888, pnl5:3.6281487941741943 
train 5, step: 0, loss: 1.4372738831795302, grad_norm: 1.764788503029857, ic: 0.3312471012105326
train 5, step: 500, loss: 0.8898956758648889, grad_norm: 0.005706651186096297, ic: 0.22997519812132317
train 5, step: 1000, loss: 0.9895064430675288, grad_norm: 0.1540192138947699, ic: -0.023953418841947963
train 5, step: 1500, loss: 1.5297252427198986, grad_norm: 0.14708924849610214, ic: 0.015364696903303506
train 5, step: 2000, loss: 1.107601015307787, grad_norm: 0.02918839545495691, ic: 0.1531080054079601
Epoch 5: 2022-04-27 13:32:30.064199: train loss: 1.64286229437293
Eval step 0: eval loss: 0.8361033046710352
Eval: 2022-04-27 13:32:42.802330: total loss: 1.0751464983386438, mse:4.633908069636745, ic :0.14019401861249536, sharpe5:11.411975086927413, irr5:399.5381774902344, ndcg5:0.8563322517952632, pnl5:3.086550712585449 
train 6, step: 0, loss: 1.3296661620314991, grad_norm: 0.3992736613613241, ic: 0.07260473298862796
train 6, step: 500, loss: 1.007251499988036, grad_norm: 0.03889990608986709, ic: 0.054598257391227825
train 6, step: 1000, loss: 1.0754060346364067, grad_norm: 0.1101349011371493, ic: 0.8042690391985561
train 6, step: 1500, loss: 1.581827967620093, grad_norm: 0.688596815355719, ic: -0.01474280827661475
train 6, step: 2000, loss: 0.8043389789956965, grad_norm: 0.09351315430783277, ic: 0.3302778423877938
Epoch 6: 2022-04-27 13:36:03.088991: train loss: 1.636066413054687
Eval step 0: eval loss: 0.8308300987058745
Eval: 2022-04-27 13:36:16.169838: total loss: 1.072257041922348, mse:4.623427267745653, ic :0.14186156065905092, sharpe5:11.645155234336853, irr5:404.2383117675781, ndcg5:0.8621024680003826, pnl5:3.3348727226257324 
train 7, step: 0, loss: 0.9927342414855957, grad_norm: 0.04317451058295438, ic: 0.0565750171259882
train 7, step: 500, loss: 0.6535825410512442, grad_norm: 0.0019098975392320527, ic: 0.005645055158418766
train 7, step: 1000, loss: 1.0206124043519136, grad_norm: 0.19231007923926474, ic: 0.025558356672442523
train 7, step: 1500, loss: 2.244775442959539, grad_norm: 0.6785772083358989, ic: 0.4244075278056303
train 7, step: 2000, loss: 0.9079591815806746, grad_norm: 0.035589229041653785, ic: -0.0031040634134474505
Epoch 7: 2022-04-27 13:39:39.873874: train loss: 1.6355397553221678
Eval step 0: eval loss: 0.8421352374415503
Eval: 2022-04-27 13:39:52.762963: total loss: 1.0800930674017915, mse:4.681100359610447, ic :0.12360191702996892, sharpe5:11.612856600880622, irr5:403.477783203125, ndcg5:0.850590013738137, pnl5:3.6877341270446777 
train 8, step: 0, loss: 3.596336829144022, grad_norm: 1.0699471771020854, ic: -0.04669436214405963
train 8, step: 500, loss: 2.730214220412234, grad_norm: 0.9290004587255519, ic: 0.04508451300641428
train 8, step: 1000, loss: 3.0624214504076086, grad_norm: 0.8366898867110211, ic: 0.04128659394747641
train 8, step: 1500, loss: 0.7034257354924476, grad_norm: 0.019588558069695308, ic: 0.5748400350507736
train 8, step: 2000, loss: 1.050210427409662, grad_norm: 0.37137972072680403, ic: 0.6591834438932921
Epoch 8: 2022-04-27 13:43:18.739108: train loss: 1.6345302586746018
Eval step 0: eval loss: 0.8288042974924262
Eval: 2022-04-27 13:43:31.428708: total loss: 1.0713333129464493, mse:4.6239921885865485, ic :0.1446831186061092, sharpe5:11.856208287477493, irr5:407.1215515136719, ndcg5:0.8497572861991188, pnl5:3.002889394760132 
train 9, step: 0, loss: 5.444493246610845, grad_norm: 0.931536481853523, ic: 0.00023618716434898896
train 9, step: 500, loss: 1.3337637639909434, grad_norm: 0.9928405863125968, ic: 0.31179336807256297
train 9, step: 1000, loss: 0.927667727415589, grad_norm: 0.010821415034886374, ic: 0.04436099991118177
train 9, step: 1500, loss: 1.0856200093197717, grad_norm: 0.0440050529084321, ic: 0.48137669822397827
train 9, step: 2000, loss: 1.0821160967080798, grad_norm: 0.18759051254302772, ic: 0.2459793267524335
Epoch 9: 2022-04-27 13:46:56.679643: train loss: 1.6338498563813761
Eval step 0: eval loss: 0.8299574696226291
Eval: 2022-04-27 13:47:09.126322: total loss: 1.0717466435153569, mse:4.626275190942569, ic :0.14774910820368858, sharpe5:12.019479795098304, irr5:406.9434509277344, ndcg5:0.8525170246854842, pnl5:3.1614325046539307 
train 10, step: 0, loss: 7.150326564777696, grad_norm: 1.1224130657753728, ic: 0.1961100318239112
train 10, step: 500, loss: 1.1262902659561422, grad_norm: 0.045597524396117105, ic: -0.01702431187882138
train 10, step: 1000, loss: 2.3929314174535086, grad_norm: 0.6961348129246417, ic: -0.029183770226487715
train 10, step: 1500, loss: 1.0990251813616072, grad_norm: 0.2591449768294244, ic: -0.011353150559786992
train 10, step: 2000, loss: 2.7597949367163754, grad_norm: 0.4926570417969603, ic: 0.4923896872929867
Epoch 10: 2022-04-27 13:50:28.224305: train loss: 1.63378975623071
Eval step 0: eval loss: 0.8294445556383363
Eval: 2022-04-27 13:50:41.086247: total loss: 1.0691971224118315, mse:4.617892137742354, ic :0.1614965544242481, sharpe5:12.22441743850708, irr5:409.15496826171875, ndcg5:0.8531773453094821, pnl5:4.219106197357178 
train 11, step: 0, loss: 1.2696540755812549, grad_norm: 0.027686363761414846, ic: 0.12891751099768872
train 11, step: 500, loss: 0.6683136558135626, grad_norm: 0.05616960523043672, ic: 0.5890173590138863
train 11, step: 1000, loss: 0.9451107267299568, grad_norm: 0.15136049213947234, ic: 0.06612902025477085
train 11, step: 1500, loss: 1.0665133292214912, grad_norm: 0.052759351350564254, ic: 0.13486447943332402
train 11, step: 2000, loss: 0.7923725724785249, grad_norm: 0.0005276645434163981, ic: 0.08504171546450741
Epoch 11: 2022-04-27 13:54:00.340814: train loss: 1.632667227422599
Eval step 0: eval loss: 0.8362175285250921
Eval: 2022-04-27 13:54:12.735332: total loss: 1.0724231095509702, mse:4.613174800100025, ic :0.16036059768912997, sharpe5:12.137955098748206, irr5:411.64605712890625, ndcg5:0.8522907011586307, pnl5:3.9840898513793945 
train 12, step: 0, loss: 0.9980976581573486, grad_norm: 0.07337846739532025, ic: 0.28699568557818333
train 12, step: 500, loss: 0.9429488748336405, grad_norm: 0.07571257388799749, ic: 0.16448855983355445
train 12, step: 1000, loss: 2.9955570682598527, grad_norm: 0.2140983534679197, ic: 0.28421065107938476
train 12, step: 1500, loss: 0.943386429425695, grad_norm: 0.1059868773445205, ic: -0.11584013729085083
train 12, step: 2000, loss: 0.8744276340634441, grad_norm: 0.00270508812487038, ic: 0.22160271776143087
Epoch 12: 2022-04-27 13:57:27.675870: train loss: 1.6288814811683432
Eval step 0: eval loss: 0.8284512068624867
Eval: 2022-04-27 13:57:40.412188: total loss: 1.0703646542113718, mse:4.604005178390527, ic :0.18052658349738543, sharpe5:16.37047037601471, irr5:519.9180908203125, ndcg5:0.8438436194144455, pnl5:5.165927410125732 
train 13, step: 0, loss: 2.0568265018644403, grad_norm: 0.8730576943665442, ic: 0.43290546980321226
train 13, step: 500, loss: 0.8187948645868861, grad_norm: 0.09196295537224133, ic: 0.5850796866277915
train 13, step: 1000, loss: 0.9240079534133808, grad_norm: 0.34934038830361647, ic: 0.6139174046360958
train 13, step: 1500, loss: 2.368523888807572, grad_norm: 0.191893183013763, ic: -0.05837417168869733
train 13, step: 2000, loss: 1.4499184694356235, grad_norm: 0.1388753279550149, ic: 0.22335941657067565
Epoch 13: 2022-04-27 14:00:59.984591: train loss: 1.6257815758966712
Eval step 0: eval loss: 0.8235500002058087
Eval: 2022-04-27 14:01:12.739658: total loss: 1.0671368388545068, mse:4.604485940407968, ic :0.18198273962560116, sharpe5:16.246686537265777, irr5:541.0906372070312, ndcg5:0.8418440733418963, pnl5:5.499130725860596 
train 14, step: 0, loss: 4.573887008214704, grad_norm: 1.3555888688502589, ic: 0.13398323059427936
train 14, step: 500, loss: 0.8266111601383315, grad_norm: 0.004546523951993279, ic: 0.22452698523253062
train 14, step: 1000, loss: 1.8685876474112568, grad_norm: 2.0895342765136045, ic: 0.4360941326073621
train 14, step: 1500, loss: 1.1271363262853218, grad_norm: 0.0653542202461404, ic: -0.03318809075628541
train 14, step: 2000, loss: 1.1331437325532918, grad_norm: 0.20751687435116142, ic: 0.07717831622789548
Epoch 14: 2022-04-27 14:04:33.743403: train loss: 1.6257009158616118
Eval step 0: eval loss: 0.8319966484045705
Eval: 2022-04-27 14:04:46.241382: total loss: 1.0691624519898837, mse:4.598715661843589, ic :0.1840064007421346, sharpe5:16.792567023038863, irr5:544.37109375, ndcg5:0.8339795755338146, pnl5:7.65482759475708 
train 15, step: 0, loss: 3.332513451483463, grad_norm: 0.44866150165614727, ic: 0.08878680147291558
train 15, step: 500, loss: 1.2553568877285952, grad_norm: 0.12415037220149745, ic: 0.015925532009619964
train 15, step: 1000, loss: 1.3139719893292683, grad_norm: 0.12650136944907345, ic: 0.0970610300773269
train 15, step: 1500, loss: 0.8486547274852362, grad_norm: 0.17952584157285645, ic: 0.061825662260881944
train 15, step: 2000, loss: 1.4575230695199275, grad_norm: 0.5228755637657606, ic: 0.07535336504271956
Epoch 15: 2022-04-27 14:08:09.296777: train loss: 1.625151029063523
Eval step 0: eval loss: 0.8350873812483535
Eval: 2022-04-27 14:08:21.876768: total loss: 1.071364736417074, mse:4.591784259728072, ic :0.18758772607009744, sharpe5:17.268116040229796, irr5:552.04248046875, ndcg5:0.8536390022014861, pnl5:8.134004592895508 
train 16, step: 0, loss: 0.6952805084929236, grad_norm: 0.22187777354695354, ic: -0.023542752855688548
train 16, step: 500, loss: 1.5714260604155639, grad_norm: 0.2846339674411764, ic: 0.20117425480622994
train 16, step: 1000, loss: 0.877041348544034, grad_norm: 0.0034418113179878933, ic: -0.07622821099116216
train 16, step: 1500, loss: 0.8563939448507684, grad_norm: 0.1971562129175769, ic: 0.1440619960259166
train 16, step: 2000, loss: 3.373456732878303, grad_norm: 0.8554037106856539, ic: 0.018275721357036433
Epoch 16: 2022-04-27 14:11:43.890222: train loss: 1.6248697175916775
Eval step 0: eval loss: 0.8254942497036354
Eval: 2022-04-27 14:11:56.580023: total loss: 1.0682642869024876, mse:4.601366563137468, ic :0.18321942445610842, sharpe5:16.776645201444627, irr5:551.7149047851562, ndcg5:0.8539882852121761, pnl5:6.731778144836426 
train 17, step: 0, loss: 1.2880494135444296, grad_norm: 0.2418009195257564, ic: -0.08213907456563371
train 17, step: 500, loss: 1.7661540375169376, grad_norm: 0.6173007705035531, ic: 0.17189175903506454
train 17, step: 1000, loss: 1.2924268769054879, grad_norm: 0.1037984246857473, ic: 0.1449992574215109
train 17, step: 1500, loss: 4.515852457981263, grad_norm: 1.045934288901862, ic: 0.2381233934717049
train 17, step: 2000, loss: 1.2681371040920844, grad_norm: 0.5521032060373734, ic: 0.09766428068231149
Epoch 17: 2022-04-27 14:15:21.817143: train loss: 1.6239898504499934
Eval step 0: eval loss: 0.835001327466412
Eval: 2022-04-27 14:15:34.543673: total loss: 1.073427047772931, mse:4.644286957981696, ic :0.17016443088633706, sharpe5:16.715271649360655, irr5:549.050537109375, ndcg5:0.8481679774703542, pnl5:5.28124475479126 
train 18, step: 0, loss: 1.418824298657553, grad_norm: 0.4683350252009555, ic: 0.13400103676383524
train 18, step: 500, loss: 1.4580992420803067, grad_norm: 0.7300596471973679, ic: 0.0333786344880409
train 18, step: 1000, loss: 0.6607449299015411, grad_norm: 0.060529033025995174, ic: 0.5624292232344459
train 18, step: 1500, loss: 1.4408141939880221, grad_norm: 0.03466917081337285, ic: 0.09210344682028938
train 18, step: 2000, loss: 0.9090587834643711, grad_norm: 0.005435201418383311, ic: 0.0220011040535002
Epoch 18: 2022-04-27 14:18:59.370425: train loss: 1.6241377737220088
Eval step 0: eval loss: 0.8230440965819283
Eval: 2022-04-27 14:19:12.100762: total loss: 1.0657275833875444, mse:4.593909373263572, ic :0.19156712916198249, sharpe5:16.890209258794783, irr5:581.6961669921875, ndcg5:0.8370519093117232, pnl5:5.007848262786865 
train 19, step: 0, loss: 1.4820068359375, grad_norm: 0.700273296765672, ic: -0.008561020459937757
train 19, step: 500, loss: 0.86705893057364, grad_norm: 0.0375595023884962, ic: 0.22723679155697526
train 19, step: 1000, loss: 0.9563641732808941, grad_norm: 0.007523273299884996, ic: 0.20298022151394313
train 19, step: 1500, loss: 3.9534983309908642, grad_norm: 0.8019076257984827, ic: 0.1615463545425194
train 19, step: 2000, loss: 1.0061500901442308, grad_norm: 0.08216229997111828, ic: 0.08281546623423343
Epoch 19: 2022-04-27 14:22:36.671344: train loss: 1.6236967749158038
Eval step 0: eval loss: 0.8292409979254478
Eval: 2022-04-27 14:22:49.123068: total loss: 1.0672025302043326, mse:4.584625320186967, ic :0.19079631208331121, sharpe5:17.171871882677078, irr5:571.82666015625, ndcg5:0.8420821192183782, pnl5:4.629889011383057 
train 20, step: 0, loss: 2.3043767755681817, grad_norm: 0.7631496829846476, ic: 0.05057367262222394
train 20, step: 500, loss: 3.18959375, grad_norm: 0.4323929317714885, ic: 0.08452193294144159
train 20, step: 1000, loss: 0.9842103958129883, grad_norm: 0.21227303598342728, ic: 0.12306226399334455
train 20, step: 1500, loss: 1.8774952443051303, grad_norm: 0.3862946683580459, ic: 0.24057482884027528
train 20, step: 2000, loss: 1.0467099163310563, grad_norm: 0.07523768198842765, ic: -0.01575499183895021
Epoch 20: 2022-04-27 14:26:10.262854: train loss: 1.6235824399582623
Eval step 0: eval loss: 0.8301142701610247
Eval: 2022-04-27 14:26:23.002666: total loss: 1.0674764418299836, mse:4.590153740312316, ic :0.18851110128044193, sharpe5:17.38467111468315, irr5:574.8091430664062, ndcg5:0.8508655037904255, pnl5:7.041291236877441 
train 21, step: 0, loss: 1.0186392335287948, grad_norm: 0.2923171200838845, ic: 0.057817052195278926
train 21, step: 500, loss: 0.7735211532727807, grad_norm: 0.009568199902116797, ic: 0.19742141078883482
train 21, step: 1000, loss: 0.9271514624880071, grad_norm: 0.5299654266437398, ic: 0.13549080292733845
train 21, step: 1500, loss: 0.9996786975791936, grad_norm: 0.17508527112145011, ic: 0.2987997111972061
train 21, step: 2000, loss: 0.9414770183373131, grad_norm: 0.042109062787448345, ic: 0.05275827315461259
Epoch 21: 2022-04-27 14:29:37.674637: train loss: 1.6238825024833086
Eval step 0: eval loss: 0.8263341423332126
Eval: 2022-04-27 14:29:49.882578: total loss: 1.0653841597689564, mse:4.594875732125395, ic :0.19167974356349748, sharpe5:17.80385998606682, irr5:587.1216430664062, ndcg5:0.8376646940147775, pnl5:7.097605228424072 
train 22, step: 0, loss: 1.0445162670760504, grad_norm: 0.022528508221833884, ic: 0.20172756318585877
train 22, step: 500, loss: 3.25189834222561, grad_norm: 0.6921498230062382, ic: -0.1408999685679057
train 22, step: 1000, loss: 1.1929717135567197, grad_norm: 0.08428338653395022, ic: 0.4623914446119258
train 22, step: 1500, loss: 0.9705114293981482, grad_norm: 0.05760800082589784, ic: 0.11750575921546164
train 22, step: 2000, loss: 1.7552333840437218, grad_norm: 0.4832850765803367, ic: 0.18330554227179718
Epoch 22: 2022-04-27 14:33:55.813996: train loss: 1.623693512806595
Eval step 0: eval loss: 0.8286664056325737
Eval: 2022-04-27 14:34:11.985025: total loss: 1.0663923379907387, mse:4.596078668702948, ic :0.18759545657941074, sharpe5:17.48972184062004, irr5:567.1481323242188, ndcg5:0.8368521098972669, pnl5:6.278407096862793 
train 23, step: 0, loss: 0.9886204436464338, grad_norm: 0.045384696322891896, ic: 0.19292584030759982
train 23, step: 500, loss: 1.425545157967033, grad_norm: 1.3596636574366738, ic: 0.05907188326372849
train 23, step: 1000, loss: 1.6716398111979167, grad_norm: 0.10754959385100497, ic: 0.2553025963242999
train 23, step: 1500, loss: 1.1181504783132674, grad_norm: 0.198845977882713, ic: 0.08249501869793459
train 23, step: 2000, loss: 1.924892833730273, grad_norm: 0.610561966759629, ic: 0.4346704882021012
Epoch 23: 2022-04-27 14:38:48.747467: train loss: 1.6236540139598516
Eval step 0: eval loss: 0.828128215761657
Eval: 2022-04-27 14:39:06.154767: total loss: 1.0667232688837676, mse:4.581816272300553, ic :0.19381873925056703, sharpe5:17.073242100477216, irr5:576.2139892578125, ndcg5:0.8651676422290205, pnl5:4.603450298309326 
train 24, step: 0, loss: 2.2012330016632307, grad_norm: 0.012685911541725627, ic: 0.12251880617659466
train 24, step: 500, loss: 1.2232169184703308, grad_norm: 0.06649558063870115, ic: 0.21445473070076176
train 24, step: 1000, loss: 0.9122338356157158, grad_norm: 0.02842874667005125, ic: 0.5201836148668304
train 24, step: 1500, loss: 2.6041248695769785, grad_norm: 0.7176654072898432, ic: 0.0815678305218126
train 24, step: 2000, loss: 0.9310745450667277, grad_norm: 0.0162843007785841, ic: 0.10268968687132166
Epoch 24: 2022-04-27 14:43:44.415375: train loss: 1.6224314325141738
Eval step 0: eval loss: 0.8257642450523577
Eval: 2022-04-27 14:44:02.252990: total loss: 1.0659920571872175, mse:4.598223902853154, ic :0.18737509315320122, sharpe5:16.82470957875252, irr5:567.406982421875, ndcg5:0.8357306092066575, pnl5:8.091525077819824 
train 25, step: 0, loss: 0.8556587837837838, grad_norm: 0.20128389602121438, ic: 0.6007026831203431
train 25, step: 500, loss: 0.867884886588935, grad_norm: 0.003036778126711917, ic: 0.23451250545633018
train 25, step: 1000, loss: 2.0983455335467442, grad_norm: 0.033977257305243896, ic: 0.24488113015138174
train 25, step: 1500, loss: 1.1348117936770552, grad_norm: 0.36628029499434944, ic: 0.5412376056412325
train 25, step: 2000, loss: 1.0174310645818876, grad_norm: 0.48163295615688484, ic: 0.6021064481886439
Epoch 25: 2022-04-27 14:48:49.209186: train loss: 1.6224646002739667
Eval step 0: eval loss: 0.824785495834431
Eval: 2022-04-27 14:49:06.706075: total loss: 1.0681280383758263, mse:4.681841327327731, ic :0.17608958965754065, sharpe5:18.2575259578228, irr5:585.43701171875, ndcg5:0.8518015936430685, pnl5:8.099588394165039 
train 26, step: 0, loss: 6.679542419628594, grad_norm: 0.27938339221325936, ic: 0.13266051038652618
train 26, step: 500, loss: 3.8385831521207976, grad_norm: 1.5739291136744527, ic: 0.37131321146005525
train 26, step: 1000, loss: 1.2490257370977238, grad_norm: 0.8406995149168917, ic: -0.027025922887362344
train 26, step: 1500, loss: 0.8311888500994216, grad_norm: 0.18156420203479967, ic: 0.302623570767675
train 26, step: 2000, loss: 0.9539664303759343, grad_norm: 0.09602736035514466, ic: 0.10542090237257883
Epoch 26: 2022-04-27 14:53:53.244272: train loss: 1.622844110667272
Eval step 0: eval loss: 0.8285972024417149
Eval: 2022-04-27 14:54:10.073519: total loss: 1.0652441970612745, mse:4.585953339978686, ic :0.1933646140356185, sharpe5:17.969648602008817, irr5:585.3211669921875, ndcg5:0.8483435004269542, pnl5:7.0581135749816895 
train 27, step: 0, loss: 0.8315580001531863, grad_norm: 0.019572622632991015, ic: 0.09391230438293621
train 27, step: 500, loss: 0.923579032232505, grad_norm: 0.7376903684817384, ic: 0.3039793761906115
train 27, step: 1000, loss: 0.7524714281830047, grad_norm: 0.2190273392459789, ic: 0.18827091601091128
train 27, step: 1500, loss: 0.6364290488557536, grad_norm: 0.034437857734698867, ic: 0.5192631278422175
train 27, step: 2000, loss: 1.384584697703113, grad_norm: 0.012909045225071823, ic: -0.00013976895353452583
Epoch 27: 2022-04-27 14:58:48.411546: train loss: 1.6212206340746422
Eval step 0: eval loss: 0.8318761216576659
Eval: 2022-04-27 14:59:05.531425: total loss: 1.0674449130424146, mse:4.59645879203203, ic :0.19065635105861187, sharpe5:17.772657680511475, irr5:581.3463134765625, ndcg5:0.8393372477892146, pnl5:7.393640518188477 
train 28, step: 0, loss: 1.5411100763151544, grad_norm: 0.2656738960590946, ic: 0.1950532163896918
train 28, step: 500, loss: 1.3617281116807574, grad_norm: 1.6654911117116507, ic: 0.19287727452988096
train 28, step: 1000, loss: 0.9126390079818767, grad_norm: 0.32454199693655433, ic: 0.5794314168343875
train 28, step: 1500, loss: 1.0380759783835956, grad_norm: 0.020566918722054642, ic: -0.002380052177816276
train 28, step: 2000, loss: 1.048071551176668, grad_norm: 0.10305954699614951, ic: 0.06963827905275718
Epoch 28: 2022-04-27 15:03:48.040792: train loss: 1.6220822954266507
Eval step 0: eval loss: 0.8239179476546035
Eval: 2022-04-27 15:04:05.627494: total loss: 1.0670226721916054, mse:4.605528285162775, ic :0.1900040032610216, sharpe5:17.779960227012634, irr5:583.8136596679688, ndcg5:0.8417195569471071, pnl5:6.781064033508301 
train 29, step: 0, loss: 0.9073117063115997, grad_norm: 0.02219774668361847, ic: 0.09888345239350531
train 29, step: 500, loss: 1.1073309136221008, grad_norm: 0.1438874724723413, ic: 0.6134487711107498
train 29, step: 1000, loss: 1.0627681237408864, grad_norm: 0.9350322947620848, ic: 0.11264538027319893
train 29, step: 1500, loss: 2.4041579378293325, grad_norm: 0.5277301296956993, ic: -0.09882844650555236
train 29, step: 2000, loss: 4.669274224175347, grad_norm: 1.9491021372119415, ic: 0.19604502955149433
Epoch 29: 2022-04-27 15:08:54.649219: train loss: 1.6209624242397593
Eval step 0: eval loss: 0.8274365697444678
Eval: 2022-04-27 15:09:10.827098: total loss: 1.065585124251118, mse:4.5941917528069665, ic :0.19566318467381982, sharpe5:18.162004487514494, irr5:614.926025390625, ndcg5:0.8407106311151656, pnl5:4.512418746948242 
train 30, step: 0, loss: 1.0010125015938873, grad_norm: 0.05697930479528276, ic: 0.5188013168662697
train 30, step: 500, loss: 1.4048662694190936, grad_norm: 1.1718730025743436, ic: 0.005762435646332553
train 30, step: 1000, loss: 0.9739059910629735, grad_norm: 0.023726792429033708, ic: -0.06449322857938747
train 30, step: 1500, loss: 1.5120974491162291, grad_norm: 1.0367034803756905, ic: 0.158756677773247
train 30, step: 2000, loss: 1.8493783100014345, grad_norm: 0.26145642617178444, ic: 0.04069326639168227
Epoch 30: 2022-04-27 15:14:12.576710: train loss: 1.6217019362565972
Eval step 0: eval loss: 0.8306693106230242
Eval: 2022-04-27 15:14:29.884247: total loss: 1.0666835185952763, mse:4.591897115003997, ic :0.19193573157825353, sharpe5:17.205047389268874, irr5:581.2732543945312, ndcg5:0.848947694158, pnl5:4.828928470611572 
train 31, step: 0, loss: 1.053424225787092, grad_norm: 0.07113869474749876, ic: 0.3284224404940138
train 31, step: 500, loss: 1.518800033757716, grad_norm: 0.7478628047354259, ic: 0.043453647224958494
train 31, step: 1000, loss: 4.340774953039618, grad_norm: 1.1342653555781972, ic: 0.46088340550628604
train 31, step: 1500, loss: 0.7731694654523137, grad_norm: 0.20088435750955064, ic: 0.7123087205600355
train 31, step: 2000, loss: 1.2494653394519377, grad_norm: 0.9984955265596753, ic: 0.22699499048011312
Epoch 31: 2022-04-27 15:19:35.115302: train loss: 1.6202551418978133
Eval step 0: eval loss: 0.836949435878227
Eval: 2022-04-27 15:19:52.936068: total loss: 1.0684954944640839, mse:4.591764520541301, ic :0.18896331751416245, sharpe5:17.405190135240552, irr5:576.474609375, ndcg5:0.8556840236806839, pnl5:6.084463596343994 
train 32, step: 0, loss: 1.132897368837685, grad_norm: 0.01687667663326957, ic: 0.1813486430877353
train 32, step: 500, loss: 1.4873046875, grad_norm: 0.44649940305707536, ic: 0.15994603809791236
train 32, step: 1000, loss: 1.0343891233389986, grad_norm: 0.06939862588263597, ic: 0.5134589767776543
train 32, step: 1500, loss: 0.9930197383319032, grad_norm: 0.3846374486794585, ic: 0.0682902163516646
train 32, step: 2000, loss: 0.9520678605509717, grad_norm: 0.02722681129721219, ic: 0.5395143769064599
Epoch 32: 2022-04-27 15:24:43.084045: train loss: 1.621727009918874
Eval step 0: eval loss: 0.8242079450408324
Eval: 2022-04-27 15:25:00.116205: total loss: 1.0655309753704976, mse:4.600086086558238, ic :0.19438794635388373, sharpe5:17.391003141403196, irr5:585.6767578125, ndcg5:0.8555279824572847, pnl5:9.339130401611328 
train 33, step: 0, loss: 1.259282968300036, grad_norm: 0.18623591946509627, ic: 0.21902653709173975
train 33, step: 500, loss: 0.9987152309432296, grad_norm: 0.19796381979875258, ic: 0.11733854989526478
train 33, step: 1000, loss: 1.0460239095575428, grad_norm: 0.7060633705883491, ic: 0.19691004020281722
train 33, step: 1500, loss: 0.8937648714366474, grad_norm: 0.11740560375284416, ic: 0.5547336785344652
train 33, step: 2000, loss: 0.8136568628664818, grad_norm: 0.030131079731431074, ic: 0.24585665968243717
Epoch 33: 2022-04-27 15:30:00.336171: train loss: 1.6211778214392547
Eval step 0: eval loss: 0.8291766183770745
Eval: 2022-04-27 15:30:17.277863: total loss: 1.066464089135502, mse:4.6125272360749605, ic :0.1949411713088697, sharpe5:17.28023524045944, irr5:583.313720703125, ndcg5:0.8362732300224274, pnl5:7.205643653869629 
train 34, step: 0, loss: 1.0084176841169326, grad_norm: 0.681477239621392, ic: 0.6086295209542546
train 34, step: 500, loss: 0.8270779764251243, grad_norm: 0.6497771487792714, ic: 0.2733195021266865
train 34, step: 1000, loss: 3.292282456077189, grad_norm: 0.23729693805488997, ic: 0.2127003303109014
train 34, step: 1500, loss: 0.8112580546036948, grad_norm: 0.24716994933667064, ic: 0.6823294337498036
train 34, step: 2000, loss: 6.873559740511232, grad_norm: 2.5393151168652963, ic: 0.4441700224337666
Epoch 34: 2022-04-27 15:35:03.373284: train loss: 1.6213520438403795
Eval step 0: eval loss: 0.8239695284715819
Eval: 2022-04-27 15:35:20.898396: total loss: 1.0665032822304437, mse:4.59925016265485, ic :0.19656195236467366, sharpe5:17.737225195169447, irr5:593.1513671875, ndcg5:0.8305525158094043, pnl5:8.614153861999512 
train 35, step: 0, loss: 1.218094554227941, grad_norm: 0.8004597576122368, ic: 0.5501299224382906
train 35, step: 500, loss: 1.1624599154231399, grad_norm: 0.3868857430547249, ic: 0.09154619803980339
train 35, step: 1000, loss: 1.7358127602093285, grad_norm: 4.813248338867206, ic: 0.06972072198389757
train 35, step: 1500, loss: 1.6381331135455828, grad_norm: 0.8345760984165453, ic: 0.03710823076686417
train 35, step: 2000, loss: 0.778820670224766, grad_norm: 0.07399127809509788, ic: 0.559458985469793
Epoch 35: 2022-04-27 15:40:08.379968: train loss: 1.6232746803694214
Eval step 0: eval loss: 0.8316007238293598
Eval: 2022-04-27 15:40:25.694813: total loss: 1.0669567938083806, mse:4.578691833910156, ic :0.19694004097116913, sharpe5:18.115118733644486, irr5:596.3681030273438, ndcg5:0.8419695647038355, pnl5:10.025455474853516 
train 36, step: 0, loss: 1.8346366942209578, grad_norm: 1.1366362725400738, ic: 0.09947943683089121
train 36, step: 500, loss: 0.8449387666839047, grad_norm: 0.008224664837048952, ic: 0.10764152019499526
train 36, step: 1000, loss: 1.7189467329545454, grad_norm: 1.864909162492645, ic: 0.211716388078737
train 36, step: 1500, loss: 0.7643466327312783, grad_norm: 0.057771346093651324, ic: 0.38930640963462987
train 36, step: 2000, loss: 1.1286314705991858, grad_norm: 0.8665599547590603, ic: 0.7772105379797931
Epoch 36: 2022-04-27 15:45:11.428916: train loss: 1.6210216672069857
Eval step 0: eval loss: 0.8277283036419915
Eval: 2022-04-27 15:45:29.112688: total loss: 1.0651422783943476, mse:4.589538121502807, ic :0.196010947346003, sharpe5:18.01737244606018, irr5:590.4387817382812, ndcg5:0.8676943729793909, pnl5:6.287452220916748 
train 37, step: 0, loss: 2.051317013423622, grad_norm: 1.2274966833620387, ic: 0.1615312767397078
train 37, step: 500, loss: 2.346831030791191, grad_norm: 0.7403944702811243, ic: -0.034390267059507755
train 37, step: 1000, loss: 1.0668809678819444, grad_norm: 0.05824798249754295, ic: 0.09558043971744631
train 37, step: 1500, loss: 2.0209255727531397, grad_norm: 0.6799281244555377, ic: 0.598601217110482
train 37, step: 2000, loss: 1.3208295752439785, grad_norm: 0.1583763065798539, ic: 0.09385532595172913
Epoch 37: 2022-04-27 15:50:18.175546: train loss: 1.6186570063134942
Eval step 0: eval loss: 0.8258183341634285
Eval: 2022-04-27 15:50:35.022956: total loss: 1.0679630410265673, mse:4.602948137537038, ic :0.18844512889629625, sharpe5:17.452036160230637, irr5:583.9213256835938, ndcg5:0.8410831886338784, pnl5:7.26233434677124 
train 38, step: 0, loss: 1.3265798615246285, grad_norm: 0.26058476079312753, ic: -0.08250802716118692
train 38, step: 500, loss: 0.905274643132716, grad_norm: 0.04430058172906937, ic: 0.2628697227033722
train 38, step: 1000, loss: 0.8957760776926877, grad_norm: 0.11983858906934076, ic: 0.22603374268435344
train 38, step: 1500, loss: 0.9518037302166382, grad_norm: 0.01575152946299793, ic: 0.21153507748493677
train 38, step: 2000, loss: 2.3112682331004533, grad_norm: 1.7104106294312713, ic: 0.00815713548069985
Epoch 38: 2022-04-27 15:55:17.182069: train loss: 1.618705431845553
Eval step 0: eval loss: 0.8256526581228595
Eval: 2022-04-27 15:55:34.281583: total loss: 1.0651001414852652, mse:4.585981588844313, ic :0.19857561061855503, sharpe5:17.807836657762525, irr5:591.6414184570312, ndcg5:0.8554449159930039, pnl5:8.530169486999512 
train 39, step: 0, loss: 0.9700403242665329, grad_norm: 0.0022633451511603004, ic: 0.10000717046917271
train 39, step: 500, loss: 0.9003070241941296, grad_norm: 0.15743899250042276, ic: 0.24308724956379074
train 39, step: 1000, loss: 0.9399557237123953, grad_norm: 0.0362378971553888, ic: 0.20098082878268436
train 39, step: 1500, loss: 2.0770244326342118, grad_norm: 0.04667308836645128, ic: 0.18293989869680205
train 39, step: 2000, loss: 0.6132144295208827, grad_norm: 0.023849166688743595, ic: 0.16988794751095934
Epoch 39: 2022-04-27 16:00:19.489365: train loss: 1.6186059994731923
Eval step 0: eval loss: 0.8300248076717267
Eval: 2022-04-27 16:00:37.277391: total loss: 1.0664750398074714, mse:4.595220372570351, ic :0.1942673220950564, sharpe5:17.844773164987565, irr5:583.1074829101562, ndcg5:0.852458122616053, pnl5:5.2388529777526855 

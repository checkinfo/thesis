Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='AdjSeqTimeDataset', dout=0.3, epochs=60, glstm_layers=1, gnn_layers=1, gpu=0, graph_attn=True, hidden_dim=128, inner_prod=False, input_dim=9, input_graph=True, label_cnt=3, lr=0.0001, lstm_layers=1, market=None, mask_adj=True, mask_type='soft', model_type='BiGLSTM', normalize_adj=True, num_days=8, num_heads=1, print_inteval=500, rank_loss=False, relation_num=1, rsr_data_path=None, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_250_0.8/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
72278
BiGLSTM(
  (input_to_hidden): Linear(in_features=9, out_features=128, bias=True)
  (forward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (attention): ModuleList(
            (0): GraphAttentionLayer (128 -> 128)
          )
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
  )
  (backward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (attention): ModuleList(
            (0): GraphAttentionLayer (128 -> 128)
          )
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
  )
  (fc0): ModuleList(
    (0): Linear(in_features=256, out_features=128, bias=True)
  )
  (w_out): Linear(in_features=128, out_features=1, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
)
train 0, step: 0, loss: 4.939038906738663, grad_norm: 4.425279322819397, ic: -0.04507333263499234
train 0, step: 500, loss: 0.8603711563029861, grad_norm: 0.03776961878139398, ic: 0.06587786403146711
train 0, step: 1000, loss: 1.9568521182905085, grad_norm: 0.84962715520815, ic: 0.03581276251310054
train 0, step: 1500, loss: 0.9498847810647233, grad_norm: 0.05179813512497085, ic: 0.04795741953332261
train 0, step: 2000, loss: 0.9998975277290316, grad_norm: 0.20903587497205114, ic: 0.036287620313231
Epoch 0: 2022-04-27 14:35:56.638172: train loss: 1.6481036306782235
Eval step 0: eval loss: 0.8354279947230637
Eval: 2022-04-27 14:36:14.798223: total loss: 1.0792225342284059, mse:4.823087898429425, ic :0.006786451205662366, sharpe5:7.851635093986988, irr5:222.86276245117188, ndcg5:0.8471345601517424, pnl5:2.678335428237915 
train 1, step: 0, loss: 2.7788660849294353, grad_norm: 1.1385666826016272, ic: 0.06290452300251956
train 1, step: 500, loss: 1.7671914025625395, grad_norm: 1.0588956642439808, ic: 0.07416082182765268
train 1, step: 1000, loss: 0.8776344725492881, grad_norm: 0.22863210548498356, ic: 0.07579468843380474
train 1, step: 1500, loss: 1.7121430495689656, grad_norm: 0.2651158813208094, ic: -0.014715272739765448
train 1, step: 2000, loss: 2.1804734375, grad_norm: 1.152982559756056, ic: -0.004604026809554535
Epoch 1: 2022-04-27 14:41:56.849354: train loss: 1.6464657239569587
Eval step 0: eval loss: 0.8336829938175052
Eval: 2022-04-27 14:42:14.964448: total loss: 1.0793965534920567, mse:4.826440880238245, ic :0.006620389357825097, sharpe5:7.704017710983753, irr5:220.88925170898438, ndcg5:0.8481390298426497, pnl5:2.77325439453125 
train 2, step: 0, loss: 2.142359730113636, grad_norm: 0.017327817264458954, ic: 0.13933481028730316
train 2, step: 500, loss: 3.310778789490415, grad_norm: 0.39218891639538445, ic: 0.07391442387366769
train 2, step: 1000, loss: 2.0717605064655173, grad_norm: 0.0007819475262216975, ic: 0.14377846875183603
train 2, step: 1500, loss: 1.4896187119811546, grad_norm: 0.0823017343396273, ic: -0.021567152851454545
train 2, step: 2000, loss: 3.256014873798077, grad_norm: 1.0985551152247817, ic: 0.17143635612379554
Epoch 2: 2022-04-27 14:47:59.773566: train loss: 1.646319649963637
Eval step 0: eval loss: 0.8353442562895153
Eval: 2022-04-27 14:48:17.569858: total loss: 1.0799025106451128, mse:4.825579356078296, ic :0.008699674169856154, sharpe5:7.592787725329399, irr5:217.671875, ndcg5:0.8573219128508384, pnl5:3.0107109546661377 
train 3, step: 0, loss: 1.5200875134972054, grad_norm: 0.6984952550759819, ic: 0.00537565993335645
train 3, step: 500, loss: 1.5086061004184612, grad_norm: 0.44995396752112177, ic: 0.08352163443721654
train 3, step: 1000, loss: 3.678613112586356, grad_norm: 0.9165257852937119, ic: -0.056029787978452684
train 3, step: 1500, loss: 1.9749801810556467, grad_norm: 1.3769035516415498, ic: -0.05190245624716126
train 3, step: 2000, loss: 0.8976636402027027, grad_norm: 0.0014284218618939126, ic: 0.03545220310544297
Epoch 3: 2022-04-27 14:53:48.947999: train loss: 1.6462153207698234
Eval step 0: eval loss: 0.8342543703487223
Eval: 2022-04-27 14:54:07.196595: total loss: 1.079811389520037, mse:4.827572230704256, ic :0.008712079016949956, sharpe5:7.787737812101841, irr5:220.48086547851562, ndcg5:0.8352479727209344, pnl5:2.9474220275878906 
train 4, step: 0, loss: 1.4299869459502552, grad_norm: 0.05728380481433873, ic: 0.15366217280989225
train 4, step: 500, loss: 1.65958511472687, grad_norm: 0.7582463341356231, ic: 0.03330520543946271
train 4, step: 1000, loss: 2.9638042915158156, grad_norm: 0.9123048470322807, ic: 0.01405734377783262
train 4, step: 1500, loss: 2.1554411425369198, grad_norm: 0.6223414136020223, ic: -0.016944573223911196
train 4, step: 2000, loss: 1.0850561447499514, grad_norm: 0.4837144817131247, ic: 0.14411122475811194
Epoch 4: 2022-04-27 14:59:51.619226: train loss: 1.6457014186510652
Eval step 0: eval loss: 0.8428273336653714
Eval: 2022-04-27 15:00:09.280615: total loss: 1.0821577720519153, mse:4.82469459125022, ic :0.01975231668386887, sharpe5:8.358373646736144, irr5:234.87257385253906, ndcg5:0.8389907816329211, pnl5:2.7956924438476562 
train 5, step: 0, loss: 1.3379456795302012, grad_norm: 0.12537595168939186, ic: 0.02920811980177262
train 5, step: 500, loss: 0.8894618954760607, grad_norm: 0.008508158778348415, ic: 0.035277103202334875
train 5, step: 1000, loss: 0.9784230199353449, grad_norm: 0.18934269728200934, ic: -0.007476845388953561
train 5, step: 1500, loss: 1.5345169230953293, grad_norm: 0.19628793312727788, ic: 0.010157451872822767
train 5, step: 2000, loss: 1.108103528653386, grad_norm: 0.0339312141333536, ic: 0.10778230990506787
Epoch 5: 2022-04-27 15:05:48.326780: train loss: 1.645041802386673
Eval step 0: eval loss: 0.8397015490195271
Eval: 2022-04-27 15:06:05.942068: total loss: 1.082069823611117, mse:4.834212244370153, ic :0.03455947291503445, sharpe5:10.07759835898876, irr5:282.1534118652344, ndcg5:0.8418870972121493, pnl5:3.557325839996338 
train 6, step: 0, loss: 1.3425727126320774, grad_norm: 0.5407964956728301, ic: 0.03929458856411089
train 6, step: 500, loss: 1.011583407111409, grad_norm: 0.05975646728763234, ic: 0.007021935206713674
train 6, step: 1000, loss: 1.1255255057331273, grad_norm: 0.11471806931366313, ic: 0.09878309912585723
train 6, step: 1500, loss: 1.5644626081482438, grad_norm: 0.8781067786833552, ic: 0.17159452329858008
train 6, step: 2000, loss: 0.8119995996797438, grad_norm: 0.06243310407363332, ic: 0.00046565727101993
Epoch 6: 2022-04-27 15:11:50.117439: train loss: 1.64405527593312
Eval step 0: eval loss: 0.8348602198449024
Eval: 2022-04-27 15:12:08.720938: total loss: 1.078874862391121, mse:4.826277479450992, ic :0.04158479023165913, sharpe5:11.508333701491356, irr5:331.3934326171875, ndcg5:0.8423226718002379, pnl5:3.3188159465789795 
train 7, step: 0, loss: 0.99516019821167, grad_norm: 0.06347214019332909, ic: 0.04203835404503191
train 7, step: 500, loss: 0.6480414671738459, grad_norm: 0.0020751232451097523, ic: 0.054164943212550866
train 7, step: 1000, loss: 1.0388950600664033, grad_norm: 0.2568435289027481, ic: 0.0899438974979371
train 7, step: 1500, loss: 2.2689144874564575, grad_norm: 0.7915797822378376, ic: 0.15778802579308127
train 7, step: 2000, loss: 0.9140297638580372, grad_norm: 0.05108030892656987, ic: -0.0830490494717923
Epoch 7: 2022-04-27 15:17:44.776703: train loss: 1.6433413377246662
Eval step 0: eval loss: 0.8380332761871048
Eval: 2022-04-27 15:18:02.783900: total loss: 1.0780335903573612, mse:4.811225424013544, ic :0.057234493203517325, sharpe5:12.334836292862892, irr5:379.3307189941406, ndcg5:0.8468718975250115, pnl5:3.77116322517395 
train 8, step: 0, loss: 3.62717674365942, grad_norm: 1.3352483645949342, ic: -0.01861454997807823
train 8, step: 500, loss: 2.781926766717325, grad_norm: 1.1044167146471868, ic: 0.017471264360252637
train 8, step: 1000, loss: 3.095251641757246, grad_norm: 1.2312228513515906, ic: 0.07683084520275082
train 8, step: 1500, loss: 0.7433326429562269, grad_norm: 0.002627240463908285, ic: 0.35664506807669283
train 8, step: 2000, loss: 1.1101080276830024, grad_norm: 0.4487677667369168, ic: 0.2710006659589101
Epoch 8: 2022-04-27 15:23:42.552714: train loss: 1.6421669273834387
Eval step 0: eval loss: 0.8325305291548669
Eval: 2022-04-27 15:24:01.492436: total loss: 1.076068194996126, mse:4.801084296891666, ic :0.081116053228946, sharpe5:12.513166937828064, irr5:401.2975158691406, ndcg5:0.8568391012630248, pnl5:2.788388252258301 
train 9, step: 0, loss: 5.437350089089913, grad_norm: 1.040876519647198, ic: 0.14457546310777833
train 9, step: 500, loss: 1.385113646376239, grad_norm: 1.1618472638848691, ic: 0.28803451517639905
train 9, step: 1000, loss: 0.9262120038613505, grad_norm: 0.01494723772041571, ic: 0.0470705661125
train 9, step: 1500, loss: 1.09159687025382, grad_norm: 0.023181199897750103, ic: 0.4107652998842628
train 9, step: 2000, loss: 1.0775430407211375, grad_norm: 0.32667677773978543, ic: 0.17161683174254644
Epoch 9: 2022-04-27 15:29:42.912027: train loss: 1.6352602805092011
Eval step 0: eval loss: 0.8243033888468124
Eval: 2022-04-27 15:30:00.672651: total loss: 1.0718001812650741, mse:4.704737039659476, ic :0.15448700302525117, sharpe5:15.97485397338867, irr5:512.2516479492188, ndcg5:0.858491437463363, pnl5:5.866756916046143 
train 10, step: 0, loss: 7.063546316964286, grad_norm: 1.7411106659619775, ic: 0.2484859198793623
train 10, step: 500, loss: 1.1330340279140503, grad_norm: 0.08356047649955683, ic: -0.010338735032682749
train 10, step: 1000, loss: 2.355645115390146, grad_norm: 1.0188594123429702, ic: -0.03312472889730307
train 10, step: 1500, loss: 1.111103206485897, grad_norm: 0.3599688448036634, ic: -0.008882416634486554
train 10, step: 2000, loss: 2.7196926128538186, grad_norm: 0.646979517598214, ic: 0.4417833350620167
Epoch 10: 2022-04-27 15:35:49.560324: train loss: 1.629669677100577
Eval step 0: eval loss: 0.825041599092795
Eval: 2022-04-27 15:36:07.775942: total loss: 1.0699842511392632, mse:4.6909662894371875, ic :0.16263184475731796, sharpe5:17.316984454393385, irr5:543.8126220703125, ndcg5:0.8599493187147151, pnl5:7.5736894607543945 
train 11, step: 0, loss: 1.2518159493124035, grad_norm: 0.034120948027748656, ic: 0.20961942417302162
train 11, step: 500, loss: 0.6698019224930604, grad_norm: 0.021675773175616808, ic: 0.5009143737290722
train 11, step: 1000, loss: 0.9444996707221249, grad_norm: 0.19019726165839063, ic: 0.012770115700077975
train 11, step: 1500, loss: 1.0489380150510552, grad_norm: 0.07548295466104592, ic: 0.18519455375884142
train 11, step: 2000, loss: 0.7881592182563191, grad_norm: 0.003791678737217723, ic: 0.0922469823091359
Epoch 11: 2022-04-27 15:41:49.195353: train loss: 1.627943456248467
Eval step 0: eval loss: 0.8266840815167281
Eval: 2022-04-27 15:42:06.653557: total loss: 1.069662834805971, mse:4.678415386171263, ic :0.17220797127446424, sharpe5:17.278315011262894, irr5:565.5517578125, ndcg5:0.8483557499910349, pnl5:5.271843433380127 
train 12, step: 0, loss: 0.9566245873769124, grad_norm: 0.1329422469488204, ic: 0.3985639412156369
train 12, step: 500, loss: 0.9393564485117221, grad_norm: 0.08962378578179322, ic: 0.06475471267805535
train 12, step: 1000, loss: 2.934713570175657, grad_norm: 0.5435694014568777, ic: 0.3516734950818536
train 12, step: 1500, loss: 0.921413773175695, grad_norm: 0.16795176543453272, ic: -0.06085673673757827
train 12, step: 2000, loss: 0.8714145072637368, grad_norm: 0.013244786746589129, ic: 0.2430025057305834
Epoch 12: 2022-04-27 15:47:45.257588: train loss: 1.6259998265357551
Eval step 0: eval loss: 0.8237278961406743
Eval: 2022-04-27 15:48:03.911059: total loss: 1.0688078798327136, mse:4.701588725327894, ic :0.16322945050650012, sharpe5:17.17037542819977, irr5:529.0951538085938, ndcg5:0.848507688359372, pnl5:7.694520950317383 
train 13, step: 0, loss: 2.070552644659121, grad_norm: 1.4897513043985022, ic: 0.2830528851566606
train 13, step: 500, loss: 0.8233819105452763, grad_norm: 0.06064188199578172, ic: 0.514184242002104
train 13, step: 1000, loss: 0.976889222420302, grad_norm: 0.5697230311926818, ic: 0.4761896807855924
train 13, step: 1500, loss: 2.436677430962139, grad_norm: 0.611119828119568, ic: -0.026582739187344447
train 13, step: 2000, loss: 1.4762827437872883, grad_norm: 0.09956381724602718, ic: 0.20476206456014462
Epoch 13: 2022-04-27 15:53:55.481038: train loss: 1.6256956815143928
Eval step 0: eval loss: 0.8217439641440002
Eval: 2022-04-27 15:54:13.431905: total loss: 1.069796761161786, mse:4.683535057306552, ic :0.1707959900446036, sharpe5:17.597720071077347, irr5:561.0198364257812, ndcg5:0.8590308765834311, pnl5:8.440651893615723 
train 14, step: 0, loss: 4.486394397182138, grad_norm: 3.008872198672107, ic: 0.18005493211249418
train 14, step: 500, loss: 0.8255456580299121, grad_norm: 0.013350564211411762, ic: 0.13732719555891948
train 14, step: 1000, loss: 1.8384059711940015, grad_norm: 0.897223273299379, ic: 0.3799290832043749
train 14, step: 1500, loss: 1.1262617126177394, grad_norm: 0.11713266563941593, ic: -0.0486223257757252
train 14, step: 2000, loss: 1.1513298016966358, grad_norm: 1.1951276378177023, ic: 0.04405827082626983
Epoch 14: 2022-04-27 15:59:50.197622: train loss: 1.6242047288563517
Eval step 0: eval loss: 0.8276080341560195
Eval: 2022-04-27 16:00:08.938949: total loss: 1.0693104048915492, mse:4.642939097298979, ic :0.1829843920502541, sharpe5:17.742825075387955, irr5:576.306396484375, ndcg5:0.8518109205706584, pnl5:8.808589935302734 
train 15, step: 0, loss: 3.4527453945768487, grad_norm: 2.40102683147114, ic: 0.11588473814938376
train 15, step: 500, loss: 1.2612431526976828, grad_norm: 0.137076125615279, ic: 0.007888770019113072
train 15, step: 1000, loss: 1.3219115218495936, grad_norm: 0.2649883801728546, ic: 0.043128094259858564
train 15, step: 1500, loss: 0.8400421382874016, grad_norm: 0.2564412951052194, ic: 0.06509900843048032
train 15, step: 2000, loss: 1.474109397802184, grad_norm: 1.197056560177033, ic: 0.0418285928532502
Epoch 15: 2022-04-27 16:04:24.873160: train loss: 1.6225098807909146
Eval step 0: eval loss: 0.828128215761657
Eval: 2022-04-27 16:04:37.863430: total loss: 1.0693181454322023, mse:4.619420863889423, ic :0.1858697687423549, sharpe5:17.242330105304717, irr5:566.8416748046875, ndcg5:0.8584242910468728, pnl5:4.608293056488037 
train 16, step: 0, loss: 0.7051877273233372, grad_norm: 0.8551691261332703, ic: -0.04231116669028399
train 16, step: 500, loss: 1.6122064625794073, grad_norm: 2.3573519489197103, ic: 0.1776449583470501
train 16, step: 1000, loss: 0.8782239509351326, grad_norm: 0.047131216361352854, ic: -0.05796484427124662
train 16, step: 1500, loss: 0.8339705230496455, grad_norm: 0.26973759872493364, ic: 0.16400503480204512
train 16, step: 2000, loss: 3.315376262838047, grad_norm: 1.7809775271187602, ic: 0.03393180821076983
Epoch 16: 2022-04-27 16:08:42.885848: train loss: 1.62108462429803
Eval step 0: eval loss: 0.8246147388904438
Eval: 2022-04-27 16:08:55.327460: total loss: 1.0666653391413305, mse:4.594357861454772, ic :0.19013876214275707, sharpe5:17.347961629629133, irr5:563.7614135742188, ndcg5:0.8554968923284142, pnl5:9.408967971801758 
train 17, step: 0, loss: 1.2701801330404507, grad_norm: 0.7613461702019209, ic: -0.08776531925434972
train 17, step: 500, loss: 1.7830963382876017, grad_norm: 1.4292061720742903, ic: 0.18108654380517983
train 17, step: 1000, loss: 1.2784025125513654, grad_norm: 0.16847785303333523, ic: 0.14608013171562528
train 17, step: 1500, loss: 4.503106559400257, grad_norm: 1.7799670771472103, ic: 0.20439488873283365
train 17, step: 2000, loss: 1.293155982746619, grad_norm: 1.2732953859714036, ic: 0.07685702875950229
Epoch 17: 2022-04-27 16:13:00.383723: train loss: 1.6198630127106666
Eval step 0: eval loss: 0.8318492378902134
Eval: 2022-04-27 16:13:13.063417: total loss: 1.068782961943524, mse:4.5893240251447205, ic :0.1913928879464597, sharpe5:17.562862708568574, irr5:569.5673217773438, ndcg5:0.8465385962120954, pnl5:4.606258392333984 
train 18, step: 0, loss: 1.4222622442958301, grad_norm: 1.3200831835043605, ic: 0.12481633517172319
train 18, step: 500, loss: 1.4434969134634785, grad_norm: 3.015260176074059, ic: -0.012775355963741917
train 18, step: 1000, loss: 0.654061362906678, grad_norm: 0.04010101545083927, ic: 0.5772672239994516
train 18, step: 1500, loss: 1.4196265468238125, grad_norm: 0.09845685474869008, ic: 0.20562158693494786
train 18, step: 2000, loss: 0.9102266153712182, grad_norm: 0.008165176072477031, ic: -0.018487429879882236
Epoch 18: 2022-04-27 16:17:17.684593: train loss: 1.6196061954149479
Eval step 0: eval loss: 0.8207734472759154
Eval: 2022-04-27 16:17:30.126339: total loss: 1.0651798278927382, mse:4.59297411511765, ic :0.1940416302886332, sharpe5:17.56450105190277, irr5:580.6734008789062, ndcg5:0.839472454178157, pnl5:5.2606096267700195 
train 19, step: 0, loss: 1.5052618117559524, grad_norm: 1.2428919119177886, ic: 0.055409982768149145
train 19, step: 500, loss: 0.8574335310194227, grad_norm: 0.09477221778369725, ic: 0.23441014367346838
train 19, step: 1000, loss: 0.9585168558988232, grad_norm: 0.05085884001322531, ic: 0.19620928835634385
train 19, step: 1500, loss: 3.9406609605586786, grad_norm: 1.4696716778163934, ic: 0.15596621450847742
train 19, step: 2000, loss: 1.0131722318209135, grad_norm: 0.2237585039999592, ic: 0.189671532779602
Epoch 19: 2022-04-27 16:21:34.524118: train loss: 1.6189176181800702
Eval step 0: eval loss: 0.8256079590358272
Eval: 2022-04-27 16:21:47.001563: total loss: 1.0665683966187147, mse:4.5862073599442335, ic :0.19316498478361593, sharpe5:17.09972802042961, irr5:569.511474609375, ndcg5:0.8442368243267389, pnl5:5.955569744110107 
train 20, step: 0, loss: 2.313428120368083, grad_norm: 2.2771560631036394, ic: 0.04759496311376562
train 20, step: 500, loss: 3.2322116477272727, grad_norm: 1.1602514133183206, ic: 0.11728157736044252
train 20, step: 1000, loss: 0.9781888961791992, grad_norm: 0.18512975542321497, ic: 0.0692288344361542
train 20, step: 1500, loss: 1.7435442937643568, grad_norm: 21.153903806000248, ic: 0.26175722820418534
train 20, step: 2000, loss: 1.0389876248980425, grad_norm: 0.1935364631036715, ic: 0.01948975421507755
Epoch 20: 2022-04-27 16:25:50.655895: train loss: 1.6176079528188207
Eval step 0: eval loss: 0.8326644977854978
Eval: 2022-04-27 16:26:03.605705: total loss: 1.0676536809513333, mse:4.59112649135438, ic :0.19338692293244938, sharpe5:17.92918379187584, irr5:588.7659912109375, ndcg5:0.8470657211551244, pnl5:6.90354585647583 
train 21, step: 0, loss: 1.0060700882854214, grad_norm: 0.7501123401828106, ic: 0.07164143362084283
train 21, step: 500, loss: 0.766856235740459, grad_norm: 0.006008934581969638, ic: 0.20097866587232294
train 21, step: 1000, loss: 0.9397743626644737, grad_norm: 2.9414649208318737, ic: 0.1623740307301224
train 21, step: 1500, loss: 0.981810117299991, grad_norm: 0.4023840832186844, ic: 0.31502678198959666
train 21, step: 2000, loss: 0.9360763194949128, grad_norm: 0.23711783171090733, ic: 0.08211478206474632
Epoch 21: 2022-04-27 16:30:05.717222: train loss: 1.6178963728500266
Eval step 0: eval loss: 0.8222400918524433
Eval: 2022-04-27 16:30:18.309199: total loss: 1.0656930474482147, mse:4.591664941364239, ic :0.19346414373030302, sharpe5:17.058850786685944, irr5:570.0328979492188, ndcg5:0.8666118202645937, pnl5:5.006475925445557 
train 22, step: 0, loss: 1.0390740518516066, grad_norm: 0.03234924895880535, ic: 0.22057771543808175
train 22, step: 500, loss: 3.2808951028963413, grad_norm: 3.4884744774912777, ic: -0.1501510594934402
train 22, step: 1000, loss: 1.1945611678106938, grad_norm: 0.04044311835107241, ic: 0.46307657116723844
train 22, step: 1500, loss: 0.965822120949074, grad_norm: 0.5708447497129077, ic: 0.1329106932298381
train 22, step: 2000, loss: 1.763457905948838, grad_norm: 4.451002346508215, ic: 0.18130765575283364
Epoch 22: 2022-04-27 16:34:19.857767: train loss: 1.6174791735806986
Eval step 0: eval loss: 0.8217545761574683
Eval: 2022-04-27 16:34:32.479890: total loss: 1.0662074933851933, mse:4.593376818612313, ic :0.19299571244690264, sharpe5:16.90943803668022, irr5:566.3600463867188, ndcg5:0.8396462397251967, pnl5:5.0838117599487305 
train 23, step: 0, loss: 0.9727794460329612, grad_norm: 0.09946237498950239, ic: 0.20665548940982018
train 23, step: 500, loss: 1.4215984733737246, grad_norm: 0.2044506405862061, ic: 0.03822756989246576
train 23, step: 1000, loss: 1.6463527425130209, grad_norm: 0.13216185440078176, ic: 0.26312937465058395
train 23, step: 1500, loss: 1.1409858709468534, grad_norm: 1.8759526779939264, ic: 0.09466340541031219
train 23, step: 2000, loss: 1.8270217625336795, grad_norm: 20.92785425136327, ic: 0.4461484437052172
Epoch 23: 2022-04-27 16:38:39.045448: train loss: 1.616485235961654
Eval step 0: eval loss: 0.8260621532122628
Eval: 2022-04-27 16:38:51.590236: total loss: 1.0665838043635472, mse:4.5881851633631605, ic :0.19271905720260762, sharpe5:16.928008450269697, irr5:575.4732055664062, ndcg5:0.846557511302047, pnl5:3.746492862701416 
train 24, step: 0, loss: 2.2065766433189653, grad_norm: 0.7485075341342169, ic: 0.1372132427092835
train 24, step: 500, loss: 1.2143001808730545, grad_norm: 0.26448148379664654, ic: 0.1329345691236548
train 24, step: 1000, loss: 0.9046897089698684, grad_norm: 0.07493253060403993, ic: 0.5331736938433874
train 24, step: 1500, loss: 2.62027337309357, grad_norm: 15.224528492007758, ic: 0.05549344270317093
train 24, step: 2000, loss: 0.9327012538521291, grad_norm: 0.06797023714454876, ic: 0.08398341264542634
Epoch 24: 2022-04-27 16:42:56.425127: train loss: 1.6131751822153846
Eval step 0: eval loss: 0.8201958321670837
Eval: 2022-04-27 16:43:09.355268: total loss: 1.069421877981542, mse:4.61924591416583, ic :0.18990633398987428, sharpe5:17.185792125463486, irr5:564.1859130859375, ndcg5:0.8527942545253362, pnl5:4.571290016174316 
train 25, step: 0, loss: 0.8281286291173987, grad_norm: 0.12035789908150564, ic: 0.6219094937773945
train 25, step: 500, loss: 0.870336987820997, grad_norm: 0.010196417989160322, ic: 0.19926030089232832
train 25, step: 1000, loss: 2.0802090275133285, grad_norm: 0.4022981691707596, ic: 0.2739370272928919
train 25, step: 1500, loss: 1.1267275674739936, grad_norm: 1.0857084598055202, ic: 0.535456576166526
train 25, step: 2000, loss: 1.0188574489829112, grad_norm: 0.840884362399619, ic: 0.5691050082962084
Epoch 25: 2022-04-27 16:47:14.874021: train loss: 1.6142820653106702
Eval step 0: eval loss: 0.8215796387233272
Eval: 2022-04-27 16:47:27.445314: total loss: 1.0648532468434864, mse:4.584797281144864, ic :0.19756030149985498, sharpe5:17.78738952755928, irr5:594.9166870117188, ndcg5:0.8643556165064732, pnl5:10.150952339172363 
train 26, step: 0, loss: 6.294330243485423, grad_norm: 22.404941959974806, ic: 0.2876816728574898
train 26, step: 500, loss: 3.957647041756255, grad_norm: 22.778566811686343, ic: 0.38370113937937367
train 26, step: 1000, loss: 1.2890953650841346, grad_norm: 1.6611557768787197, ic: 0.011493508408035601
train 26, step: 1500, loss: 0.8398170940098517, grad_norm: 0.46062203961330356, ic: 0.3047360748148854
train 26, step: 2000, loss: 0.9540728457231019, grad_norm: 0.9141970265962562, ic: 0.15294620052778546
Epoch 26: 2022-04-27 16:51:31.355458: train loss: 1.6149825835222018
Eval step 0: eval loss: 0.8217243479978925
Eval: 2022-04-27 16:51:43.889508: total loss: 1.0647245972748085, mse:4.589740679153754, ic :0.19428700413018624, sharpe5:17.259538385868073, irr5:574.7042236328125, ndcg5:0.8426196723847946, pnl5:6.5169501304626465 
train 27, step: 0, loss: 0.8228413181678921, grad_norm: 0.08395493692100628, ic: 0.1520355955229853
train 27, step: 500, loss: 0.9207198302273496, grad_norm: 12.21623184238878, ic: 0.2968651828025265
train 27, step: 1000, loss: 0.7587284521824247, grad_norm: 0.35010349153099524, ic: 0.16266609168843948
train 27, step: 1500, loss: 0.6376691450880713, grad_norm: 0.3782530218848083, ic: 0.5310397532384735
train 27, step: 2000, loss: 1.387818031629651, grad_norm: 0.11976569004891749, ic: -0.011747663124931168
Epoch 27: 2022-04-27 16:55:48.932119: train loss: 1.6120000418254559
Eval step 0: eval loss: 0.8260359125971417
Eval: 2022-04-27 16:56:01.754209: total loss: 1.068334437337327, mse:4.607000091842674, ic :0.18531725689307554, sharpe5:16.46702668905258, irr5:554.0564575195312, ndcg5:0.8471370146908772, pnl5:4.144062519073486 
train 28, step: 0, loss: 1.5612809936052123, grad_norm: 2.9034955173582775, ic: 0.2310254039288403
train 28, step: 500, loss: 1.4072859259275434, grad_norm: 8.064646373506008, ic: 0.15799001447150507
train 28, step: 1000, loss: 0.9185829059218327, grad_norm: 0.348134442076919, ic: 0.5891137807870277
train 28, step: 1500, loss: 1.0336683580091783, grad_norm: 0.03731518232057079, ic: 0.013257938644337025
train 28, step: 2000, loss: 1.0528356634034701, grad_norm: 1.2901711394122497, ic: 0.08282849295989594
Epoch 28: 2022-04-27 17:00:06.610241: train loss: 1.6115611458362222
Eval step 0: eval loss: 0.8223859588012051
Eval: 2022-04-27 17:00:18.677753: total loss: 1.0850302401703447, mse:4.736387791928453, ic :0.17871426703695578, sharpe5:17.606804741621016, irr5:584.0186157226562, ndcg5:0.8360794114764016, pnl5:6.582754135131836 
train 29, step: 0, loss: 0.9044404163606425, grad_norm: 0.08804689554694618, ic: 0.11914266515249466
train 29, step: 500, loss: 1.0983622937922048, grad_norm: 0.2661538229853237, ic: 0.6204688895093711
train 29, step: 1000, loss: 1.0658460194023407, grad_norm: 2.1536715742806445, ic: 0.010868515053088734
train 29, step: 1500, loss: 2.455565834492096, grad_norm: 8.634779578457158, ic: 0.004152464802374165
train 29, step: 2000, loss: 3.092847094123746, grad_norm: 53.663970302759765, ic: 0.23743973477529937
Epoch 29: 2022-04-27 17:04:21.528795: train loss: 1.6121972987520952
Eval step 0: eval loss: 0.8231329159188948
Eval: 2022-04-27 17:04:34.423318: total loss: 1.064462818972578, mse:4.587578920775531, ic :0.1975400124504862, sharpe5:17.988086585998534, irr5:603.1229858398438, ndcg5:0.8387615986824625, pnl5:4.784478187561035 
train 30, step: 0, loss: 1.0200103357462336, grad_norm: 0.3437710814444665, ic: 0.5104414171472096
train 30, step: 500, loss: 1.442571075164069, grad_norm: 2.3629315246269753, ic: 0.054041955649079675
train 30, step: 1000, loss: 0.9808956261837121, grad_norm: 0.12155888789726849, ic: -0.03570997146989854
train 30, step: 1500, loss: 1.494173316567354, grad_norm: 14.941461401096305, ic: 0.14118461848448274
train 30, step: 2000, loss: 1.8433855636118017, grad_norm: 0.8105089274778636, ic: 0.046551888792075564
Epoch 30: 2022-04-27 17:08:40.847841: train loss: 1.6129689544903876
Eval step 0: eval loss: 0.8253227209768506
Eval: 2022-04-27 17:08:53.568783: total loss: 1.0648820634396758, mse:4.580450694952518, ic :0.19736950300099168, sharpe5:18.22741146683693, irr5:598.4630126953125, ndcg5:0.8567515236595429, pnl5:7.029886245727539 
train 31, step: 0, loss: 1.03201163244604, grad_norm: 0.610284068074389, ic: 0.3750034243893302
train 31, step: 500, loss: 1.5063610186792695, grad_norm: 1.3955701643939447, ic: 0.04199344981029804
train 31, step: 1000, loss: 4.517009416471507, grad_norm: 44.72691165606051, ic: 0.4853919533862648
train 31, step: 1500, loss: 0.7648095182985187, grad_norm: 0.042276632763547095, ic: 0.7158877096892926
train 31, step: 2000, loss: 1.2486345934650456, grad_norm: 3.9313065358492443, ic: 0.21880501653674606
Epoch 31: 2022-04-27 17:13:01.526063: train loss: 1.6116515915014478
Eval step 0: eval loss: 0.8219700321884879
Eval: 2022-04-27 17:13:13.996467: total loss: 1.064968921479209, mse:4.6041653030092204, ic :0.19399052044365242, sharpe5:17.66511727809906, irr5:585.6948852539062, ndcg5:0.8504688921741967, pnl5:4.914366722106934 
train 32, step: 0, loss: 1.1285880870031177, grad_norm: 0.2880126452736047, ic: 0.18913880098057995
train 32, step: 500, loss: 1.510441529281496, grad_norm: 7.048095285525091, ic: 0.048381925215780205
train 32, step: 1000, loss: 1.0409244872141532, grad_norm: 0.3208267558350558, ic: 0.5130755945496548
train 32, step: 1500, loss: 0.9576208375047675, grad_norm: 5.062612529048554, ic: 0.06975404568569721
train 32, step: 2000, loss: 0.9391419624267427, grad_norm: 0.07803386542517769, ic: 0.562332699137873
Epoch 32: 2022-04-27 17:17:18.601675: train loss: 1.6092720224941226
Eval step 0: eval loss: 0.8198828742426237
Eval: 2022-04-27 17:17:31.209645: total loss: 1.0653762757078462, mse:4.603292246985283, ic :0.1968965714730825, sharpe5:17.479363954067228, irr5:586.3888549804688, ndcg5:0.8563564431358982, pnl5:6.544717311859131 
train 33, step: 0, loss: 1.272756577911267, grad_norm: 1.5744845477085674, ic: 0.19629197144823285
train 33, step: 500, loss: 0.9899489225732907, grad_norm: 0.04872171972835116, ic: 0.1521487114496909
train 33, step: 1000, loss: 1.033924294949089, grad_norm: 17.591988929900246, ic: 0.1944599436156746
train 33, step: 1500, loss: 0.887246635319358, grad_norm: 0.22111865527722185, ic: 0.5530148888162347
train 33, step: 2000, loss: 0.8110808600714392, grad_norm: 0.10525968053923346, ic: 0.24794821603963954
Epoch 33: 2022-04-27 17:21:34.748506: train loss: 1.6098449095476142
Eval step 0: eval loss: 0.8230097522474314
Eval: 2022-04-27 17:21:47.140639: total loss: 1.0642038259614055, mse:4.572824240173384, ic :0.20148803990437378, sharpe5:18.01645111441612, irr5:598.8056640625, ndcg5:0.8468713970650846, pnl5:7.510950565338135 
train 34, step: 0, loss: 1.0053603352977531, grad_norm: 8.392437226334321, ic: 0.6064854426086767
train 34, step: 500, loss: 0.7912986825365539, grad_norm: 1.2877501182837625, ic: 0.3038795337769267
train 34, step: 1000, loss: 3.1327931862639207, grad_norm: 29.15233343595426, ic: 0.3667136193428632
train 34, step: 1500, loss: 0.8186460001676102, grad_norm: 3.0543363304922018, ic: 0.6987793900709817
train 34, step: 2000, loss: 3.9211178047540667, grad_norm: 71.06077570532109, ic: 0.4519420654426656
Epoch 34: 2022-04-27 17:25:49.035564: train loss: 1.605877023906134
Eval step 0: eval loss: 0.8197244015081664
Eval: 2022-04-27 17:26:01.395358: total loss: 1.0653327682174019, mse:4.604012660078041, ic :0.1987928206510286, sharpe5:17.557902274131774, irr5:586.5678100585938, ndcg5:0.8657610392321643, pnl5:5.982486248016357 
train 35, step: 0, loss: 1.1613202263327205, grad_norm: 1.0406724815141875, ic: 0.5549624196719506
train 35, step: 500, loss: 1.1892717662446342, grad_norm: 1.7733659927256222, ic: 0.037741139402941506
train 35, step: 1000, loss: 1.8147229237161624, grad_norm: 41.94733915269111, ic: 0.04514004411482318
train 35, step: 1500, loss: 1.6185495476973686, grad_norm: 2.7041156524333596, ic: 0.011428660363672502
train 35, step: 2000, loss: 0.7954149705203458, grad_norm: 0.5323255276283498, ic: 0.555822867023111
Epoch 35: 2022-04-27 17:30:12.284803: train loss: 1.6102924716169391
Eval step 0: eval loss: 0.823737414795179
Eval: 2022-04-27 17:30:26.160670: total loss: 1.0651770910706075, mse:4.583120410943593, ic :0.19709576001895068, sharpe5:17.308376530408857, irr5:582.3422241210938, ndcg5:0.8635850998140103, pnl5:6.3337273597717285 
train 36, step: 0, loss: 1.84560788332761, grad_norm: 4.130206589995716, ic: 0.13301465971172655
train 36, step: 500, loss: 0.8329379755836289, grad_norm: 0.0811437809899007, ic: 0.21510995850518505
train 36, step: 1000, loss: 1.8076667258522727, grad_norm: 114.09313718692532, ic: 0.2469692863084072
train 36, step: 1500, loss: 0.7660576000548245, grad_norm: 0.2922439202813739, ic: 0.3896131942689715
train 36, step: 2000, loss: 1.1312528311780181, grad_norm: 3.656757350300068, ic: 0.7712168477421578
Epoch 36: 2022-04-27 17:34:44.898437: train loss: 1.6085071141238627
Eval step 0: eval loss: 0.8247795145177489
Eval: 2022-04-27 17:34:57.840949: total loss: 1.0648263688235307, mse:4.589000187390016, ic :0.1944727000647338, sharpe5:17.49130153656006, irr5:585.2354736328125, ndcg5:0.8417574124383739, pnl5:6.708866119384766 
train 37, step: 0, loss: 1.9874718097961332, grad_norm: 13.682893061583787, ic: 0.18626774820073705
train 37, step: 500, loss: 2.3617044918688825, grad_norm: 19.603198585740422, ic: -0.07389235769603616
train 37, step: 1000, loss: 1.0657150756278537, grad_norm: 0.5171267249471433, ic: 0.07944258137144827
train 37, step: 1500, loss: 2.016431392268446, grad_norm: 10.822353756659341, ic: 0.6098298146869062
train 37, step: 2000, loss: 1.3064819538712107, grad_norm: 1.2826283110277643, ic: 0.21928036600003495
Epoch 37: 2022-04-27 17:39:06.702007: train loss: 1.6022131836832065
Eval step 0: eval loss: 0.8236400415322049
Eval: 2022-04-27 17:39:19.424062: total loss: 1.0668462469618072, mse:4.604631001756765, ic :0.19306717048761174, sharpe5:17.031672449111937, irr5:572.3652954101562, ndcg5:0.8534107787271091, pnl5:4.385385513305664 
train 38, step: 0, loss: 1.3124642721036586, grad_norm: 1.4958052548269483, ic: -0.07125614372330048
train 38, step: 500, loss: 0.9009690272955246, grad_norm: 0.09537266775521429, ic: 0.26815716276315943
train 38, step: 1000, loss: 0.9081728245429842, grad_norm: 0.33743137351239505, ic: 0.19443375456284379
train 38, step: 1500, loss: 0.9555049539970103, grad_norm: 0.12717565852043017, ic: 0.20727392009382
train 38, step: 2000, loss: 2.307578464289086, grad_norm: 15.189837679579753, ic: 0.006745586875053856
Epoch 38: 2022-04-27 17:43:23.526627: train loss: 1.6065012161163097
Eval step 0: eval loss: 0.8217271135529175
Eval: 2022-04-27 17:43:36.111834: total loss: 1.0639262573208526, mse:4.592059586322126, ic :0.20006514559567673, sharpe5:18.049768509864805, irr5:607.5084228515625, ndcg5:0.8479494526388681, pnl5:4.261806011199951 
train 39, step: 0, loss: 0.970306489810302, grad_norm: 0.057277580187579294, ic: 0.05310936965162269
train 39, step: 500, loss: 0.8785936148875865, grad_norm: 0.670243144759259, ic: 0.24380051507321585
train 39, step: 1000, loss: 0.9371548933739527, grad_norm: 0.38268246127444955, ic: 0.19610781532642635
train 39, step: 1500, loss: 2.082832928882726, grad_norm: 6.6624598856683175, ic: 0.2396825380028747
train 39, step: 2000, loss: 0.6132579640754591, grad_norm: 0.060737622733123865, ic: 0.0923485005482861
Epoch 39: 2022-04-27 17:47:43.028304: train loss: 1.6041585063484811
Eval step 0: eval loss: 0.8240483146321785
Eval: 2022-04-27 17:47:56.051723: total loss: 1.0646977150826107, mse:4.585269703377095, ic :0.19717971092201889, sharpe5:17.871792587041853, irr5:596.5994873046875, ndcg5:0.857414673098887, pnl5:4.90716028213501 
train 40, step: 0, loss: 0.8768123515168129, grad_norm: 0.05223154288707313, ic: 0.2422706378619416
train 40, step: 500, loss: 1.09183236236184, grad_norm: 0.08481458108186683, ic: 0.4723721840278455
train 40, step: 1000, loss: 1.3248981754954268, grad_norm: 2.2745656630560624, ic: 0.12575958964016665
train 40, step: 1500, loss: 2.6058600989754943, grad_norm: 7.448984033514668, ic: 0.08314164324331462
train 40, step: 2000, loss: 1.0366589105210706, grad_norm: 9.003762868823891, ic: 0.12558484964184824
Epoch 40: 2022-04-27 17:52:00.098757: train loss: 1.6073703280846618
Eval step 0: eval loss: 0.8238692610231164
Eval: 2022-04-27 17:52:12.284810: total loss: 1.063781182847085, mse:4.577610554171419, ic :0.2015005599518412, sharpe5:17.25169666171074, irr5:601.0557250976562, ndcg5:0.8424218554169531, pnl5:4.376595973968506 
train 41, step: 0, loss: 1.6152326912715518, grad_norm: 0.4721077034990262, ic: 0.41054265935541023
train 41, step: 500, loss: 1.2017503937636962, grad_norm: 20.485409800681932, ic: 0.2598977616791658
train 41, step: 1000, loss: 1.0849206822519084, grad_norm: 4.42908896812675, ic: 0.11846255428613348
train 41, step: 1500, loss: 3.213900957968877, grad_norm: 26.048803729304144, ic: 0.04355791557648423
train 41, step: 2000, loss: 1.0330503990207862, grad_norm: 0.5390630300746226, ic: 0.09769748031841272
Epoch 41: 2022-04-27 17:56:16.336667: train loss: 1.6039347799092665
Eval step 0: eval loss: 0.8270209647079162
Eval: 2022-04-27 17:56:28.985455: total loss: 1.0655934600989534, mse:4.597750869752181, ic :0.19401582573206486, sharpe5:18.1088964343071, irr5:608.3609619140625, ndcg5:0.8500897643799054, pnl5:5.099266529083252 
train 42, step: 0, loss: 2.1833666337404214, grad_norm: 13.2764499842012, ic: 0.0768961616139409
train 42, step: 500, loss: 1.4615552121060102, grad_norm: 11.994144814683198, ic: 0.18527374542444264
train 42, step: 1000, loss: 3.282036717534992, grad_norm: 75.15572388148527, ic: 0.058088130131605256
train 42, step: 1500, loss: 1.2007885415127562, grad_norm: 0.042594032430838716, ic: 0.5663296476887484
train 42, step: 2000, loss: 1.1820636374412934, grad_norm: 0.10430188140899883, ic: 0.47862324976275183
Epoch 42: 2022-04-27 18:00:40.092772: train loss: 1.6106123926829148
Eval step 0: eval loss: 0.8234216913156941
Eval: 2022-04-27 18:00:54.004762: total loss: 1.0637477659569157, mse:4.573144326072265, ic :0.20087563287750893, sharpe5:17.50876521706581, irr5:605.135986328125, ndcg5:0.8670782985076376, pnl5:4.18843412399292 
train 43, step: 0, loss: 0.8272147842600376, grad_norm: 1.9875286648624826, ic: 0.062155213114982386
train 43, step: 500, loss: 0.9462500651552689, grad_norm: 6.982593880430262, ic: 0.27262155257189374
train 43, step: 1000, loss: 1.6862144953904268, grad_norm: 2.2828051354987435, ic: -0.12236057770403633
train 43, step: 1500, loss: 1.3942423153332886, grad_norm: 0.12578310497658401, ic: 0.12681326078799846
train 43, step: 2000, loss: 1.6866528128075786, grad_norm: 1.4632959822135994, ic: -0.07596248711329685
Epoch 43: 2022-04-27 18:05:18.487663: train loss: 1.5984955747662335
Eval step 0: eval loss: 0.822081168911354
Eval: 2022-04-27 18:05:32.791471: total loss: 1.0647243779839164, mse:4.604007653859088, ic :0.19750622537843524, sharpe5:17.158515411615372, irr5:589.7766723632812, ndcg5:0.8364222868988219, pnl5:3.397791862487793 
train 44, step: 0, loss: 1.0385279898407793, grad_norm: 0.2614386964291339, ic: 0.06066491354849417
train 44, step: 500, loss: 2.082795507965927, grad_norm: 7.795919511641592, ic: 0.10295182152131682
train 44, step: 1000, loss: 1.8082649101645258, grad_norm: 6.825258867632612, ic: 0.13109536176304143
train 44, step: 1500, loss: 1.0324167934247792, grad_norm: 0.24332851652387705, ic: 0.15999241073643766
train 44, step: 2000, loss: 0.921327405098157, grad_norm: 0.7076164178609936, ic: 0.7035270974982333
Epoch 44: 2022-04-27 18:09:48.439054: train loss: 1.5983185946878762
Eval step 0: eval loss: 0.8190514069085879
Eval: 2022-04-27 18:10:00.587089: total loss: 1.0666220668551725, mse:4.615038984181708, ic :0.2010436493014514, sharpe5:18.763231086730958, irr5:641.16748046875, ndcg5:0.8402394748659069, pnl5:4.4116010665893555 
train 45, step: 0, loss: 1.6227074644619361, grad_norm: 5.421757806941362, ic: 0.030131958825628257
train 45, step: 500, loss: 0.9456408585869958, grad_norm: 0.3120506963991689, ic: 0.48989085426047996
train 45, step: 1000, loss: 1.5438567099593898, grad_norm: 2.6178548377470374, ic: 0.8906529864904497
train 45, step: 1500, loss: 1.0215678179936631, grad_norm: 12.387465836418803, ic: 0.15435308952904508
train 45, step: 2000, loss: 1.7076470588235293, grad_norm: 2.1784280450929088, ic: 0.4448097919727779
Epoch 45: 2022-04-27 18:14:04.021802: train loss: 1.5979691335895991
Eval step 0: eval loss: 0.8194333107629741
Eval: 2022-04-27 18:14:16.431241: total loss: 1.0652014964638368, mse:4.6051683975734505, ic :0.20232132809001627, sharpe5:18.486443763971327, irr5:640.136962890625, ndcg5:0.8364929670498892, pnl5:5.305051803588867 
train 46, step: 0, loss: 2.202445890199546, grad_norm: 3.7100350238827327, ic: 0.03467019470926578
train 46, step: 500, loss: 1.9604294270833333, grad_norm: 39.75717816062651, ic: 0.1327061234797764
train 46, step: 1000, loss: 0.8783811068498673, grad_norm: 3.4423147949437443, ic: 0.06277731946561033
train 46, step: 1500, loss: 1.2500955889301915, grad_norm: 3.7961674384560453, ic: 0.8970471850138889
train 46, step: 2000, loss: 2.719448139909814, grad_norm: 14.779350999709926, ic: 0.33758726303980313
Epoch 46: 2022-04-27 18:18:19.065181: train loss: 1.602804228137501
Eval step 0: eval loss: 0.8209691585303609
Eval: 2022-04-27 18:18:31.577314: total loss: 1.0651101476199638, mse:4.598868339204012, ic :0.20334098810418144, sharpe5:18.732098779678346, irr5:636.9358520507812, ndcg5:0.8598778187530188, pnl5:4.788971424102783 
train 47, step: 0, loss: 1.0664507872543865, grad_norm: 0.1268678172078021, ic: 0.2179481775836965
train 47, step: 500, loss: 1.5092842471281946, grad_norm: 2.1504249648239746, ic: 0.15549893083421973
norm clip needed:  tensor(48.6599, device='cuda:0') input_to_hidden.weight torch.Size([128, 9])
train 47, step: 1000, loss: 2.879318509149884, grad_norm: 2813.1222136783863, ic: 0.5257816535209646
train 47, step: 1500, loss: 1.6385680408012577, grad_norm: 14.283762231044614, ic: -0.004667134999532044
train 47, step: 2000, loss: 1.2907277634706815, grad_norm: 4.038591583465358, ic: 0.07402951740469976
Epoch 47: 2022-04-27 18:22:33.892594: train loss: 1.5960834576246754
Eval step 0: eval loss: 0.8217170160613145
Eval: 2022-04-27 18:22:46.142489: total loss: 1.0644027741600264, mse:4.600748108763795, ic :0.20059584905991146, sharpe5:17.447652740478514, irr5:602.9337158203125, ndcg5:0.8548164648509214, pnl5:5.620918273925781 
train 48, step: 0, loss: 1.0704830154718137, grad_norm: 3.5406661470734195, ic: 0.2008313716649746
train 48, step: 500, loss: 1.2825782345139696, grad_norm: 5.215237828019176, ic: 0.2300022480911082
train 48, step: 1000, loss: 1.5968490496469863, grad_norm: 13.422481216005664, ic: 0.14415435713250221
train 48, step: 1500, loss: 1.1142048628919987, grad_norm: 0.18127171785104856, ic: 0.521209882968013
train 48, step: 2000, loss: 2.393398743342589, grad_norm: 3.7209808858086877, ic: 0.5491941346186687
Epoch 48: 2022-04-27 18:26:55.122600: train loss: 1.5995990596517247
Eval step 0: eval loss: 0.8378131894592992
Eval: 2022-04-27 18:27:09.286229: total loss: 1.0712130429349331, mse:4.617091924424404, ic :0.19386178780293967, sharpe5:19.154392179250717, irr5:639.5817260742188, ndcg5:0.8644755877700205, pnl5:5.364974498748779 
train 49, step: 0, loss: 0.9114712889089525, grad_norm: 1.3857942234208105, ic: 0.10865643866083946
train 49, step: 500, loss: 1.5151452707985822, grad_norm: 0.22529968740959644, ic: -0.012296624933587613
train 49, step: 1000, loss: 1.7560997009277344, grad_norm: 0.8213552071050327, ic: 0.039865359113481894
train 49, step: 1500, loss: 1.588465716219996, grad_norm: 1.5886482796008876, ic: 0.4568703948108552
train 49, step: 2000, loss: 0.957692232067953, grad_norm: 2.017335149695338, ic: 0.6047760501096046
Epoch 49: 2022-04-27 18:31:27.083810: train loss: 1.5999292524410358
Eval step 0: eval loss: 0.8197794553477344
Eval: 2022-04-27 18:31:39.944595: total loss: 1.0689720431095868, mse:4.617338263633224, ic :0.20041200545358043, sharpe5:18.934118242263793, irr5:637.8742065429688, ndcg5:0.8627576621853721, pnl5:4.789053916931152 
train 50, step: 0, loss: 1.4181845195431957, grad_norm: 3.894116946265793, ic: 0.189589680890518
train 50, step: 500, loss: 2.8200673943922925, grad_norm: 2.8736137871693503, ic: 0.3120042602030863
train 50, step: 1000, loss: 0.8462453917529446, grad_norm: 0.12414441823488508, ic: 0.2016154273561493
train 50, step: 1500, loss: 1.4175679571725845, grad_norm: 2.922325037034759, ic: 0.38091786301748504
train 50, step: 2000, loss: 9.816932504418697, grad_norm: 235.41881810401622, ic: 0.13501025101939262
Epoch 50: 2022-04-27 18:35:44.356500: train loss: 1.5950678143426635
Eval step 0: eval loss: 0.8206189620859128
Eval: 2022-04-27 18:35:57.299191: total loss: 1.0664201775674664, mse:4.617365824101866, ic :0.1993074659276059, sharpe5:18.794369069337844, irr5:632.6907348632812, ndcg5:0.8503880574571155, pnl5:6.572267532348633 
train 51, step: 0, loss: 3.372193894831234, grad_norm: 18.995823718010143, ic: -0.0038936863908174647
train 51, step: 500, loss: 1.4534758941302282, grad_norm: 3.843813727793214, ic: 0.08342141660946639
train 51, step: 1000, loss: 1.5014660044819732, grad_norm: 1.2121332155161013, ic: 0.9148473972726151
train 51, step: 1500, loss: 1.0227638562770456, grad_norm: 0.48687873253024544, ic: 0.19941212743579417
train 51, step: 2000, loss: 2.3461186705783192, grad_norm: 0.09994168359203563, ic: 0.17710552382359218
Epoch 51: 2022-04-27 18:40:01.068439: train loss: 1.5943769267272416
Eval step 0: eval loss: 0.819223514472471
Eval: 2022-04-27 18:40:13.362525: total loss: 1.0676918324865674, mse:4.624039380238824, ic :0.2037187154363056, sharpe5:19.208601289987563, irr5:645.951904296875, ndcg5:0.8558449045440363, pnl5:3.3806979656219482 
train 52, step: 0, loss: 1.1812967849990068, grad_norm: 3.048095381221877, ic: 0.13044050662328766
train 52, step: 500, loss: 1.7059958699430549, grad_norm: 5.53592167615246, ic: 0.1987786285026808
train 52, step: 1000, loss: 1.1806075822061566, grad_norm: 1.5057922345148385, ic: 0.5931792239992638
train 52, step: 1500, loss: 1.0435711384185533, grad_norm: 0.8137517292844395, ic: -0.05491438945701133
train 52, step: 2000, loss: 1.388767045319624, grad_norm: 4.191146959578624, ic: 0.15352918153101702
Epoch 52: 2022-04-27 18:44:15.753002: train loss: 1.602909845795945
Eval step 0: eval loss: 0.8203743712542808
Eval: 2022-04-27 18:44:28.282628: total loss: 1.0661519786699032, mse:4.592411042731142, ic :0.2025628366835768, sharpe5:17.344747374057768, irr5:595.4620971679688, ndcg5:0.8477435217091775, pnl5:4.711721897125244 
train 53, step: 0, loss: 2.9574000243256697, grad_norm: 45.099717700295116, ic: 0.15878178293588185
train 53, step: 500, loss: 1.0518649611100883, grad_norm: 0.09487479046692249, ic: 0.5078969469464856
train 53, step: 1000, loss: 1.2515911032272546, grad_norm: 0.4805067757003477, ic: 0.17363832060443868
train 53, step: 1500, loss: 1.3462236390260474, grad_norm: 3.177191434508898, ic: 0.1512904595395818
train 53, step: 2000, loss: 3.0764567377434107, grad_norm: 79.64004413238818, ic: 0.2549676736674236
Epoch 53: 2022-04-27 18:48:33.151007: train loss: 1.5979346455233003
Eval step 0: eval loss: 0.820219371542413
Eval: 2022-04-27 18:48:45.879169: total loss: 1.0653958760206113, mse:4.597234213280967, ic :0.20141104988018116, sharpe5:18.308929452896116, irr5:626.3582153320312, ndcg5:0.8452852270599585, pnl5:4.300989151000977 
train 54, step: 0, loss: 1.9939910404265873, grad_norm: 30.55425665653915, ic: 0.08715517272803228
train 54, step: 500, loss: 0.8555774249861725, grad_norm: 0.05285403804563572, ic: 0.5351718865538607
train 54, step: 1000, loss: 2.2464858257183344, grad_norm: 5.661542525863906, ic: 0.16958782452349358
train 54, step: 1500, loss: 1.758032264649961, grad_norm: 47.88837040316818, ic: 0.10555992972263284
train 54, step: 2000, loss: 2.154071392276423, grad_norm: 24.38170059488742, ic: 0.03643867528524667
Epoch 54: 2022-04-27 18:52:50.614372: train loss: 1.5920046215869739
Eval step 0: eval loss: 0.8211154113705216
Eval: 2022-04-27 18:53:03.377867: total loss: 1.0672195020068418, mse:4.6107555112287315, ic :0.1997150335163173, sharpe5:19.494236801862716, irr5:649.581787109375, ndcg5:0.8544046318873482, pnl5:5.901206970214844 
train 55, step: 0, loss: 1.8107779845712324, grad_norm: 2.0799016299844073, ic: 0.07926333785564897
train 55, step: 500, loss: 0.8724368737109935, grad_norm: 0.11399228423650637, ic: 0.35474698296700086
train 55, step: 1000, loss: 1.0233735488313427, grad_norm: 6.087822221520869, ic: 0.11122547244661272
train 55, step: 1500, loss: 1.0761907300682425, grad_norm: 0.22608788090608023, ic: 0.5612208332898652
train 55, step: 2000, loss: 2.257566489998086, grad_norm: 6.3707320377567855, ic: 0.018529531529690967
Epoch 55: 2022-04-27 18:57:07.017959: train loss: 1.5912970843683505
Eval step 0: eval loss: 0.8217556052011986
Eval: 2022-04-27 18:57:19.673629: total loss: 1.064743451254865, mse:4.594848479330883, ic :0.1970286240531374, sharpe5:18.89557366132736, irr5:642.413330078125, ndcg5:0.8568510027635806, pnl5:6.793993949890137 
train 56, step: 0, loss: 1.0101915236291394, grad_norm: 0.14025680373801339, ic: 0.10349046050422259
train 56, step: 500, loss: 0.9013478300718043, grad_norm: 1.1015795332217977, ic: 0.0738948708866588
train 56, step: 1000, loss: 4.90851367342387, grad_norm: 34.1229257771398, ic: 0.015844598723183504
train 56, step: 1500, loss: 1.1673374692370797, grad_norm: 1.5779108303178544, ic: 0.08652948353017786
train 56, step: 2000, loss: 0.9980662553692727, grad_norm: 3.9181288706722777, ic: 0.4460012751307968
Epoch 56: 2022-04-27 19:01:25.995645: train loss: 1.5977481573708214
Eval step 0: eval loss: 0.8228662006470626
Eval: 2022-04-27 19:01:38.396215: total loss: 1.0656105436946408, mse:4.591863386575341, ic :0.20064526440213337, sharpe5:18.09827936410904, irr5:620.4395751953125, ndcg5:0.8563732380971879, pnl5:5.452353477478027 
train 57, step: 0, loss: 1.0383453458321157, grad_norm: 0.08245986517920376, ic: 0.1358001543247149
train 57, step: 500, loss: 0.8688448177763717, grad_norm: 0.42524770688027963, ic: 0.5786018531178552
train 57, step: 1000, loss: 2.2302524388762954, grad_norm: 7.024945978875882, ic: 0.1325854809400563
train 57, step: 1500, loss: 1.1093413864356885, grad_norm: 4.982757825926511, ic: 0.1494491037214978
train 57, step: 2000, loss: 1.066612181624746, grad_norm: 31.143957918151763, ic: 0.6141962230564029
Epoch 57: 2022-04-27 19:05:41.261330: train loss: 1.595099676504591
Eval step 0: eval loss: 0.8222370690364857
Eval: 2022-04-27 19:05:53.932123: total loss: 1.0641529029803074, mse:4.593626750488951, ic :0.20259485455448403, sharpe5:18.772410349845885, irr5:643.6107177734375, ndcg5:0.8456688547897657, pnl5:3.5201191902160645 
train 58, step: 0, loss: 1.477223037086433, grad_norm: 6.343065012653974, ic: 0.21152034554538063
train 58, step: 500, loss: 1.5163926133164416, grad_norm: 32.90958501281537, ic: 0.1196686782924263
train 58, step: 1000, loss: 1.504163743622449, grad_norm: 4.533970553312238, ic: 0.10957396975289774
train 58, step: 1500, loss: 2.2361213217365012, grad_norm: 1.069268729629964, ic: 0.42552691589843344
train 58, step: 2000, loss: 0.8974263007132166, grad_norm: 1.5081222353218986, ic: 0.2849950150518439
Epoch 58: 2022-04-27 19:09:57.945921: train loss: 1.6008486437620713
Eval step 0: eval loss: 0.8217446716115647
Eval: 2022-04-27 19:10:10.859411: total loss: 1.0640993463633281, mse:4.6031480607061335, ic :0.2026245484686085, sharpe5:18.15632893323898, irr5:627.0281372070312, ndcg5:0.8574103468094956, pnl5:4.618034839630127 
train 59, step: 0, loss: 1.1789235098268935, grad_norm: 0.9773862035319132, ic: 2.0428455465933484e-05
train 59, step: 500, loss: 0.6902478394908875, grad_norm: 2.7327802674424575, ic: 0.15291069779992594
train 59, step: 1000, loss: 4.95479513064133, grad_norm: 58.90915062764774, ic: -0.06333228612611129
train 59, step: 1500, loss: 1.3532080156000799, grad_norm: 5.75676952030551, ic: 0.18453078361387837
train 59, step: 2000, loss: 0.9930076688878675, grad_norm: 0.5709167164529798, ic: 0.02006644127544522
Epoch 59: 2022-04-27 19:14:03.401036: train loss: 1.5965108601975928
Eval step 0: eval loss: 0.8201544131569415
Eval: 2022-04-27 19:14:14.031248: total loss: 1.0637842602504928, mse:4.582223878185868, ic :0.20666986507608354, sharpe5:19.141860555410386, irr5:650.460205078125, ndcg5:0.8539081041786688, pnl5:8.18313980102539 

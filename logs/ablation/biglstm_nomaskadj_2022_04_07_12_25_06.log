Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='AdjTimeDataset', dout=0.3, epochs=40, glstm_layers=1, gnn_layers=1, gpu=0, hidden_dim=128, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=1, mask_adj=False, mask_type='soft', model_type='BiGLSTM', normalize_adj=True, num_days=8, num_heads=1, print_inteval=500, relation_num=1, seed=10086, shuffle=True, side_info=False, sparse_adj_path=None, stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
61198
BiGLSTM(
  (input_to_hidden): Linear(in_features=9, out_features=128, bias=True)
  (forward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
  )
  (backward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
  )
  (fc0): ModuleList(
    (0): Linear(in_features=256, out_features=128, bias=True)
  )
  (w_out): Linear(in_features=128, out_features=1, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
)
train 0, step: 0, loss: 4.812983700034207, grad_norm: 4.553529075703324, ic: 0.03161013369248165
train 0, step: 500, loss: 0.8656210996373399, grad_norm: 0.025309315554284645, ic: 0.019100561092671813
train 0, step: 1000, loss: 1.9484636464429408, grad_norm: 0.4441113962105849, ic: -0.022537626908348096
train 0, step: 1500, loss: 0.9546164772727272, grad_norm: 0.05094970889249416, ic: 0.047459284835967216
train 0, step: 2000, loss: 1.0006854920356372, grad_norm: 0.13093434980440752, ic: 0.04447706327135963
Epoch 0: 2022-04-07 00:26:28.690876: train loss: 1.649155177047699
Eval step 0: eval loss: 0.8362233168960748
Eval: 2022-04-07 00:26:31.670341: total loss: 1.0792905387837242, mse:4.823188419731919, ic :0.0075883470532928255, sharpe5:8.038887237310409, irr5:224.7877197265625, ndcg5:0.8586708507654569, pnl5:2.997129201889038 
train 1, step: 0, loss: 2.7675060641381046, grad_norm: 0.74042542877392, ic: 0.04718838447484999
train 1, step: 500, loss: 1.7483269683665041, grad_norm: 0.6561214184054854, ic: 0.12393079751379023
train 1, step: 1000, loss: 0.8749449146015882, grad_norm: 0.14985422019299163, ic: 0.05924257978198689
train 1, step: 1500, loss: 1.7078377559267242, grad_norm: 0.17992642315544297, ic: -0.007119419924796387
train 1, step: 2000, loss: 2.172355859375, grad_norm: 0.8427582951200432, ic: -0.00403448075080561
Epoch 1: 2022-04-07 00:27:52.654069: train loss: 1.6468336163824069
Eval step 0: eval loss: 0.8363076984819546
Eval: 2022-04-07 00:27:55.572543: total loss: 1.0793132652142314, mse:4.823087689509577, ic :0.012042707515229858, sharpe5:8.199445829987525, irr5:229.79457092285156, ndcg5:0.8549134205217698, pnl5:2.574476718902588 
train 2, step: 0, loss: 2.1404479758522728, grad_norm: 0.0065041519203499565, ic: 0.09795168409513617
train 2, step: 500, loss: 3.289776964739828, grad_norm: 0.2555287994287478, ic: 0.0067913910416064795
train 2, step: 1000, loss: 2.0740181992337163, grad_norm: 2.353136593109977e-05, ic: 0.25135497289410014
train 2, step: 1500, loss: 1.4807273340589218, grad_norm: 0.051266147630836534, ic: -0.021672347649860826
train 2, step: 2000, loss: 3.2153635817307693, grad_norm: 0.728196893822819, ic: 0.1329540961480552
Epoch 2: 2022-04-07 00:29:14.120551: train loss: 1.646615739023926
Eval step 0: eval loss: 0.8366919176847338
Eval: 2022-04-07 00:29:17.062190: total loss: 1.0794310747988622, mse:4.8227480724637335, ic :0.020006356512510294, sharpe5:11.478310019373893, irr5:331.6448059082031, ndcg5:0.8678887681392493, pnl5:2.4929068088531494 
train 3, step: 0, loss: 1.5235389275279472, grad_norm: 0.49313961848140875, ic: -0.01200165698490866
train 3, step: 500, loss: 1.4938840574833594, grad_norm: 0.3248030778803756, ic: 0.04631262467859676
train 3, step: 1000, loss: 3.6866094559585494, grad_norm: 0.6791594906931289, ic: -0.02022943747109738
train 3, step: 1500, loss: 1.9602336477726066, grad_norm: 0.9524629067318287, ic: -0.01726592482026458
train 3, step: 2000, loss: 0.8989562658361486, grad_norm: 0.0042917058254164225, ic: -0.0009567063846174818
Epoch 3: 2022-04-07 00:30:34.522787: train loss: 1.648348487379886
Eval step 0: eval loss: 0.8338990930008561
Eval: 2022-04-07 00:30:37.467595: total loss: 1.0787518848836213, mse:4.825319881322713, ic :0.005157474287501512, sharpe5:7.317716311812401, irr5:205.2373809814453, ndcg5:0.860925556796113, pnl5:2.6437907218933105 
train 4, step: 0, loss: 1.4445085299744898, grad_norm: 0.06978468892387854, ic: 0.02856644964845278
train 4, step: 500, loss: 1.639294721948819, grad_norm: 0.5440851925652144, ic: -0.019817299975535593
train 4, step: 1000, loss: 2.9660666861185216, grad_norm: 0.7639528120988194, ic: -0.040657680669864464
train 4, step: 1500, loss: 2.154429967695148, grad_norm: 0.4528752881195873, ic: -0.029830813157628734
train 4, step: 2000, loss: 1.1021426662130638, grad_norm: 0.3815700282575026, ic: -0.018248089754481587
Epoch 4: 2022-04-07 00:31:54.350802: train loss: 1.6467638109318001
Eval step 0: eval loss: 0.9215550317151276
Eval: 2022-04-07 00:31:57.305489: total loss: 1.1324145440281472, mse:4.988556028571663, ic :0.01748087662594379, sharpe5:7.1605143365263935, irr5:202.06268310546875, ndcg5:0.8461225602587542, pnl5:2.5811567306518555 
train 5, step: 0, loss: 1.4762885381711408, grad_norm: 0.9751262181349956, ic: -0.0024386231914817237
train 5, step: 500, loss: 0.8905252914973235, grad_norm: 0.0071820133047761385, ic: 0.007282743365576569
train 5, step: 1000, loss: 0.9925886950730365, grad_norm: 0.15196098244887699, ic: 0.019332584625427335
train 5, step: 1500, loss: 1.5219249871386868, grad_norm: 0.1353533995875713, ic: 0.018661672574477497
train 5, step: 2000, loss: 1.116061960738109, grad_norm: 0.026498998516326935, ic: 0.014936313047220975
Epoch 5: 2022-04-07 00:33:12.629911: train loss: 1.6473717635854304
Eval step 0: eval loss: 0.8455666480752766
Eval: 2022-04-07 00:33:15.517394: total loss: 1.0832941904913151, mse:4.828390269369106, ic :-0.006666720491866634, sharpe5:0.029717157846316695, irr5:-0.7552408576011658, ndcg5:0.8440028783051327, pnl5:1.2514334917068481 
train 6, step: 0, loss: 1.356068296295604, grad_norm: 0.6218042548151133, ic: 0.006073237422865184
train 6, step: 500, loss: 1.0052407047102316, grad_norm: 0.03384540066000551, ic: 0.012890341036909187
train 6, step: 1000, loss: 1.1176464472433458, grad_norm: 0.056735588254705094, ic: -0.013321863525971468
train 6, step: 1500, loss: 1.5721683722882231, grad_norm: 0.6460317177004871, ic: -0.02345429947982733
train 6, step: 2000, loss: 0.8070532109281174, grad_norm: 0.03794557656966448, ic: 0.026131723843722136
Epoch 6: 2022-04-07 00:34:30.850016: train loss: 1.6473759020144185
Eval step 0: eval loss: 0.8372093980505795
Eval: 2022-04-07 00:34:33.742802: total loss: 1.0796048033318342, mse:4.82307432631555, ic :0.01536830696202466, sharpe5:11.796721857190132, irr5:406.9259033203125, ndcg5:0.8491834623353859, pnl5:3.31949782371521 
train 7, step: 0, loss: 0.9996427536010742, grad_norm: 0.04702883177340389, ic: -0.0007251652346846466
train 7, step: 500, loss: 0.6537098986037234, grad_norm: 0.0029983713392585216, ic: -0.007626151207916383
train 7, step: 1000, loss: 1.0370128715846345, grad_norm: 0.20516449479210314, ic: -0.008158116150831916
train 7, step: 1500, loss: 2.269757335209003, grad_norm: 0.6262900693835236, ic: -0.02457595527618904
train 7, step: 2000, loss: 0.9039911076017266, grad_norm: 0.032174011000214664, ic: -0.013260402573210484
Epoch 7: 2022-04-07 00:35:48.872656: train loss: 1.6464991811399816
Eval step 0: eval loss: 0.8348131410942439
Eval: 2022-04-07 00:35:51.757371: total loss: 1.077701071559233, mse:4.754235055547861, ic :0.125395024659914, sharpe5:11.651229969263076, irr5:402.4447326660156, ndcg5:0.8508405074102304, pnl5:3.4360222816467285 
train 8, step: 0, loss: 3.615109474071558, grad_norm: 1.0388784705673821, ic: 0.006009888535039642
train 8, step: 500, loss: 2.75021445787424, grad_norm: 0.8482002834839831, ic: -0.07058507969960771
train 8, step: 1000, loss: 3.0959147135416667, grad_norm: 1.0790853083620897, ic: -0.02710556167472041
train 8, step: 1500, loss: 0.7119215884132244, grad_norm: 0.031083338889227628, ic: 0.5397793794376057
train 8, step: 2000, loss: 1.054820550582545, grad_norm: 0.3210055048467755, ic: 0.6547204135294666
Epoch 8: 2022-04-07 00:37:09.732434: train loss: 1.638269362781845
Eval step 0: eval loss: 0.8285755925233799
Eval: 2022-04-07 00:37:12.929856: total loss: 1.0727311816709895, mse:4.647292021809167, ic :0.13648596194332613, sharpe5:11.498969982862471, irr5:399.32464599609375, ndcg5:0.8402357407876595, pnl5:3.6000192165374756 
train 9, step: 0, loss: 5.43222625099681, grad_norm: 0.7695297106787399, ic: 0.0004670911167768011
train 9, step: 500, loss: 1.3186060187756323, grad_norm: 0.8278334570857702, ic: 0.30213613548345053
train 9, step: 1000, loss: 0.9350169014265188, grad_norm: 0.009634902338960579, ic: -0.006422850986052617
train 9, step: 1500, loss: 1.0871375284770803, grad_norm: 0.012676324586890874, ic: 0.47761835467401703
train 9, step: 2000, loss: 1.083155468882057, grad_norm: 0.20234568935100591, ic: 0.24882627772106253
Epoch 9: 2022-04-07 00:38:29.807084: train loss: 1.6356155366494154
Eval step 0: eval loss: 0.830060245365187
Eval: 2022-04-07 00:38:32.823872: total loss: 1.0731526443527357, mse:4.637506594795754, ic :0.1356059417294338, sharpe5:11.37357996225357, irr5:399.095458984375, ndcg5:0.8377585925641572, pnl5:3.221991539001465 
train 10, step: 0, loss: 7.181363030703353, grad_norm: 0.9641308040972456, ic: 0.16943250062844586
train 10, step: 500, loss: 1.1389480183599883, grad_norm: 0.11899152402430731, ic: 0.011606554341449426
train 10, step: 1000, loss: 2.3920112094996164, grad_norm: 0.6775729913531797, ic: 0.0798961101573899
train 10, step: 1500, loss: 1.0927716540051746, grad_norm: 0.2154264949560508, ic: -0.03455535208390544
train 10, step: 2000, loss: 2.7894617329977205, grad_norm: 0.7532972996605916, ic: 0.4885711786043651
Epoch 10: 2022-04-07 00:39:48.750633: train loss: 1.6358206239839006
Eval step 0: eval loss: 0.8298075508141793
Eval: 2022-04-07 00:39:51.735199: total loss: 1.0717942451034774, mse:4.624134761497968, ic :0.14026824236182783, sharpe5:11.668912158608435, irr5:395.37744140625, ndcg5:0.8401641121902149, pnl5:3.3051671981811523 
train 11, step: 0, loss: 1.2655477737698184, grad_norm: 0.020914879005933158, ic: 0.12203637602914466
train 11, step: 500, loss: 0.6763579708102012, grad_norm: 0.05434002390284235, ic: 0.5874085547274251
train 11, step: 1000, loss: 0.9406997919672301, grad_norm: 0.12919960354340893, ic: 0.10374457488589417
train 11, step: 1500, loss: 1.0592259189538789, grad_norm: 0.060674183955617245, ic: 0.18432455353147884
train 11, step: 2000, loss: 0.7939769389316745, grad_norm: 0.0007945939438008503, ic: 0.041841428376205705
Epoch 11: 2022-04-07 00:41:05.898130: train loss: 1.6340242642749527
Eval step 0: eval loss: 0.8343454407188488
Eval: 2022-04-07 00:41:08.805858: total loss: 1.074342589813464, mse:4.627584617255223, ic :0.14044278346796682, sharpe5:11.771269834041595, irr5:401.8338623046875, ndcg5:0.8506697672008156, pnl5:3.365978240966797 
train 12, step: 0, loss: 1.002404769261678, grad_norm: 0.1514907016170085, ic: 0.285509137667186
train 12, step: 500, loss: 0.9497964095132064, grad_norm: 0.07151203429509574, ic: 0.023641005026365673
train 12, step: 1000, loss: 3.010407854796975, grad_norm: 0.19072890799722877, ic: 0.21482680433993523
train 12, step: 1500, loss: 0.9237838710253237, grad_norm: 0.18492626291725073, ic: 0.06181555818439637
train 12, step: 2000, loss: 0.8779134606306647, grad_norm: 0.008371381759001264, ic: -0.041306589380497485
Epoch 12: 2022-04-07 00:42:25.118418: train loss: 1.6345429735066306
Eval step 0: eval loss: 0.8271690183746048
Eval: 2022-04-07 00:42:27.980448: total loss: 1.0713468813625295, mse:4.629437969980254, ic :0.14161769493823634, sharpe5:11.71428821504116, irr5:403.8658142089844, ndcg5:0.8496886657305737, pnl5:3.742241382598877 
train 13, step: 0, loss: 2.0239118598204855, grad_norm: 1.5535577697460923, ic: 0.41745105504026553
train 13, step: 500, loss: 0.8427795993029502, grad_norm: 0.06597011712778311, ic: 0.5609618928366239
train 13, step: 1000, loss: 0.9636426272808305, grad_norm: 0.5042744265776091, ic: 0.5736657079776597
train 13, step: 1500, loss: 2.363500042691257, grad_norm: 0.21119876557456085, ic: 0.07934053749205242
train 13, step: 2000, loss: 1.4900126938089395, grad_norm: 0.01807807686049344, ic: 0.07266425552008815
Epoch 13: 2022-04-07 00:43:42.680381: train loss: 1.6337169656676296
Eval step 0: eval loss: 0.8265443888303476
Eval: 2022-04-07 00:43:45.582438: total loss: 1.0711561774915401, mse:4.627320081870529, ic :0.14174944709811865, sharpe5:11.6456849527359, irr5:393.0740661621094, ndcg5:0.8432489344540751, pnl5:4.0319623947143555 
train 14, step: 0, loss: 4.557143379485179, grad_norm: 1.3586701047805287, ic: 0.1697141550673576
train 14, step: 500, loss: 0.8279915439244075, grad_norm: 0.002119192504716046, ic: 0.023373961439274216
train 14, step: 1000, loss: 1.886132219295748, grad_norm: 0.16870580817170447, ic: 0.40684318216378335
train 14, step: 1500, loss: 1.1227964104812598, grad_norm: 0.061805563566640256, ic: 0.10387899745544883
train 14, step: 2000, loss: 1.1359829294156032, grad_norm: 0.1537992982145579, ic: 0.1383322933981779
Epoch 14: 2022-04-07 00:45:03.333226: train loss: 1.6316617029642813
Eval step 0: eval loss: 0.831752250518638
Eval: 2022-04-07 00:45:06.247411: total loss: 1.0709232294738409, mse:4.596415561952838, ic :0.17418292766469892, sharpe5:14.99026260137558, irr5:497.4225158691406, ndcg5:0.8340040141329832, pnl5:5.155937671661377 
train 15, step: 0, loss: 3.330805797057393, grad_norm: 0.47858651534622293, ic: 0.0835373118709009
train 15, step: 500, loss: 1.2614488355933084, grad_norm: 0.006825097679319453, ic: -0.048051682622644115
train 15, step: 1000, loss: 1.3268500103213923, grad_norm: 0.14246009608573051, ic: -0.03734205149952951
train 15, step: 1500, loss: 0.8559954785925197, grad_norm: 0.2141746437111668, ic: -0.03124681460493814
train 15, step: 2000, loss: 1.455576824489231, grad_norm: 0.6039201491262676, ic: -0.004197156936617303
Epoch 15: 2022-04-07 00:46:21.186581: train loss: 1.6279118386154026
Eval step 0: eval loss: 0.8352807128391727
Eval: 2022-04-07 00:46:24.184257: total loss: 1.0737461969090423, mse:4.608663497213468, ic :0.16880298903495566, sharpe5:14.159908200502395, irr5:469.32391357421875, ndcg5:0.8461725965813632, pnl5:4.592280387878418 
train 16, step: 0, loss: 0.6946328979395536, grad_norm: 0.22935389478210513, ic: 0.02325409484953263
train 16, step: 500, loss: 1.561580821532557, grad_norm: 0.24673060383175632, ic: 0.19058251882935406
train 16, step: 1000, loss: 0.8719071821732954, grad_norm: 0.002078122953763498, ic: 0.020587998914557384
train 16, step: 1500, loss: 0.8490248996503152, grad_norm: 0.224541708638672, ic: 0.16785128746109768
train 16, step: 2000, loss: 3.3730938483820188, grad_norm: 1.1861150929519284, ic: -0.004990035526466842
Epoch 16: 2022-04-07 00:47:40.415034: train loss: 1.6283063912521398
Eval step 0: eval loss: 0.8266614425546628
Eval: 2022-04-07 00:47:43.292092: total loss: 1.0688717330597857, mse:4.593448770319148, ic :0.1845607828531455, sharpe5:16.052315829992292, irr5:524.224853515625, ndcg5:0.8423561893164516, pnl5:2.7335352897644043 
train 17, step: 0, loss: 1.2742877828663792, grad_norm: 0.2760467202405067, ic: -0.08623080476021608
train 17, step: 500, loss: 1.779513756563347, grad_norm: 0.39959309316169644, ic: 0.13779951247251168
train 17, step: 1000, loss: 1.293141046485618, grad_norm: 0.11093020547386633, ic: 0.14165980830319247
train 17, step: 1500, loss: 4.521559715971712, grad_norm: 1.1274170254078026, ic: 0.2379468186448556
train 17, step: 2000, loss: 1.2601857333308473, grad_norm: 0.5429445249504405, ic: 0.029378604086044088
Epoch 17: 2022-04-07 00:48:57.870928: train loss: 1.6274368247957307
Eval step 0: eval loss: 0.8324793985445205
Eval: 2022-04-07 00:49:00.742918: total loss: 1.070298503993567, mse:4.590220179139932, ic :0.18345729389603352, sharpe5:16.365292378664016, irr5:526.86376953125, ndcg5:0.8316726591060917, pnl5:4.983283519744873 
train 18, step: 0, loss: 1.4254691111206728, grad_norm: 0.5686460888451454, ic: 0.026659082623736376
train 18, step: 500, loss: 1.4935062337633676, grad_norm: 0.6555943609691477, ic: -0.02315010713964083
train 18, step: 1000, loss: 0.6550086285316781, grad_norm: 0.03680284376267863, ic: 0.572734565349446
train 18, step: 1500, loss: 1.4406275393824224, grad_norm: 0.029812038186370956, ic: 0.09205120431839417
train 18, step: 2000, loss: 0.9114592728341462, grad_norm: 0.007492828169777975, ic: 0.014488741650898286
Epoch 18: 2022-04-07 00:50:15.236766: train loss: 1.6266007749288542
Eval step 0: eval loss: 0.8239710077219441
Eval: 2022-04-07 00:50:18.147223: total loss: 1.0671336534217521, mse:4.596649649706831, ic :0.1819909102814197, sharpe5:16.5821061193943, irr5:524.635986328125, ndcg5:0.8610306720765556, pnl5:4.9163947105407715 
train 19, step: 0, loss: 1.4706298828125, grad_norm: 0.6590541971537649, ic: -0.00269811863834743
train 19, step: 500, loss: 0.8708228358515986, grad_norm: 0.0634760113943891, ic: 0.24093498017436604
train 19, step: 1000, loss: 0.9602883120966211, grad_norm: 0.02988213232631536, ic: 0.19616942173668728
train 19, step: 1500, loss: 3.963091702169712, grad_norm: 0.7477267198058303, ic: 0.09301809522621793
train 19, step: 2000, loss: 1.0214371431790865, grad_norm: 0.08005946632157498, ic: 0.16562267512137516
Epoch 19: 2022-04-07 00:51:34.375348: train loss: 1.6259081657306917
Eval step 0: eval loss: 0.8309225840111301
Eval: 2022-04-07 00:51:37.251338: total loss: 1.0692105692230411, mse:4.592405367405969, ic :0.18418715889648107, sharpe5:16.47137605547905, irr5:528.6631469726562, ndcg5:0.8545869187961425, pnl5:3.7378346920013428 
train 20, step: 0, loss: 2.306440680583004, grad_norm: 0.71840225203415, ic: 0.050710377987237154
train 20, step: 500, loss: 3.1861420454545453, grad_norm: 0.4261181236334809, ic: 0.06651401415390039
train 20, step: 1000, loss: 0.9898864746093751, grad_norm: 0.04973277812646004, ic: 0.02232547086886772
train 20, step: 1500, loss: 1.9179565990500576, grad_norm: 0.7371777146923674, ic: 0.2247918917923063
train 20, step: 2000, loss: 1.051175937372553, grad_norm: 0.08674536199387957, ic: -0.020454116821766597
Epoch 20: 2022-04-07 00:52:50.567147: train loss: 1.626375889365364
Eval step 0: eval loss: 0.8289207080644099
Eval: 2022-04-07 00:52:53.463932: total loss: 1.0685832926345067, mse:4.602701752275356, ic :0.18536095497137484, sharpe5:16.344814978837967, irr5:538.2882080078125, ndcg5:0.8433546744740298, pnl5:4.8034892082214355 
train 21, step: 0, loss: 1.0176855766709574, grad_norm: 0.28927647261003236, ic: 0.05948970218116664
train 21, step: 500, loss: 0.7808496255790238, grad_norm: 0.006724829330461491, ic: 0.16810277121259287
train 21, step: 1000, loss: 0.9236243398565994, grad_norm: 0.3771776859548779, ic: 0.15401520782319733
train 21, step: 1500, loss: 0.996912825098992, grad_norm: 0.16519446690183573, ic: 0.30637407773079117
train 21, step: 2000, loss: 0.9386110020634344, grad_norm: 0.04352228998747475, ic: 0.08894708104946239
Epoch 21: 2022-04-07 00:54:10.167686: train loss: 1.6257898590840794
Eval step 0: eval loss: 0.8269987759524828
Eval: 2022-04-07 00:54:13.052578: total loss: 1.0691456212134163, mse:4.611754244426835, ic :0.18041459948114566, sharpe5:16.851343063116072, irr5:528.5113525390625, ndcg5:0.8431734521635642, pnl5:5.147975921630859 
train 22, step: 0, loss: 1.0544476697673906, grad_norm: 0.008755081776101153, ic: 0.13684584252916013
train 22, step: 500, loss: 3.239454514418191, grad_norm: 0.5324276154098564, ic: -0.08933104128904394
train 22, step: 1000, loss: 1.2046398008489885, grad_norm: 0.05944613619603462, ic: 0.4448130311859702
train 22, step: 1500, loss: 0.9761813191229424, grad_norm: 0.04958970136474914, ic: 0.09776004446099563
train 22, step: 2000, loss: 1.7761777155523668, grad_norm: 0.42997544508959723, ic: 0.15178929900502808
Epoch 22: 2022-04-07 00:55:28.300196: train loss: 1.6253767386763884
Eval step 0: eval loss: 0.8272101158085814
Eval: 2022-04-07 00:55:31.214565: total loss: 1.068113024139119, mse:4.603434407633905, ic :0.18357600217586523, sharpe5:16.602051908969877, irr5:539.3245239257812, ndcg5:0.8524861568275918, pnl5:4.951106548309326 
train 23, step: 0, loss: 0.9936347543677955, grad_norm: 0.04087618045069254, ic: 0.17842089552674467
train 23, step: 500, loss: 1.4272206065418958, grad_norm: 0.08548164974321154, ic: -0.01522149473729031
train 23, step: 1000, loss: 1.6727282714843752, grad_norm: 0.11365260716897307, ic: 0.25940030168752404
train 23, step: 1500, loss: 1.1139977455871066, grad_norm: 0.1605647679649084, ic: 0.08758751133360854
train 23, step: 2000, loss: 1.9368854196737875, grad_norm: 0.6501468386510426, ic: 0.44687500237779443
Epoch 23: 2022-04-07 00:56:49.103427: train loss: 1.625392534297267
Eval step 0: eval loss: 0.830500804712197
Eval: 2022-04-07 00:56:52.026987: total loss: 1.0701075002384786, mse:4.591141686887135, ic :0.18624611477844472, sharpe5:17.291469054222105, irr5:580.4859619140625, ndcg5:0.8511545490481264, pnl5:7.461805820465088 
train 24, step: 0, loss: 2.199632361553598, grad_norm: 0.03371800325305576, ic: 0.12212896162840772
train 24, step: 500, loss: 1.2338238311648833, grad_norm: 0.04994011160851161, ic: 0.19318168148747758
train 24, step: 1000, loss: 0.9057978205709825, grad_norm: 0.04865206847564511, ic: 0.5374646251589517
train 24, step: 1500, loss: 2.606058068837593, grad_norm: 0.5854492490903939, ic: 0.08563139718335125
train 24, step: 2000, loss: 0.9421925937245313, grad_norm: 0.059858664215220264, ic: 0.041011374839972935
Epoch 24: 2022-04-07 00:58:07.397714: train loss: 1.624465215551283
Eval step 0: eval loss: 0.8241203476932956
Eval: 2022-04-07 00:58:10.289964: total loss: 1.067791393787621, mse:4.600030944924184, ic :0.18435353488766493, sharpe5:17.387979962825774, irr5:575.6658935546875, ndcg5:0.8490845955826888, pnl5:9.676210403442383 
train 25, step: 0, loss: 0.8579723461254224, grad_norm: 0.09602724086702251, ic: 0.5987395992886049
train 25, step: 500, loss: 0.8712829405447508, grad_norm: 0.0022597148217385165, ic: 0.20024259539964617
train 25, step: 1000, loss: 2.0993379010377, grad_norm: 3.5008873929069315, ic: 0.2475397716032462
train 25, step: 1500, loss: 1.137573077004398, grad_norm: 0.30852786784000746, ic: 0.5463218496213567
train 25, step: 2000, loss: 1.04058698115458, grad_norm: 0.3957594808467977, ic: 0.590692116894261
Epoch 25: 2022-04-07 00:59:26.970449: train loss: 1.6240277631123456
Eval step 0: eval loss: 0.8249489851570732
Eval: 2022-04-07 00:59:29.800809: total loss: 1.0669175046968593, mse:4.590248724257766, ic :0.19033167641065785, sharpe5:17.76650537967682, irr5:582.2561645507812, ndcg5:0.8418576564933095, pnl5:10.028097152709961 
train 26, step: 0, loss: 6.660277930311501, grad_norm: 0.2753994457914584, ic: 0.12573784348602732
train 26, step: 500, loss: 3.8090033870455433, grad_norm: 0.6453583591849259, ic: 0.38748819123903505
train 26, step: 1000, loss: 1.2584920311273549, grad_norm: 0.9756066024545194, ic: 0.04944776153443334
train 26, step: 1500, loss: 0.8429584406634129, grad_norm: 0.13094631014035918, ic: 0.2770541365376231
train 26, step: 2000, loss: 0.9641708746189024, grad_norm: 0.09862526339047652, ic: 0.10228562413737721
Epoch 26: 2022-04-07 01:00:45.725372: train loss: 1.6246744300566085
Eval step 0: eval loss: 0.826635394885241
Eval: 2022-04-07 01:00:48.635175: total loss: 1.0674766055905966, mse:4.588695343954927, ic :0.18868982407585683, sharpe5:17.575161634683607, irr5:580.5769653320312, ndcg5:0.8556846316169006, pnl5:8.32259750366211 
train 27, step: 0, loss: 0.8234380744485293, grad_norm: 0.026943047552217197, ic: 0.14269592050376909
train 27, step: 500, loss: 0.8896031253961714, grad_norm: 1.2520650204382653, ic: 0.30710396172142373
train 27, step: 1000, loss: 0.7556558300705724, grad_norm: 0.6820431064588632, ic: 0.16589138258292485
train 27, step: 1500, loss: 0.6349982094583106, grad_norm: 0.03201228136439098, ic: 0.5183264091447518
train 27, step: 2000, loss: 1.3830651679361239, grad_norm: 0.0267136295402803, ic: 0.018095960453672018
Epoch 27: 2022-04-07 01:02:04.104091: train loss: 1.6239443711036754
Eval step 0: eval loss: 0.8302574358699947
Eval: 2022-04-07 01:02:06.957707: total loss: 1.0679633047213033, mse:4.60575914740529, ic :0.1864696371509659, sharpe5:16.854127868413926, irr5:567.5422973632812, ndcg5:0.859478779066573, pnl5:6.90340518951416 
train 28, step: 0, loss: 1.5215778836872587, grad_norm: 0.1365066649539769, ic: 0.22261602767857597
train 28, step: 500, loss: 1.377296887009153, grad_norm: 0.21854071597922292, ic: 0.18370065255411983
train 28, step: 1000, loss: 0.9050542733210535, grad_norm: 0.18283439544211005, ic: 0.5840237459538576
train 28, step: 1500, loss: 1.0355365933979215, grad_norm: 0.02020067712646038, ic: 0.023423175801475835
train 28, step: 2000, loss: 1.0458686688194978, grad_norm: 0.04279181972849812, ic: 0.008239502889506768
Epoch 28: 2022-04-07 01:03:23.158086: train loss: 1.6230808428787424
Eval step 0: eval loss: 0.8251620615244665
Eval: 2022-04-07 01:03:26.076219: total loss: 1.0693775418314153, mse:4.624865155488211, ic :0.17977058404140936, sharpe5:16.960432891845702, irr5:554.0857543945312, ndcg5:0.8501768533206564, pnl5:5.498576641082764 
train 29, step: 0, loss: 0.9061335750923996, grad_norm: 0.015620174484180658, ic: 0.07894647252002839
train 29, step: 500, loss: 1.1075613634486934, grad_norm: 0.24138311744216334, ic: 0.6187457471190471
train 29, step: 1000, loss: 1.0556475741078282, grad_norm: 0.2716975459426853, ic: 0.08984927793769465
train 29, step: 1500, loss: 2.3392620816256833, grad_norm: 0.20194454134057552, ic: -0.039853003432376216
train 29, step: 2000, loss: 4.461839463975694, grad_norm: 1.8693987218600183, ic: 0.22579168501699584
Epoch 29: 2022-04-07 01:04:40.453443: train loss: 1.6230869313574883
Eval step 0: eval loss: 0.8313864254725368
Eval: 2022-04-07 01:04:43.445748: total loss: 1.0679298512023607, mse:4.599482458839486, ic :0.19036251320855557, sharpe5:17.71770696401596, irr5:580.5287475585938, ndcg5:0.848790874426008, pnl5:5.737005710601807 
train 30, step: 0, loss: 1.0116855695572426, grad_norm: 0.049218624455188556, ic: 0.5106946337790531
train 30, step: 500, loss: 1.402734495167658, grad_norm: 1.096299299436396, ic: 0.03774788175088711
train 30, step: 1000, loss: 0.9722386215672348, grad_norm: 0.03161772405878273, ic: -0.029097751705969205
train 30, step: 1500, loss: 1.5190238768746651, grad_norm: 0.4945114201083325, ic: 0.18216029847688292
train 30, step: 2000, loss: 1.831708468821729, grad_norm: 0.17036022494643954, ic: 0.06901588610810233
Epoch 30: 2022-04-07 01:05:58.893278: train loss: 1.6231908981337149
Eval step 0: eval loss: 0.8295137588291951
Eval: 2022-04-07 01:06:01.856360: total loss: 1.0682613020407905, mse:4.598812972342712, ic :0.18969911339723938, sharpe5:17.617889099121093, irr5:587.6702880859375, ndcg5:0.8501208180126889, pnl5:4.502373218536377 
train 31, step: 0, loss: 1.0515795616289938, grad_norm: 0.054793621414889394, ic: 0.32299891271412556
train 31, step: 500, loss: 1.518188175154321, grad_norm: 0.4026735162519583, ic: 0.018086235194952806
train 31, step: 1000, loss: 4.2818484399395, grad_norm: 1.0952298647887457, ic: 0.4540384291538029
train 31, step: 1500, loss: 0.7700046585022055, grad_norm: 0.22581992459172828, ic: 0.7090854712156491
train 31, step: 2000, loss: 1.234238830380889, grad_norm: 0.43983694955685626, ic: 0.15106420011253102
Epoch 31: 2022-04-07 01:07:17.560793: train loss: 1.6225719573152821
Eval step 0: eval loss: 0.8328474103085484
Eval: 2022-04-07 01:07:20.490831: total loss: 1.0704091180238586, mse:4.602393058891251, ic :0.18204272851872377, sharpe5:17.298854842185975, irr5:561.1041259765625, ndcg5:0.8412623751803537, pnl5:7.5615739822387695 
train 32, step: 0, loss: 1.1329607350326383, grad_norm: 0.1813967789407835, ic: 0.18236223455712008
train 32, step: 500, loss: 1.4902493694635826, grad_norm: 0.41382251619614957, ic: 0.06338073174869252
train 32, step: 1000, loss: 1.0411087243607076, grad_norm: 0.20412334865593215, ic: 0.5197619094961508
train 32, step: 1500, loss: 1.0102911511966057, grad_norm: 0.5182666616854406, ic: 0.06876852913969372
train 32, step: 2000, loss: 0.9565958332530075, grad_norm: 0.1932740567529864, ic: 0.5419678509171255
Epoch 32: 2022-04-07 01:08:35.202756: train loss: 1.6235894255974677
Eval step 0: eval loss: 0.8254581688578437
Eval: 2022-04-07 01:08:38.202488: total loss: 1.0669250159775299, mse:4.594722950626508, ic :0.18703598773347813, sharpe5:16.84810799717903, irr5:556.8536376953125, ndcg5:0.8425121702196117, pnl5:5.3437395095825195 
train 33, step: 0, loss: 1.2675048300823433, grad_norm: 0.1674092530256034, ic: 0.21632789781764544
train 33, step: 500, loss: 1.0023855467257925, grad_norm: 0.01004040213848316, ic: 0.06831500293253148
train 33, step: 1000, loss: 1.0528569686578912, grad_norm: 1.784197793756104, ic: 0.19166520878531548
train 33, step: 1500, loss: 0.8903213446674823, grad_norm: 0.04751037510709845, ic: 0.5561725136134521
train 33, step: 2000, loss: 0.8168993676332211, grad_norm: 0.029240951472663656, ic: 0.24332554310821455
Epoch 33: 2022-04-07 01:09:54.606955: train loss: 1.622852857165478
Eval step 0: eval loss: 0.8261195224002239
Eval: 2022-04-07 01:09:57.664172: total loss: 1.0667598285178037, mse:4.594513937917792, ic :0.19265078357102589, sharpe5:18.127143341302872, irr5:611.1802368164062, ndcg5:0.8536830630550364, pnl5:20.650951385498047 
train 34, step: 0, loss: 1.0181153699145558, grad_norm: 0.34191912056196155, ic: 0.6048628602633868
train 34, step: 500, loss: 0.8077538166571101, grad_norm: 0.1628242551249461, ic: 0.19718541437317047
train 34, step: 1000, loss: 3.226999777985791, grad_norm: 0.8854737279554372, ic: 0.24653412683107756
train 34, step: 1500, loss: 0.7847120537377086, grad_norm: 0.6138725774707142, ic: 0.6892845065057808
train 34, step: 2000, loss: 6.728320463787762, grad_norm: 5.050781700240007, ic: 0.4587200364562017
Epoch 34: 2022-04-07 01:11:13.615145: train loss: 1.623305087825271
Eval step 0: eval loss: 0.8221030360906216
Eval: 2022-04-07 01:11:16.477012: total loss: 1.0663032502639571, mse:4.5999622325705225, ic :0.18947711979841575, sharpe5:17.691385635137557, irr5:580.0712280273438, ndcg5:0.8406685322302442, pnl5:6.476655960083008 
train 35, step: 0, loss: 1.2235756548713235, grad_norm: 0.6614538876763657, ic: 0.5522088662469783
train 35, step: 500, loss: 1.185630018557083, grad_norm: 0.4126776582124272, ic: 0.129141029648458
train 35, step: 1000, loss: 1.8710086117884155, grad_norm: 1.1843621576524483, ic: 0.0339602177445843
train 35, step: 1500, loss: 1.648628039826128, grad_norm: 0.8967113703320606, ic: 0.03432222129970601
train 35, step: 2000, loss: 0.7825997908485126, grad_norm: 0.04925377909897246, ic: 0.5615378472253919
Epoch 35: 2022-04-07 01:12:32.390231: train loss: 1.6231755235409473
Eval step 0: eval loss: 0.8290360252774301
Eval: 2022-04-07 01:12:35.347003: total loss: 1.0675421760919013, mse:4.586327076826894, ic :0.18965124889883386, sharpe5:17.684626049995423, irr5:581.4896240234375, ndcg5:0.8391733274870367, pnl5:4.6789374351501465 
train 36, step: 0, loss: 1.8152675658604789, grad_norm: 0.6058554712152937, ic: 0.12398292718456058
train 36, step: 500, loss: 0.8409044823372243, grad_norm: 0.009377078281108574, ic: 0.1444004217312857
train 36, step: 1000, loss: 1.7286649502840907, grad_norm: 5.618565837907452, ic: 0.197917941964649
train 36, step: 1500, loss: 0.7651019774914717, grad_norm: 0.03421855988677166, ic: 0.3839484624042962
train 36, step: 2000, loss: 1.1392840687673749, grad_norm: 0.37606687371409975, ic: 0.7716117519589165
Epoch 36: 2022-04-07 01:13:52.302271: train loss: 1.6227156322243927
Eval step 0: eval loss: 0.8268976080907534
Eval: 2022-04-07 01:13:55.203213: total loss: 1.0666151945732623, mse:4.602045926355464, ic :0.18773708311528842, sharpe5:18.063465514183044, irr5:597.00048828125, ndcg5:0.8407843466799327, pnl5:4.1939263343811035 
train 37, step: 0, loss: 2.034864066388304, grad_norm: 0.847777824930522, ic: 0.19229183721181298
train 37, step: 500, loss: 2.3313265080164154, grad_norm: 0.5137404370780108, ic: -0.033372168284985994
train 37, step: 1000, loss: 1.0715333889245624, grad_norm: 0.098844271114329, ic: 0.06433584816894411
train 37, step: 1500, loss: 2.024967307385695, grad_norm: 0.6966965416288123, ic: 0.6122887799920373
train 37, step: 2000, loss: 1.3170751020361815, grad_norm: 0.06892481537722635, ic: 0.20580164551124955
Epoch 37: 2022-04-07 01:15:11.170815: train loss: 1.622155654561597
Eval step 0: eval loss: 0.8244764611391925
Eval: 2022-04-07 01:15:14.125223: total loss: 1.0669807912529174, mse:4.599793833652304, ic :0.18558364184226633, sharpe5:18.228230638504026, irr5:589.3101196289062, ndcg5:0.8379006834111572, pnl5:5.764434814453125 
train 38, step: 0, loss: 1.3354139560606422, grad_norm: 0.260261377713109, ic: -0.08340153004592991
train 38, step: 500, loss: 0.9150690526138117, grad_norm: 0.10084342411171952, ic: 0.258343935456945
train 38, step: 1000, loss: 0.8996608085783102, grad_norm: 0.11288958574093502, ic: 0.15846345317505872
train 38, step: 1500, loss: 0.9539662377799925, grad_norm: 0.008707189308302365, ic: 0.2014117240989009
train 38, step: 2000, loss: 2.314272785474887, grad_norm: 1.1366815607879706, ic: 0.005372329541981817
Epoch 38: 2022-04-07 01:16:28.080416: train loss: 1.622266514903197
Eval step 0: eval loss: 0.8226707466535498
Eval: 2022-04-07 01:16:31.028568: total loss: 1.0655638698455052, mse:4.604579817024907, ic :0.1908909785518099, sharpe5:17.973332036733627, irr5:601.1674194335938, ndcg5:0.8426391607872372, pnl5:5.916675567626953 
train 39, step: 0, loss: 0.9709896355958525, grad_norm: 0.002832133832655478, ic: 0.06729214128751951
train 39, step: 500, loss: 0.8994755198825423, grad_norm: 0.05913854025564183, ic: 0.198651312122226
train 39, step: 1000, loss: 0.9531941700780655, grad_norm: 0.35759870558792667, ic: 0.10810496827532687
train 39, step: 1500, loss: 2.080397326292591, grad_norm: 0.10979771770685254, ic: 0.20953457067575323
train 39, step: 2000, loss: 0.6191131929274042, grad_norm: 0.020745680847411137, ic: 0.09274100739424476
Epoch 39: 2022-04-07 01:17:47.892007: train loss: 1.622789722272984
Eval step 0: eval loss: 0.8267511623048932
Eval: 2022-04-07 01:17:50.762277: total loss: 1.06683321804641, mse:4.592231873343237, ic :0.18848166972147787, sharpe5:17.323766741752625, irr5:564.4664306640625, ndcg5:0.8320266406048243, pnl5:9.807585716247559 

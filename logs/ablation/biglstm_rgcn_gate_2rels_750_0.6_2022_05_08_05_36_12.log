Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='RGCNSeqTimeDataset', dout=0.3, epochs=40, glstm_layers=1, gnn_layers=1, gpu=0, graph_attn=False, hidden_dim=128, inner_prod=False, input_dim=9, input_graph=True, label_cnt=3, lr=0.0004, lstm_layers=1, market=None, mask_adj=True, mask_type='soft', model_type='BiGLSTM', normalize_adj=True, num_days=8, num_heads=1, print_inteval=500, rank_loss=False, relation_num=2, rsr_data_path=None, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_750_0.6/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
load 2305 train graphs successful!
load 126 test graphs successful!
6316
BiGLSTM(
  (input_to_hidden): Linear(in_features=9, out_features=128, bias=True)
  (forward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
            (1): Linear(in_features=128, out_features=128, bias=False)
          )
          (lin_gate): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (backward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
            (1): Linear(in_features=128, out_features=128, bias=False)
          )
          (lin_gate): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (fc0): ModuleList(
    (0): Linear(in_features=256, out_features=128, bias=True)
  )
  (w_out): Linear(in_features=128, out_features=1, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
)
train 0, step: 0, loss: 4.8978182723319, grad_norm: 4.894494425242579, ic: 0.026634357070640297
train 0, step: 500, loss: 0.8650486478252166, grad_norm: 0.024844444541939802, ic: 0.01966038230403106
train 0, step: 1000, loss: 1.943431884944221, grad_norm: 0.5522128403805042, ic: -0.05217185717458491
train 0, step: 1500, loss: 0.9573660989995059, grad_norm: 0.05978749419700259, ic: 0.04695453591544486
train 0, step: 2000, loss: 0.9967589409253509, grad_norm: 0.1565950461111082, ic: 0.06521145156722653
Epoch 0: 2022-05-08 17:45:53.423873: train loss: 1.6490035280231035
Eval step 0: eval loss: 0.8354306959628556
Eval: 2022-05-08 17:46:23.665135: total loss: 1.0790783953199434, mse:4.823194619847872, ic :0.007841469257975053, sharpe5:7.541868071258068, irr5:212.51763916015625, ndcg5:0.8527671333080954, pnl5:2.6570351123809814 
train 1, step: 0, loss: 2.76587150327621, grad_norm: 0.9145845971762533, ic: 0.043330040439479495
train 1, step: 500, loss: 1.7663428256765263, grad_norm: 0.8186035718173066, ic: 0.10466155339617746
train 1, step: 1000, loss: 0.8751238084440033, grad_norm: 0.1851360839690793, ic: 0.08028132748098793
train 1, step: 1500, loss: 1.7128702799479167, grad_norm: 0.22651447813097841, ic: -0.036394569777390126
train 1, step: 2000, loss: 2.18890234375, grad_norm: 0.9214494078784529, ic: -0.018772096201926547
Epoch 1: 2022-05-08 17:55:17.927614: train loss: 1.646809587820779
Eval step 0: eval loss: 0.8336905830150158
Eval: 2022-05-08 17:55:56.508563: total loss: 1.078844102091978, mse:4.824513623730875, ic :0.007957348267789497, sharpe5:7.443165925741195, irr5:210.261962890625, ndcg5:0.86854655869461, pnl5:2.6958577632904053 
train 2, step: 0, loss: 2.1430078125, grad_norm: 0.010734560974089667, ic: 0.13731132636355248
train 2, step: 500, loss: 3.306670044136346, grad_norm: 0.2921455143947511, ic: 0.04663935710631541
train 2, step: 1000, loss: 2.072025038912835, grad_norm: 0.00030728683082777673, ic: 0.18142937334444653
train 2, step: 1500, loss: 1.4863435002683683, grad_norm: 0.06790104131903386, ic: -0.02965644104623831
train 2, step: 2000, loss: 3.24181640625, grad_norm: 0.8220633655074288, ic: 0.23558838702520188
Epoch 2: 2022-05-08 18:06:46.185540: train loss: 1.646566037201226
Eval step 0: eval loss: 0.8356191395959562
Eval: 2022-05-08 18:07:31.306132: total loss: 1.0792471936968098, mse:4.822401907252218, ic :0.015897024921602602, sharpe5:7.460902978777885, irr5:210.89027404785156, ndcg5:0.8375054762536992, pnl5:3.0685055255889893 
train 3, step: 0, loss: 1.5193408997078253, grad_norm: 0.5648929909174861, ic: -0.003416355542229409
train 3, step: 500, loss: 1.4975050625244715, grad_norm: 0.37436565234803104, ic: 0.08193982011711076
train 3, step: 1000, loss: 3.6700354418537713, grad_norm: 0.749692780765538, ic: 0.014746796574886522
train 3, step: 1500, loss: 1.973773662860577, grad_norm: 0.9682946088653669, ic: -0.030383996639655943
train 3, step: 2000, loss: 0.8984746489653717, grad_norm: 0.0006601010341061405, ic: 0.009420072421519007
Epoch 3: 2022-05-08 18:19:34.141855: train loss: 1.645686880368471
Eval step 0: eval loss: 0.8330541194678609
Eval: 2022-05-08 18:20:17.693344: total loss: 1.0774677154650425, mse:4.819612917314216, ic :0.0363189589543214, sharpe5:7.526377591788768, irr5:198.55633544921875, ndcg5:0.8434311265501752, pnl5:3.812492609024048 
train 4, step: 0, loss: 1.4392506377551022, grad_norm: 0.047934633063063725, ic: 0.07959286430273427
train 4, step: 500, loss: 1.646632781742126, grad_norm: 0.6275556620165582, ic: 0.0963503900837891
train 4, step: 1000, loss: 2.948418221822599, grad_norm: 0.7049300980447712, ic: 0.0763625199020908
train 4, step: 1500, loss: 2.144332023008966, grad_norm: 0.47798916976607786, ic: 0.0033725431674802298
train 4, step: 2000, loss: 1.0778140339473172, grad_norm: 0.46827492975299956, ic: 0.29665077328118955
Epoch 4: 2022-05-08 18:32:09.038474: train loss: 1.6448107252558741
Eval step 0: eval loss: 0.8633586855407007
Eval: 2022-05-08 18:32:58.566434: total loss: 1.0924711969182894, mse:4.792265771148799, ic :0.12071890562535381, sharpe5:11.776755257248878, irr5:396.8821716308594, ndcg5:0.8447058146943864, pnl5:2.8655922412872314 
train 5, step: 0, loss: 1.3521323799286913, grad_norm: 0.1614042674874639, ic: 0.29408972961290936
train 5, step: 500, loss: 0.8822432902954005, grad_norm: 0.011802179384738331, ic: 0.8476638457136515
train 5, step: 1000, loss: 0.9855309731202108, grad_norm: 0.16426543729310736, ic: -0.01087340689105596
train 5, step: 1500, loss: 1.5277105217505744, grad_norm: 0.28310127377007277, ic: 0.020558321244647362
train 5, step: 2000, loss: 1.2173545465668503, grad_norm: 1.5248174157889307, ic: 0.1272849160816871
Epoch 5: 2022-05-08 18:44:39.375799: train loss: 1.6424410141402497
Eval step 0: eval loss: 0.8364311837295837
Eval: 2022-05-08 18:45:30.722424: total loss: 1.0754395058220827, mse:4.715647516666217, ic :0.1464415517290366, sharpe5:11.467374172210693, irr5:388.78240966796875, ndcg5:0.8483688044464517, pnl5:3.1097819805145264 
train 6, step: 0, loss: 1.33531371486244, grad_norm: 0.6345376933522737, ic: 0.13155090077412462
train 6, step: 500, loss: 1.0078990521511295, grad_norm: 0.05643712962878954, ic: 0.022452119464281974
train 6, step: 1000, loss: 1.1192048627614068, grad_norm: 0.10183855274590245, ic: 0.5308308391252009
train 6, step: 1500, loss: 1.5761012558109504, grad_norm: 0.8057293293942822, ic: 0.15997117912452186
train 6, step: 2000, loss: 0.7983024603276371, grad_norm: 0.043451114271796425, ic: 0.35985570273506845
Epoch 6: 2022-05-08 18:57:09.804479: train loss: 1.6356272873150186
Eval step 0: eval loss: 0.8299884695650026
Eval: 2022-05-08 18:57:54.344579: total loss: 1.0713007616495311, mse:4.704032314772358, ic :0.1532644262246083, sharpe5:14.056670814156531, irr5:456.66326904296875, ndcg5:0.8468690531791309, pnl5:6.79503870010376 
train 7, step: 0, loss: 0.989934539794922, grad_norm: 0.04740710909340774, ic: 0.07552243475647577
train 7, step: 500, loss: 0.6489988750237462, grad_norm: 0.004799638090915237, ic: 0.06908354607275202
train 7, step: 1000, loss: 1.0265876206385662, grad_norm: 0.20061343087736394, ic: 0.11734811572942917
train 7, step: 1500, loss: 2.2185333350080385, grad_norm: 0.7317560686500632, ic: 0.442344599515345
train 7, step: 2000, loss: 0.9204985043921649, grad_norm: 0.1063732858884151, ic: -0.07235445583615593
Epoch 7: 2022-05-08 19:09:44.340738: train loss: 1.629228424654138
Eval step 0: eval loss: 0.8278523034114857
Eval: 2022-05-08 19:10:24.666725: total loss: 1.0703068348459062, mse:4.678851922622342, ic :0.16844608251171195, sharpe5:15.854746001958846, irr5:510.4576110839844, ndcg5:0.8467327319746544, pnl5:5.129122257232666 
train 8, step: 0, loss: 3.5944254557291666, grad_norm: 2.0304966098857884, ic: 0.18489737449155147
train 8, step: 500, loss: 2.760808417137633, grad_norm: 0.8993671621469501, ic: 0.019610934852796264
train 8, step: 1000, loss: 3.0418665789175723, grad_norm: 0.9076433594990849, ic: 0.11545010405059274
train 8, step: 1500, loss: 0.7103418992274199, grad_norm: 0.27544459237258856, ic: 0.467530813797017
train 8, step: 2000, loss: 1.0983262736507444, grad_norm: 0.36263749064500117, ic: 0.5133364736387178
Epoch 8: 2022-05-08 19:21:50.430662: train loss: 1.6283900863747989
Eval step 0: eval loss: 0.8223460190414251
Eval: 2022-05-08 19:22:22.696719: total loss: 1.06931747331445, mse:4.678412145734909, ic :0.1725524918958158, sharpe5:16.11250319123268, irr5:535.4434814453125, ndcg5:0.8567191009394249, pnl5:5.843842506408691 
train 9, step: 0, loss: 5.434328118769936, grad_norm: 0.9274423774585795, ic: 0.03965459644886997
train 9, step: 500, loss: 1.3334949256130384, grad_norm: 1.4793964529010353, ic: 0.3277355015300134
train 9, step: 1000, loss: 0.9340593810934934, grad_norm: 0.2573199625908859, ic: -0.021844958287513677
train 9, step: 1500, loss: 1.0893423448430597, grad_norm: 0.019272651715505122, ic: 0.4041298368395018
train 9, step: 2000, loss: 1.064066362671146, grad_norm: 0.4943576449197625, ic: 0.26244694057125373
Epoch 9: 2022-05-08 19:30:18.056890: train loss: 1.6271761927554822
Eval step 0: eval loss: 0.8235702595042478
Eval: 2022-05-08 19:30:50.635977: total loss: 1.0704961187020403, mse:4.684575059909311, ic :0.16589445406354755, sharpe5:16.307570099830627, irr5:530.7667846679688, ndcg5:0.8406860773761552, pnl5:9.854927062988281 
train 10, step: 0, loss: 7.080962867848032, grad_norm: 1.7542246084673019, ic: 0.25568282880140847
train 10, step: 500, loss: 1.1480768464236657, grad_norm: 0.4890596904410995, ic: 0.03855566006101377
train 10, step: 1000, loss: 2.3847212528158552, grad_norm: 0.7283428938195473, ic: 0.15772844873755518
train 10, step: 1500, loss: 1.1217540394176138, grad_norm: 0.29356361966373623, ic: 0.0038233997321024636
train 10, step: 2000, loss: 2.7178363278281723, grad_norm: 0.9401561222643723, ic: 0.4796239690468636
Epoch 10: 2022-05-08 19:38:53.717111: train loss: 1.6264903425220834
Eval step 0: eval loss: 0.8253809905780756
Eval: 2022-05-08 19:39:25.270793: total loss: 1.0688250581524112, mse:4.653881670918775, ic :0.17772798293112038, sharpe5:16.317375565767286, irr5:531.9038696289062, ndcg5:0.8459793144367487, pnl5:6.414143085479736 
train 11, step: 0, loss: 1.2493429161832947, grad_norm: 0.059401363494884625, ic: 0.2132184021696029
train 11, step: 500, loss: 0.6500953605487725, grad_norm: 0.10175056899599838, ic: 0.6010190150078099
train 11, step: 1000, loss: 0.9324569765045342, grad_norm: 0.11277281931028706, ic: 0.05878245396248441
train 11, step: 1500, loss: 1.0588113215931674, grad_norm: 0.4125164471713467, ic: 0.16958494595243376
train 11, step: 2000, loss: 0.7879528750740521, grad_norm: 0.10144296852221221, ic: 0.11487704462081966
Epoch 11: 2022-05-08 19:47:22.276739: train loss: 1.624920076749622
Eval step 0: eval loss: 0.8299344447691649
Eval: 2022-05-08 19:47:56.060763: total loss: 1.0684938049544936, mse:4.595102401116705, ic :0.1834048167551168, sharpe5:16.318344193696976, irr5:544.451904296875, ndcg5:0.8566669150907597, pnl5:4.980492115020752 
train 12, step: 0, loss: 0.9575220743815104, grad_norm: 0.08830052512188208, ic: 0.39499014056316395
train 12, step: 500, loss: 0.9355433758509931, grad_norm: 0.08108743514742767, ic: 0.1759102327184555
train 12, step: 1000, loss: 2.935059760026871, grad_norm: 0.40375589323047234, ic: 0.42985809283226245
train 12, step: 1500, loss: 0.9268281911950209, grad_norm: 0.14981373396541772, ic: -0.12460412837571427
train 12, step: 2000, loss: 0.8742394576980268, grad_norm: 0.0064055833197147255, ic: 0.1978544007895738
Epoch 12: 2022-05-08 19:55:54.167568: train loss: 1.621391744584568
Eval step 0: eval loss: 0.826987392156217
Eval: 2022-05-08 19:56:26.575571: total loss: 1.0658044867753222, mse:4.588314297161571, ic :0.1883892139332182, sharpe5:16.135385134220122, irr5:527.779541015625, ndcg5:0.845982567100937, pnl5:7.71227502822876 
train 13, step: 0, loss: 2.042501350894271, grad_norm: 0.6520953670457305, ic: 0.4507692863808008
train 13, step: 500, loss: 0.8129839513344134, grad_norm: 0.050770726335939216, ic: 0.5942382301433913
train 13, step: 1000, loss: 0.9472100789114932, grad_norm: 0.38789826380684145, ic: 0.5822786165582132
train 13, step: 1500, loss: 2.396273777505367, grad_norm: 0.2855406745802863, ic: -0.10543474671215056
train 13, step: 2000, loss: 1.4640388753067262, grad_norm: 0.062432426294617746, ic: 0.19604139435030032
Epoch 13: 2022-05-08 20:04:24.255578: train loss: 1.6211730241869302
Eval step 0: eval loss: 0.8221088244616043
Eval: 2022-05-08 20:04:56.572728: total loss: 1.0677449571093274, mse:4.612807102245625, ic :0.18527551670130674, sharpe5:16.742726197242735, irr5:565.1339721679688, ndcg5:0.8492926416235478, pnl5:7.703783988952637 
train 14, step: 0, loss: 4.559246569081513, grad_norm: 1.291075471385808, ic: 0.19971159260963542
train 14, step: 500, loss: 0.829345889776854, grad_norm: 0.0024332733940980685, ic: 0.03566231500268793
train 14, step: 1000, loss: 1.8172524929408695, grad_norm: 0.9490142998879931, ic: 0.4615817143891906
train 14, step: 1500, loss: 1.1280716876594388, grad_norm: 0.06745291350122118, ic: -0.07905754177256713
train 14, step: 2000, loss: 1.1634066198928725, grad_norm: 0.22547914164178556, ic: 0.06841205322325988
Epoch 14: 2022-05-08 20:13:02.048517: train loss: 1.6202951328719255
Eval step 0: eval loss: 0.8314412220511722
Eval: 2022-05-08 20:13:34.389561: total loss: 1.0664831191249449, mse:4.583646444470994, ic :0.191853158431458, sharpe5:17.088736363649367, irr5:577.0477294921875, ndcg5:0.855294614084142, pnl5:5.1884050369262695 
train 15, step: 0, loss: 3.439965725316148, grad_norm: 1.1004273801863382, ic: 0.13737882813923818
train 15, step: 500, loss: 1.2560641446513923, grad_norm: 0.0230509384956854, ic: 0.027976178572279076
train 15, step: 1000, loss: 1.3136927162728658, grad_norm: 0.1215579254914104, ic: 0.06468880270796201
train 15, step: 1500, loss: 0.8576018085629921, grad_norm: 0.24240942082742784, ic: 0.06717168509705246
train 15, step: 2000, loss: 1.4523561142876913, grad_norm: 0.5472827406554763, ic: 0.054311315818012865
Epoch 15: 2022-05-08 20:21:27.729456: train loss: 1.6210714558355315
Eval step 0: eval loss: 0.8344875773840884
Eval: 2022-05-08 20:21:59.524468: total loss: 1.0681331723841354, mse:4.5791718170758, ic :0.19524953999267633, sharpe5:17.167006040811536, irr5:583.914306640625, ndcg5:0.8454240339265057, pnl5:6.902237892150879 
train 16, step: 0, loss: 0.701710414810966, grad_norm: 0.22951428118344655, ic: -0.06813305502308539
train 16, step: 500, loss: 1.6014071495334834, grad_norm: 0.5172073394758914, ic: 0.1828159793346884
train 16, step: 1000, loss: 0.8792427756569602, grad_norm: 0.005098133551160372, ic: -0.10112280334684282
train 16, step: 1500, loss: 0.8579609467346336, grad_norm: 0.198345483526764, ic: 0.1622652066566453
train 16, step: 2000, loss: 3.3436911320706026, grad_norm: 0.875685387308082, ic: 0.02766092052623868
Epoch 16: 2022-05-08 20:29:53.968135: train loss: 1.6186614128485532
Eval step 0: eval loss: 0.8291367429325276
Eval: 2022-05-08 20:30:26.476212: total loss: 1.0676875012924554, mse:4.597760921351541, ic :0.18301411078196111, sharpe5:16.304471247196197, irr5:524.3923950195312, ndcg5:0.8516516955897797, pnl5:10.579339027404785 
train 17, step: 0, loss: 1.2889742985328247, grad_norm: 0.23821790504763846, ic: -0.1038354811117026
train 17, step: 500, loss: 1.7376251799627371, grad_norm: 0.46767549736431946, ic: 0.1824253006071014
train 17, step: 1000, loss: 1.2829694697358829, grad_norm: 0.08912870491675128, ic: 0.16043397627711437
train 17, step: 1500, loss: 4.525168189750183, grad_norm: 1.0398255575170678, ic: 0.2276636858260885
train 17, step: 2000, loss: 1.2725328006911298, grad_norm: 0.5728708881405178, ic: 0.10957046546071704
Epoch 17: 2022-05-08 20:38:28.389730: train loss: 1.6198579476761223
Eval step 0: eval loss: 0.8303724315068493
Eval: 2022-05-08 20:39:01.026992: total loss: 1.065423972985053, mse:4.572333080449317, ic :0.2005552900039013, sharpe5:18.690831824541092, irr5:631.0934448242188, ndcg5:0.8468359276090487, pnl5:6.759912014007568 
train 18, step: 0, loss: 1.4098728278975707, grad_norm: 1.442680321553198, ic: 0.23437085793484233
train 18, step: 500, loss: 1.5201612076901734, grad_norm: 0.6666773077418401, ic: -0.032385742127879105
train 18, step: 1000, loss: 0.6571250936429794, grad_norm: 0.029141047868257566, ic: 0.5756756294436537
train 18, step: 1500, loss: 1.4240986592060811, grad_norm: 0.03721335863495791, ic: 0.22411934221624794
train 18, step: 2000, loss: 0.9123832556852111, grad_norm: 0.0074131836230447124, ic: -0.022389324985131624
Epoch 18: 2022-05-08 20:47:09.639874: train loss: 1.617251677787007
Eval step 0: eval loss: 0.8226577549764554
Eval: 2022-05-08 20:47:39.363895: total loss: 1.0649077581127524, mse:4.59402004711509, ic :0.19530460811162853, sharpe5:17.605595848560334, irr5:604.0100708007812, ndcg5:0.8640309178997563, pnl5:6.045523643493652 
train 19, step: 0, loss: 1.4816377185639882, grad_norm: 0.6931590764984739, ic: -0.017449202254341475
train 19, step: 500, loss: 0.8599640175148292, grad_norm: 0.026411465000570872, ic: 0.22471078932884864
train 19, step: 1000, loss: 0.9537020765114845, grad_norm: 0.0035893933632611835, ic: 0.21185035635499694
train 19, step: 1500, loss: 3.960828039902495, grad_norm: 0.7696216650615214, ic: 0.13905789588463283
train 19, step: 2000, loss: 1.012650428185096, grad_norm: 0.08529512997520107, ic: 0.21412466768330704
Epoch 19: 2022-05-08 20:55:49.634137: train loss: 1.6193719045300117
Eval step 0: eval loss: 0.8281479605382309
Eval: 2022-05-08 20:56:22.466025: total loss: 1.0657234778056883, mse:4.5770708912339355, ic :0.19725317376892956, sharpe5:17.880065653324127, irr5:615.1795043945312, ndcg5:0.8439093755909217, pnl5:7.7441887855529785 
train 20, step: 0, loss: 2.30182844923419, grad_norm: 0.6792386618752073, ic: 0.04147702911725638
train 20, step: 500, loss: 3.236438920454545, grad_norm: 0.5466243992077717, ic: 0.05129459492352299
train 20, step: 1000, loss: 0.9675446510314942, grad_norm: 0.07603933361145421, ic: 0.2217702422650784
train 20, step: 1500, loss: 1.6635702930584801, grad_norm: 0.7547081641883006, ic: 0.2624828231464987
train 20, step: 2000, loss: 1.0382186615836562, grad_norm: 0.07668375881155773, ic: -0.005065144730233978
Epoch 20: 2022-05-08 21:04:30.809762: train loss: 1.6175468542232756
Eval step 0: eval loss: 0.8280429980777463
Eval: 2022-05-08 21:05:00.718566: total loss: 1.0646461812242674, mse:4.5783035960426846, ic :0.1984323992065987, sharpe5:18.034610996246336, irr5:609.2794799804688, ndcg5:0.8458369075751916, pnl5:5.766488075256348 
train 21, step: 0, loss: 1.0127658916738178, grad_norm: 0.3499174024321837, ic: 0.07087075444028443
train 21, step: 500, loss: 0.7703519838046183, grad_norm: 0.009281582808697486, ic: 0.19442133318978932
train 21, step: 1000, loss: 0.9447899533991228, grad_norm: 0.48703256835597697, ic: 0.14389116237569974
train 21, step: 1500, loss: 0.9888669941560925, grad_norm: 0.21295807430706157, ic: 0.32170163609751473
train 21, step: 2000, loss: 0.9378282244947397, grad_norm: 0.05420883703042356, ic: 0.06659516690294448
Epoch 21: 2022-05-08 21:12:56.677032: train loss: 1.6171938279443394
Eval step 0: eval loss: 0.8239268874720099
Eval: 2022-05-08 21:13:28.734113: total loss: 1.065725773065555, mse:4.590855188659875, ic :0.19289079970441775, sharpe5:17.921096127033234, irr5:596.59716796875, ndcg5:0.8427290192893698, pnl5:6.930291652679443 
train 22, step: 0, loss: 1.0441320386983581, grad_norm: 0.14220398304347381, ic: 0.2179063443253504
train 22, step: 500, loss: 3.255141641260163, grad_norm: 0.6185777221486086, ic: -0.2225989118580609
train 22, step: 1000, loss: 1.1852939848265898, grad_norm: 0.013620238259791693, ic: 0.4690110058702547
train 22, step: 1500, loss: 0.966162913130144, grad_norm: 0.04871917574534115, ic: 0.13617730328320193
train 22, step: 2000, loss: 1.7744887994260206, grad_norm: 0.8752310629146105, ic: 0.12101665775603646
Epoch 22: 2022-05-08 21:21:23.427032: train loss: 1.6160495844597322
Eval step 0: eval loss: 0.8233603345832784
Eval: 2022-05-08 21:21:56.015601: total loss: 1.065013070905977, mse:4.592618666725049, ic :0.19381205458982606, sharpe5:18.24221142053604, irr5:611.0411987304688, ndcg5:0.8392651504897292, pnl5:6.17042350769043 
train 23, step: 0, loss: 0.988106130110771, grad_norm: 0.03057628500656847, ic: 0.1184142850672022
train 23, step: 500, loss: 1.4230934035272764, grad_norm: 0.16829934749306752, ic: 0.040497914987465765
train 23, step: 1000, loss: 1.6596959431966147, grad_norm: 0.07948052860874467, ic: 0.2593316854506175
train 23, step: 1500, loss: 1.1132772215860034, grad_norm: 0.18502112499352835, ic: 0.09022050403021828
train 23, step: 2000, loss: 1.9248977203016742, grad_norm: 1.1057433606160407, ic: 0.44044628897557003
Epoch 23: 2022-05-08 21:29:55.377055: train loss: 1.6147398673017042
Eval step 0: eval loss: 0.8275012708690068
Eval: 2022-05-08 21:30:28.382601: total loss: 1.064775761270369, mse:4.576496770561515, ic :0.20005000667301606, sharpe5:17.711072241067885, irr5:608.8978271484375, ndcg5:0.8538474151420786, pnl5:6.0814642906188965 
train 24, step: 0, loss: 2.1826612938647862, grad_norm: 0.06967006091895026, ic: 0.1702295309036581
train 24, step: 500, loss: 1.2174301206833658, grad_norm: 0.07706988940721768, ic: 0.17662294798545283
train 24, step: 1000, loss: 0.9128175641458475, grad_norm: 0.04453917998753662, ic: 0.5189189005383881
train 24, step: 1500, loss: 2.622604483331616, grad_norm: 0.8737801056678786, ic: 0.05726790290672521
train 24, step: 2000, loss: 0.9283577593342501, grad_norm: 0.02942530866317302, ic: 0.178138008927559
Epoch 24: 2022-05-08 21:38:30.410287: train loss: 1.6130470960393015
Eval step 0: eval loss: 0.8197543724068097
Eval: 2022-05-08 21:39:01.705213: total loss: 1.065417821716429, mse:4.604265391158292, ic :0.19654998206903868, sharpe5:18.486432412862776, irr5:621.7109985351562, ndcg5:0.841120831917702, pnl5:8.855491638183594 
train 25, step: 0, loss: 0.8380587191195101, grad_norm: 0.1809620995598629, ic: 0.6092466204849272
train 25, step: 500, loss: 0.8677251994429759, grad_norm: 0.0076681548008339625, ic: 0.2233385246887891
train 25, step: 1000, loss: 2.108119339953827, grad_norm: 0.5429890091180607, ic: 0.24040737227492795
train 25, step: 1500, loss: 1.13486556077681, grad_norm: 0.4022721511167582, ic: 0.5377409711046318
train 25, step: 2000, loss: 1.0230309660446304, grad_norm: 0.603181171062521, ic: 0.5944084715173898
Epoch 25: 2022-05-08 21:47:00.342665: train loss: 1.6160574669342769
Eval step 0: eval loss: 0.8222855627222734
Eval: 2022-05-08 21:47:32.454758: total loss: 1.0648073426069171, mse:4.591463098238098, ic :0.1998638072389369, sharpe5:18.5738529753685, irr5:630.1817626953125, ndcg5:0.8484426458207484, pnl5:6.243985652923584 
train 26, step: 0, loss: 6.82767805885583, grad_norm: 2.2883094606924104, ic: 0.08766656565280927
train 26, step: 500, loss: 3.878136605746677, grad_norm: 1.3893566629079979, ic: 0.38217530041518233
train 26, step: 1000, loss: 1.266659339892808, grad_norm: 0.8365045695124609, ic: -0.0011881040757402567
train 26, step: 1500, loss: 0.8257029237561009, grad_norm: 0.1254581754764562, ic: 0.30921341880351966
train 26, step: 2000, loss: 0.949214908290716, grad_norm: 0.11435931319613996, ic: 0.19286351336395763
Epoch 26: 2022-05-08 21:55:25.747614: train loss: 1.614419581351039
Eval step 0: eval loss: 0.8265716584891991
Eval: 2022-05-08 21:55:57.925198: total loss: 1.0654473412422327, mse:4.590004730833854, ic :0.193905124812939, sharpe5:18.348376446962355, irr5:630.8956298828125, ndcg5:0.8401287402233835, pnl5:9.399325370788574 
train 27, step: 0, loss: 0.830560183057598, grad_norm: 0.01593729795645255, ic: 0.1262383474143614
train 27, step: 500, loss: 0.9186090620245944, grad_norm: 0.5466621311678374, ic: 0.26520974591603924
train 27, step: 1000, loss: 0.7540320022476799, grad_norm: 0.44694592297509794, ic: 0.20675773747608722
train 27, step: 1500, loss: 0.6442798037523804, grad_norm: 0.06991375932590337, ic: 0.5155419776832216
train 27, step: 2000, loss: 1.3849020619779804, grad_norm: 0.01950674372125735, ic: 0.008333628602365369
Epoch 27: 2022-05-08 22:03:53.528239: train loss: 1.61291750622312
Eval step 0: eval loss: 0.8276347892930057
Eval: 2022-05-08 22:04:26.260465: total loss: 1.0649465142142849, mse:4.586023540797975, ic :0.1961198398794095, sharpe5:18.207821345329283, irr5:618.4917602539062, ndcg5:0.856656623273134, pnl5:5.707533836364746 
train 28, step: 0, loss: 1.5273456352557915, grad_norm: 0.16806211077473715, ic: 0.25037692253055993
train 28, step: 500, loss: 1.3901028747729178, grad_norm: 0.6652144553494215, ic: 0.18746507501528098
train 28, step: 1000, loss: 0.9142967162093496, grad_norm: 0.335418056689986, ic: 0.5759987348620621
train 28, step: 1500, loss: 1.0350836907233392, grad_norm: 0.03665131244331133, ic: 0.0291318356560195
train 28, step: 2000, loss: 1.043230770555742, grad_norm: 0.1377911558372939, ic: 0.09096629110999654
Epoch 28: 2022-05-08 22:12:21.812913: train loss: 1.6102409904824695
Eval step 0: eval loss: 0.8219535031735709
Eval: 2022-05-08 22:12:53.546002: total loss: 1.075396678458087, mse:4.659020724717041, ic :0.1846359499150585, sharpe5:18.460173515081404, irr5:619.4121704101562, ndcg5:0.8544297570224209, pnl5:4.431951522827148 
train 29, step: 0, loss: 0.90528620907174, grad_norm: 0.05981296286089034, ic: 0.10571772483371077
train 29, step: 500, loss: 1.1061175934931005, grad_norm: 0.38922084014790786, ic: 0.6172501991329702
train 29, step: 1000, loss: 1.0658268141728222, grad_norm: 0.4959307826932614, ic: 0.07806699831038874
train 29, step: 1500, loss: 2.340885492901054, grad_norm: 0.23391332356495675, ic: -0.02144515914122346
train 29, step: 2000, loss: 3.792515130690586, grad_norm: 16.999370100863715, ic: 0.17172450707090695
Epoch 29: 2022-05-08 22:20:49.682286: train loss: 1.6103752042428072
Eval step 0: eval loss: 0.8308239244434931
Eval: 2022-05-08 22:21:22.229912: total loss: 1.0646457299460141, mse:4.578393557100928, ic :0.1962133339771346, sharpe5:18.3380677485466, irr5:621.7810668945312, ndcg5:0.8586553159533742, pnl5:7.6013712882995605 
train 30, step: 0, loss: 1.0072974751598793, grad_norm: 0.150779152364449, ic: 0.5141693798018117
train 30, step: 500, loss: 1.4213951304860541, grad_norm: 1.633549240864717, ic: 0.012337891907200145
train 30, step: 1000, loss: 0.9780652595288826, grad_norm: 0.036476856745412074, ic: -0.051933364386495734
train 30, step: 1500, loss: 1.4931717777098956, grad_norm: 1.1900122347790079, ic: 0.1796707454990383
train 30, step: 2000, loss: 1.8265073582153786, grad_norm: 0.6533305630905153, ic: 0.12908406921984433
Epoch 30: 2022-05-08 22:29:17.388194: train loss: 1.6115307225102515
Eval step 0: eval loss: 0.8259969375658588
Eval: 2022-05-08 22:29:50.336287: total loss: 1.0632916154677752, mse:4.576513544858474, ic :0.1995318447428357, sharpe5:18.950978422164916, irr5:630.1248168945312, ndcg5:0.8463946436206998, pnl5:6.542797088623047 
train 31, step: 0, loss: 1.0448059455461844, grad_norm: 0.10916409089285625, ic: 0.3526095164430473
train 31, step: 500, loss: 1.5111247749485597, grad_norm: 1.3077686638043013, ic: 0.07565581621416528
train 31, step: 1000, loss: 4.417012389612608, grad_norm: 2.1683493051697083, ic: 0.46188410272225905
train 31, step: 1500, loss: 0.7658066425755243, grad_norm: 0.046802561038312075, ic: 0.7153607478130468
train 31, step: 2000, loss: 1.2322413667719414, grad_norm: 0.7932371741224284, ic: 0.20159552849839824
Epoch 31: 2022-05-08 22:37:48.452076: train loss: 1.6058739734832115
Eval step 0: eval loss: 0.8325560623024235
Eval: 2022-05-08 22:38:20.815937: total loss: 1.0674158586077418, mse:4.572820833615424, ic :0.1944564269775943, sharpe5:18.501147233247757, irr5:619.8258056640625, ndcg5:0.8488208906643344, pnl5:6.702140808105469 
train 32, step: 0, loss: 1.1289174770435504, grad_norm: 0.024198558270620694, ic: 0.17971047493543194
train 32, step: 500, loss: 1.481244232898622, grad_norm: 0.8235795910953028, ic: 0.13492100913573138
train 32, step: 1000, loss: 1.0414950037179387, grad_norm: 0.21387689716460978, ic: 0.515364176519521
train 32, step: 1500, loss: 0.9688432985912472, grad_norm: 0.31660503754206326, ic: 0.0613824957730049
train 32, step: 2000, loss: 0.9313295377323026, grad_norm: 0.21456622241142018, ic: 0.5685041100720948
Epoch 32: 2022-05-08 22:46:22.534581: train loss: 1.6111485587873622
Eval step 0: eval loss: 0.8196320448333771
Eval: 2022-05-08 22:46:55.103153: total loss: 1.064132413739659, mse:4.595196699353323, ic :0.19736341253030704, sharpe5:18.0707377910614, irr5:622.565185546875, ndcg5:0.8439841898265753, pnl5:6.112109661102295 
train 33, step: 0, loss: 1.2511753551903346, grad_norm: 0.25096413479300467, ic: 0.24607626719908549
train 33, step: 500, loss: 0.9847876517439362, grad_norm: 0.2354838628969667, ic: 0.20363872457827592
train 33, step: 1000, loss: 1.0650417577287647, grad_norm: 0.7545328652223642, ic: 0.20230477466575533
train 33, step: 1500, loss: 0.884688009712337, grad_norm: 0.1352993170980175, ic: 0.5570363382199933
train 33, step: 2000, loss: 0.8126571824546851, grad_norm: 0.060723396960102954, ic: 0.2487438508301646
Epoch 33: 2022-05-08 22:54:52.244119: train loss: 1.6121518399384336
Eval step 0: eval loss: 0.8275109181539778
Eval: 2022-05-08 22:55:25.371502: total loss: 1.0642247114627665, mse:4.572663943066994, ic :0.19916445637087146, sharpe5:18.375428030490873, irr5:626.3926391601562, ndcg5:0.8439674122132441, pnl5:5.837536334991455 
train 34, step: 0, loss: 1.005532131684811, grad_norm: 0.8811457655327914, ic: 0.5960225221973623
train 34, step: 500, loss: 0.7875032104118884, grad_norm: 0.07169190845776535, ic: 0.2941855452648316
train 34, step: 1000, loss: 3.1593435729886714, grad_norm: 2.652870616464205, ic: 0.3141476202311385
train 34, step: 1500, loss: 0.8088326528046782, grad_norm: 0.502029033571749, ic: 0.6887935338920079
train 34, step: 2000, loss: 4.958402673557321, grad_norm: 109.45496927056696, ic: 0.40743466111246684
Epoch 34: 2022-05-08 23:03:32.294910: train loss: 1.6050386935609378
Eval step 0: eval loss: 0.8222570067587591
Eval: 2022-05-08 23:04:05.164867: total loss: 1.065210659677066, mse:4.593965490725513, ic :0.19900563362001494, sharpe5:17.202109344005585, irr5:606.8037719726562, ndcg5:0.8370320187266305, pnl5:5.066112995147705 
train 35, step: 0, loss: 1.1800158691406248, grad_norm: 1.0669476909169788, ic: 0.5610253623920475
train 35, step: 500, loss: 1.1575545453674367, grad_norm: 0.4438354274440439, ic: 0.09463170030651746
train 35, step: 1000, loss: 1.6582788034102973, grad_norm: 2.5685417194850424, ic: 0.05926173560090951
train 35, step: 1500, loss: 1.6327174136513158, grad_norm: 2.61684222682373, ic: 0.041544682223945945
train 35, step: 2000, loss: 0.7872757529192429, grad_norm: 0.08897238797562616, ic: 0.5550484503001659
Epoch 35: 2022-05-08 23:12:15.534114: train loss: 1.605642946815259
Eval step 0: eval loss: 0.8305339913724973
Eval: 2022-05-08 23:12:46.447653: total loss: 1.0645850369899479, mse:4.580551457595711, ic :0.1974593774759499, sharpe5:18.037643634080887, irr5:621.3360595703125, ndcg5:0.8693226479344948, pnl5:4.8326802253723145 
train 36, step: 0, loss: 1.8392358896683674, grad_norm: 1.8564367741361836, ic: 0.1001597163363656
train 36, step: 500, loss: 0.8401579199295706, grad_norm: 0.06539185311446064, ic: 0.11681411174310885
train 36, step: 1000, loss: 1.6255015980113636, grad_norm: 0.35973094491821855, ic: 0.2630070121894435
train 36, step: 1500, loss: 0.7652313450546214, grad_norm: 0.10412413696176034, ic: 0.39697619281442703
train 36, step: 2000, loss: 1.1245808499118843, grad_norm: 1.4761798356228442, ic: 0.7736850380064217
Epoch 36: 2022-05-08 23:20:56.189540: train loss: 1.604992986595252
Eval step 0: eval loss: 0.8312219071061643
Eval: 2022-05-08 23:21:27.085927: total loss: 1.065062208966052, mse:4.598577131003046, ic :0.19326653077154465, sharpe5:17.445636026859283, irr5:607.6573486328125, ndcg5:0.8483181722676784, pnl5:6.374088764190674 
train 37, step: 0, loss: 1.989328288009667, grad_norm: 2.9533404120459066, ic: 0.23552295974022294
train 37, step: 500, loss: 2.3663915537698816, grad_norm: 1.3775901544662097, ic: -0.047583629906908786
train 37, step: 1000, loss: 1.0637162439355021, grad_norm: 0.12622750733946683, ic: 0.10233475879671222
train 37, step: 1500, loss: 2.008475742310145, grad_norm: 3.6859810229432233, ic: 0.6077032769983727
train 37, step: 2000, loss: 1.3048442447700375, grad_norm: 0.3068779793562169, ic: 0.19780541512912975
Epoch 37: 2022-05-08 23:29:30.570981: train loss: 1.6054347874519492
Eval step 0: eval loss: 0.8221995089403319
Eval: 2022-05-08 23:30:00.387205: total loss: 1.0656851872985749, mse:4.590452643827149, ic :0.19623507364749998, sharpe5:18.07402015328407, irr5:630.0465087890625, ndcg5:0.8251254146773814, pnl5:5.712100028991699 

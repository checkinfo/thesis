Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='RGCNSeqTimeDataset', dout=0.3, epochs=40, glstm_layers=1, gnn_layers=1, gpu=0, graph_attn=False, hidden_dim=128, inner_prod=False, input_dim=9, input_graph=True, label_cnt=3, lr=0.0004, lstm_layers=1, market=None, mask_adj=True, mask_type='soft', model_type='BiGLSTM', normalize_adj=True, num_days=8, num_heads=1, print_inteval=500, rank_loss=False, relation_num=2, rsr_data_path=None, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_750_0.6/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
load 2305 train graphs successful!
load 126 test graphs successful!
15924
BiGLSTM(
  (input_to_hidden): Linear(in_features=9, out_features=128, bias=True)
  (forward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
            (1): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
  )
  (backward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
            (1): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
  )
  (fc0): ModuleList(
    (0): Linear(in_features=256, out_features=128, bias=True)
  )
  (w_out): Linear(in_features=128, out_features=1, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
)
train 0, step: 0, loss: 4.8149769106724, grad_norm: 5.259441020817423, ic: 0.02692422633440904
train 0, step: 500, loss: 0.8633847383960531, grad_norm: 0.028259388933621135, ic: 0.038902353021370475
train 0, step: 1000, loss: 1.9567422817986468, grad_norm: 0.543591071528928, ic: 0.02717709919404763
train 0, step: 1500, loss: 0.9549740033658597, grad_norm: 0.04646819865316616, ic: 0.032762801974944716
train 0, step: 2000, loss: 1.0046762860533658, grad_norm: 0.17000444220822303, ic: 0.004713216360102308
Epoch 0: 2022-04-27 22:22:19.051862: train loss: 1.6487461388764015
Eval step 0: eval loss: 0.8365195528599183
Eval: 2022-04-27 22:23:47.290971: total loss: 1.0794073305720173, mse:4.822807707522996, ic :0.008385220724471131, sharpe5:7.81016854852438, irr5:221.6893768310547, ndcg5:0.8610490197483734, pnl5:2.5772411823272705 
train 1, step: 0, loss: 2.7765664377520163, grad_norm: 0.922668307636566, ic: 0.029968563381997694
train 1, step: 500, loss: 1.7519721768801133, grad_norm: 0.8019107263953098, ic: 0.1051304362438985
train 1, step: 1000, loss: 0.8787857841165799, grad_norm: 0.18371066976069717, ic: 0.06116248626643656
train 1, step: 1500, loss: 1.7148210196659484, grad_norm: 0.21725358553917298, ic: -0.013472267112422154
train 1, step: 2000, loss: 2.1810644531250003, grad_norm: 0.9291608338840673, ic: -0.01304181393979864
Epoch 1: 2022-04-27 22:45:57.084871: train loss: 1.6467888610509718
Eval step 0: eval loss: 0.8341957791713316
Eval: 2022-04-27 22:47:29.923247: total loss: 1.0789354317232274, mse:4.823902832625854, ic :0.008441648307095515, sharpe5:7.398943425714969, irr5:209.2897186279297, ndcg5:0.8584837477831433, pnl5:2.6748805046081543 
train 2, step: 0, loss: 2.141806818181818, grad_norm: 0.009985174586029122, ic: 0.15002081469013573
train 2, step: 500, loss: 3.301287488385172, grad_norm: 0.2937141175579021, ic: 0.06383097888478377
train 2, step: 1000, loss: 2.0724452227011496, grad_norm: 0.00024280782580292913, ic: 0.14192127985005948
train 2, step: 1500, loss: 1.4872405772900763, grad_norm: 0.06312403025906237, ic: -0.0707649878212028
train 2, step: 2000, loss: 3.233193359375, grad_norm: 0.8047308247212972, ic: 0.22225694364013332
Epoch 2: 2022-04-27 23:09:41.995947: train loss: 1.646490851951956
Eval step 0: eval loss: 0.8359640621912868
Eval: 2022-04-27 23:11:07.352863: total loss: 1.0793819725734348, mse:4.82229196121234, ic :0.015863154198688497, sharpe5:7.535332197546959, irr5:214.27317810058594, ndcg5:0.854446189773022, pnl5:2.8289661407470703 
train 3, step: 0, loss: 1.521923034171748, grad_norm: 0.5358919821826472, ic: 0.0009428016965007564
train 3, step: 500, loss: 1.5030091240150254, grad_norm: 0.3506633249327409, ic: 0.0884943700716988
train 3, step: 1000, loss: 3.6781959511729996, grad_norm: 0.7192608376072719, ic: 0.024073427841394483
train 3, step: 1500, loss: 1.9784285175429623, grad_norm: 1.19297582239331, ic: -0.04374421109386231
train 3, step: 2000, loss: 0.8978626478040541, grad_norm: 0.0011230736635385223, ic: 0.025294890137886224
Epoch 3: 2022-04-27 23:33:32.310734: train loss: 1.645759182565274
Eval step 0: eval loss: 0.8344520753753951
Eval: 2022-04-27 23:35:00.440457: total loss: 1.0780830793864478, mse:4.820095758186402, ic :0.03333384703179005, sharpe5:7.236888851523399, irr5:170.442138671875, ndcg5:0.8533163406973815, pnl5:2.5773978233337402 
train 4, step: 0, loss: 1.4367431640625001, grad_norm: 0.04371615342583835, ic: 0.07327191142960501
train 4, step: 500, loss: 1.6483050489050197, grad_norm: 0.5676390889773856, ic: 0.10943970580150075
train 4, step: 1000, loss: 2.96510463807641, grad_norm: 0.705694551953191, ic: 0.05765805765118349
train 4, step: 1500, loss: 2.1483726018591773, grad_norm: 0.4736936709225913, ic: 0.004391161937494909
train 4, step: 2000, loss: 1.055725287501215, grad_norm: 0.4213760142943063, ic: 0.2601186977904242
Epoch 4: 2022-04-27 23:57:25.716029: train loss: 1.643823876917227
Eval step 0: eval loss: 0.875425895473854
Eval: 2022-04-27 23:58:53.096833: total loss: 1.097985113174493, mse:4.766903754492288, ic :0.14694965449992173, sharpe5:12.519856524467468, irr5:436.5840759277344, ndcg5:0.8409662771077185, pnl5:3.75787615776062 
train 5, step: 0, loss: 1.3734866558305368, grad_norm: 0.4337897469519717, ic: 0.3421228683974459
train 5, step: 500, loss: 0.8835695101853688, grad_norm: 0.013202877023973117, ic: 0.9405322487196072
train 5, step: 1000, loss: 0.9934725589679119, grad_norm: 0.19049332999648577, ic: -0.06623862889732782
train 5, step: 1500, loss: 1.5277706222183671, grad_norm: 0.1929346367080633, ic: 0.10409859646462642
train 5, step: 2000, loss: 1.0987016363652842, grad_norm: 0.05591843376250945, ic: 0.1956964446926018
Epoch 5: 2022-04-28 00:20:58.646304: train loss: 1.6348820579696905
Eval step 0: eval loss: 0.828811114907139
Eval: 2022-04-28 00:22:26.982433: total loss: 1.072792272454819, mse:4.685291766023688, ic :0.16647250714399361, sharpe5:16.788071984052657, irr5:548.8446655273438, ndcg5:0.8417395386997203, pnl5:8.540895462036133 
train 6, step: 0, loss: 1.331868684272827, grad_norm: 0.4753895452784499, ic: 0.19062434975166004
train 6, step: 500, loss: 1.0076048122248278, grad_norm: 0.04963643763893996, ic: 0.0493240235370861
train 6, step: 1000, loss: 1.1129224653932983, grad_norm: 0.17483585635158705, ic: 0.638819963684607
train 6, step: 1500, loss: 1.5650336147339876, grad_norm: 0.7659348741979228, ic: 0.12915914843817033
train 6, step: 2000, loss: 0.805886701548739, grad_norm: 0.058352533794589476, ic: 0.36796674165416293
Epoch 6: 2022-04-28 00:44:31.212253: train loss: 1.6291594983784705
Eval step 0: eval loss: 0.8253400217745652
Eval: 2022-04-28 00:46:05.612023: total loss: 1.0700879427906138, mse:4.681672477829139, ic :0.16909673451055135, sharpe5:17.32360782623291, irr5:573.5042114257812, ndcg5:0.8461535170395134, pnl5:7.690051078796387 
train 7, step: 0, loss: 0.9869943618774415, grad_norm: 0.06284681927683708, ic: 0.15036558507791903
train 7, step: 500, loss: 0.6507597578332779, grad_norm: 0.00809597878003833, ic: 0.058925645011740656
train 7, step: 1000, loss: 1.033959998125714, grad_norm: 0.7328984844863112, ic: 0.17187572939380982
train 7, step: 1500, loss: 2.2440527029742765, grad_norm: 0.8239899855494276, ic: 0.44008691135818756
train 7, step: 2000, loss: 0.9136083353316842, grad_norm: 0.07192584156835888, ic: -0.028303114352565203
Epoch 7: 2022-04-28 01:08:17.685047: train loss: 1.62874765473317
Eval step 0: eval loss: 0.8293597238458245
Eval: 2022-04-28 01:09:49.980556: total loss: 1.0720785806294648, mse:4.684613183135215, ic :0.1650901164423061, sharpe5:15.552243688702582, irr5:528.4647216796875, ndcg5:0.8476841641650569, pnl5:3.9766440391540527 
train 8, step: 0, loss: 3.6014726279438407, grad_norm: 1.194730968769769, ic: 0.21718844731207465
train 8, step: 500, loss: 2.763608613637443, grad_norm: 0.9473451036596849, ic: 0.01965108379489724
train 8, step: 1000, loss: 3.0609682829483695, grad_norm: 0.9523545339156557, ic: 0.1119056162034186
train 8, step: 1500, loss: 0.7143307837546239, grad_norm: 0.034378163035412794, ic: 0.44915785536610076
train 8, step: 2000, loss: 1.0940584319992632, grad_norm: 0.3680777562006129, ic: 0.5040731163678278
Epoch 8: 2022-04-28 01:32:13.538833: train loss: 1.6276902804206688
Eval step 0: eval loss: 0.8240553249925908
Eval: 2022-04-28 01:33:41.873315: total loss: 1.0690350087798595, mse:4.673201404302184, ic :0.17511863524665774, sharpe5:17.55865523099899, irr5:586.6692504882812, ndcg5:0.8436397367163427, pnl5:6.580419063568115 
train 9, step: 0, loss: 5.4465624065490434, grad_norm: 1.0673298667936386, ic: 0.1994777589763205
train 9, step: 500, loss: 1.3383904207429085, grad_norm: 1.6653475995054108, ic: 0.35127264376574724
train 9, step: 1000, loss: 0.926304007594417, grad_norm: 0.18110063581635738, ic: 0.10495274985742689
train 9, step: 1500, loss: 1.089979213888761, grad_norm: 0.010954427435446737, ic: 0.39086885856899956
train 9, step: 2000, loss: 1.0633136370119167, grad_norm: 0.19985856016593162, ic: 0.25605590621109475
Epoch 9: 2022-04-28 01:55:51.721568: train loss: 1.6277292573524704
Eval step 0: eval loss: 0.8295296446917808
Eval: 2022-04-28 01:57:17.591726: total loss: 1.0726965312248824, mse:4.686966475705561, ic :0.16294437587883345, sharpe5:17.250298583507536, irr5:571.47802734375, ndcg5:0.8511343160234983, pnl5:4.887296676635742 
train 10, step: 0, loss: 7.080130796738338, grad_norm: 2.3749965411158307, ic: 0.27005046858987625
train 10, step: 500, loss: 1.1364239224085066, grad_norm: 0.12174697705202159, ic: 0.03543758722914219
train 10, step: 1000, loss: 2.3783756560343177, grad_norm: 1.17236044247978, ic: 0.17390474133515527
train 10, step: 1500, loss: 1.109865461077009, grad_norm: 0.36818617623266797, ic: -0.00562296372741591
train 10, step: 2000, loss: 2.726334684887918, grad_norm: 0.5413739733858092, ic: 0.44996498908225335
Epoch 10: 2022-04-28 02:19:33.640211: train loss: 1.6268405517395206
Eval step 0: eval loss: 0.8241626028014686
Eval: 2022-04-28 02:21:04.809174: total loss: 1.0679915989620379, mse:4.670294934074286, ic :0.1756027698049164, sharpe5:17.61043520450592, irr5:585.64453125, ndcg5:0.8387509922254803, pnl5:9.611042022705078 
train 11, step: 0, loss: 1.245802405077823, grad_norm: 0.0225857591287706, ic: 0.2148211381231772
train 11, step: 500, loss: 0.652401100174575, grad_norm: 0.051314227415788706, ic: 0.5397024951986538
train 11, step: 1000, loss: 0.9391022105897053, grad_norm: 0.2248871298135024, ic: 0.04596284408334446
train 11, step: 1500, loss: 1.0665023536012883, grad_norm: 0.6811952726677648, ic: 0.14590455758769044
train 11, step: 2000, loss: 0.7862162657823608, grad_norm: 0.006520678187681414, ic: 0.12820615897518853
Epoch 11: 2022-04-28 02:43:31.526804: train loss: 1.62514294440673
Eval step 0: eval loss: 0.8284374434025947
Eval: 2022-04-28 02:45:01.858173: total loss: 1.0688973101248864, mse:4.641683804030372, ic :0.18348813551271884, sharpe5:16.68160993695259, irr5:566.0995483398438, ndcg5:0.8258464257837421, pnl5:4.647989273071289 
train 12, step: 0, loss: 0.9703283309936523, grad_norm: 0.11145011290236406, ic: 0.3871798460734653
train 12, step: 500, loss: 0.9288206108274468, grad_norm: 0.10959902154837306, ic: 0.1766457012170661
train 12, step: 1000, loss: 2.9534406722730893, grad_norm: 0.34774132313530653, ic: 0.32434909568394554
train 12, step: 1500, loss: 0.9511095847415271, grad_norm: 0.39008451359783763, ic: -0.09411551827337633
train 12, step: 2000, loss: 0.8739800121849037, grad_norm: 0.008385984806121991, ic: 0.20696322258372668
Epoch 12: 2022-04-28 03:07:07.634936: train loss: 1.6236455094098474
Eval step 0: eval loss: 0.82632610292907
Eval: 2022-04-28 03:08:40.242184: total loss: 1.066831893539878, mse:4.597069022044925, ic :0.18645593180136547, sharpe5:16.91507953763008, irr5:556.03173828125, ndcg5:0.8359065718305804, pnl5:4.719544887542725 
train 13, step: 0, loss: 2.0785331041281676, grad_norm: 1.1016200602484534, ic: 0.4426575266740392
train 13, step: 500, loss: 0.8191189421150239, grad_norm: 0.04086468459364235, ic: 0.5878473582305846
train 13, step: 1000, loss: 0.9440700044567952, grad_norm: 0.4214944267378218, ic: 0.5950222791688957
train 13, step: 1500, loss: 2.4723353032298987, grad_norm: 1.2931039895259753, ic: -0.06315780746034512
train 13, step: 2000, loss: 1.4628489011980368, grad_norm: 0.12823045329796787, ic: 0.2112129798599645
Epoch 13: 2022-04-28 03:31:02.969341: train loss: 1.6219894057200475
Eval step 0: eval loss: 0.82281269037309
Eval: 2022-04-28 03:32:28.446624: total loss: 1.0660437391735538, mse:4.604617673561966, ic :0.18482419039692624, sharpe5:17.288332364559174, irr5:576.3843383789062, ndcg5:0.8563908534619021, pnl5:5.684093475341797 
train 14, step: 0, loss: 4.494400381484009, grad_norm: 2.2292496324004683, ic: 0.20384679781771214
train 14, step: 500, loss: 0.8259101891007263, grad_norm: 0.01665068714239185, ic: 0.11539060559391781
train 14, step: 1000, loss: 1.8055213227268414, grad_norm: 0.23130252040038718, ic: 0.4587342277647762
train 14, step: 1500, loss: 1.1297487651160225, grad_norm: 0.11180841475587917, ic: -0.07089184230552825
train 14, step: 2000, loss: 1.1541894616217734, grad_norm: 0.713120416053366, ic: 0.09702432623849762
Epoch 14: 2022-04-28 03:54:35.435523: train loss: 1.6201128218162313
Eval step 0: eval loss: 0.8324616475401738
Eval: 2022-04-28 03:56:00.885281: total loss: 1.0675006777046665, mse:4.590955396281213, ic :0.1838592681577098, sharpe5:16.79552966237068, irr5:554.0640869140625, ndcg5:0.8677847131455352, pnl5:3.804107427597046 
train 15, step: 0, loss: 3.4284343081225686, grad_norm: 2.048679080361617, ic: 0.0815678605769747
train 15, step: 500, loss: 1.258773943234362, grad_norm: 0.03794728174210173, ic: 0.05581099073024487
train 15, step: 1000, loss: 1.316140077172256, grad_norm: 0.17941374081039047, ic: 0.06656986970250944
train 15, step: 1500, loss: 0.841336852546752, grad_norm: 0.42423740805639143, ic: 0.07763173422717659
train 15, step: 2000, loss: 1.449523434354871, grad_norm: 0.9122036173570404, ic: 0.05675389537999092
Epoch 15: 2022-04-28 04:18:04.446343: train loss: 1.6199829021914374
Eval step 0: eval loss: 0.8342089637941253
Eval: 2022-04-28 04:19:25.935000: total loss: 1.069903464380866, mse:4.5872708339507, ic :0.18801832782766809, sharpe5:17.194521127939222, irr5:582.2144165039062, ndcg5:0.8440590256938347, pnl5:4.830889701843262 
train 16, step: 0, loss: 0.6864063447180572, grad_norm: 1.542990621540796, ic: 0.041524195216824225
train 16, step: 500, loss: 1.5935949080201166, grad_norm: 0.7625617385967525, ic: 0.18307642295339116
train 16, step: 1000, loss: 0.8768388227982955, grad_norm: 0.016644372704005095, ic: -0.04023106101997034
train 16, step: 1500, loss: 0.8345804898357467, grad_norm: 0.40041415321931956, ic: 0.11467972849694749
train 16, step: 2000, loss: 3.327045015418559, grad_norm: 1.8857008626972895, ic: 0.015018286344849197
Epoch 16: 2022-04-28 04:41:26.976339: train loss: 1.6188851610565718
Eval step 0: eval loss: 0.8309407209068757
Eval: 2022-04-28 04:42:52.237374: total loss: 1.0685296157720388, mse:4.595696573764128, ic :0.18459828685668606, sharpe5:16.7343282687664, irr5:562.7939453125, ndcg5:0.8395788893597496, pnl5:4.9189229011535645 
train 17, step: 0, loss: 1.2645661938411803, grad_norm: 0.5782371650525382, ic: -0.08991128584382369
train 17, step: 500, loss: 1.7622762375084688, grad_norm: 0.9609776600233688, ic: 0.20900739494510354
train 17, step: 1000, loss: 1.283034711981376, grad_norm: 0.12390703162337807, ic: 0.1814593869147105
train 17, step: 1500, loss: 4.515112681392358, grad_norm: 1.7126803527820749, ic: 0.19428124806840524
train 17, step: 2000, loss: 1.2878669489918955, grad_norm: 1.7944720425043355, ic: 0.11311642565095463
Epoch 17: 2022-04-28 05:05:24.544155: train loss: 1.6187471734813725
Eval step 0: eval loss: 0.83157512636657
Eval: 2022-04-28 05:06:47.397957: total loss: 1.066968653468822, mse:4.582264386463526, ic :0.19301728012728947, sharpe5:17.475162152051926, irr5:594.7001953125, ndcg5:0.8530940963229164, pnl5:4.8651556968688965 
train 18, step: 0, loss: 1.4173730929755115, grad_norm: 0.8936725343295158, ic: 0.2336973202280722
train 18, step: 500, loss: 1.4810764414346247, grad_norm: 3.20141988267126, ic: 0.02619367787717464
train 18, step: 1000, loss: 0.6555674764554794, grad_norm: 0.029749332016221913, ic: 0.569919487214362
train 18, step: 1500, loss: 1.4254199378711099, grad_norm: 0.07908345502619195, ic: 0.2134540070956957
train 18, step: 2000, loss: 0.9110809131792397, grad_norm: 0.015950468705255332, ic: -0.0018837859866621467
Epoch 18: 2022-04-28 05:29:02.899602: train loss: 1.6190288386335185
Eval step 0: eval loss: 0.8235902615417544
Eval: 2022-04-28 05:30:29.460972: total loss: 1.064899137618213, mse:4.589805448898351, ic :0.19028655467274735, sharpe5:17.668221806287765, irr5:591.3494873046875, ndcg5:0.8346130955965912, pnl5:4.908105850219727 
train 19, step: 0, loss: 1.475711689298115, grad_norm: 1.2964814863507577, ic: -0.011514119189589903
train 19, step: 500, loss: 0.8641751607259114, grad_norm: 0.11680109659731831, ic: 0.21718135152266368
train 19, step: 1000, loss: 0.9541610683015377, grad_norm: 0.007147005173201784, ic: 0.19851726143986165
train 19, step: 1500, loss: 3.9592012363843994, grad_norm: 1.7421185037778444, ic: 0.140710896566692
train 19, step: 2000, loss: 0.9999692007211538, grad_norm: 0.35248662957050747, ic: 0.19305120769763331
Epoch 19: 2022-04-28 05:52:59.844824: train loss: 1.61907122712808
Eval step 0: eval loss: 0.8253402790354978
Eval: 2022-04-28 05:54:23.926380: total loss: 1.065195325355568, mse:4.588107594419565, ic :0.19423615712074974, sharpe5:17.400348887443542, irr5:596.04345703125, ndcg5:0.8332779375548057, pnl5:5.443628787994385 
train 20, step: 0, loss: 2.3342848706151185, grad_norm: 2.245150223971577, ic: 0.04596075219225632
train 20, step: 500, loss: 3.2330699573863635, grad_norm: 1.4584082243923926, ic: 0.04611493944277925
train 20, step: 1000, loss: 0.9654838562011719, grad_norm: 0.116138816342956, ic: 0.14707113337508446
train 20, step: 1500, loss: 1.7831507824464012, grad_norm: 5.087699146216867, ic: 0.24786044906087398
train 20, step: 2000, loss: 1.0143877685945146, grad_norm: 0.08845706624122872, ic: 0.08246952345100635
Epoch 20: 2022-04-28 06:16:47.280087: train loss: 1.6182019485603467
Eval step 0: eval loss: 0.8346367887249736
Eval: 2022-04-28 06:18:14.598324: total loss: 1.0706734763582602, mse:4.670496045087261, ic :0.1791466794076695, sharpe5:17.21843980550766, irr5:588.2803955078125, ndcg5:0.857555826119938, pnl5:6.002269268035889 
train 21, step: 0, loss: 1.0028267983350019, grad_norm: 0.37537437093182235, ic: 0.08183645032794148
train 21, step: 500, loss: 0.764307612866427, grad_norm: 0.019453841135848058, ic: 0.20096983516496864
train 21, step: 1000, loss: 0.9342558342113829, grad_norm: 2.4286881888141023, ic: 0.15381718935070995
train 21, step: 1500, loss: 0.9875198265388768, grad_norm: 0.4307126309359694, ic: 0.3116304315458537
train 21, step: 2000, loss: 0.9289120223171027, grad_norm: 0.07919612441915762, ic: 0.09992459657058891
Epoch 21: 2022-04-28 06:37:45.239797: train loss: 1.6166875559738696
Eval step 0: eval loss: 0.823629107942571
Eval: 2022-04-28 06:38:32.570306: total loss: 1.0644400678355694, mse:4.591552735615837, ic :0.19241905931975167, sharpe5:17.71707508563995, irr5:591.1340942382812, ndcg5:0.8487149152364482, pnl5:5.9442620277404785 
train 22, step: 0, loss: 1.04029501360015, grad_norm: 0.01744769452338392, ic: 0.221592907308977
train 22, step: 500, loss: 3.2670870649136177, grad_norm: 0.9511286396100952, ic: -0.2429609733288323
train 22, step: 1000, loss: 1.1883901959898844, grad_norm: 0.13852643888598803, ic: 0.4759348033043845
train 22, step: 1500, loss: 0.9674707232188786, grad_norm: 0.08881352414121527, ic: 0.10042306428254184
train 22, step: 2000, loss: 1.7475799076140874, grad_norm: 1.8730401317649328, ic: 0.1266311756615842
Epoch 22: 2022-04-28 06:50:57.114053: train loss: 1.6168652545322444
Eval step 0: eval loss: 0.8234032971590161
Eval: 2022-04-28 06:51:45.635945: total loss: 1.0658202955719556, mse:4.598851091020346, ic :0.19141568595051234, sharpe5:17.778068375587463, irr5:604.8178100585938, ndcg5:0.835909884485698, pnl5:6.322751522064209 
train 23, step: 0, loss: 0.979995243831052, grad_norm: 0.04538534369133332, ic: 0.14308117025248562
train 23, step: 500, loss: 1.4194671295501375, grad_norm: 0.299823382472171, ic: 0.0677891596215055
train 23, step: 1000, loss: 1.6533868408203125, grad_norm: 0.08912495825630318, ic: 0.2582668520351787
train 23, step: 1500, loss: 1.1331145373656946, grad_norm: 1.0900802577285564, ic: 0.10137310824785524
train 23, step: 2000, loss: 1.8867478814833525, grad_norm: 1.9607556463947171, ic: 0.4384318016897051
Epoch 23: 2022-04-28 07:04:03.728260: train loss: 1.6176322871779063
Eval step 0: eval loss: 0.8293927818756586
Eval: 2022-04-28 07:04:51.810465: total loss: 1.065606657301326, mse:4.578056658151463, ic :0.1947283428984635, sharpe5:17.354539597034453, irr5:585.9872436523438, ndcg5:0.8506663411654276, pnl5:3.4837076663970947 
train 24, step: 0, loss: 2.182048014078898, grad_norm: 0.14061956472884618, ic: 0.18410717611205246
train 24, step: 500, loss: 1.2141406819978113, grad_norm: 0.38535937573659024, ic: 0.21089319391478817
train 24, step: 1000, loss: 0.90997837847105, grad_norm: 0.06677559327969762, ic: 0.5197203046452112
train 24, step: 1500, loss: 2.6180936179668177, grad_norm: 2.190670886021897, ic: 0.06124763452130967
train 24, step: 2000, loss: 0.9313833521164425, grad_norm: 0.09263777981517753, ic: 0.12381559931203624
Epoch 24: 2022-04-28 07:17:07.499982: train loss: 1.614954355010036
Eval step 0: eval loss: 0.8231182520457389
Eval: 2022-04-28 07:17:56.423959: total loss: 1.0656586853615844, mse:4.603595424217294, ic :0.1907900260007575, sharpe5:17.62357411265373, irr5:590.7693481445312, ndcg5:0.8650488077309366, pnl5:5.604682445526123 
train 25, step: 0, loss: 0.8307211386190879, grad_norm: 0.059946441278119586, ic: 0.6165823805467527
train 25, step: 500, loss: 0.8656080539853191, grad_norm: 0.006024719426130163, ic: 0.2554154504573229
train 25, step: 1000, loss: 2.1097041156940213, grad_norm: 0.29847457962414603, ic: 0.23440678914405697
train 25, step: 1500, loss: 1.1311053326391238, grad_norm: 0.4030186509994158, ic: 0.5403010881348151
train 25, step: 2000, loss: 1.0055017199969638, grad_norm: 0.6351634007171729, ic: 0.6047043093688348
Epoch 25: 2022-04-28 07:30:03.394997: train loss: 1.6165312066711777
Eval step 0: eval loss: 0.8223723882870125
Eval: 2022-04-28 07:30:52.136360: total loss: 1.0635340660519081, mse:4.5975601729330835, ic :0.19951959085752427, sharpe5:19.168492147922514, irr5:633.5416259765625, ndcg5:0.871469194054035, pnl5:6.593067646026611 
train 26, step: 0, loss: 6.798379623851837, grad_norm: 17.79962659714146, ic: 0.11764801939944582
train 26, step: 500, loss: 3.8826334508160674, grad_norm: 1.6191186052519992, ic: 0.38185772581104627
train 26, step: 1000, loss: 1.2719731353328592, grad_norm: 1.210627971977018, ic: -0.051851757425868616
train 26, step: 1500, loss: 0.8238481258190979, grad_norm: 0.24314780290230847, ic: 0.31499651295101727
train 26, step: 2000, loss: 0.95107083804583, grad_norm: 0.35997223206591566, ic: 0.15202131921432538
Epoch 26: 2022-04-28 07:43:10.733182: train loss: 1.6159678475833372
Eval step 0: eval loss: 0.8233540960056638
Eval: 2022-04-28 07:44:00.171554: total loss: 1.0640501710523114, mse:4.587434129491593, ic :0.19456229861344224, sharpe5:17.83482770204544, irr5:594.2451782226562, ndcg5:0.8487490158171038, pnl5:4.578296661376953 
train 27, step: 0, loss: 0.829788028492647, grad_norm: 0.02861076318652491, ic: 0.12103368859796024
train 27, step: 500, loss: 0.937711951698783, grad_norm: 2.06557418236875, ic: 0.2564351939171588
train 27, step: 1000, loss: 0.7492315140419568, grad_norm: 0.3554488858853185, ic: 0.19539342486865724
train 27, step: 1500, loss: 0.6479259735871191, grad_norm: 0.11840660010520081, ic: 0.5097789587823678
train 27, step: 2000, loss: 1.3824501819654045, grad_norm: 0.17429543789129825, ic: 0.0524640484759125
Epoch 27: 2022-04-28 07:56:17.508043: train loss: 1.6124137102057565
Eval step 0: eval loss: 0.8243610796109391
Eval: 2022-04-28 07:57:05.533651: total loss: 1.0635659841275196, mse:4.58433222423778, ic :0.19817961333314155, sharpe5:18.228565496206283, irr5:606.8177490234375, ndcg5:0.8515117160771984, pnl5:6.897632598876953 
train 28, step: 0, loss: 1.5378787478885134, grad_norm: 1.3242189779143474, ic: 0.22176633129299647
train 28, step: 500, loss: 1.3946850490410145, grad_norm: 4.054908705777076, ic: 0.17386445384243499
train 28, step: 1000, loss: 0.9282992396574357, grad_norm: 0.35049463813813403, ic: 0.5750544141209213
train 28, step: 1500, loss: 1.0340958412247474, grad_norm: 0.046460676562792236, ic: 0.02621490427545327
train 28, step: 2000, loss: 1.050761685049607, grad_norm: 0.5686601917551615, ic: 0.07104549149996572
Epoch 28: 2022-04-28 08:09:13.566009: train loss: 1.6082680106833422
Eval step 0: eval loss: 0.82450283038478
Eval: 2022-04-28 08:10:03.866946: total loss: 1.0792487323210707, mse:4.699279227823266, ic :0.17691246145476122, sharpe5:18.527328565120698, irr5:609.8629760742188, ndcg5:0.8494220162697572, pnl5:7.388702869415283 
train 29, step: 0, loss: 0.9162585625059231, grad_norm: 0.09895330942645744, ic: 0.0679585593159251
train 29, step: 500, loss: 1.1083098415480035, grad_norm: 0.3101187176246707, ic: 0.6135580740633365
train 29, step: 1000, loss: 1.0809922002410304, grad_norm: 0.5798307887104247, ic: 0.06352887934634184
train 29, step: 1500, loss: 2.34503435883831, grad_norm: 0.437607094444393, ic: -0.06947867335152368
train 29, step: 2000, loss: 4.181479748384452, grad_norm: 7.826536576536665, ic: 0.2094298363102495
Epoch 29: 2022-04-28 08:22:19.058914: train loss: 1.611762084321923
Eval step 0: eval loss: 0.8265903099068097
Eval: 2022-04-28 08:23:03.306578: total loss: 1.0635561108853115, mse:4.57502729058419, ic :0.20043397173441607, sharpe5:18.539559384584425, irr5:615.5784912109375, ndcg5:0.8469306891986608, pnl5:7.605101108551025 
train 30, step: 0, loss: 1.0143554074466417, grad_norm: 0.09244443486449705, ic: 0.5125903469327432
train 30, step: 500, loss: 1.4004413958354698, grad_norm: 2.0413139702677108, ic: 0.03047221385503127
train 30, step: 1000, loss: 0.9878956187855114, grad_norm: 0.20227761130867217, ic: -0.06719215744403423
train 30, step: 1500, loss: 1.4753516043452062, grad_norm: 3.2903558300343603, ic: 0.18724952228149527
train 30, step: 2000, loss: 1.8182555171671766, grad_norm: 0.220373965808824, ic: 0.11818727527974007
Epoch 30: 2022-04-28 08:35:37.556322: train loss: 1.6097068802404972
Eval step 0: eval loss: 0.8314976908258693
Eval: 2022-04-28 08:36:26.667578: total loss: 1.0670440622596296, mse:4.610847966771956, ic :0.19803702322808078, sharpe5:17.67340358734131, irr5:593.2267456054688, ndcg5:0.8398162385453201, pnl5:5.786283016204834 
train 31, step: 0, loss: 1.038556791988868, grad_norm: 0.24994481736856683, ic: 0.3519603069339786
train 31, step: 500, loss: 1.4414183063271604, grad_norm: 1.6730466704907652, ic: -0.009332538829758368
train 31, step: 1000, loss: 4.407356923302108, grad_norm: 2.2257874072040638, ic: 0.47083842269951437
train 31, step: 1500, loss: 0.7689430856514231, grad_norm: 0.21470417375522466, ic: 0.7122922022282119
train 31, step: 2000, loss: 1.2372460640672491, grad_norm: 2.8181038620510614, ic: 0.22285739016919615
Epoch 31: 2022-04-28 08:49:11.959587: train loss: 1.605650902415664
Eval step 0: eval loss: 0.825550975739265
Eval: 2022-04-28 08:49:59.259396: total loss: 1.0633443048400464, mse:4.574111252427201, ic :0.19930797401368505, sharpe5:18.15064959526062, irr5:613.4031982421875, ndcg5:0.8326748834874281, pnl5:6.227986812591553 
train 32, step: 0, loss: 1.1192567012129775, grad_norm: 0.03900501875967134, ic: 0.20773242971897432
train 32, step: 500, loss: 1.5001893531619095, grad_norm: 1.22963667171721, ic: 0.1281473836568203
train 32, step: 1000, loss: 1.0498334321162313, grad_norm: 0.11257919913032635, ic: 0.5070056027170907
train 32, step: 1500, loss: 0.9422737779188121, grad_norm: 1.0130195616555033, ic: 0.058192632764403965
train 32, step: 2000, loss: 0.9390328446705352, grad_norm: 0.0402221993682612, ic: 0.5599406170941823
Epoch 32: 2022-04-28 09:02:24.777011: train loss: 1.604745454246108
Eval step 0: eval loss: 0.8198817165684272
Eval: 2022-04-28 09:03:13.123284: total loss: 1.0627095793137968, mse:4.585840479788543, ic :0.2000240359183862, sharpe5:18.8652491748333, irr5:623.8705444335938, ndcg5:0.8483744532080504, pnl5:9.360893249511719 
train 33, step: 0, loss: 1.2536891775220482, grad_norm: 0.7127341546807573, ic: 0.2553586611094437
train 33, step: 500, loss: 0.9781454041133498, grad_norm: 0.06433997314797203, ic: 0.21872940394873092
train 33, step: 1000, loss: 1.0514843645330922, grad_norm: 1.8627186253271542, ic: 0.22957031677537956
train 33, step: 1500, loss: 0.8968376983244366, grad_norm: 0.13347006540284756, ic: 0.5570348398767019
train 33, step: 2000, loss: 0.8114695601909172, grad_norm: 0.08745612934305554, ic: 0.2521080205255465
Epoch 33: 2022-04-28 09:15:44.199729: train loss: 1.6080811158630972
Eval step 0: eval loss: 0.821232207833904
Eval: 2022-04-28 09:16:27.423439: total loss: 1.0627649739560596, mse:4.575474879287183, ic :0.20363477823228673, sharpe5:18.599264323711395, irr5:610.55078125, ndcg5:0.8501296092556073, pnl5:4.738029479980469 
train 34, step: 0, loss: 0.9993379739818268, grad_norm: 0.5408722282959852, ic: 0.6052171102369011
train 34, step: 500, loss: 0.8041887662461774, grad_norm: 0.36826314518557896, ic: 0.23937150881349273
train 34, step: 1000, loss: 3.140533869167627, grad_norm: 2.0578936484975165, ic: 0.35057256170691065
train 34, step: 1500, loss: 0.8085357702389376, grad_norm: 0.42982254661908864, ic: 0.6875986846310626
train 34, step: 2000, loss: 2.831550911357475, grad_norm: 99.9058863707942, ic: 0.37360064827160955
Epoch 34: 2022-04-28 09:28:58.974219: train loss: 1.5955578957958751
Eval step 0: eval loss: 0.9181919881742294
Eval: 2022-04-28 09:29:44.689068: total loss: 1.2085679762871688, mse:5.774726165035236, ic :0.12300423187184753, sharpe5:16.938069316148756, irr5:568.5665283203125, ndcg5:0.8554574059410659, pnl5:5.2548041343688965 
train 35, step: 0, loss: 1.1643777286305146, grad_norm: 11.047192128117167, ic: 0.46863161553542526
train 35, step: 500, loss: 1.18654619468009, grad_norm: 0.5699027541539382, ic: 0.10056578065838911
train 35, step: 1000, loss: 1.8243745127554405, grad_norm: 3.8201876579681624, ic: 0.08486346157496097
train 35, step: 1500, loss: 1.6219267651550753, grad_norm: 1.549916956851015, ic: 0.025429373204275865
train 35, step: 2000, loss: 0.7893622903262867, grad_norm: 0.07166336447524511, ic: 0.5465783285305569
Epoch 35: 2022-04-28 09:42:19.216965: train loss: 1.6056899321836737
Eval step 0: eval loss: 0.824954387636657
Eval: 2022-04-28 09:43:00.511710: total loss: 1.0635438989848849, mse:4.5763728809927, ic :0.19985618717994466, sharpe5:18.293675454854963, irr5:604.6981201171875, ndcg5:0.847171620502518, pnl5:7.1943488121032715 
train 36, step: 0, loss: 1.838648725716248, grad_norm: 2.6941384947773006, ic: 0.10556808547242563
train 36, step: 500, loss: 0.8528059049325256, grad_norm: 0.15226318404040623, ic: 0.0039667610920062005
train 36, step: 1000, loss: 1.6544438920454545, grad_norm: 2.712501746828296, ic: 0.26968883706427277
train 36, step: 1500, loss: 0.7660812368014944, grad_norm: 0.10362090143898808, ic: 0.39307800886362754
train 36, step: 2000, loss: 1.14156530015141, grad_norm: 0.7285084361681389, ic: 0.7303406816880669
Epoch 36: 2022-04-28 09:55:01.391445: train loss: 1.6087653087854448
Eval step 0: eval loss: 0.8324541869731296
Eval: 2022-04-28 09:55:46.321677: total loss: 1.067567218901571, mse:4.594788271817251, ic :0.19555209240936594, sharpe5:18.295567306280134, irr5:603.4912719726562, ndcg5:0.8402429077781329, pnl5:5.475528717041016 
train 37, step: 0, loss: 1.962580308432236, grad_norm: 3.189042246960088, ic: 0.22335424118983405
train 37, step: 500, loss: 2.337448344145086, grad_norm: 1.2552166640798819, ic: -0.03635070646781469
train 37, step: 1000, loss: 1.0607135372074772, grad_norm: 0.3435145472774951, ic: 0.06076830649114651
train 37, step: 1500, loss: 1.9985750159438778, grad_norm: 1.9399585211742045, ic: 0.6164614976618273
train 37, step: 2000, loss: 1.3046466409169954, grad_norm: 0.26976933486037985, ic: 0.2535019354038486
Epoch 37: 2022-04-28 10:08:12.681426: train loss: 1.605932820726645
Eval step 0: eval loss: 0.823648788403912
Eval: 2022-04-28 10:08:59.292990: total loss: 1.0666548526003556, mse:4.598950488031767, ic :0.19697527376642585, sharpe5:18.94790037989616, irr5:620.529052734375, ndcg5:0.8434874767321908, pnl5:6.796894550323486 
train 38, step: 0, loss: 1.338967486125667, grad_norm: 0.3432637255989817, ic: -0.0824986744618245
train 38, step: 500, loss: 0.911709255642361, grad_norm: 0.09503124242440553, ic: 0.2680060574370647
train 38, step: 1000, loss: 0.9005087388833992, grad_norm: 0.32795590940784236, ic: 0.20246761411331263
train 38, step: 1500, loss: 0.9538379573604784, grad_norm: 0.068595190228904, ic: 0.21199319192850685
train 38, step: 2000, loss: 2.293292549801737, grad_norm: 6.865862897019797, ic: 0.04672206854849649
Epoch 38: 2022-04-28 10:21:12.614384: train loss: 1.6029646681554106
Eval step 0: eval loss: 0.8225345913049921
Eval: 2022-04-28 10:21:47.871672: total loss: 1.0637774039916204, mse:4.580882710718762, ic :0.1987482734630086, sharpe5:18.459861359596253, irr5:624.299072265625, ndcg5:0.8434625861632495, pnl5:5.246361255645752 
train 39, step: 0, loss: 0.9699070548427944, grad_norm: 0.007966471699997795, ic: 0.06535964916293042
train 39, step: 500, loss: 0.8894597492613855, grad_norm: 0.17421388693264936, ic: 0.22324915494356468
train 39, step: 1000, loss: 0.9429532797029703, grad_norm: 0.4081612579452374, ic: 0.1674569213123161
train 39, step: 1500, loss: 2.0631786412935815, grad_norm: 0.22901084256961896, ic: 0.21664324415225159
train 39, step: 2000, loss: 0.613293977710308, grad_norm: 0.08975698234496951, ic: 0.15530617303221866
Epoch 39: 2022-04-28 10:30:13.691802: train loss: 1.607361167561824
Eval step 0: eval loss: 0.8265921750485709
Eval: 2022-04-28 10:30:49.334257: total loss: 1.064463346330124, mse:4.587878764893534, ic :0.1927938816398637, sharpe5:18.49162176132202, irr5:611.3036499023438, ndcg5:0.8459670143068269, pnl5:8.878623008728027 

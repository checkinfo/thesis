Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='AdjSeqTimeDataset', dout=0.3, epochs=40, glstm_layers=1, gnn_layers=1, gpu=0, graph_attn=True, hidden_dim=128, inner_prod=False, input_dim=9, input_graph=True, label_cnt=3, lr=0.0004, lstm_layers=1, market=None, mask_adj=False, mask_type='soft', model_type='BiGLSTM', normalize_adj=True, num_days=8, num_heads=1, print_inteval=500, rank_loss=False, relation_num=1, rsr_data_path=None, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_250_0.8/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
62520
BiGLSTM(
  (input_to_hidden): Linear(in_features=9, out_features=128, bias=True)
  (forward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (attention): ModuleList(
            (0): GraphAttentionLayer (128 -> 128)
          )
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
          (lin_gate): Linear(in_features=128, out_features=128, bias=True)
        )
      )
    )
  )
  (backward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (attention): ModuleList(
            (0): GraphAttentionLayer (128 -> 128)
          )
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
          (lin_gate): Linear(in_features=128, out_features=128, bias=True)
        )
      )
    )
  )
  (fc0): ModuleList(
    (0): Linear(in_features=256, out_features=128, bias=True)
  )
  (w_out): Linear(in_features=128, out_features=1, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
)
train 0, step: 0, loss: 4.883979946491399, grad_norm: 5.067780056608495, ic: 0.011299796758358183
train 0, step: 500, loss: 0.8627023589099002, grad_norm: 0.02206821953696195, ic: 0.052714895081230645
train 0, step: 1000, loss: 1.9451830179567484, grad_norm: 0.5893908777610413, ic: 0.005248718963899914
train 0, step: 1500, loss: 0.9747626142539526, grad_norm: 0.11810052975125261, ic: 0.0790701397576403
train 0, step: 2000, loss: 0.9942394061600072, grad_norm: 0.15919605700358463, ic: 0.023188237635663245
Epoch 0: 2022-05-09 12:41:27.750804: train loss: 1.6493806292317086
Eval step 0: eval loss: 0.8351409558375592
Eval: 2022-05-09 12:41:37.176945: total loss: 1.078998521907629, mse:4.823393157868756, ic :0.007351828644137651, sharpe5:7.379548164904117, irr5:208.3437042236328, ndcg5:0.8467750392809152, pnl5:2.561756134033203 
train 1, step: 0, loss: 2.762479720577117, grad_norm: 0.9538345748974255, ic: 0.06164275206168128
train 1, step: 500, loss: 1.7642873736430147, grad_norm: 0.8591087575454286, ic: 0.10799203716367417
train 1, step: 1000, loss: 0.8747418874717621, grad_norm: 0.19436907065056236, ic: 0.058873795134595217
train 1, step: 1500, loss: 1.7120895911907328, grad_norm: 0.23698534245544534, ic: -0.02166999854234844
train 1, step: 2000, loss: 2.1933171875, grad_norm: 0.9754617678767817, ic: 0.04650475042825088
Epoch 1: 2022-05-09 12:45:09.947152: train loss: 1.6469116137317854
Eval step 0: eval loss: 0.8342067770761986
Eval: 2022-05-09 12:45:19.410958: total loss: 1.078832155318463, mse:4.823673495549075, ic :0.009137573756600664, sharpe5:7.268450135886669, irr5:205.64073181152344, ndcg5:0.8613897736734537, pnl5:2.6678478717803955 
train 2, step: 0, loss: 2.1428805042613637, grad_norm: 0.010543521342005684, ic: 0.12166199283003577
train 2, step: 500, loss: 3.3046959054675273, grad_norm: 0.31020905205079924, ic: 0.04070906586041272
train 2, step: 1000, loss: 2.072662610751916, grad_norm: 0.00021448898709725925, ic: 0.2185570517934475
train 2, step: 1500, loss: 1.486010462637166, grad_norm: 0.07050825204302825, ic: -0.010273750047112565
train 2, step: 2000, loss: 3.2322543569711537, grad_norm: 0.8807970345572019, ic: 0.20811622235833296
Epoch 2: 2022-05-09 12:48:51.012439: train loss: 1.6467879676033126
Eval step 0: eval loss: 0.8360377031332323
Eval: 2022-05-09 12:49:00.578933: total loss: 1.0794062844657875, mse:4.822349370934461, ic :0.012876028185183217, sharpe5:7.080231256484985, irr5:202.4051971435547, ndcg5:0.8507865677968421, pnl5:2.5815021991729736 
train 3, step: 0, loss: 1.5227049788808436, grad_norm: 0.6067074951199494, ic: 0.00834333970772592
train 3, step: 500, loss: 1.4936131512455952, grad_norm: 0.38626362676772485, ic: 0.1280798380728296
train 3, step: 1000, loss: 3.6724256867983596, grad_norm: 0.8010267129209562, ic: -0.037070368213586544
train 3, step: 1500, loss: 1.9952726223659984, grad_norm: 1.0518764502554059, ic: -0.055351144985428376
train 3, step: 2000, loss: 0.899664207664696, grad_norm: 0.00041314746664512553, ic: 0.0017328949003682058
Epoch 3: 2022-05-09 12:52:35.748975: train loss: 1.6463551367707112
Eval step 0: eval loss: 0.8330327668104583
Eval: 2022-05-09 12:52:45.263853: total loss: 1.0789974064016972, mse:4.826079620602554, ic :0.014291613603913149, sharpe5:8.237400153279305, irr5:241.29513549804688, ndcg5:0.8507031716580399, pnl5:2.5870518684387207 
train 4, step: 0, loss: 1.4374631297831633, grad_norm: 0.05379737518443222, ic: 0.12916714489360118
train 4, step: 500, loss: 1.6472648560531495, grad_norm: 0.665340240903988, ic: 0.01982432013770846
train 4, step: 1000, loss: 2.9561116288347944, grad_norm: 0.7524353487667929, ic: 0.03188808363264101
train 4, step: 1500, loss: 2.1409744198312235, grad_norm: 0.49817617896947386, ic: -0.01950104357077332
train 4, step: 2000, loss: 1.0852314665751361, grad_norm: 0.4650298847375459, ic: 0.2728373007822208
Epoch 4: 2022-05-09 12:56:18.512128: train loss: 1.6452872553148983
Eval step 0: eval loss: 0.8594515351274367
Eval: 2022-05-09 12:56:27.988303: total loss: 1.0909634158364028, mse:4.797929861841609, ic :0.11679735233877434, sharpe5:11.110018572807311, irr5:371.8221130371094, ndcg5:0.8533298723109087, pnl5:3.1482045650482178 
train 5, step: 0, loss: 1.3371716390520134, grad_norm: 0.2093781966984934, ic: 0.3603462283892015
train 5, step: 500, loss: 0.8854523552116376, grad_norm: 0.026834659168256995, ic: 0.860866186382315
train 5, step: 1000, loss: 0.9803997171336207, grad_norm: 0.17713793051353657, ic: 0.014053591641288006
train 5, step: 1500, loss: 1.5296204641438553, grad_norm: 0.17845714645520996, ic: 0.012318849021879377
train 5, step: 2000, loss: 1.0984392984837223, grad_norm: 0.029050545276799216, ic: 0.1790963916741479
Epoch 5: 2022-05-09 13:00:00.865973: train loss: 1.638796030422408
Eval step 0: eval loss: 0.8358034670541359
Eval: 2022-05-09 13:00:10.008459: total loss: 1.078459526358763, mse:4.738219795838471, ic :0.1252210745165081, sharpe5:11.76823530435562, irr5:395.0782470703125, ndcg5:0.838448633244684, pnl5:3.432742118835449 
train 6, step: 0, loss: 1.3336142702726277, grad_norm: 0.5035366797885442, ic: 0.11161504827718347
train 6, step: 500, loss: 1.0058019851287328, grad_norm: 0.049043231824272726, ic: 0.055000636768037736
train 6, step: 1000, loss: 1.1251492692490495, grad_norm: 0.10766163502886787, ic: 0.09988310433725894
train 6, step: 1500, loss: 1.5732199928977273, grad_norm: 0.8346540194627945, ic: 0.11380425919469866
train 6, step: 2000, loss: 0.806180784471327, grad_norm: 0.057105881055569324, ic: 0.06593781027104609
Epoch 6: 2022-05-09 13:03:44.179600: train loss: 1.6341760676322712
Eval step 0: eval loss: 0.8235983652611301
Eval: 2022-05-09 13:03:53.602358: total loss: 1.071081932274441, mse:4.692750319783584, ic :0.16167026720767363, sharpe5:15.519161828756332, irr5:501.6865234375, ndcg5:0.8487601020700195, pnl5:4.4619269371032715 
train 7, step: 0, loss: 0.9877155303955079, grad_norm: 0.046043993640586756, ic: 0.08281847936652986
train 7, step: 500, loss: 0.6512453027046923, grad_norm: 0.0023920465647563633, ic: 0.04830458844402082
train 7, step: 1000, loss: 1.0186206036093393, grad_norm: 0.207555119865023, ic: 0.1097231793481438
train 7, step: 1500, loss: 2.249502560205654, grad_norm: 0.6864578466199884, ic: 0.43986776618849366
train 7, step: 2000, loss: 0.9154455033950929, grad_norm: 0.05772124558712826, ic: -0.04622855014301853
Epoch 7: 2022-05-09 13:07:24.720368: train loss: 1.6310725738363507
Eval step 0: eval loss: 0.8295093210781085
Eval: 2022-05-09 13:07:34.161242: total loss: 1.0722121613486508, mse:4.679667224113678, ic :0.16707864596891114, sharpe5:16.163938847780226, irr5:524.5240478515625, ndcg5:0.8315364554058413, pnl5:5.698375701904297 
train 8, step: 0, loss: 3.5904410099637682, grad_norm: 1.4879001988962202, ic: 0.1677075038618787
train 8, step: 500, loss: 2.7547459008121202, grad_norm: 1.0594258663011447, ic: 0.035793289622732
train 8, step: 1000, loss: 3.059177918365036, grad_norm: 1.1333815700518648, ic: 0.10913498648627937
train 8, step: 1500, loss: 0.7165107397792078, grad_norm: 0.024594245714998283, ic: 0.48635488402824767
train 8, step: 2000, loss: 1.0879978530164391, grad_norm: 0.4593455592283264, ic: 0.5056661652185388
Epoch 8: 2022-05-09 13:11:07.243278: train loss: 1.6292473149543796
Eval step 0: eval loss: 0.8226829022326132
Eval: 2022-05-09 13:11:16.724988: total loss: 1.0697131256823327, mse:4.680108881623019, ic :0.17154042527246316, sharpe5:16.98659530520439, irr5:556.3980712890625, ndcg5:0.8407945736919095, pnl5:8.498406410217285 
train 9, step: 0, loss: 5.464145593475878, grad_norm: 0.8723715147446487, ic: 0.18493976227936587
train 9, step: 500, loss: 1.3407735870215312, grad_norm: 1.0931313345450198, ic: 0.325213466485045
train 9, step: 1000, loss: 0.9509576005105705, grad_norm: 16.723612236014194, ic: 0.04125145583288055
train 9, step: 1500, loss: 1.0913645051891567, grad_norm: 0.018523845821284572, ic: 0.40849638848555503
train 9, step: 2000, loss: 1.0670359974539385, grad_norm: 0.2847606691928814, ic: 0.2693384582184842
Epoch 9: 2022-05-09 13:14:50.075688: train loss: 1.628419062269998
Eval step 0: eval loss: 0.8228169351784773
Eval: 2022-05-09 13:14:59.578827: total loss: 1.071123311560427, mse:4.682425036523856, ic :0.16764381124183295, sharpe5:17.386080543994904, irr5:561.9425659179688, ndcg5:0.8250823029753369, pnl5:8.686840057373047 
train 10, step: 0, loss: 7.0773890192237605, grad_norm: 1.3330302769729334, ic: 0.24015269446248666
train 10, step: 500, loss: 1.122724643868966, grad_norm: 0.07937464085030362, ic: 0.07021157092755942
train 10, step: 1000, loss: 2.4257303249616564, grad_norm: 0.9847394782217357, ic: 0.020692993427427114
train 10, step: 1500, loss: 1.1273729398653105, grad_norm: 0.32100400839579263, ic: -0.008624917271675839
train 10, step: 2000, loss: 2.725297643783245, grad_norm: 0.4931765616364596, ic: 0.4599804545438303
Epoch 10: 2022-05-09 13:18:35.396333: train loss: 1.6284890389480342
Eval step 0: eval loss: 0.8259914064558087
Eval: 2022-05-09 13:18:44.852506: total loss: 1.0699122472608438, mse:4.659674353743515, ic :0.17767048268495114, sharpe5:17.442531498670576, irr5:573.7083129882812, ndcg5:0.839434186478589, pnl5:5.6108317375183105 
train 11, step: 0, loss: 1.246567869960847, grad_norm: 0.038084453288332695, ic: 0.22091895970325803
train 11, step: 500, loss: 0.65488477782356, grad_norm: 0.15660800873274738, ic: 0.5924386240548273
train 11, step: 1000, loss: 0.9343082588365622, grad_norm: 0.1827339429882898, ic: 0.026043469997202057
train 11, step: 1500, loss: 1.0554489671138294, grad_norm: 0.07011021230612323, ic: 0.19177212238656494
train 11, step: 2000, loss: 0.7894065338665087, grad_norm: 0.0008586672565050343, ic: 0.10028889001697866
Epoch 11: 2022-05-09 13:22:17.363859: train loss: 1.6265540995631613
Eval step 0: eval loss: 0.8291847220964501
Eval: 2022-05-09 13:22:26.857320: total loss: 1.069689468096845, mse:4.592398314336661, ic :0.18398952162631485, sharpe5:16.21883091688156, irr5:541.6035766601562, ndcg5:0.8379404224068039, pnl5:3.544119119644165 
train 12, step: 0, loss: 0.9662760098775227, grad_norm: 0.14479757215283823, ic: 0.4049364959677053
train 12, step: 500, loss: 0.9360543515816954, grad_norm: 0.176012355234205, ic: 0.14494403990861288
train 12, step: 1000, loss: 2.9791747658116043, grad_norm: 0.25528913871716563, ic: 0.35054855283047837
train 12, step: 1500, loss: 0.9419504995120906, grad_norm: 0.11071924961760296, ic: -0.10236059866338305
train 12, step: 2000, loss: 0.8733430153653701, grad_norm: 0.005191946290194068, ic: 0.256196146974144
Epoch 12: 2022-05-09 13:25:58.000358: train loss: 1.6235465701120044
Eval step 0: eval loss: 0.8239819413115779
Eval: 2022-05-09 13:26:07.494251: total loss: 1.066361555390417, mse:4.582687698863557, ic :0.19101463099430277, sharpe5:17.483369003534317, irr5:571.0316772460938, ndcg5:0.8550734639086871, pnl5:6.106472969055176 
train 13, step: 0, loss: 2.0545152867608234, grad_norm: 0.7950750083562822, ic: 0.44515067529910746
train 13, step: 500, loss: 0.8135786485867156, grad_norm: 0.08202833022681329, ic: 0.592211359212126
train 13, step: 1000, loss: 0.9452619514209312, grad_norm: 0.6435338022145962, ic: 0.5911033203950298
train 13, step: 1500, loss: 2.405063983521175, grad_norm: 0.45056073278242237, ic: -0.09048151002993153
train 13, step: 2000, loss: 1.4720266340694765, grad_norm: 0.03373259345830875, ic: 0.146641825558582
Epoch 13: 2022-05-09 13:29:38.189892: train loss: 1.6229168872427135
Eval step 0: eval loss: 0.8228354579656216
Eval: 2022-05-09 13:29:47.659299: total loss: 1.0674816937319467, mse:4.6047384691952296, ic :0.18406619963650322, sharpe5:16.536154940128327, irr5:552.6986083984375, ndcg5:0.854690233236664, pnl5:5.170192718505859 
train 14, step: 0, loss: 4.52808607461486, grad_norm: 1.36777034804504, ic: 0.19391523874646416
train 14, step: 500, loss: 0.8264877832628535, grad_norm: 0.006365215548503172, ic: 0.16801651892655084
train 14, step: 1000, loss: 1.83017822821754, grad_norm: 0.3932249295279152, ic: 0.43946188443768275
train 14, step: 1500, loss: 1.1262291349833202, grad_norm: 0.07620748101922634, ic: -0.03858497465192416
train 14, step: 2000, loss: 1.133192872226653, grad_norm: 0.3259261912939642, ic: 0.08545343248795212
Epoch 14: 2022-05-09 13:33:19.471030: train loss: 1.622331060949813
Eval step 0: eval loss: 0.8285698041523972
Eval: 2022-05-09 13:33:28.929653: total loss: 1.0686228036134744, mse:4.605382965238606, ic :0.18843895664870733, sharpe5:17.179473341703414, irr5:578.67236328125, ndcg5:0.8333357396732392, pnl5:5.065775394439697 
train 15, step: 0, loss: 3.39869361016537, grad_norm: 0.8466508500686276, ic: 0.1046614174003436
train 15, step: 500, loss: 1.2636464056330527, grad_norm: 0.041567795557703915, ic: -0.054923961969924356
train 15, step: 1000, loss: 1.311767181148374, grad_norm: 0.14002331924129174, ic: 0.06695164198509981
train 15, step: 1500, loss: 0.8537893700787401, grad_norm: 0.2783471258571351, ic: 0.0457617835495468
train 15, step: 2000, loss: 1.4635980824149557, grad_norm: 0.6561580882524491, ic: 0.03431082229574076
Epoch 15: 2022-05-09 13:37:02.394070: train loss: 1.621262770543727
Eval step 0: eval loss: 0.8326421160843651
Eval: 2022-05-09 13:37:11.830793: total loss: 1.0698945541411709, mse:4.582421962516579, ic :0.19348894804721353, sharpe5:18.127287122011182, irr5:617.9840087890625, ndcg5:0.8698261608012706, pnl5:6.727375507354736 
train 16, step: 0, loss: 0.7057822764344566, grad_norm: 0.5471084234356693, ic: -0.013278663420342044
train 16, step: 500, loss: 1.5894412863122023, grad_norm: 0.5401764069321433, ic: 0.1738306725019052
train 16, step: 1000, loss: 0.8805642792672822, grad_norm: 0.07280417800864697, ic: -0.11210092586684418
train 16, step: 1500, loss: 0.8435960894405043, grad_norm: 0.2519556404581639, ic: 0.15213124917704152
train 16, step: 2000, loss: 3.303717388779934, grad_norm: 1.4869338560166516, ic: 0.04214888653207095
Epoch 16: 2022-05-09 13:40:44.012403: train loss: 1.6211433584910104
Eval step 0: eval loss: 0.8265683784123089
Eval: 2022-05-09 13:40:53.484500: total loss: 1.0678741712961943, mse:4.587495982556653, ic :0.18583751308988514, sharpe5:16.14578653335571, irr5:544.59716796875, ndcg5:0.8340646905908032, pnl5:5.547781467437744 
train 17, step: 0, loss: 1.2646812054459549, grad_norm: 0.3352924102755814, ic: -0.09013603070197979
train 17, step: 500, loss: 1.771558212652439, grad_norm: 1.7624462936091898, ic: 0.20846186335258166
train 17, step: 1000, loss: 1.2692068510571317, grad_norm: 0.16270602843592796, ic: 0.16262281057161476
train 17, step: 1500, loss: 4.509691719094415, grad_norm: 1.9344978505920511, ic: 0.2333019277770213
train 17, step: 2000, loss: 1.274365214952516, grad_norm: 1.0936869745080267, ic: 0.08774456410996849
Epoch 17: 2022-05-09 13:44:27.243319: train loss: 1.6204164466965532
Eval step 0: eval loss: 0.8327580121344836
Eval: 2022-05-09 13:44:36.465980: total loss: 1.0686046681660806, mse:4.586202193906133, ic :0.19442806587141515, sharpe5:17.628591302633286, irr5:604.5936279296875, ndcg5:0.8431691901605411, pnl5:4.68103551864624 
train 18, step: 0, loss: 1.4151185858821793, grad_norm: 1.3334117137622299, ic: 0.14519692204880932
train 18, step: 500, loss: 1.4980051996632868, grad_norm: 3.2229529186971533, ic: -0.016171193261166544
train 18, step: 1000, loss: 0.6561916738013698, grad_norm: 0.01979131295335384, ic: 0.5705288461713821
train 18, step: 1500, loss: 1.42103420448147, grad_norm: 0.1428302499816699, ic: 0.20580168392053166
train 18, step: 2000, loss: 0.9109394049188894, grad_norm: 0.022379386198361835, ic: 0.00587625212599528
Epoch 18: 2022-05-09 13:48:08.284627: train loss: 1.6204509978679427
Eval step 0: eval loss: 0.8188278471581928
Eval: 2022-05-09 13:48:17.692695: total loss: 1.0644160375929017, mse:4.587384674870598, ic :0.19580105463333744, sharpe5:17.021044027805328, irr5:594.0492553710938, ndcg5:0.8612827027948307, pnl5:5.2042646408081055 
train 19, step: 0, loss: 1.4878487723214286, grad_norm: 1.0271861274552099, ic: -0.02855710573246686
train 19, step: 500, loss: 0.8655736004864728, grad_norm: 0.07516426088569395, ic: 0.21935366562352226
train 19, step: 1000, loss: 0.9546466615947704, grad_norm: 0.010447534778342761, ic: 0.2051013345899908
train 19, step: 1500, loss: 3.947880866237702, grad_norm: 1.0836255935433439, ic: 0.14557365995435556
train 19, step: 2000, loss: 1.0061394794170673, grad_norm: 0.24223977145747672, ic: 0.18461912084381837
Epoch 19: 2022-05-09 13:51:49.063229: train loss: 1.6196230293739076
Eval step 0: eval loss: 0.8264873412185524
Eval: 2022-05-09 13:51:58.555549: total loss: 1.0671138375772966, mse:4.596427199213187, ic :0.193222322524392, sharpe5:17.5520867228508, irr5:599.9549560546875, ndcg5:0.8584696808727813, pnl5:3.979142427444458 
train 20, step: 0, loss: 2.3201723845108697, grad_norm: 2.5006026812428983, ic: 0.05210109967726194
train 20, step: 500, loss: 3.219775568181818, grad_norm: 0.6055466464713655, ic: 0.1061564762927984
train 20, step: 1000, loss: 0.9759225845336914, grad_norm: 0.15042175444882017, ic: 0.05528256880468385
train 20, step: 1500, loss: 1.8190117875430705, grad_norm: 4.375439490381902, ic: 0.25331738902183754
train 20, step: 2000, loss: 1.0456776953443618, grad_norm: 0.09751302020165863, ic: -0.00042351448674732284
Epoch 20: 2022-05-09 13:55:30.927033: train loss: 1.6192339486851506
Eval step 0: eval loss: 0.8277923616141991
Eval: 2022-05-09 13:55:40.415107: total loss: 1.0661290718108782, mse:4.581461389885882, ic :0.19500931127222035, sharpe5:17.698234137296676, irr5:599.1377563476562, ndcg5:0.8367482783919756, pnl5:4.6329874992370605 
train 21, step: 0, loss: 1.0202739142353165, grad_norm: 0.7645244454557425, ic: 0.05281885610714006
train 21, step: 500, loss: 0.7688602683818445, grad_norm: 0.03792323728296157, ic: 0.19528181643878395
train 21, step: 1000, loss: 0.9226220114189281, grad_norm: 1.5568649577300075, ic: 0.14832387956427878
train 21, step: 1500, loss: 0.9873472231596472, grad_norm: 0.29407634232791063, ic: 0.31466653305192066
train 21, step: 2000, loss: 0.9419506322241833, grad_norm: 0.14008262922039263, ic: 0.0877653513397491
Epoch 21: 2022-05-09 13:59:12.642385: train loss: 1.6194878159983133
Eval step 0: eval loss: 0.8242896897021535
Eval: 2022-05-09 13:59:22.118768: total loss: 1.0675358380589899, mse:4.5965439654172995, ic :0.18984331613278868, sharpe5:17.44217015504837, irr5:598.7501220703125, ndcg5:0.8638371745984432, pnl5:6.492086410522461 
train 22, step: 0, loss: 1.0453605005296611, grad_norm: 0.023849399608048376, ic: 0.20126677687200858
train 22, step: 500, loss: 3.2597636401168697, grad_norm: 1.9184333952875066, ic: -0.21970100290286598
train 22, step: 1000, loss: 1.192961835034321, grad_norm: 0.2266761854368903, ic: 0.46934989705082847
train 22, step: 1500, loss: 0.973242488908179, grad_norm: 0.20751866714822498, ic: 0.11358327704234242
train 22, step: 2000, loss: 1.8080617338081066, grad_norm: 2.3138676823204265, ic: 0.15678267675099627
Epoch 22: 2022-05-09 14:02:55.303977: train loss: 1.6188463685687862
Eval step 0: eval loss: 0.8254227311643835
Eval: 2022-05-09 14:03:04.753041: total loss: 1.0674068482528338, mse:4.597864762379088, ic :0.19020688551828382, sharpe5:17.541895319223404, irr5:598.250244140625, ndcg5:0.8494980683010643, pnl5:3.7114040851593018 
train 23, step: 0, loss: 0.9843535409537104, grad_norm: 0.041673494846561146, ic: 0.19945695083851017
train 23, step: 500, loss: 1.4242819122841446, grad_norm: 0.26840706315240903, ic: 0.021827472489335586
train 23, step: 1000, loss: 1.648206787109375, grad_norm: 0.12224824719255893, ic: 0.2604867628853318
train 23, step: 1500, loss: 1.1190527493644473, grad_norm: 2.5616219387182015, ic: 0.10030187093578086
train 23, step: 2000, loss: 1.9055630608280407, grad_norm: 2.788533059051699, ic: 0.4334251547947875
Epoch 23: 2022-05-09 14:06:38.568125: train loss: 1.618098102884877
Eval step 0: eval loss: 0.830733497225698
Eval: 2022-05-09 14:06:47.976719: total loss: 1.0706267449550964, mse:4.586742125593787, ic :0.19269358282994192, sharpe5:17.29913861989975, irr5:597.0381469726562, ndcg5:0.8490302986338023, pnl5:5.33701229095459 
train 24, step: 0, loss: 2.1836854399948464, grad_norm: 0.07346067038000179, ic: 0.17256808618046093
train 24, step: 500, loss: 1.2277398847884242, grad_norm: 0.33147507884530175, ic: 0.09845764060813142
train 24, step: 1000, loss: 0.9026792166926908, grad_norm: 0.07041764540208216, ic: 0.5348032259190761
train 24, step: 1500, loss: 2.606537896743611, grad_norm: 4.332879688509988, ic: 0.056622505960939554
train 24, step: 2000, loss: 0.9216024061481255, grad_norm: 0.06488807247015238, ic: 0.1469545741999406
Epoch 24: 2022-05-09 14:10:22.479930: train loss: 1.6152692621789666
Eval step 0: eval loss: 0.8218423021354715
Eval: 2022-05-09 14:10:31.624865: total loss: 1.067789320684396, mse:4.607643337555006, ic :0.1932872597495722, sharpe5:17.678927793502808, irr5:608.8937377929688, ndcg5:0.8390033808213659, pnl5:7.883955955505371 
train 25, step: 0, loss: 0.8364894557643582, grad_norm: 0.10723870253337138, ic: 0.6185104403186755
train 25, step: 500, loss: 0.868040332621318, grad_norm: 0.007242635992932917, ic: 0.25729905503017425
train 25, step: 1000, loss: 2.095165755307502, grad_norm: 0.1032777699104473, ic: 0.25390032903449633
train 25, step: 1500, loss: 1.1336301563557172, grad_norm: 1.1159820228854398, ic: 0.5457049963601768
train 25, step: 2000, loss: 1.0130607610274982, grad_norm: 0.3892431086149436, ic: 0.5937860717621058
Epoch 25: 2022-05-09 14:14:05.482075: train loss: 1.6153131004238697
Eval step 0: eval loss: 0.8251249516349446
Eval: 2022-05-09 14:14:15.125085: total loss: 1.0647865107387744, mse:4.59253150337146, ic :0.19790478857178365, sharpe5:17.504968271255493, irr5:607.3930053710938, ndcg5:0.8589619550766493, pnl5:5.7620649337768555 
train 26, step: 0, loss: 6.712922605081869, grad_norm: 1.1717521345601232, ic: 0.13070022550443475
train 26, step: 500, loss: 3.8523962812744332, grad_norm: 3.1670783300321776, ic: 0.38715441477108203
train 26, step: 1000, loss: 1.2739768514827807, grad_norm: 0.9364109678282541, ic: 0.042603913114979235
train 26, step: 1500, loss: 0.8350341973404736, grad_norm: 0.15644860179684483, ic: 0.2990357408433585
train 26, step: 2000, loss: 0.9651347594782651, grad_norm: 0.5788782732435382, ic: 0.12174261079615312
Epoch 26: 2022-05-09 14:17:47.831379: train loss: 1.617187689558551
Eval step 0: eval loss: 0.8255646748839238
Eval: 2022-05-09 14:17:57.279623: total loss: 1.0660640442999967, mse:4.5887988109982905, ic :0.1940982985762229, sharpe5:17.88104752421379, irr5:604.0367431640625, ndcg5:0.8490973878106018, pnl5:5.5131707191467285 
train 27, step: 0, loss: 0.8197852519914215, grad_norm: 0.15592846347818357, ic: 0.17019244630908145
train 27, step: 500, loss: 0.9246620657961461, grad_norm: 3.3842099507834185, ic: 0.26811336111590767
train 27, step: 1000, loss: 0.7604077922587974, grad_norm: 0.36326210508059537, ic: 0.17785666253864757
train 27, step: 1500, loss: 0.6415317605966063, grad_norm: 0.048831067801762953, ic: 0.4992195536326906
train 27, step: 2000, loss: 1.3849687047681758, grad_norm: 0.07402470589094763, ic: 0.021366911669572775
Epoch 27: 2022-05-09 14:21:31.028320: train loss: 1.6135063351163446
Eval step 0: eval loss: 0.8332805734037473
Eval: 2022-05-09 14:21:40.401796: total loss: 1.0701402892391243, mse:4.611456826242662, ic :0.18481040004456553, sharpe5:17.13806071400642, irr5:586.0707397460938, ndcg5:0.8409746108106437, pnl5:5.834107398986816 
train 28, step: 0, loss: 1.537938321971525, grad_norm: 1.505153185800875, ic: 0.22178006967764324
train 28, step: 500, loss: 1.3795692098413919, grad_norm: 2.4004062701451625, ic: 0.13684621763106514
train 28, step: 1000, loss: 0.9206910172129065, grad_norm: 0.48118846532200543, ic: 0.5686426253365287
train 28, step: 1500, loss: 1.0317244333357614, grad_norm: 0.06018634644928135, ic: 0.053598360764450695
train 28, step: 2000, loss: 1.0436263757249329, grad_norm: 0.2514935966951506, ic: 0.0940149976277362
Epoch 28: 2022-05-09 14:25:11.063361: train loss: 1.613002234883953
Eval step 0: eval loss: 0.8279493550982941
Eval: 2022-05-09 14:25:20.428874: total loss: 1.0834631534037567, mse:4.7396594333362705, ic :0.16938266714764202, sharpe5:17.284959193468094, irr5:600.76611328125, ndcg5:0.8528349880994548, pnl5:4.124386310577393 
train 29, step: 0, loss: 0.9049829305167266, grad_norm: 0.1083510630681735, ic: 0.10146314681978442
train 29, step: 500, loss: 1.1108051508367587, grad_norm: 0.7456694837872083, ic: 0.6183924349523546
train 29, step: 1000, loss: 1.0682923909068016, grad_norm: 0.39503558170760905, ic: 0.02770497984625562
train 29, step: 1500, loss: 2.356959894613583, grad_norm: 0.40389445039631344, ic: -0.07391506356549557
train 29, step: 2000, loss: 4.330894187644676, grad_norm: 21.23550031553041, ic: 0.1568101145682176
Epoch 29: 2022-05-09 14:28:52.428165: train loss: 1.6122507833036552
Eval step 0: eval loss: 0.8276356897062697
Eval: 2022-05-09 14:29:01.846966: total loss: 1.0654113085778385, mse:4.5840690333355925, ic :0.19698288756915697, sharpe5:18.00552945613861, irr5:617.088623046875, ndcg5:0.8485578992893051, pnl5:6.559285640716553 
train 30, step: 0, loss: 1.0070535644224734, grad_norm: 0.09063778365866648, ic: 0.5154454155884873
train 30, step: 500, loss: 1.427883983734106, grad_norm: 1.134864734656151, ic: 0.06053540225594272
train 30, step: 1000, loss: 0.9753371729995265, grad_norm: 0.09747010394742876, ic: -0.03968373155737599
train 30, step: 1500, loss: 1.5356736921280798, grad_norm: 5.719883101358381, ic: 0.14214998508922216
train 30, step: 2000, loss: 1.8478785356493879, grad_norm: 1.33596508735769, ic: 0.04091666420428819
Epoch 30: 2022-05-09 14:32:33.159356: train loss: 1.612836910733675
Eval step 0: eval loss: 0.8381619709686182
Eval: 2022-05-09 14:32:42.596531: total loss: 1.0709685042832888, mse:4.622385054582311, ic :0.1959153494145245, sharpe5:18.21685304403305, irr5:626.5816040039062, ndcg5:0.8300920877406839, pnl5:4.959282875061035 
train 31, step: 0, loss: 1.0530462310396838, grad_norm: 0.9913923716782506, ic: 0.3365514812723902
train 31, step: 500, loss: 1.5054865330825618, grad_norm: 1.6954450253417368, ic: 0.025322854233082046
train 31, step: 1000, loss: 4.336815338968579, grad_norm: 5.9089045257375385, ic: 0.4615475306518618
train 31, step: 1500, loss: 0.7686868355213882, grad_norm: 0.06245589319916314, ic: 0.7144236268426852
train 31, step: 2000, loss: 1.2246192074111892, grad_norm: 5.368263992276717, ic: 0.20763382346547954
Epoch 31: 2022-05-09 14:36:16.644191: train loss: 1.6101280623297565
Eval step 0: eval loss: 0.8283199394716477
Eval: 2022-05-09 14:36:26.361138: total loss: 1.0662294339368872, mse:4.575693852270339, ic :0.1973801069489154, sharpe5:17.53335550189018, irr5:602.7394409179688, ndcg5:0.859697457571187, pnl5:6.821499824523926 
train 32, step: 0, loss: 1.1260631439375488, grad_norm: 0.09907199993692296, ic: 0.20609383025021666
train 32, step: 500, loss: 1.4913483867495079, grad_norm: 1.215329021385281, ic: 0.05688834005998531
train 32, step: 1000, loss: 1.0439128710696075, grad_norm: 0.08861618996342722, ic: 0.5086905707577405
train 32, step: 1500, loss: 0.9841411948476831, grad_norm: 2.1481632145892435, ic: 0.08601214627757663
train 32, step: 2000, loss: 0.9454972245382866, grad_norm: 0.10091336268446487, ic: 0.5553690492754811
Epoch 32: 2022-05-09 14:39:58.395408: train loss: 1.6100720506668753
Eval step 0: eval loss: 0.8197121172986367
Eval: 2022-05-09 14:40:07.911322: total loss: 1.063671157004033, mse:4.58973033173345, ic :0.19874506170488407, sharpe5:18.332363816499708, irr5:622.4869995117188, ndcg5:0.8390524234135999, pnl5:4.045433044433594 
train 33, step: 0, loss: 1.267352264162617, grad_norm: 0.7663394814098309, ic: 0.205158100097271
train 33, step: 500, loss: 0.9928220045120321, grad_norm: 0.020374972207312825, ic: 0.1343373199740142
train 33, step: 1000, loss: 1.018505623869574, grad_norm: 6.229427570810016, ic: 0.21637119292252893
train 33, step: 1500, loss: 0.8807695961224793, grad_norm: 0.12339257825922202, ic: 0.5622420853247289
train 33, step: 2000, loss: 0.8145661029120445, grad_norm: 0.0995159571958139, ic: 0.25562255901237885
Epoch 33: 2022-05-09 14:43:40.270790: train loss: 1.610410183925058
Eval step 0: eval loss: 0.8243027456944809
Eval: 2022-05-09 14:43:49.807358: total loss: 1.0653055784308554, mse:4.571343854361293, ic :0.2011257159074145, sharpe5:18.909535524845122, irr5:638.2446899414062, ndcg5:0.8418163093216816, pnl5:7.888762474060059 
train 34, step: 0, loss: 1.0242768286996877, grad_norm: 4.644556963159708, ic: 0.6073606213677448
train 34, step: 500, loss: 0.8017914098337156, grad_norm: 1.095931183091345, ic: 0.2675481336166486
train 34, step: 1000, loss: 3.1147999096942205, grad_norm: 1.7463114191098728, ic: 0.33927911408213884
train 34, step: 1500, loss: 0.7958972735399285, grad_norm: 1.0449591582399627, ic: 0.696221706668874
train 34, step: 2000, loss: 5.662722090433773, grad_norm: 45.421484858088945, ic: 0.4386624694230472
Epoch 34: 2022-05-09 14:47:21.575908: train loss: 1.6097013037519003
Eval step 0: eval loss: 0.8188200006997497
Eval: 2022-05-09 14:47:31.079048: total loss: 1.0651250179941427, mse:4.587191137622788, ic :0.19961654097910597, sharpe5:17.90417351603508, irr5:625.8428344726562, ndcg5:0.8454935971624076, pnl5:6.1730499267578125 
train 35, step: 0, loss: 1.1933649758731617, grad_norm: 0.9777519043672673, ic: 0.558510318430441
train 35, step: 500, loss: 1.1707381391174367, grad_norm: 0.8935100031068286, ic: 0.1480288243861702
train 35, step: 1000, loss: 1.721797351877654, grad_norm: 6.454545819104462, ic: 0.023476263672995816
train 35, step: 1500, loss: 1.6019887364896617, grad_norm: 1.1020250298455756, ic: 0.06963106161180464
train 35, step: 2000, loss: 0.795143086642505, grad_norm: 0.511270608317811, ic: 0.5538230342926886
Epoch 35: 2022-05-09 14:51:01.936185: train loss: 1.6103569116221226
Eval step 0: eval loss: 0.832764572288264
Eval: 2022-05-09 14:51:11.331950: total loss: 1.0681056767801274, mse:4.587858305722793, ic :0.19625871960814767, sharpe5:18.050657680034636, irr5:625.6159057617188, ndcg5:0.847551622729723, pnl5:4.88115119934082 
train 36, step: 0, loss: 1.8487309286695448, grad_norm: 3.665704635007879, ic: 0.08454469139294823
train 36, step: 500, loss: 0.831363566754088, grad_norm: 0.0638648169574779, ic: 0.22759100330118437
train 36, step: 1000, loss: 1.744104580965909, grad_norm: 8.121483996518382, ic: 0.25077832229730207
train 36, step: 1500, loss: 0.7674131436809616, grad_norm: 0.11767144471325912, ic: 0.3964505778363453
train 36, step: 2000, loss: 1.1299969322440924, grad_norm: 1.7590462746777982, ic: 0.7697782171164027
Epoch 36: 2022-05-09 14:54:45.198947: train loss: 1.6062794479299198
Eval step 0: eval loss: 0.8288026252963645
Eval: 2022-05-09 14:54:54.669437: total loss: 1.0657917269134123, mse:4.590025702503313, ic :0.19660814975557703, sharpe5:18.376712597608567, irr5:621.139404296875, ndcg5:0.8518654434139955, pnl5:5.582310199737549 
train 37, step: 0, loss: 2.0182428754307047, grad_norm: 2.8064329826397767, ic: 0.20684212798706697
train 37, step: 500, loss: 2.3445624745106035, grad_norm: 2.149799636123397, ic: -0.04434372877957379
train 37, step: 1000, loss: 1.0832760141683313, grad_norm: 0.20956164473936506, ic: -0.00040903849526768843
train 37, step: 1500, loss: 2.006996526074372, grad_norm: 2.608339170398245, ic: 0.6146540599769548
train 37, step: 2000, loss: 1.3045946292306894, grad_norm: 0.17893391220336202, ic: 0.24604421288574838
Epoch 37: 2022-05-09 14:58:26.159390: train loss: 1.6075847289900924
Eval step 0: eval loss: 0.8229688477591544
Eval: 2022-05-09 14:58:35.628120: total loss: 1.0676028162851268, mse:4.599108549879924, ic :0.1948528974984426, sharpe5:18.150462301969526, irr5:635.0506591796875, ndcg5:0.8538746072744087, pnl5:7.515607833862305 
train 38, step: 0, loss: 1.3051001385944645, grad_norm: 0.9389971169813824, ic: 0.07382252359532371
train 38, step: 500, loss: 0.9142470371576003, grad_norm: 0.06385890603167171, ic: 0.25837715040270626
train 38, step: 1000, loss: 0.8997987046072135, grad_norm: 0.2127658494283618, ic: 0.13712353217282316
train 38, step: 1500, loss: 0.9514700528248387, grad_norm: 0.05069164183700297, ic: 0.20864227419432285
train 38, step: 2000, loss: 2.316506930348376, grad_norm: 5.1602556564763535, ic: 0.022028770986142865
Epoch 38: 2022-05-09 15:02:10.140889: train loss: 1.612663601579249
Eval step 0: eval loss: 0.8252420053592597
Eval: 2022-05-09 15:02:19.478457: total loss: 1.0645826026632776, mse:4.581397053804355, ic :0.20108699544811373, sharpe5:18.594337942600248, irr5:633.9241333007812, ndcg5:0.8468130919044695, pnl5:5.489729881286621 
train 39, step: 0, loss: 0.9640068030867737, grad_norm: 0.022992428787603235, ic: 0.10196255608464108
train 39, step: 500, loss: 0.8854259869211184, grad_norm: 0.17291038888138405, ic: 0.2207424184254066
train 39, step: 1000, loss: 0.9450369353341584, grad_norm: 0.16131083950659958, ic: 0.1932670691070324
train 39, step: 1500, loss: 2.0574440449806857, grad_norm: 0.43510389179551434, ic: 0.22095071514289574
train 39, step: 2000, loss: 0.6120330183803564, grad_norm: 0.20806296921291967, ic: 0.1136905249573493
Epoch 39: 2022-05-09 15:05:53.270608: train loss: 1.6106476163156054
Eval step 0: eval loss: 0.8288185754741833
Eval: 2022-05-09 15:06:02.907080: total loss: 1.0681587907105896, mse:4.598075151627861, ic :0.19205259788946574, sharpe5:18.295081100463868, irr5:619.173583984375, ndcg5:0.8546839952910816, pnl5:5.514419078826904 

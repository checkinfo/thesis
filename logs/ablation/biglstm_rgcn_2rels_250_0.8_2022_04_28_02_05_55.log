Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='RGCNSeqTimeDataset', dout=0.3, epochs=40, glstm_layers=1, gnn_layers=1, gpu=0, graph_attn=False, hidden_dim=128, inner_prod=False, input_dim=9, input_graph=True, label_cnt=3, lr=0.0004, lstm_layers=1, market=None, mask_adj=True, mask_type='soft', model_type='BiGLSTM', normalize_adj=True, num_days=8, num_heads=1, print_inteval=500, rank_loss=False, relation_num=2, rsr_data_path=None, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_250_0.8/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
load 2305 train graphs successful!
load 126 test graphs successful!
57435
BiGLSTM(
  (input_to_hidden): Linear(in_features=9, out_features=128, bias=True)
  (forward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
            (1): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
  )
  (backward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
            (1): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
  )
  (fc0): ModuleList(
    (0): Linear(in_features=256, out_features=128, bias=True)
  )
  (w_out): Linear(in_features=128, out_features=1, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
)
train 0, step: 0, loss: 4.81497958304828, grad_norm: 5.25894194229995, ic: 0.026913900202296143
train 0, step: 500, loss: 0.8633162060804446, grad_norm: 0.028192098505515045, ic: 0.03974332425425701
train 0, step: 1000, loss: 1.9567679996113754, grad_norm: 0.5435256091033978, ic: 0.02775144526293139
train 0, step: 1500, loss: 0.9553080803791996, grad_norm: 0.047257564594763615, ic: 0.03340361840809888
train 0, step: 2000, loss: 1.0046323442562095, grad_norm: 0.16989036641583627, ic: 0.005858033549190286
Epoch 0: 2022-04-28 14:13:04.212197: train loss: 1.64874453809115
Eval step 0: eval loss: 0.8365155010002304
Eval: 2022-04-28 14:13:35.131001: total loss: 1.0794099403703705, mse:4.822831907885259, ic :0.007676602376015648, sharpe5:7.8472814708948135, irr5:223.96624755859375, ndcg5:0.8583863863241934, pnl5:2.8044521808624268 
train 1, step: 0, loss: 2.776582188760081, grad_norm: 0.9226073263637098, ic: 0.029474171013061726
train 1, step: 500, loss: 1.7520357855766207, grad_norm: 0.8019310480170188, ic: 0.10541412479487766
train 1, step: 1000, loss: 0.8787781630784501, grad_norm: 0.18367042705259978, ic: 0.060790200361898084
train 1, step: 1500, loss: 1.7147734543372846, grad_norm: 0.21717691099322178, ic: -0.013082906677530454
train 1, step: 2000, loss: 2.1811947265625, grad_norm: 0.9292545755952879, ic: -0.011590555856234752
Epoch 1: 2022-04-28 14:21:24.073789: train loss: 1.6467897111086096
Eval step 0: eval loss: 0.8341899264851158
Eval: 2022-04-28 14:21:54.902360: total loss: 1.0789700530369395, mse:4.824126601552531, ic :0.0070703789405353835, sharpe5:7.681948791146278, irr5:215.7593994140625, ndcg5:0.8623577889046591, pnl5:2.8738200664520264 
train 2, step: 0, loss: 2.141814630681818, grad_norm: 0.009967380599357928, ic: 0.1493146570359287
train 2, step: 500, loss: 3.3013146151212833, grad_norm: 0.29371942061852835, ic: 0.06401670410081493
train 2, step: 1000, loss: 2.0724388619492338, grad_norm: 0.00024311688684560317, ic: 0.1433777727130169
train 2, step: 1500, loss: 1.4872351726502862, grad_norm: 0.06315567715155931, ic: -0.06982069582635274
train 2, step: 2000, loss: 3.233487079326923, grad_norm: 0.8049913604317074, ic: 0.2162655206098993
Epoch 2: 2022-04-28 14:30:02.340912: train loss: 1.6464926991774922
Eval step 0: eval loss: 0.8358571059585748
Eval: 2022-04-28 14:30:32.181242: total loss: 1.0794970912143185, mse:4.823184720919383, ic :0.012163621970456466, sharpe5:7.588439304828643, irr5:216.81175231933594, ndcg5:0.870117335265228, pnl5:2.3218557834625244 
train 3, step: 0, loss: 1.5220236677464432, grad_norm: 0.5358266065892802, ic: -0.0011220990596950264
train 3, step: 500, loss: 1.5030927665549139, grad_norm: 0.35029581648519187, ic: 0.08926530816612505
train 3, step: 1000, loss: 3.6778102736398965, grad_norm: 0.7196423804305847, ic: 0.030763440204922006
train 3, step: 1500, loss: 1.9748291415200492, grad_norm: 1.1679757589532942, ic: -0.04555942881852356
train 3, step: 2000, loss: 0.8980340741131757, grad_norm: 0.0017529792861122814, ic: 0.014969972762503192
Epoch 3: 2022-04-28 14:38:24.420099: train loss: 1.6457250792612643
Eval step 0: eval loss: 0.8344372828717729
Eval: 2022-04-28 14:38:52.386434: total loss: 1.077991256039703, mse:4.81978610552278, ic :0.031943214901400806, sharpe5:5.796739656329155, irr5:129.392578125, ndcg5:0.840425170024011, pnl5:2.4285430908203125 
train 4, step: 0, loss: 1.438725884885204, grad_norm: 0.04418833130730857, ic: 0.040648965792026676
train 4, step: 500, loss: 1.6443343996062991, grad_norm: 0.5603953856907121, ic: 0.06163199828974619
train 4, step: 1000, loss: 2.9731845390505907, grad_norm: 0.7005951355882396, ic: 0.08522854302501598
train 4, step: 1500, loss: 2.1455364500922998, grad_norm: 0.4880447192749695, ic: 0.021451824986233707
train 4, step: 2000, loss: 1.085641152009623, grad_norm: 0.39264981219428785, ic: 0.2273200068594063
Epoch 4: 2022-04-28 14:47:00.027868: train loss: 1.6458792507002844
Eval step 0: eval loss: 0.8481489690010866
Eval: 2022-04-28 14:47:29.977620: total loss: 1.0834867678406959, mse:4.819175612040621, ic :0.052480005808987935, sharpe5:10.775761533379555, irr5:339.9988098144531, ndcg5:0.8521642227585106, pnl5:3.0051755905151367 
train 5, step: 0, loss: 1.3500257248846477, grad_norm: 0.13992839584744615, ic: 0.07517227675184418
train 5, step: 500, loss: 0.8864135258165642, grad_norm: 0.008151453336625075, ic: 0.4260498602406535
train 5, step: 1000, loss: 0.9815905808488985, grad_norm: 0.15086519948734808, ic: -0.002398070597301588
train 5, step: 1500, loss: 1.5339144229158692, grad_norm: 0.165928105085645, ic: 0.031053159140201018
train 5, step: 2000, loss: 1.100688040394794, grad_norm: 0.0339360145526824, ic: 0.1785776161404245
Epoch 5: 2022-04-28 14:55:24.806771: train loss: 1.6404268749711544
Eval step 0: eval loss: 0.8344622371822312
Eval: 2022-04-28 14:55:53.255578: total loss: 1.0760318071545762, mse:4.717359315576056, ic :0.13838322854601287, sharpe5:11.908698651194571, irr5:416.4966125488281, ndcg5:0.8432328310072202, pnl5:2.476214647293091 
train 6, step: 0, loss: 1.335468103630881, grad_norm: 0.42703570247259826, ic: 0.13717149038370646
train 6, step: 500, loss: 1.0070720398042687, grad_norm: 0.042842726820544665, ic: 0.034457458288500505
train 6, step: 1000, loss: 1.1088880183578897, grad_norm: 0.12441424594690186, ic: 0.6265993877875338
train 6, step: 1500, loss: 1.5688418049457644, grad_norm: 0.7152718363758418, ic: 0.152762080590856
train 6, step: 2000, loss: 0.8007212410553443, grad_norm: 0.058801489726658385, ic: 0.3595829991018379
Epoch 6: 2022-04-28 15:03:45.417786: train loss: 1.6345811044291751
Eval step 0: eval loss: 0.8267391996715292
Eval: 2022-04-28 15:04:15.836916: total loss: 1.0707075646932576, mse:4.6912951984649744, ic :0.16109897937766232, sharpe5:17.05999914050102, irr5:550.6690063476562, ndcg5:0.8619128604159036, pnl5:6.79326868057251 
train 7, step: 0, loss: 0.9864563941955566, grad_norm: 0.06342832009165195, ic: 0.1446800312374973
train 7, step: 500, loss: 0.6579607004090283, grad_norm: 0.028186242978461146, ic: -0.06497375204544692
train 7, step: 1000, loss: 1.0245261849652514, grad_norm: 0.3333108057448471, ic: 0.148708799872314
train 7, step: 1500, loss: 2.231539514670418, grad_norm: 0.7984724719375873, ic: 0.43696795153151025
train 7, step: 2000, loss: 0.9204970253496063, grad_norm: 0.0931812689391396, ic: -0.043979950414458575
Epoch 7: 2022-04-28 15:12:09.373771: train loss: 1.6285690748018924
Eval step 0: eval loss: 0.8335369982382771
Eval: 2022-04-28 15:12:39.975521: total loss: 1.0721381475279779, mse:4.682680942355718, ic :0.16412283195986427, sharpe5:15.656957665085791, irr5:519.2415771484375, ndcg5:0.8446633964946639, pnl5:5.630548477172852 
train 8, step: 0, loss: 3.5821862262228263, grad_norm: 1.09409408082385, ic: 0.20761549370312432
train 8, step: 500, loss: 2.7643846320526215, grad_norm: 0.8495102035076987, ic: 0.019207495176610537
train 8, step: 1000, loss: 3.044723731884058, grad_norm: 0.8953640797501707, ic: 0.1185684036487271
train 8, step: 1500, loss: 0.7114265338413225, grad_norm: 0.033997500304416006, ic: 0.48325010287660064
train 8, step: 2000, loss: 1.0850624103404156, grad_norm: 0.5441645645339843, ic: 0.5428466784105417
Epoch 8: 2022-04-28 15:20:30.527826: train loss: 1.6276694454845728
Eval step 0: eval loss: 0.8276722207586933
Eval: 2022-04-28 15:21:02.017211: total loss: 1.070675524645724, mse:4.68319872352849, ic :0.16430616688407315, sharpe5:15.758549140691757, irr5:517.2348022460938, ndcg5:0.8495667644722938, pnl5:4.8234333992004395 
train 9, step: 0, loss: 5.433126495215311, grad_norm: 0.8218179250231512, ic: 0.14251624966315812
train 9, step: 500, loss: 1.350251349698821, grad_norm: 1.6222432379419325, ic: 0.33479958111033964
train 9, step: 1000, loss: 0.938124983964491, grad_norm: 0.3374074809075025, ic: 0.013317059727992811
train 9, step: 1500, loss: 1.087991661105486, grad_norm: 0.016851493288674843, ic: 0.4150571970482238
train 9, step: 2000, loss: 1.0694605664194556, grad_norm: 0.17676668784852306, ic: 0.24240494782977728
Epoch 9: 2022-04-28 15:28:54.459549: train loss: 1.6265351524972793
Eval step 0: eval loss: 0.8250183812936314
Eval: 2022-04-28 15:29:26.161381: total loss: 1.0696950788166644, mse:4.6621748597012544, ic :0.17420293256681876, sharpe5:17.72652488350868, irr5:570.6497192382812, ndcg5:0.8295586701235582, pnl5:11.606639862060547 
train 10, step: 0, loss: 7.067466090788994, grad_norm: 1.9344684230348763, ic: 0.2584698472556439
train 10, step: 500, loss: 1.1321379513343799, grad_norm: 0.09103946438662114, ic: 0.02658231850105968
train 10, step: 1000, loss: 2.3927432569258054, grad_norm: 1.0071084823638266, ic: 0.15734359119966687
train 10, step: 1500, loss: 1.1152879789278105, grad_norm: 0.33012852399267734, ic: 0.023940583100380913
train 10, step: 2000, loss: 2.719342356394852, grad_norm: 0.8710835718483156, ic: 0.4979292287409447
Epoch 10: 2022-04-28 15:37:18.628476: train loss: 1.6265097228101144
Eval step 0: eval loss: 0.8274972833245521
Eval: 2022-04-28 15:37:49.088541: total loss: 1.0689348125383544, mse:4.647024955820767, ic :0.18054754076194252, sharpe5:17.728341060876847, irr5:585.4574584960938, ndcg5:0.8557467662948262, pnl5:7.786693096160889 
train 11, step: 0, loss: 1.2498461139912027, grad_norm: 0.02561312622078582, ic: 0.21353526023651664
train 11, step: 500, loss: 0.6552977499078331, grad_norm: 0.09578314020644496, ic: 0.5801877635769119
train 11, step: 1000, loss: 0.9281085361062449, grad_norm: 0.11771529310198363, ic: 0.06167158678269946
train 11, step: 1500, loss: 1.0540410092002466, grad_norm: 0.19518525036373208, ic: 0.17249718295542218
train 11, step: 2000, loss: 0.7881510223822571, grad_norm: 0.0022283741748038975, ic: 0.11904316411908211
Epoch 11: 2022-04-28 15:45:53.900400: train loss: 1.6251139929528757
Eval step 0: eval loss: 0.8330414493669323
Eval: 2022-04-28 15:46:25.654460: total loss: 1.069802300472893, mse:4.611353429245672, ic :0.17626480122968274, sharpe5:16.65924068570137, irr5:546.6649169921875, ndcg5:0.8232610909765943, pnl5:5.500982761383057 
train 12, step: 0, loss: 0.9651183287302653, grad_norm: 0.1634295771568678, ic: 0.379188800681755
train 12, step: 500, loss: 0.920289285645731, grad_norm: 0.19127799562289877, ic: 0.17221888906914679
train 12, step: 1000, loss: 2.9654488533165804, grad_norm: 0.2484052384376726, ic: 0.23481502725761633
train 12, step: 1500, loss: 0.9330059902775133, grad_norm: 0.129519770658034, ic: -0.11820503945682044
train 12, step: 2000, loss: 0.8749011636140483, grad_norm: 0.004329561317676341, ic: 0.17795480117364393
Epoch 12: 2022-04-28 15:54:23.518444: train loss: 1.6246956559915684
Eval step 0: eval loss: 0.8321655402067966
Eval: 2022-04-28 15:54:54.742578: total loss: 1.0676927445945297, mse:4.5909553220055805, ic :0.1837743325996099, sharpe5:16.768179166316987, irr5:562.1890258789062, ndcg5:0.8489053201922162, pnl5:4.902159690856934 
train 13, step: 0, loss: 2.055418375049498, grad_norm: 1.1550403648831051, ic: 0.44322332229881367
train 13, step: 500, loss: 0.8113264263408083, grad_norm: 0.17266896436162088, ic: 0.5998320687266597
train 13, step: 1000, loss: 0.9312136246854026, grad_norm: 0.37824701558235174, ic: 0.5885668104531456
train 13, step: 1500, loss: 2.3939326194745316, grad_norm: 0.36423130432339806, ic: -0.1184501432594058
train 13, step: 2000, loss: 1.47908077577704, grad_norm: 0.1225183091179805, ic: 0.19012143687669975
Epoch 13: 2022-04-28 16:02:45.229945: train loss: 1.6221420209969775
Eval step 0: eval loss: 0.8256369652059733
Eval: 2022-04-28 16:03:16.134857: total loss: 1.0687360761289701, mse:4.618087649966066, ic :0.17878074368781927, sharpe5:16.90270304560661, irr5:554.9107666015625, ndcg5:0.8416592209792331, pnl5:7.147566318511963 
train 14, step: 0, loss: 4.533593140600624, grad_norm: 1.5147797299003865, ic: 0.19012378774624766
train 14, step: 500, loss: 0.8275516055045872, grad_norm: 0.005386057174238236, ic: 0.07116116989840836
train 14, step: 1000, loss: 1.8395447379816818, grad_norm: 0.31641626406782253, ic: 0.43325063113365997
train 14, step: 1500, loss: 1.1262322011136185, grad_norm: 0.08851807711559297, ic: -0.050625473928295306
train 14, step: 2000, loss: 1.167079845879858, grad_norm: 0.37177863895679875, ic: 0.09471837531346178
Epoch 14: 2022-04-28 16:11:13.973880: train loss: 1.6207419896374258
Eval step 0: eval loss: 0.8339643086472602
Eval: 2022-04-28 16:11:45.494030: total loss: 1.0674130973004925, mse:4.5895753089905, ic :0.18643542712466807, sharpe5:17.705466685295104, irr5:576.37353515625, ndcg5:0.8510958638374373, pnl5:6.496001243591309 
train 15, step: 0, loss: 3.4208475194552532, grad_norm: 0.868791670323342, ic: 0.11516648430513685
train 15, step: 500, loss: 1.2533571872727036, grad_norm: 0.016753746478135517, ic: 0.06853991321825613
train 15, step: 1000, loss: 1.3168050130208333, grad_norm: 0.1721615491273552, ic: 0.06817234911725549
train 15, step: 1500, loss: 0.8544061615711122, grad_norm: 0.465946503018989, ic: 0.07933627877398394
train 15, step: 2000, loss: 1.4622394850480576, grad_norm: 0.7349158448073357, ic: 0.03773088089790811
Epoch 15: 2022-04-28 16:19:42.096026: train loss: 1.62037081926896
Eval step 0: eval loss: 0.8388559966494336
Eval: 2022-04-28 16:20:12.856187: total loss: 1.0689648199932102, mse:4.579231109550874, ic :0.192386448051583, sharpe5:17.656876373291016, irr5:591.5227661132812, ndcg5:0.8541998941404655, pnl5:4.685762405395508 
train 16, step: 0, loss: 0.7090254517084817, grad_norm: 1.0052493824360025, ic: -0.19485402969216847
train 16, step: 500, loss: 1.5938849300224989, grad_norm: 0.452395868427617, ic: 0.17762952144392216
train 16, step: 1000, loss: 0.875288252397017, grad_norm: 0.0036519079892334645, ic: -0.03659089026743209
train 16, step: 1500, loss: 0.858204991165534, grad_norm: 0.2371423830398074, ic: 0.083015879893092
train 16, step: 2000, loss: 3.3491505277146985, grad_norm: 1.8916877072522431, ic: -0.015487892891496505
Epoch 16: 2022-04-28 16:28:06.857803: train loss: 1.619879705601391
Eval step 0: eval loss: 0.831371825914614
Eval: 2022-04-28 16:28:38.504299: total loss: 1.0684343068536657, mse:4.596168914319419, ic :0.18593726598319324, sharpe5:17.829842673540114, irr5:580.564453125, ndcg5:0.8548924762496346, pnl5:6.036095142364502 
train 17, step: 0, loss: 1.281154416031167, grad_norm: 0.49120448157929447, ic: -0.09859442629643854
train 17, step: 500, loss: 1.7456251852557587, grad_norm: 2.7143833922344545, ic: 0.21879386893410419
train 17, step: 1000, loss: 1.2742131578075293, grad_norm: 0.13879367092364503, ic: 0.16635304410497032
train 17, step: 1500, loss: 4.51975081511756, grad_norm: 1.7035229666172336, ic: 0.20566284597259613
train 17, step: 2000, loss: 1.27515299090717, grad_norm: 2.567908906096353, ic: 0.08962601419347221
Epoch 17: 2022-04-28 16:36:41.880611: train loss: 1.6196624965505126
Eval step 0: eval loss: 0.8377460443559009
Eval: 2022-04-28 16:37:12.997465: total loss: 1.067965664833488, mse:4.585800470192563, ic :0.1915497158531714, sharpe5:17.659227944612503, irr5:590.1011352539062, ndcg5:0.8346686977104225, pnl5:4.9615397453308105 
train 18, step: 0, loss: 1.4101778596147228, grad_norm: 2.4356890754569394, ic: 0.19471748274118617
train 18, step: 500, loss: 1.4591678253001412, grad_norm: 2.7468338680888684, ic: -0.004811509481765494
train 18, step: 1000, loss: 0.6519793450342465, grad_norm: 0.038089235816738454, ic: 0.5782078527014433
train 18, step: 1500, loss: 1.4261150688152642, grad_norm: 0.06574236203594007, ic: 0.2202554022893161
train 18, step: 2000, loss: 0.9138352703896299, grad_norm: 0.013495915577280873, ic: -0.018619222410914
Epoch 18: 2022-04-28 16:45:18.856020: train loss: 1.6201456351671923
Eval step 0: eval loss: 0.8249609477904373
Eval: 2022-04-28 16:45:51.051042: total loss: 1.0657593451898404, mse:4.5975628381721325, ic :0.18993411460635728, sharpe5:17.412258092164993, irr5:581.5311279296875, ndcg5:0.842172105776034, pnl5:5.0472493171691895 
train 19, step: 0, loss: 1.4626832992311507, grad_norm: 0.9511586376109189, ic: 0.03782302047934995
train 19, step: 500, loss: 0.8641089686640986, grad_norm: 0.04376147136060869, ic: 0.21318859161113402
train 19, step: 1000, loss: 0.9580656499145787, grad_norm: 0.042971948878592924, ic: 0.20245250101614948
train 19, step: 1500, loss: 3.953000785093113, grad_norm: 1.2174243679146246, ic: 0.14659110833116618
train 19, step: 2000, loss: 1.010525653545673, grad_norm: 0.4200470837554311, ic: 0.22212521133254923
Epoch 19: 2022-04-28 16:53:52.379099: train loss: 1.621288587084611
Eval step 0: eval loss: 0.829566047113738
Eval: 2022-04-28 16:54:24.096463: total loss: 1.0663234130426429, mse:4.582907413298059, ic :0.1935985669616701, sharpe5:17.784886608123777, irr5:598.716552734375, ndcg5:0.8469313566952351, pnl5:4.736042022705078 
train 20, step: 0, loss: 2.3348308578310277, grad_norm: 2.2297298502592593, ic: 0.043195410903123385
train 20, step: 500, loss: 3.2099655539772725, grad_norm: 0.6151927004625697, ic: 0.06520803764819164
train 20, step: 1000, loss: 0.9694975852966309, grad_norm: 0.31176303830716223, ic: 0.15004339041577172
train 20, step: 1500, loss: 1.7041290423406394, grad_norm: 1.2193978952243543, ic: 0.25746837934816147
train 20, step: 2000, loss: 1.0493289518122961, grad_norm: 0.08665847351398269, ic: -0.007062434511052136
Epoch 20: 2022-04-28 17:02:26.705491: train loss: 1.618481439360263
Eval step 0: eval loss: 0.8301348510356296
Eval: 2022-04-28 17:02:58.418993: total loss: 1.0654783232335328, mse:4.586939307150163, ic :0.19161444872378253, sharpe5:17.796674734354017, irr5:593.7390747070312, ndcg5:0.8507503359668721, pnl5:5.881618499755859 
train 21, step: 0, loss: 1.0166505396047865, grad_norm: 1.0298019596212535, ic: 0.0524763248163826
train 21, step: 500, loss: 0.7653059157650027, grad_norm: 0.02597691050685298, ic: 0.2069443985440667
train 21, step: 1000, loss: 0.9536690293696888, grad_norm: 1.7319142461973849, ic: 0.13864769217099848
train 21, step: 1500, loss: 0.9989816927927015, grad_norm: 0.3298769661339285, ic: 0.31857162761711144
train 21, step: 2000, loss: 0.9306990073236779, grad_norm: 0.14762616287973607, ic: 0.0981693875738379
Epoch 21: 2022-04-28 17:11:01.488243: train loss: 1.6213681091846641
Eval step 0: eval loss: 0.8254825443312038
Eval: 2022-04-28 17:11:33.295711: total loss: 1.064502359145536, mse:4.586161326227523, ic :0.19444153874244202, sharpe5:18.05896858334541, irr5:604.47021484375, ndcg5:0.8461525145102627, pnl5:5.196191787719727 
train 22, step: 0, loss: 1.0417108050847457, grad_norm: 0.017729482197696662, ic: 0.21463826005529005
train 22, step: 500, loss: 3.257840486852134, grad_norm: 1.1664975557694761, ic: -0.21068041073647925
train 22, step: 1000, loss: 1.1856784004696532, grad_norm: 0.1293001628456531, ic: 0.47818990628919794
train 22, step: 1500, loss: 0.9674611786265432, grad_norm: 0.1120276025776766, ic: 0.08677297123568656
train 22, step: 2000, loss: 1.7297714821605725, grad_norm: 2.191613483340864, ic: 0.14096089448248406
Epoch 22: 2022-04-28 17:19:35.537641: train loss: 1.6160968383164827
Eval step 0: eval loss: 0.8307897087394626
Eval: 2022-04-28 17:20:07.295639: total loss: 1.0675246429620624, mse:4.588533789770097, ic :0.18934393318966358, sharpe5:18.02001347064972, irr5:605.0052490234375, ndcg5:0.8468660715252395, pnl5:5.950551509857178 
train 23, step: 0, loss: 0.982859780259366, grad_norm: 0.06320243936769548, ic: 0.13413784428831232
train 23, step: 500, loss: 1.4169320146928965, grad_norm: 0.232078040222296, ic: 0.02917249861794253
train 23, step: 1000, loss: 1.6702962239583334, grad_norm: 0.12923779982108108, ic: 0.2610912252909793
train 23, step: 1500, loss: 1.1223401225537222, grad_norm: 1.5052725348193179, ic: 0.10371469666346111
train 23, step: 2000, loss: 1.9313669770015396, grad_norm: 1.2800488116014588, ic: 0.43428459597964736
Epoch 23: 2022-04-28 17:28:03.608494: train loss: 1.6172133784678329
Eval step 0: eval loss: 0.8329351362865516
Eval: 2022-04-28 17:28:35.004655: total loss: 1.0654403822919074, mse:4.575656687000573, ic :0.1948910308199759, sharpe5:17.214885016679762, irr5:592.715576171875, ndcg5:0.8521774587637734, pnl5:5.390265941619873 
train 24, step: 0, loss: 2.1878038031765366, grad_norm: 0.10004340655001422, ic: 0.16115743089898982
train 24, step: 500, loss: 1.2155338984982977, grad_norm: 0.26980356223303237, ic: 0.22738141889957833
train 24, step: 1000, loss: 0.9110014282473836, grad_norm: 0.048079980220443824, ic: 0.5199842432543202
train 24, step: 1500, loss: 2.6195890547712284, grad_norm: 2.989961083109274, ic: 0.045968769259248476
train 24, step: 2000, loss: 0.9313176908236552, grad_norm: 0.13940648769057373, ic: 0.09991164870257234
Epoch 24: 2022-04-28 17:36:33.125104: train loss: 1.6124665871970545
Eval step 0: eval loss: 0.8274988268901474
Eval: 2022-04-28 17:37:04.958332: total loss: 1.0674151178429356, mse:4.61432999523487, ic :0.18800244204353053, sharpe5:16.88446370601654, irr5:573.249755859375, ndcg5:0.8473722624432648, pnl5:5.082355976104736 
train 25, step: 0, loss: 0.8297910123258024, grad_norm: 0.08684217612714856, ic: 0.6185118911902563
train 25, step: 500, loss: 0.8662517812677021, grad_norm: 0.027239782956421363, ic: 0.21165937059663814
train 25, step: 1000, loss: 2.0916224622762756, grad_norm: 0.1392266227336174, ic: 0.2516363949814133
train 25, step: 1500, loss: 1.1144260514895552, grad_norm: 0.6526359448671016, ic: 0.5559607398836857
train 25, step: 2000, loss: 1.0048895894777932, grad_norm: 0.4788499929860594, ic: 0.5938609796812839
Epoch 25: 2022-04-28 17:45:07.959128: train loss: 1.6189945416843456
Eval step 0: eval loss: 0.8299347020300974
Eval: 2022-04-28 17:45:39.150525: total loss: 1.068986715135027, mse:4.598027362237712, ic :0.1907941706936778, sharpe5:18.03872766494751, irr5:590.6278076171875, ndcg5:0.8532391565294026, pnl5:7.350954532623291 
train 26, step: 0, loss: 6.696769543730031, grad_norm: 0.32423823415747854, ic: 0.10319991977576345
train 26, step: 500, loss: 3.9213897728938623, grad_norm: 4.099535939040793, ic: 0.36827481077814384
train 26, step: 1000, loss: 1.2637560019500589, grad_norm: 1.4978786489913007, ic: 0.024676447058556282
train 26, step: 1500, loss: 0.8295561265704086, grad_norm: 0.19102746290422978, ic: 0.30364801571803923
train 26, step: 2000, loss: 0.9438587972069237, grad_norm: 0.510423328694831, ic: 0.16728860469895782
Epoch 26: 2022-04-28 17:53:40.678818: train loss: 1.6184772401315326
Eval step 0: eval loss: 0.8250791591889488
Eval: 2022-04-28 17:54:13.402182: total loss: 1.0647846497833264, mse:4.582516313449135, ic :0.19401914967783018, sharpe5:18.170621870756147, irr5:598.3959350585938, ndcg5:0.8523572628771671, pnl5:5.980518341064453 
train 27, step: 0, loss: 0.8304766965379902, grad_norm: 0.0821501634094808, ic: 0.11100733922217008
train 27, step: 500, loss: 0.9589748833935514, grad_norm: 1.1692297107038652, ic: 0.2691877125759312
train 27, step: 1000, loss: 0.742800778228925, grad_norm: 1.1809076311303999, ic: 0.20862690260134936
train 27, step: 1500, loss: 0.6486030719744628, grad_norm: 0.1349640837674635, ic: 0.5035877559879607
train 27, step: 2000, loss: 1.3811442984173312, grad_norm: 0.047049385832186694, ic: 0.02656301378367171
Epoch 27: 2022-04-28 18:02:17.423420: train loss: 1.6148001413744149
Eval step 0: eval loss: 0.8290995044125394
Eval: 2022-04-28 18:02:49.222333: total loss: 1.06675725550795, mse:4.5877449626724, ic :0.19049040550121224, sharpe5:16.951403084993363, irr5:578.4207763671875, ndcg5:0.8561514973335074, pnl5:5.322811126708984 
train 28, step: 0, loss: 1.542775417018581, grad_norm: 2.25863713702521, ic: 0.2168024901976548
train 28, step: 500, loss: 1.4087229302770403, grad_norm: 5.905092633898447, ic: 0.1706359697553766
train 28, step: 1000, loss: 0.9185976271383808, grad_norm: 0.29612886461121335, ic: 0.5822267445521873
train 28, step: 1500, loss: 1.036696972732129, grad_norm: 0.072749472467774, ic: 0.010202028710105043
train 28, step: 2000, loss: 1.043319421311829, grad_norm: 0.2748092040412455, ic: 0.09019126693367997
Epoch 28: 2022-04-28 18:10:54.048950: train loss: 1.6076736529960476
Eval step 0: eval loss: 0.8249841012743677
Eval: 2022-04-28 18:11:25.440458: total loss: 1.0694591773468876, mse:4.61895193551526, ic :0.19081716101651128, sharpe5:18.29316465497017, irr5:617.9379272460938, ndcg5:0.8586501009976325, pnl5:5.255997180938721 
train 29, step: 0, loss: 0.9088546602539803, grad_norm: 0.10812792625507114, ic: 0.10413424692353304
train 29, step: 500, loss: 1.0981144258294186, grad_norm: 0.3273098301911023, ic: 0.6195084788274006
train 29, step: 1000, loss: 1.0623542276237528, grad_norm: 1.2153515644786241, ic: 0.07400447295644286
train 29, step: 1500, loss: 2.3587190030981655, grad_norm: 0.6222305334005176, ic: -0.05919864981809796
train 29, step: 2000, loss: 4.191184714988426, grad_norm: 21.32137090402961, ic: 0.17437311822194118
Epoch 29: 2022-04-28 18:19:26.553628: train loss: 1.6116316153656995
Eval step 0: eval loss: 0.8326190269156678
Eval: 2022-04-28 18:19:55.156795: total loss: 1.06712528162616, mse:4.586525362611249, ic :0.18696828993087491, sharpe5:16.57733487010002, irr5:573.5289916992188, ndcg5:0.8469041878779902, pnl5:5.046658039093018 
train 30, step: 0, loss: 1.027051103092632, grad_norm: 0.17490710488182729, ic: 0.4957630440182565
train 30, step: 500, loss: 1.4152185128691552, grad_norm: 1.5588909633651469, ic: 0.000416213047802174
train 30, step: 1000, loss: 0.9798256613991477, grad_norm: 0.08841185589137944, ic: -0.01654522338673519
train 30, step: 1500, loss: 1.4900395332585699, grad_norm: 7.464322745984398, ic: 0.1635067241999526
train 30, step: 2000, loss: 1.835048730991775, grad_norm: 1.6203239750231189, ic: 0.11833325586904209
Epoch 30: 2022-04-28 18:27:57.968189: train loss: 1.6099357574544293
Eval step 0: eval loss: 0.8279809338777661
Eval: 2022-04-28 18:28:29.428986: total loss: 1.0669365695524027, mse:4.613415073629687, ic :0.19760996523605548, sharpe5:17.414095079898832, irr5:607.0673828125, ndcg5:0.8330772491538602, pnl5:5.521718978881836 
train 31, step: 0, loss: 1.0391476421758157, grad_norm: 0.27361186794745235, ic: 0.3602501222186412
train 31, step: 500, loss: 1.5296754436728395, grad_norm: 3.6261584445674924, ic: 0.020334720764582856
train 31, step: 1000, loss: 4.4008518430425445, grad_norm: 2.3797317478802684, ic: 0.46367274820745125
train 31, step: 1500, loss: 0.7708097374074152, grad_norm: 0.18892497098472172, ic: 0.7151299879545303
train 31, step: 2000, loss: 1.208636901298917, grad_norm: 1.5567452686067698, ic: 0.21877762820118837
Epoch 31: 2022-04-28 18:36:38.313081: train loss: 1.6068539107892035
Eval step 0: eval loss: 0.8342676192867492
Eval: 2022-04-28 18:37:08.052627: total loss: 1.066352223175834, mse:4.587802519289658, ic :0.18864215257829042, sharpe5:16.480678288936613, irr5:563.519287109375, ndcg5:0.8565687160567013, pnl5:4.01499605178833 
train 32, step: 0, loss: 1.1307890632611555, grad_norm: 0.07631861104804132, ic: 0.18742685502358386
train 32, step: 500, loss: 1.5013916976808563, grad_norm: 1.5016381683190172, ic: 0.12003619297073675
train 32, step: 1000, loss: 1.0383366418562654, grad_norm: 0.25451089868816873, ic: 0.5139776254053318
train 32, step: 1500, loss: 0.9576558477545767, grad_norm: 3.655427713861751, ic: 0.05437306470464708
train 32, step: 2000, loss: 0.9431244969588602, grad_norm: 0.09606376616217203, ic: 0.5516064845344415
Epoch 32: 2022-04-28 18:45:11.816716: train loss: 1.6058735629607537
Eval step 0: eval loss: 0.8246131953248484
Eval: 2022-04-28 18:45:42.385062: total loss: 1.0641435645145945, mse:4.5921896759649945, ic :0.19456561570456019, sharpe5:17.49148126244545, irr5:587.1594848632812, ndcg5:0.8554866228752458, pnl5:4.4029011726379395 
train 33, step: 0, loss: 1.254149863323434, grad_norm: 0.3166796640315418, ic: 0.22249652884666427
train 33, step: 500, loss: 0.9851747517188694, grad_norm: 0.10796910219168204, ic: 0.21513290153359704
train 33, step: 1000, loss: 1.0632780183422093, grad_norm: 2.5512087723210204, ic: 0.20219247154240044
train 33, step: 1500, loss: 0.8881509403034179, grad_norm: 0.1829682617748567, ic: 0.5502734707420001
train 33, step: 2000, loss: 0.8080666325927348, grad_norm: 0.08878617021591256, ic: 0.25295497251247373
Epoch 33: 2022-04-28 18:53:41.917492: train loss: 1.6152519575348925
Eval step 0: eval loss: 0.8376828867969572
Eval: 2022-04-28 18:54:12.929875: total loss: 1.0669988670360295, mse:4.5818752598218, ic :0.1947484135628196, sharpe5:16.34430796265602, irr5:577.7190551757812, ndcg5:0.8474954655341681, pnl5:4.539747714996338 
train 34, step: 0, loss: 1.0265206013347936, grad_norm: 1.194156458858838, ic: 0.5940445161188216
train 34, step: 500, loss: 0.795173855002867, grad_norm: 1.341820489988026, ic: 0.2872138368054481
train 34, step: 1000, loss: 3.233639952956989, grad_norm: 1.9155375790102047, ic: 0.3070704902345699
train 34, step: 1500, loss: 0.8153527933877756, grad_norm: 0.28840698221555666, ic: 0.6809561346493043
train 34, step: 2000, loss: 6.065810932658792, grad_norm: 353.2846228306451, ic: 0.4811544656344951
Epoch 34: 2022-04-28 19:02:08.167097: train loss: 1.6145734296375882
Eval step 0: eval loss: 1.1088374532814145
Eval: 2022-04-28 19:02:39.757492: total loss: 1.2625532781008548, mse:5.994643759004049, ic :0.10288095016412539, sharpe5:16.92774169921875, irr5:564.45361328125, ndcg5:0.8533580597461752, pnl5:4.457737445831299 
train 35, step: 0, loss: 1.1196599264705882, grad_norm: 8.30138970185131, ic: 0.46916503124949915
train 35, step: 500, loss: 1.172211566716067, grad_norm: 2.0252384922729076, ic: 0.14044193272461505
train 35, step: 1000, loss: 1.6463755224920382, grad_norm: 9.084899356891306, ic: 0.1041366566581313
train 35, step: 1500, loss: 1.6101742393092107, grad_norm: 3.4357449896151038, ic: 0.05879450492884474
train 35, step: 2000, loss: 0.7874429468165106, grad_norm: 0.051570495868431404, ic: 0.5427543655544127
Epoch 35: 2022-04-28 19:10:41.604265: train loss: 1.6113041420486245
Eval step 0: eval loss: 0.8271093338382507
Eval: 2022-04-28 19:11:13.099646: total loss: 1.0645715073953053, mse:4.586613329866154, ic :0.1935609803594993, sharpe5:16.010102949142457, irr5:556.8038940429688, ndcg5:0.8384940803392061, pnl5:4.145700931549072 
train 36, step: 0, loss: 1.8088148946477631, grad_norm: 1.9805804126288007, ic: 0.0888244404354174
train 36, step: 500, loss: 0.8397013827324665, grad_norm: 0.8095924672495918, ic: 0.1581534315463078
train 36, step: 1000, loss: 1.6278227982954545, grad_norm: 3.624093683162434, ic: 0.24290008082858652
train 36, step: 1500, loss: 0.7645142315423976, grad_norm: 0.06253561760596732, ic: 0.3815095895514289
train 36, step: 2000, loss: 1.1164044659700159, grad_norm: 1.9915054141594508, ic: 0.7771302835909165
Epoch 36: 2022-04-28 19:19:07.852944: train loss: 1.609175800076545
Eval step 0: eval loss: 0.8315500434256453
Eval: 2022-04-28 19:19:38.662015: total loss: 1.0660745685697706, mse:4.6067462525825595, ic :0.19460487993884237, sharpe5:16.927435219287872, irr5:579.9382934570312, ndcg5:0.8474491237574806, pnl5:3.7167253494262695 
train 37, step: 0, loss: 2.0228944460064127, grad_norm: 6.714649565669784, ic: 0.19057439432023648
train 37, step: 500, loss: 2.3583227658544046, grad_norm: 5.31582918822837, ic: -0.006626861304584709
train 37, step: 1000, loss: 1.0677027593464612, grad_norm: 0.45125186280392376, ic: 0.08516464599664304
train 37, step: 1500, loss: 1.9822492135375787, grad_norm: 3.224157742105164, ic: 0.612227152331003
train 37, step: 2000, loss: 1.3075430733816964, grad_norm: 0.36667721880180987, ic: 0.1570439021711592
Epoch 37: 2022-04-28 19:27:28.785884: train loss: 1.6078377355891578
Eval step 0: eval loss: 0.8282001845075407
Eval: 2022-04-28 19:28:00.116271: total loss: 1.0655880845349814, mse:4.597563057765583, ic :0.19352197226809828, sharpe5:17.49720789670944, irr5:587.4552612304688, ndcg5:0.8330297741380149, pnl5:7.352624893188477 
train 38, step: 0, loss: 1.3313782854778011, grad_norm: 1.3978522301373368, ic: -0.07974402565486403
train 38, step: 500, loss: 0.904518711419753, grad_norm: 0.16397642647943966, ic: 0.26186679350672104
train 38, step: 1000, loss: 0.8965189213809288, grad_norm: 0.5494583509064376, ic: 0.1881667740668806
train 38, step: 1500, loss: 0.9578643312215263, grad_norm: 0.19233771161157448, ic: 0.1755074518540891
train 38, step: 2000, loss: 2.3107135692031724, grad_norm: 11.043281650884914, ic: 0.0012297357850728705
Epoch 38: 2022-04-28 19:35:57.606067: train loss: 1.5998980736697601
Eval step 0: eval loss: 0.8276974323300842
Eval: 2022-04-28 19:36:27.998499: total loss: 1.063193120520133, mse:4.584499158640405, ic :0.19891060203323976, sharpe5:17.405362293720245, irr5:595.0289306640625, ndcg5:0.8373438840437684, pnl5:5.450070858001709 
train 39, step: 0, loss: 0.9715876681359901, grad_norm: 0.01175822017231465, ic: 0.05774652195212913
train 39, step: 500, loss: 0.889550668656322, grad_norm: 0.7574342015580023, ic: 0.250601786194695
train 39, step: 1000, loss: 0.9400836511686025, grad_norm: 0.10577836438559354, ic: 0.17392693601402628
train 39, step: 1500, loss: 2.1037814326218305, grad_norm: 1.7068179922368345, ic: 0.17749645183996027
train 39, step: 2000, loss: 0.6064773246198657, grad_norm: 0.04044441826886343, ic: 0.18450771624090478
Epoch 39: 2022-04-28 19:44:31.448340: train loss: 1.6078956294337086
Eval step 0: eval loss: 0.8294051304004214
Eval: 2022-04-28 19:45:03.403318: total loss: 1.0660891115749382, mse:4.606902953610794, ic :0.19018653971711738, sharpe5:17.39183177232742, irr5:586.5602416992188, ndcg5:0.8324599047829515, pnl5:5.5876874923706055 

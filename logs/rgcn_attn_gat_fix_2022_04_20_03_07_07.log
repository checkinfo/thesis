Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='AdjSeqTimeDataset', dout=0.3, epochs=40, glstm_layers=1, gnn_layers=2, gpu=0, graph_attn=True, hidden_dim=128, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=3, mask_adj=True, mask_type='soft', model_type='RGCNModel', normalize_adj=True, num_days=1, num_heads=1, print_inteval=500, relation_num=1, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_250_0.8/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
29289
RGCNModel(
  (fc1): Linear(in_features=9, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
  (fc4): Linear(in_features=128, out_features=1, bias=True)
  (gnns): ModuleList(
    (0): RGCN(
      (attention): ModuleList(
        (0): GraphAttentionLayer (128 -> 128)
      )
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
    )
    (1): RGCN(
      (attention): ModuleList(
        (0): GraphAttentionLayer (128 -> 128)
      )
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
    )
  )
  (dropout): Dropout(p=0.3, inplace=False)
  (relu): LeakyReLU(negative_slope=0.01)
)
train 0, step: 0, loss: 2.0705317440711464, grad_norm: 0.502037390053473, ic: -0.12396493901293616
train 0, step: 500, loss: 1.370422872293167, grad_norm: 0.8143774494778271, ic: -0.010050694273339766
train 0, step: 1000, loss: 1.5076045209569353, grad_norm: 0.03217452430539799, ic: -0.00835354608085633
train 0, step: 1500, loss: 1.187320037771426, grad_norm: 0.09523142812209053, ic: -0.011886841400707223
train 0, step: 2000, loss: 1.558237959698933, grad_norm: 0.046923581946997146, ic: -0.02732120152588408
Epoch 0: 2022-04-20 15:07:38.483447: train loss: 1.647403076935161
Eval step 0: eval loss: 1.0139230865751712
Eval: 2022-04-20 15:07:40.982788: total loss: 1.0923057050550942, mse:4.890248605346903, ic :-0.0031517781115521113, sharpe5:-0.8776759900152683, irr5:-8.530738830566406, ndcg5:0.8326678093534768, pnl5:0.8915984630584717 
train 1, step: 0, loss: 0.637586008204092, grad_norm: 0.04600563122828552, ic: 0.0413731824695609
train 1, step: 500, loss: 1.2673486459031502, grad_norm: 0.29016691091793045, ic: 0.004089509577225792
train 1, step: 1000, loss: 0.8812039010618428, grad_norm: 0.06385915243753933, ic: 0.027749168212437746
train 1, step: 1500, loss: 1.84735647061976, grad_norm: 0.5371906081494084, ic: 0.03919232689555785
train 1, step: 2000, loss: 1.3892930689486027, grad_norm: 0.2314950446214163, ic: -0.0317265937034124
Epoch 1: 2022-04-20 15:08:08.391005: train loss: 1.6466767329071579
Eval step 0: eval loss: 1.0130656374448723
Eval: 2022-04-20 15:08:11.050815: total loss: 1.090280406025219, mse:4.8884643018743, ic :0.00982253766234033, sharpe5:0.4669027536548674, irr5:4.6410393714904785, ndcg5:0.8362494503390829, pnl5:1.0449706315994263 
train 2, step: 0, loss: 1.3352786992447339, grad_norm: 0.49513170724385613, ic: -0.01886366065458004
train 2, step: 500, loss: 0.9512999654720694, grad_norm: 0.26146000332996805, ic: -0.0028655327868225763
train 2, step: 1000, loss: 3.0437774160092492, grad_norm: 1.4379472530728328, ic: 0.011096087170311013
train 2, step: 1500, loss: 2.2907925877279935, grad_norm: 0.8407883108071272, ic: -0.09973076753329518
train 2, step: 2000, loss: 1.458079278030458, grad_norm: 0.2750258384072489, ic: 0.013253408878829465
Epoch 2: 2022-04-20 15:08:42.409459: train loss: 1.6465606890584454
Eval step 0: eval loss: 1.0134119211591626
Eval: 2022-04-20 15:08:45.365021: total loss: 1.091377992841968, mse:4.888798241097782, ic :-0.0022828159211506103, sharpe5:0.19295340017415583, irr5:0.9481004476547241, ndcg5:0.8496289383509562, pnl5:1.064754605293274 
train 3, step: 0, loss: 1.8158604359936878, grad_norm: 0.05452924057566185, ic: -0.05929781481077054
train 3, step: 500, loss: 0.7860247968547867, grad_norm: 0.02366368348741812, ic: -0.001743998048770918
train 3, step: 1000, loss: 1.4343140949034436, grad_norm: 0.368215073608085, ic: 0.06218728232364988
train 3, step: 1500, loss: 2.6494916663645594, grad_norm: 0.35377090698945807, ic: 0.13892341533497748
train 3, step: 2000, loss: 1.3599777684067236, grad_norm: 0.15560959240483455, ic: 0.09986054370543554
Epoch 3: 2022-04-20 15:09:19.592260: train loss: 1.6465085006647442
Eval step 0: eval loss: 1.013542798018694
Eval: 2022-04-20 15:09:22.472185: total loss: 1.0916424309052029, mse:4.889148740088957, ic :-0.0055645972629767785, sharpe5:-0.7753444457799196, irr5:-7.547840595245361, ndcg5:0.8545451970261072, pnl5:0.8238930106163025 
train 4, step: 0, loss: 1.1715533809574772, grad_norm: 0.14936752989147975, ic: -0.03822488009776639
train 4, step: 500, loss: 0.9985756953704779, grad_norm: 0.0026641480354417787, ic: -0.10005022191585893
train 4, step: 1000, loss: 1.3368392001573228, grad_norm: 0.06071813655987997, ic: -0.026676734171464697
train 4, step: 1500, loss: 1.0929613944811698, grad_norm: 0.07078470501974359, ic: -0.01831904294978757
train 4, step: 2000, loss: 4.167713660503541, grad_norm: 0.8638681977099634, ic: -0.01041260615899963
Epoch 4: 2022-04-20 15:09:57.046279: train loss: 1.646328982763633
Eval step 0: eval loss: 1.0151634597979198
Eval: 2022-04-20 15:09:59.970046: total loss: 1.0941950352617833, mse:4.894314697551274, ic :-0.00599202697355679, sharpe5:-0.5907114525139332, irr5:-6.331018924713135, ndcg5:0.8634565943358055, pnl5:0.9066950678825378 
train 5, step: 0, loss: 0.9799557385876809, grad_norm: 0.15030678764695518, ic: 0.027966611161352226
train 5, step: 500, loss: 0.7991966500666469, grad_norm: 0.005719389009035639, ic: 0.05043786130817335
train 5, step: 1000, loss: 1.112629692942527, grad_norm: 0.03146926587378632, ic: -0.020396349395868096
train 5, step: 1500, loss: 1.7370692803607723, grad_norm: 0.3159544404691028, ic: 0.04148049159733026
train 5, step: 2000, loss: 2.18719920007966, grad_norm: 0.7985802026906846, ic: 0.02034622446110854
Epoch 5: 2022-04-20 15:10:34.668662: train loss: 1.6467602790124158
Eval step 0: eval loss: 1.0140484352372958
Eval: 2022-04-20 15:10:37.764488: total loss: 1.0925114612347104, mse:4.890635909681076, ic :0.008904554975642883, sharpe5:-1.2799953404814004, irr5:-18.027544021606445, ndcg5:0.8483289765672173, pnl5:0.8903738856315613 
train 6, step: 0, loss: 0.7756342643095483, grad_norm: 0.010645519094731794, ic: -0.04167184529655732
train 6, step: 500, loss: 1.4469465289199561, grad_norm: 0.22270460197464162, ic: -0.04984155821166896
train 6, step: 1000, loss: 1.2447291681772041, grad_norm: 0.17483978212101656, ic: -0.2698677534245403
train 6, step: 1500, loss: 1.0771545179834905, grad_norm: 0.30784970025750247, ic: 0.038080763646432675
train 6, step: 2000, loss: 2.28062945926248, grad_norm: 0.9214188882261012, ic: 0.03742385549969615
Epoch 6: 2022-04-20 15:11:14.235178: train loss: 1.6463087534453253
Eval step 0: eval loss: 1.0133869799894681
Eval: 2022-04-20 15:11:17.399915: total loss: 1.0913335739605816, mse:4.888742897566944, ic :-0.007709184403349559, sharpe5:-0.958484472669661, irr5:-8.868518829345703, ndcg5:0.8623078296160156, pnl5:0.8519283533096313 
train 7, step: 0, loss: 1.4554121592488674, grad_norm: 0.48668321396056763, ic: 0.04719684452923658
train 7, step: 500, loss: 1.3321982093954752, grad_norm: 0.02198003777640529, ic: 0.03120760829456788
train 7, step: 1000, loss: 0.6637134366307371, grad_norm: 0.0032808939075691327, ic: -0.030068089688140693
train 7, step: 1500, loss: 1.0136368371666347, grad_norm: 0.13340585618283618, ic: 0.07391143024421505
train 7, step: 2000, loss: 1.6068408641623746, grad_norm: 0.5480921544879234, ic: 0.028083766090410793
Epoch 7: 2022-04-20 15:11:53.861906: train loss: 1.6468248707302364
Eval step 0: eval loss: 1.0134546039856502
Eval: 2022-04-20 15:11:57.090900: total loss: 1.0914737841199222, mse:4.88891956203154, ic :-0.009368348258459443, sharpe5:0.9425375249236821, irr5:5.389438629150391, ndcg5:0.853603281205718, pnl5:1.2474429607391357 
train 8, step: 0, loss: 1.2165608338270142, grad_norm: 0.08288517979029222, ic: -0.010667810666943896
train 8, step: 500, loss: 5.5500587774294665, grad_norm: 1.0234782714194883, ic: -0.010295126742751038
train 8, step: 1000, loss: 1.8597087036036921, grad_norm: 0.5252046305998447, ic: -0.004729001506901309
train 8, step: 1500, loss: 1.1397422620143842, grad_norm: 0.2987738097118312, ic: 0.05771125880851019
train 8, step: 2000, loss: 1.1262039771446815, grad_norm: 0.45865368875577306, ic: -0.00664514625520893
Epoch 8: 2022-04-20 15:12:34.299029: train loss: 1.6465686932058727
Eval step 0: eval loss: 1.0158740260087544
Eval: 2022-04-20 15:12:37.312752: total loss: 1.095165112070665, mse:4.896755304960327, ic :-0.012024824245961581, sharpe5:-1.2038696039468049, irr5:-11.18665885925293, ndcg5:0.8424200491002231, pnl5:0.925676703453064 
train 9, step: 0, loss: 1.1506657399879723, grad_norm: 0.008655914496717022, ic: -0.06761617924503854
train 9, step: 500, loss: 3.188487710473744, grad_norm: 0.6150640319015682, ic: -0.017925332821575858
train 9, step: 1000, loss: 0.8643995746561766, grad_norm: 0.06055564878632692, ic: -0.03126915313180438
train 9, step: 1500, loss: 2.1376955103449147, grad_norm: 0.816396468754776, ic: -0.005033294166130971
train 9, step: 2000, loss: 0.6086070423141228, grad_norm: 0.008901531090207793, ic: -0.031485866093667644
Epoch 9: 2022-04-20 15:13:15.886110: train loss: 1.6466424451440314
Eval step 0: eval loss: 1.0137387276197998
Eval: 2022-04-20 15:13:18.989964: total loss: 1.0919972443980257, mse:4.889706475200011, ic :0.0037294669760734103, sharpe5:1.0830351615697145, irr5:7.4914398193359375, ndcg5:0.8558934851051939, pnl5:1.091752529144287 
train 10, step: 0, loss: 1.340200380405766, grad_norm: 0.02195073585698243, ic: -0.02030301932367949
train 10, step: 500, loss: 0.9059821671839462, grad_norm: 0.006945053489199789, ic: 0.06941388456455878
train 10, step: 1000, loss: 1.5333511136552873, grad_norm: 0.4684530231562137, ic: -0.029703630986158386
train 10, step: 1500, loss: 3.1160557324449254, grad_norm: 0.6746256839874653, ic: 0.04169283736953824
train 10, step: 2000, loss: 1.3941500121699277, grad_norm: 0.10793053805839709, ic: 0.08157578614480629
Epoch 10: 2022-04-20 15:13:56.171749: train loss: 1.6466577870836963
Eval step 0: eval loss: 1.0135633680555556
Eval: 2022-04-20 15:13:59.662137: total loss: 1.0916168483693283, mse:4.889024162322621, ic :-0.008815295934920156, sharpe5:-0.36036784071475264, irr5:-4.189422607421875, ndcg5:0.8449810897254448, pnl5:0.9138362407684326 
train 11, step: 0, loss: 4.870411148846755, grad_norm: 0.46906687686988424, ic: -0.01887679200546483
train 11, step: 500, loss: 0.9917020314300116, grad_norm: 0.05583809063255466, ic: -0.07827036533012088
train 11, step: 1000, loss: 1.0440825601282417, grad_norm: 0.2736481930984039, ic: 0.00908342748418706
train 11, step: 1500, loss: 0.69662205540023, grad_norm: 0.0008281979458694128, ic: 0.026381481324694624
train 11, step: 2000, loss: 1.0997948108118398, grad_norm: 0.03680662462264032, ic: 0.009540218338300155
Epoch 11: 2022-04-20 15:14:37.548607: train loss: 1.64611118798177
Eval step 0: eval loss: 1.0132613099205172
Eval: 2022-04-20 15:14:40.742273: total loss: 1.0909968177708356, mse:4.8883606583714, ic :-0.0035802198620067606, sharpe5:-0.9156653716787695, irr5:-9.988160133361816, ndcg5:0.8600673574320125, pnl5:0.941379725933075 
train 12, step: 0, loss: 1.397089063985266, grad_norm: 0.22744669264253453, ic: -0.005176122220622246
train 12, step: 500, loss: 0.8139037604207774, grad_norm: 0.3154440313801768, ic: 0.023942233010487906
train 12, step: 1000, loss: 1.2652452614816951, grad_norm: 0.16467354425404024, ic: 0.035001600432801205
train 12, step: 1500, loss: 1.097777947008792, grad_norm: 0.17746343984282278, ic: 0.04248856282714783
train 12, step: 2000, loss: 1.1155150736876074, grad_norm: 0.04896797042395757, ic: 0.013547512665525206
Epoch 12: 2022-04-20 15:15:17.999099: train loss: 1.6464610466443566
Eval step 0: eval loss: 1.0138134868475184
Eval: 2022-04-20 15:15:21.114166: total loss: 1.0920602476741492, mse:4.8897562720417564, ic :-0.0053117840987227495, sharpe5:-1.0328664542734622, irr5:-10.932639122009277, ndcg5:0.853803087057884, pnl5:0.9220330119132996 
train 13, step: 0, loss: 1.0975940150404249, grad_norm: 0.020532302640053023, ic: 0.0342830712209021
train 13, step: 500, loss: 1.138283672769561, grad_norm: 0.004110546545406375, ic: 0.1467370389892172
train 13, step: 1000, loss: 1.38904769021071, grad_norm: 0.3789053489746415, ic: 0.02964485753378178
train 13, step: 1500, loss: 0.7760009301126094, grad_norm: 0.0010776649768190155, ic: -0.018998599710194172
train 13, step: 2000, loss: 1.0533962923627112, grad_norm: 0.030241603133098375, ic: -0.11589768302806036
Epoch 13: 2022-04-20 15:15:59.307017: train loss: 1.646785066319593
Eval step 0: eval loss: 1.0135763528913242
Eval: 2022-04-20 15:16:02.584230: total loss: 1.0917037780421799, mse:4.889233566878558, ic :-0.007678117111028448, sharpe5:-1.2825941531360148, irr5:-11.896180152893066, ndcg5:0.8571569916853484, pnl5:0.8331238627433777 
train 14, step: 0, loss: 1.812299178818525, grad_norm: 0.3789335917657962, ic: -0.06330013311219662
train 14, step: 500, loss: 1.2888622185835323, grad_norm: 0.11811034761344408, ic: -0.03481444775944144
train 14, step: 1000, loss: 1.08517874725594, grad_norm: 0.11627458089313514, ic: 0.07111789131603857
train 14, step: 1500, loss: 1.0076710713469494, grad_norm: 0.07096828938229488, ic: -0.0497101484133239
train 14, step: 2000, loss: 2.2837459694891926, grad_norm: 0.4080331648499572, ic: -0.04155081691660684
Epoch 14: 2022-04-20 15:16:40.193389: train loss: 1.646403211044814
Eval step 0: eval loss: 1.013834828260762
Eval: 2022-04-20 15:16:43.450280: total loss: 1.0921529744792897, mse:4.8899550110010725, ic :-0.008893294120130665, sharpe5:-1.1130039799958467, irr5:-10.38129997253418, ndcg5:0.8404813519674778, pnl5:0.8573274612426758 
train 15, step: 0, loss: 0.9700193169206405, grad_norm: 0.1097842620522037, ic: -0.04351791660652506
train 15, step: 500, loss: 1.2289743445318468, grad_norm: 0.0022657417335105543, ic: 0.03574699946736111
train 15, step: 1000, loss: 1.7479111979166668, grad_norm: 0.019389057938030804, ic: 0.11597119379960594
train 15, step: 1500, loss: 5.43195783787703, grad_norm: 0.7716305216139246, ic: -0.053857381595123974
train 15, step: 2000, loss: 0.9288134062673034, grad_norm: 0.01735987711651804, ic: -0.0011594650827663117
Epoch 15: 2022-04-20 15:17:20.922365: train loss: 1.6470673199301806
Eval step 0: eval loss: 1.0135650393710505
Eval: 2022-04-20 15:17:24.083123: total loss: 1.0916868875677523, mse:4.889215921234932, ic :-0.011273290049635594, sharpe5:-0.835968765579164, irr5:-7.837057113647461, ndcg5:0.8592786797192522, pnl5:0.8994997143745422 
train 16, step: 0, loss: 6.335457672093982, grad_norm: 0.8209680452498711, ic: 0.00871957594676842
train 16, step: 500, loss: 1.4118072994171627, grad_norm: 0.5922358988428493, ic: 0.004005361739468088
train 16, step: 1000, loss: 0.813963958469732, grad_norm: 0.051838377121505776, ic: -0.07859162889445856
train 16, step: 1500, loss: 1.2008150037956675, grad_norm: 0.21803165639789723, ic: -0.036574572147676176
train 16, step: 2000, loss: 1.01791424556832, grad_norm: 0.17673025560446215, ic: -0.021440181390943943
Epoch 16: 2022-04-20 15:18:02.592994: train loss: 1.6467034763714468
Eval step 0: eval loss: 1.0130676301671933
Eval: 2022-04-20 15:18:05.724403: total loss: 1.0901478956832629, mse:4.888747126585706, ic :0.00849895979606838, sharpe5:1.1588293511420489, irr5:7.448939323425293, ndcg5:0.8578585909674418, pnl5:1.2887907028198242 
train 17, step: 0, loss: 1.2007882521927722, grad_norm: 0.00011899698531935277, ic: -0.06556736256482877
train 17, step: 500, loss: 1.02033396685104, grad_norm: 0.003491489376357753, ic: -0.07278993550515142
train 17, step: 1000, loss: 3.366391625734839, grad_norm: 0.5976839077955093, ic: -0.06852648394986252
train 17, step: 1500, loss: 0.8897329781047735, grad_norm: 0.0028498272971207656, ic: -0.01791603942633948
train 17, step: 2000, loss: 1.027100756344379, grad_norm: 0.2789614408910446, ic: -0.021578801250032018
Epoch 17: 2022-04-20 15:18:42.859106: train loss: 1.6465825581829012
Eval step 0: eval loss: 1.0131772298948458
Eval: 2022-04-20 15:18:46.343268: total loss: 1.0908157632823527, mse:4.888266936079041, ic :-0.0075863545940658755, sharpe5:-0.5989083126559853, irr5:-6.14401912689209, ndcg5:0.8474592857575308, pnl5:0.9061588048934937 
train 18, step: 0, loss: 0.8558185152177726, grad_norm: 0.005077055474049484, ic: -0.01227295467016456
train 18, step: 500, loss: 2.5283281362340797, grad_norm: 0.933417761682467, ic: -0.02154047524674376
train 18, step: 1000, loss: 1.3926685799797662, grad_norm: 0.270289508655034, ic: -0.09113683360881424
train 18, step: 1500, loss: 1.8100127688394752, grad_norm: 0.5351420437576401, ic: 0.10697935323437172
train 18, step: 2000, loss: 1.2835325949595608, grad_norm: 0.2551121838504623, ic: 0.03571077733514405
Epoch 18: 2022-04-20 15:19:24.737334: train loss: 1.646483505480394
Eval step 0: eval loss: 1.0136065008515995
Eval: 2022-04-20 15:19:27.892829: total loss: 1.0917410175087903, mse:4.8892791089210865, ic :-0.0072200243000062675, sharpe5:-0.5392079257965088, irr5:-5.430018424987793, ndcg5:0.8368572235284362, pnl5:0.9445602893829346 
train 19, step: 0, loss: 2.2421671393816944, grad_norm: 0.4394235404127604, ic: 0.01368241752995049
train 19, step: 500, loss: 1.0137517175009083, grad_norm: 0.02192214617805715, ic: 0.04858667441341757
train 19, step: 1000, loss: 1.0757247934863217, grad_norm: 0.015602634114750956, ic: -0.03167870956167058
train 19, step: 1500, loss: 1.6002890504436726, grad_norm: 0.00029412515785336477, ic: 0.09786096212762366
train 19, step: 2000, loss: 2.0289035687959203, grad_norm: 0.5375771110298466, ic: -0.06231805085697789
Epoch 19: 2022-04-20 15:20:05.380875: train loss: 1.646453723887524
Eval step 0: eval loss: 1.013312027917654
Eval: 2022-04-20 15:20:08.493876: total loss: 1.0911418778752764, mse:4.8884908128528, ic :-0.00838697812449289, sharpe5:-0.7353243389725684, irr5:-7.133297443389893, ndcg5:0.8424066283336166, pnl5:0.9440895318984985 
train 20, step: 0, loss: 1.2694371097402977, grad_norm: 0.2572274591402122, ic: -0.0030061465804038416
train 20, step: 500, loss: 1.2139520548088512, grad_norm: 0.40327615281535384, ic: 0.008933062900577958
train 20, step: 1000, loss: 1.5779821861351906, grad_norm: 0.17912158746096205, ic: -0.015486008258034225
train 20, step: 1500, loss: 0.8609340814261927, grad_norm: 0.15938383988664834, ic: 0.06005199424056478
train 20, step: 2000, loss: 1.3409134688257882, grad_norm: 0.044838231881859106, ic: -0.13089277351445536
Epoch 20: 2022-04-20 15:20:45.537642: train loss: 1.6468245107999848
Eval step 0: eval loss: 1.0135952516126907
Eval: 2022-04-20 15:20:48.708602: total loss: 1.0917459558983034, mse:4.889308387556651, ic :0.008011114302012514, sharpe5:0.8513910201564431, irr5:5.026920318603516, ndcg5:0.856370150918129, pnl5:1.1539013385772705 
train 21, step: 0, loss: 1.4414876776603498, grad_norm: 0.1814417760455573, ic: 0.03462814662935493
train 21, step: 500, loss: 1.098693520765589, grad_norm: 0.05922952966095932, ic: -0.0572057142855971
train 21, step: 1000, loss: 0.9506502927280197, grad_norm: 0.15708883253220887, ic: 0.047114261019301426
train 21, step: 1500, loss: 0.8194533096303174, grad_norm: 0.08377356082921697, ic: -0.09680506132607053
train 21, step: 2000, loss: 1.1748224334044604, grad_norm: 0.0013776699038627054, ic: -0.011256134898429275
Epoch 21: 2022-04-20 15:21:26.755455: train loss: 1.6463964384626353
Eval step 0: eval loss: 1.0134138496001184
Eval: 2022-04-20 15:21:29.841810: total loss: 1.0913373285245254, mse:4.888725786849478, ic :-0.005314940501661246, sharpe5:-0.38735610634088513, irr5:-4.684120178222656, ndcg5:0.8584991898989139, pnl5:1.2103209495544434 
train 22, step: 0, loss: 1.068674428925509, grad_norm: 0.17726248773328693, ic: 0.02469599789231777
train 22, step: 500, loss: 1.0281878614050197, grad_norm: 0.002307768733345042, ic: 0.05543158945186588
train 22, step: 1000, loss: 0.9316075623445869, grad_norm: 0.012975353616238566, ic: 0.01884783422945612
train 22, step: 1500, loss: 1.036418023510514, grad_norm: 0.004164277930966145, ic: 0.05367887436636832
train 22, step: 2000, loss: 1.0725656908611918, grad_norm: 0.09204310011893088, ic: 0.06293154682395728
Epoch 22: 2022-04-20 15:22:07.036741: train loss: 1.6471322479891195
Eval step 0: eval loss: 1.0136914808163835
Eval: 2022-04-20 15:22:10.338727: total loss: 1.091856876056687, mse:4.889423242136363, ic :-0.006875065123810197, sharpe5:-0.9994534020870923, irr5:-9.68161678314209, ndcg5:0.8487922135817058, pnl5:0.8786378502845764 
train 23, step: 0, loss: 1.2870616583472332, grad_norm: 0.7100630436776894, ic: 0.09407216080006321
train 23, step: 500, loss: 0.9911728743668442, grad_norm: 0.1264247834356801, ic: -0.06970752927507218
train 23, step: 1000, loss: 2.303726994292294, grad_norm: 0.7292499098698647, ic: 0.03023503568183094
train 23, step: 1500, loss: 0.8756141762198107, grad_norm: 0.22975676413500726, ic: -0.0009744792885164138
train 23, step: 2000, loss: 1.5180434315653346, grad_norm: 0.30191063159893294, ic: -0.09328843992481398
Epoch 23: 2022-04-20 15:22:48.571032: train loss: 1.6461180521407421
Eval step 0: eval loss: 1.0152922796537651
Eval: 2022-04-20 15:22:51.649109: total loss: 1.0941981586527252, mse:4.894282334603763, ic :0.007426307148937071, sharpe5:0.820593511685729, irr5:13.45285701751709, ndcg5:0.8409392389069937, pnl5:1.1753106117248535 
train 24, step: 0, loss: 1.2026138484338407, grad_norm: 0.09269799632589298, ic: 0.03582717052039583
train 24, step: 500, loss: 1.2390268938310451, grad_norm: 0.14730231607851232, ic: -0.1325289407188212
train 24, step: 1000, loss: 1.0810964630871285, grad_norm: 0.2516249260981687, ic: -0.042334016373154836
train 24, step: 1500, loss: 1.2016355499507874, grad_norm: 0.05031931668428145, ic: 0.06095228507283344
train 24, step: 2000, loss: 1.3799870768743416, grad_norm: 0.34322717427115557, ic: -0.09107592285800982
Epoch 24: 2022-04-20 15:23:27.749758: train loss: 1.6468837108349506
Eval step 0: eval loss: 1.0141105310360716
Eval: 2022-04-20 15:23:30.873388: total loss: 1.092595935159305, mse:4.890788328998179, ic :-0.0020201266943848752, sharpe5:-0.41913956500589844, irr5:-5.471218585968018, ndcg5:0.8389542466490401, pnl5:0.9641604423522949 
train 25, step: 0, loss: 1.3571195526297035, grad_norm: 0.29658727182792866, ic: 0.005585987319628666
train 25, step: 500, loss: 1.5204792765827924, grad_norm: 0.23271850157465818, ic: 0.0251590844921408
train 25, step: 1000, loss: 1.4029033500754744, grad_norm: 0.12762214137961778, ic: 0.013219134150137554
train 25, step: 1500, loss: 2.9458529071350763, grad_norm: 0.7227909600831498, ic: -0.050363733420407356
train 25, step: 2000, loss: 1.1979293823242188, grad_norm: 0.09912988375845985, ic: -0.043778810486426095
Epoch 25: 2022-04-20 15:24:08.523805: train loss: 1.6465014709096177
Eval step 0: eval loss: 1.0135593826109135
Eval: 2022-04-20 15:24:11.635496: total loss: 1.0916681316983285, mse:4.889183232072696, ic :-0.006789724488525479, sharpe5:-0.7647285579890012, irr5:-7.620757579803467, ndcg5:0.8362353420396812, pnl5:0.8559613823890686 
train 26, step: 0, loss: 1.6373707386363636, grad_norm: 0.14331918957479323, ic: 0.06092235801637566
train 26, step: 500, loss: 1.0171531357526191, grad_norm: 0.1289386190706766, ic: 0.029251763564098664
train 26, step: 1000, loss: 1.8899013192131557, grad_norm: 0.3219896209198294, ic: 0.034779978654278024
train 26, step: 1500, loss: 0.9221166888956792, grad_norm: 0.0005725916006506188, ic: -0.0402882354180474
train 26, step: 2000, loss: 1.0019677349901575, grad_norm: 0.0750144668387389, ic: -0.01595484111808373
Epoch 26: 2022-04-20 15:24:49.529480: train loss: 1.6464215176705896
Eval step 0: eval loss: 1.0134681030723407
Eval: 2022-04-20 15:24:52.670367: total loss: 1.0914899207124367, mse:4.888936873122829, ic :-0.002817904157486206, sharpe5:0.22815129593946037, irr5:1.6432170867919922, ndcg5:0.8379391983093076, pnl5:1.1434074640274048 
train 27, step: 0, loss: 1.804718017578125, grad_norm: 0.2522881581289596, ic: 0.017839381431208726
train 27, step: 500, loss: 1.4959786090287228, grad_norm: 0.1492055744083719, ic: -0.03804087497741056
train 27, step: 1000, loss: 2.699941117909868, grad_norm: 0.12657619607326231, ic: 0.012141483268179267
train 27, step: 1500, loss: 0.8492479079469553, grad_norm: 0.17586039408033186, ic: 0.0019555297513410503
train 27, step: 2000, loss: 1.3774249051939325, grad_norm: 0.4295072145862666, ic: -0.04028600029706791
Epoch 27: 2022-04-20 15:25:30.935406: train loss: 1.646171055420797
Eval step 0: eval loss: 1.0135181139744602
Eval: 2022-04-20 15:25:34.227760: total loss: 1.0915962890816095, mse:4.889085337386129, ic :-0.012861841448218886, sharpe5:-0.9760057955235243, irr5:-9.446258544921875, ndcg5:0.875839083672024, pnl5:1.0957691669464111 
train 28, step: 0, loss: 1.1868363660147228, grad_norm: 0.10123128841882427, ic: -0.019691727260463608
train 28, step: 500, loss: 2.970450739098538, grad_norm: 0.3153012776753948, ic: -0.018667886557144617
train 28, step: 1000, loss: 2.704127596452903, grad_norm: 0.8926933663515753, ic: -0.006178398295549047
train 28, step: 1500, loss: 1.0497935096489392, grad_norm: 3.463459495322157e-05, ic: 0.054707564614707084
train 28, step: 2000, loss: 1.7768341774164245, grad_norm: 0.2968456159715514, ic: 0.016446439942786113
Epoch 28: 2022-04-20 15:26:11.985818: train loss: 1.6464061892391268
Eval step 0: eval loss: 1.013248517928844
Eval: 2022-04-20 15:26:15.269829: total loss: 1.0909196398344347, mse:4.8882175956234315, ic :-0.007540055589577075, sharpe5:-1.031274579539895, irr5:-10.168656349182129, ndcg5:0.8434801000862291, pnl5:0.9332252144813538 
train 29, step: 0, loss: 1.5179059286746588, grad_norm: 0.08078694501401719, ic: 0.006916160454272211
train 29, step: 500, loss: 2.568833981157331, grad_norm: 0.8692082895698726, ic: -0.02839514357869139
train 29, step: 1000, loss: 1.7115214100346021, grad_norm: 0.6704077606172856, ic: 0.00476128933103794
train 29, step: 1500, loss: 3.9905536055756845, grad_norm: 0.9230305609203463, ic: -0.18287717377070045
train 29, step: 2000, loss: 0.985092203732685, grad_norm: 0.14614409952913426, ic: 0.01002773271915619
Epoch 29: 2022-04-20 15:26:52.394508: train loss: 1.646761642367467
Eval step 0: eval loss: 1.0133255270043444
Eval: 2022-04-20 15:26:55.608525: total loss: 1.0910684734991527, mse:4.888331154432132, ic :-0.006285630275791486, sharpe5:-0.5832956905290484, irr5:-6.0475568771362305, ndcg5:0.8444228794570904, pnl5:0.8825088143348694 
train 30, step: 0, loss: 1.289532299749243, grad_norm: 0.013139712444960643, ic: 0.009809111700245818
train 30, step: 500, loss: 1.9320508739616298, grad_norm: 0.18881770734478878, ic: 0.029483958408198157
train 30, step: 1000, loss: 3.500837791226041, grad_norm: 0.41378152411334224, ic: 0.050060454238626276
train 30, step: 1500, loss: 1.1130043605174151, grad_norm: 0.1850674076893173, ic: -0.013835852594107242
train 30, step: 2000, loss: 1.134002721156651, grad_norm: 0.05492148171721827, ic: 0.02554450637675845
Epoch 30: 2022-04-20 15:27:33.982871: train loss: 1.646686560817472
Eval step 0: eval loss: 1.0125616072604002
Eval: 2022-04-20 15:27:37.150260: total loss: 1.0916234226877675, mse:4.888091287062651, ic :0.013545513631509307, sharpe5:1.6820780912786721, irr5:22.647123336791992, ndcg5:0.8432498786086176, pnl5:1.0896470546722412 
train 31, step: 0, loss: 1.1857648717416465, grad_norm: 0.2097674490989484, ic: 0.01930450054569219
train 31, step: 500, loss: 0.8534867563748042, grad_norm: 0.047172300566001225, ic: -0.03283579473370804
train 31, step: 1000, loss: 5.038090877310312, grad_norm: 0.30982651810184775, ic: -0.026511015817170674
train 31, step: 1500, loss: 1.7053192468846599, grad_norm: 0.2748824366388326, ic: -0.061244739332126326
train 31, step: 2000, loss: 1.018330377454502, grad_norm: 0.1929064226972235, ic: -0.05098193561454485
Epoch 31: 2022-04-20 15:28:14.519241: train loss: 1.6467373333091369
Eval step 0: eval loss: 1.0138300071583728
Eval: 2022-04-20 15:28:17.831478: total loss: 1.0921154835542577, mse:4.8899358628748155, ic :0.011462738390100017, sharpe5:-2.5241838455200196, irr5:-32.302310943603516, ndcg5:0.8485753070247752, pnl5:0.6375823020935059 
train 32, step: 0, loss: 0.8705504029153242, grad_norm: 0.34549686375425603, ic: -0.0013724196992484566
train 32, step: 500, loss: 1.121860411108994, grad_norm: 0.31155090929460294, ic: 0.006753624311888815
train 32, step: 1000, loss: 1.3775858311365456, grad_norm: 0.004519197156075356, ic: -0.0274450168900577
train 32, step: 1500, loss: 2.2312837488511033, grad_norm: 0.2779722441948097, ic: -0.015578189981251968
train 32, step: 2000, loss: 1.1014988546701083, grad_norm: 0.2703038921161638, ic: 0.027120858604464428
Epoch 32: 2022-04-20 15:28:56.699199: train loss: 1.6463273564882566
Eval step 0: eval loss: 1.013425355964488
Eval: 2022-04-20 15:28:59.920691: total loss: 1.0912749460911735, mse:4.888515822755334, ic :-0.00763287476798067, sharpe5:-1.049005484059453, irr5:-9.73863410949707, ndcg5:0.8245224684260805, pnl5:0.8713321089744568 
train 33, step: 0, loss: 1.171021906631971, grad_norm: 0.006483028148972085, ic: 0.07121925348132206
train 33, step: 500, loss: 3.505097115800346, grad_norm: 0.06081776885674334, ic: -0.029980453346247913
train 33, step: 1000, loss: 5.339182987754916, grad_norm: 1.2182202106787123, ic: 0.01860325374116253
train 33, step: 1500, loss: 1.2884070419683689, grad_norm: 0.6905553571425368, ic: 0.1140227000503765
train 33, step: 2000, loss: 1.8643000166545542, grad_norm: 0.08544162108851683, ic: 0.01933863843284519
Epoch 33: 2022-04-20 15:29:36.553662: train loss: 1.646533987391022
Eval step 0: eval loss: 1.0180783625839256
Eval: 2022-04-20 15:29:40.191288: total loss: 1.0979292330425023, mse:4.904336468708502, ic :0.011747221877608483, sharpe5:-0.3359286084026098, irr5:-6.376799583435059, ndcg5:0.8345576429307712, pnl5:0.8896062970161438 
train 34, step: 0, loss: 0.7318260325871633, grad_norm: 0.193578855588278, ic: -0.01933859279919356
train 34, step: 500, loss: 1.816717406039641, grad_norm: 0.11565587575248296, ic: -0.04683064329820616
train 34, step: 1000, loss: 0.7761301185344827, grad_norm: 0.006087968270657598, ic: -0.0721367231126402
train 34, step: 1500, loss: 1.7392554649939904, grad_norm: 0.5086786201563509, ic: -0.017490425617689744
train 34, step: 2000, loss: 2.998060550092669, grad_norm: 0.33839700788568455, ic: -0.07457937288825521
Epoch 34: 2022-04-20 15:30:17.821827: train loss: 1.6467228035160466
Eval step 0: eval loss: 1.0133286125098735
Eval: 2022-04-20 15:30:21.032489: total loss: 1.0910999827778023, mse:4.888414473426518, ic :-0.0052028273672084045, sharpe5:-0.5743193875998258, irr5:-5.741678237915039, ndcg5:0.8353925738981364, pnl5:0.9390062689781189 
train 35, step: 0, loss: 1.0318377531027492, grad_norm: 0.3415457136699198, ic: 0.005943756176936741
train 35, step: 500, loss: 3.309156383167614, grad_norm: 0.8811781025880921, ic: -0.05444896850745774
train 35, step: 1000, loss: 1.4082299115889498, grad_norm: 0.012274721686378578, ic: -0.021424259476313785
train 35, step: 1500, loss: 1.6606084400273855, grad_norm: 0.31482622891505563, ic: 0.07357237766307771
train 35, step: 2000, loss: 1.2620600582178598, grad_norm: 0.021075152875012056, ic: 0.08859836126607108
Epoch 35: 2022-04-20 15:30:58.284201: train loss: 1.646629002418464
Eval step 0: eval loss: 1.0143988329589586
Eval: 2022-04-20 15:31:01.457602: total loss: 1.092867866479006, mse:4.891183335970385, ic :-0.007702604551605773, sharpe5:-0.5342010227590799, irr5:-5.486600875854492, ndcg5:0.8539223908781995, pnl5:0.8595456480979919 
train 36, step: 0, loss: 9.020431506511445, grad_norm: 0.9834171342221348, ic: 0.13992533148123443
train 36, step: 500, loss: 0.8712657203645439, grad_norm: 0.005126118505024204, ic: -0.02425867119019556
train 36, step: 1000, loss: 1.9723353052574089, grad_norm: 0.9744820230266128, ic: -0.010048481162660567
train 36, step: 1500, loss: 1.0625263094763904, grad_norm: 0.0578269199318273, ic: 0.046343079685223734
train 36, step: 2000, loss: 2.1673198158843436, grad_norm: 0.6977579182240969, ic: 0.09417319603211412
Epoch 36: 2022-04-20 15:31:38.232720: train loss: 1.6464087330377173
Eval step 0: eval loss: 1.0147235824159095
Eval: 2022-04-20 15:31:41.515011: total loss: 1.0932397576757726, mse:4.891892774438581, ic :-0.007196847028469842, sharpe5:-0.8454919909313321, irr5:-7.874318599700928, ndcg5:0.8459357797222313, pnl5:0.8444511294364929 
train 37, step: 0, loss: 1.2199005091995991, grad_norm: 0.10205281388757069, ic: 0.11310637107394296
train 37, step: 500, loss: 2.362002398858921, grad_norm: 0.015136758987403243, ic: -0.10930719825851075
train 37, step: 1000, loss: 0.7743392436515699, grad_norm: 0.2286249460402037, ic: 0.019741197809851764
train 37, step: 1500, loss: 3.2182462275935912, grad_norm: 0.5786526739727351, ic: -0.07496483413701235
train 37, step: 2000, loss: 3.1652113533745245, grad_norm: 0.9955254978224553, ic: -0.04334161639940204
Epoch 37: 2022-04-20 15:32:18.529754: train loss: 1.6464788518278652
Eval step 0: eval loss: 1.0133027071197012
Eval: 2022-04-20 15:32:21.805815: total loss: 1.0910146986966507, mse:4.8882497253042425, ic :-0.009284117982407915, sharpe5:-0.8656394991651177, irr5:-8.351980209350586, ndcg5:0.839448512265403, pnl5:0.8944863080978394 
train 38, step: 0, loss: 1.332223973129735, grad_norm: 0.25871784238850026, ic: 0.04995657269496165
train 38, step: 500, loss: 1.7415981558866278, grad_norm: 0.5249288711704622, ic: 0.0828396050854919
train 38, step: 1000, loss: 1.8251256950240575, grad_norm: 0.45778718495861737, ic: 0.13435266649883987
train 38, step: 1500, loss: 1.0873674126284378, grad_norm: 0.06306496245969102, ic: 0.06898204955650347
train 38, step: 2000, loss: 0.8204256955161179, grad_norm: 0.0027092452367270853, ic: 0.005937844205269788
Epoch 38: 2022-04-20 15:33:03.309198: train loss: 1.6468579125084828
Eval step 0: eval loss: 1.0132892080330107
Eval: 2022-04-20 15:33:06.931499: total loss: 1.0910440305437479, mse:4.888361788992725, ic :-0.010473869453830185, sharpe5:-1.2075545758008956, irr5:-11.532276153564453, ndcg5:0.8317090853916842, pnl5:0.8942373991012573 
train 39, step: 0, loss: 0.9052740160322867, grad_norm: 0.007729774665869131, ic: -0.013626305609271416
train 39, step: 500, loss: 1.2735518369085805, grad_norm: 0.2926039305987993, ic: 0.09485811626887908
train 39, step: 1000, loss: 1.3709371855764678, grad_norm: 0.16645752312861894, ic: 0.010459464668616084
train 39, step: 1500, loss: 2.425235786311254, grad_norm: 0.2836687635613155, ic: 0.11167934262449605
train 39, step: 2000, loss: 2.8727823785183215, grad_norm: 0.46790876928539793, ic: -0.16960805428563117
Epoch 39: 2022-04-20 15:33:46.681310: train loss: 1.6464155126522686
Eval step 0: eval loss: 1.0132227411014019
Eval: 2022-04-20 15:33:49.633552: total loss: 1.090879536720583, mse:4.888099456946919, ic :-0.010724942472697478, sharpe5:-0.37835104135796427, irr5:-4.096258163452148, ndcg5:0.8388207822574728, pnl5:0.9392675757408142 

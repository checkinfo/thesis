Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='SparseAdjSeqTimeDataset', dout=0.3, epochs=40, gnn_layers=2, gpu=0, hidden_dim=128, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=3, mask_adj=True, mask_type='soft', model_type='RGCNModel', normalize_adj=True, num_days=1, num_heads=1, print_inteval=500, relation_num=1, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_250_0.6/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
load 2305 train graphs successful!
load 126 test graphs successful!
40439
RGCNModel(
  (fc1): Linear(in_features=9, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
  (fc4): Linear(in_features=128, out_features=1, bias=True)
  (gnns): ModuleList(
    (0): RGCN(
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
    )
    (1): RGCN(
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
    )
  )
  (dropout): Dropout(p=0.3, inplace=False)
  (relu): LeakyReLU(negative_slope=0.01)
)
train 0, step: 0, loss: 2.0733220880681817, grad_norm: 0.45772590353154025, ic: -0.029547558415601756
train 0, step: 500, loss: 1.3653663479079796, grad_norm: 0.8649085191010564, ic: -0.000918848803248877
train 0, step: 1000, loss: 1.505841094421287, grad_norm: 0.032930797867889584, ic: 0.1529747086456151
train 0, step: 1500, loss: 1.1910921136385473, grad_norm: 0.101590500640737, ic: 0.06886608142061534
train 0, step: 2000, loss: 1.5613989481111852, grad_norm: 0.050892087385957394, ic: 0.06413479815384904
Epoch 0: 2022-04-04 15:28:13.566497: train loss: 1.6477481808058494
Eval step 0: eval loss: 1.0111472886634412
Eval: 2022-04-04 15:28:19.063765: total loss: 1.091645007292075, mse:4.88645519254372, ic :0.03453310254604742, sharpe5:1.363005760833621, irr5:15.596101760864258, ndcg5:0.8402084805535447, pnl5:1.0347720384597778 
train 1, step: 0, loss: 0.6380183909199025, grad_norm: 0.04992026148356285, ic: 0.041796288997440645
train 1, step: 500, loss: 1.2742300079591153, grad_norm: 0.3093769015873279, ic: 0.26624994394503965
train 1, step: 1000, loss: 0.8785886104818068, grad_norm: 0.06526481330887794, ic: 0.0761237091650378
train 1, step: 1500, loss: 1.858727804044398, grad_norm: 0.5557033856369632, ic: 0.08378092412524073
train 1, step: 2000, loss: 1.3662419691567764, grad_norm: 0.24062742253498903, ic: 0.1651625616623394
Epoch 1: 2022-04-04 15:28:53.852136: train loss: 1.6456243063840514
Eval step 0: eval loss: 1.0041398484811084
Eval: 2022-04-04 15:28:59.394615: total loss: 1.0890460267815512, mse:4.8782338686674835, ic :0.05123489991324946, sharpe5:7.5607809099555014, irr5:227.22071838378906, ndcg5:0.844707323144229, pnl5:2.400864839553833 
train 2, step: 0, loss: 1.3231405975725241, grad_norm: 0.5077647141029067, ic: 0.047173861598802214
train 2, step: 500, loss: 0.9482655271955615, grad_norm: 0.2717434332040066, ic: 0.09208842195102437
train 2, step: 1000, loss: 3.026856797045022, grad_norm: 1.1283439443190284, ic: 0.1827186168622888
train 2, step: 1500, loss: 2.280191928219171, grad_norm: 0.8908852986145461, ic: 0.06428610077979491
train 2, step: 2000, loss: 1.459367254573794, grad_norm: 0.27809418930928015, ic: -0.10927829344030918
Epoch 2: 2022-04-04 15:29:34.196357: train loss: 1.6443511272080857
Eval step 0: eval loss: 0.9974577362880134
Eval: 2022-04-04 15:29:40.059684: total loss: 1.0889752565735997, mse:4.878630717552172, ic :0.05083323658769543, sharpe5:7.2701121273636815, irr5:220.401123046875, ndcg5:0.836241141931372, pnl5:2.65712833404541 
train 3, step: 0, loss: 1.8331210100659907, grad_norm: 0.0704261395432979, ic: -0.1567225709958114
train 3, step: 500, loss: 0.7803129169024904, grad_norm: 0.021381802974356996, ic: 0.0870988481435818
train 3, step: 1000, loss: 1.3759009420781012, grad_norm: 0.5194308934817392, ic: 0.23374850955798734
train 3, step: 1500, loss: 2.605026351326856, grad_norm: 0.49799271080704677, ic: -0.051469375996097015
train 3, step: 2000, loss: 1.3505991617838542, grad_norm: 0.16359457221207335, ic: 0.07746520589615799
Epoch 3: 2022-04-04 15:30:14.375528: train loss: 1.644869202679067
Eval step 0: eval loss: 0.999293033545616
Eval: 2022-04-04 15:30:19.886853: total loss: 1.0902957572559704, mse:4.876858134573834, ic :0.05573734399921263, sharpe5:7.331020283997058, irr5:222.9693145751953, ndcg5:0.8621921427138416, pnl5:2.6576993465423584 
train 4, step: 0, loss: 1.155753543569254, grad_norm: 0.15676140912435765, ic: 0.09310031630409235
train 4, step: 500, loss: 0.9932326845866188, grad_norm: 0.004695653871304139, ic: 0.14276903457050344
train 4, step: 1000, loss: 1.3315348679741132, grad_norm: 0.061353569339096505, ic: 0.042753124611739364
train 4, step: 1500, loss: 1.071205804286859, grad_norm: 0.11517894323689735, ic: 0.4585585485934764
train 4, step: 2000, loss: 4.159593055418961, grad_norm: 0.8979409667636058, ic: -0.007906622490407703
Epoch 4: 2022-04-04 15:30:54.121060: train loss: 1.6420890379093052
Eval step 0: eval loss: 1.002293623391423
Eval: 2022-04-04 15:30:59.704721: total loss: 1.0871726027192685, mse:4.716815761085011, ic :0.12326172257753794, sharpe5:7.395433568358421, irr5:217.78488159179688, ndcg5:0.8464258112625601, pnl5:2.8417398929595947 
train 5, step: 0, loss: 0.9826204600628332, grad_norm: 0.15062635209535463, ic: -0.10454059922874934
train 5, step: 500, loss: 0.7930909649455716, grad_norm: 0.03277876265187323, ic: 0.13717393707449965
train 5, step: 1000, loss: 1.099508100706539, grad_norm: 0.06447057949262001, ic: 0.3994942220717825
train 5, step: 1500, loss: 1.7762296350990854, grad_norm: 0.40535081552359764, ic: -0.04567125123692801
train 5, step: 2000, loss: 2.17968412896641, grad_norm: 0.8599141946732408, ic: 0.026203610994710275
Epoch 5: 2022-04-04 15:31:35.214458: train loss: 1.638280993428089
Eval step 0: eval loss: 1.004800596633919
Eval: 2022-04-04 15:31:40.823742: total loss: 1.08613555607169, mse:4.717697222893162, ic :0.11482276850385727, sharpe5:8.340186333060265, irr5:250.17547607421875, ndcg5:0.8507381220837803, pnl5:3.1800546646118164 
train 6, step: 0, loss: 0.7760086633994268, grad_norm: 0.005230015303673296, ic: -0.05075783860553987
train 6, step: 500, loss: 1.4167877554196362, grad_norm: 0.24515557980501942, ic: 0.0565551255222065
train 6, step: 1000, loss: 1.2242689376087588, grad_norm: 0.19451452088662818, ic: 0.22905870767524655
train 6, step: 1500, loss: 1.0534096771816037, grad_norm: 0.3252205095931798, ic: 0.07950701751294743
train 6, step: 2000, loss: 2.3090744393156712, grad_norm: 1.1787605218631034, ic: 0.09173018658108457
Epoch 6: 2022-04-04 15:32:16.261751: train loss: 1.6384794689438256
Eval step 0: eval loss: 1.0001005360551605
Eval: 2022-04-04 15:32:21.761659: total loss: 1.0866920968407476, mse:4.723201282853949, ic :0.1163851313791459, sharpe5:7.600344725847244, irr5:224.5378875732422, ndcg5:0.8429597263093096, pnl5:3.4242544174194336 
train 7, step: 0, loss: 1.46210531269306, grad_norm: 0.5630859063112843, ic: 0.20294151173707842
train 7, step: 500, loss: 1.3468432477221541, grad_norm: 0.08921909660846089, ic: 0.18157878506273328
train 7, step: 1000, loss: 0.6381759537443498, grad_norm: 0.017304688214321837, ic: 0.2940448520785697
train 7, step: 1500, loss: 1.0005835579252207, grad_norm: 0.13319454678722148, ic: 0.1253771185207942
train 7, step: 2000, loss: 1.5784853427925252, grad_norm: 0.6332743411647285, ic: 0.41723018739255513
Epoch 7: 2022-04-04 15:32:56.518705: train loss: 1.6376971795197064
Eval step 0: eval loss: 0.993204559760071
Eval: 2022-04-04 15:33:02.117893: total loss: 1.0840845283993361, mse:4.723872340251674, ic :0.1207587970246488, sharpe5:7.599636227488517, irr5:221.43890380859375, ndcg5:0.8385383898994636, pnl5:3.2778806686401367 
train 8, step: 0, loss: 1.2072511886910051, grad_norm: 0.0828701189943692, ic: 0.04590021437167758
train 8, step: 500, loss: 5.537443059365204, grad_norm: 1.1961418673102795, ic: 0.14494205886598244
train 8, step: 1000, loss: 1.9032106122348784, grad_norm: 0.6502647754372013, ic: 0.060340504121081495
train 8, step: 1500, loss: 1.077505864221464, grad_norm: 0.3580352763920602, ic: 0.6428330854505022
train 8, step: 2000, loss: 1.1228195581680689, grad_norm: 0.49412241473100704, ic: 0.009477273115728354
Epoch 8: 2022-04-04 15:33:37.040744: train loss: 1.6373014908206864
Eval step 0: eval loss: 0.9993819989550421
Eval: 2022-04-04 15:33:42.596241: total loss: 1.0873555091454083, mse:4.716304641605265, ic :0.12332924202051408, sharpe5:7.6890077617764465, irr5:228.10479736328125, ndcg5:0.8357413724256121, pnl5:3.1512632369995117 
train 9, step: 0, loss: 1.12118763016193, grad_norm: 0.02199026586025236, ic: 0.43568242987778993
train 9, step: 500, loss: 3.215181162005327, grad_norm: 1.4919366092574124, ic: 0.07990898399583363
train 9, step: 1000, loss: 0.8864001436166308, grad_norm: 0.1718484856900587, ic: 0.23046394936846276
train 9, step: 1500, loss: 2.158396221636953, grad_norm: 0.9294120849441789, ic: -0.021763110988113565
train 9, step: 2000, loss: 0.6051978134527439, grad_norm: 0.0067727348435059976, ic: 0.05376501676821854
Epoch 9: 2022-04-04 15:34:17.966410: train loss: 1.6369376989149542
Eval step 0: eval loss: 0.9945875733321813
Eval: 2022-04-04 15:34:23.611407: total loss: 1.0914418170951552, mse:4.796814707252111, ic :0.11882098213759594, sharpe5:11.520421686172485, irr5:372.2318115234375, ndcg5:0.8422849259091807, pnl5:4.435097694396973 
train 10, step: 0, loss: 1.3060240819373998, grad_norm: 0.03327468272362267, ic: 0.3741739795789981
train 10, step: 500, loss: 0.897705078125, grad_norm: 0.007320142180839976, ic: 0.10070029774328056
train 10, step: 1000, loss: 1.5311670613030808, grad_norm: 0.5163479522516288, ic: 0.04234007461452319
train 10, step: 1500, loss: 3.0473429201907947, grad_norm: 1.320467530448487, ic: 0.0244119524565673
train 10, step: 2000, loss: 1.381408042096077, grad_norm: 0.1357021454130984, ic: 0.050350966044462014
Epoch 10: 2022-04-04 15:34:58.829781: train loss: 1.6376805946105102
Eval step 0: eval loss: 1.0018014209781463
Eval: 2022-04-04 15:35:04.480993: total loss: 1.0856570716947904, mse:4.714354071097607, ic :0.12174695963337111, sharpe5:7.616779239177704, irr5:225.4981689453125, ndcg5:0.8526990426092714, pnl5:3.0044732093811035 
train 11, step: 0, loss: 4.815276216770915, grad_norm: 1.1784640366791785, ic: 0.10599942115629796
train 11, step: 500, loss: 0.9894712949128744, grad_norm: 0.05889158764686239, ic: 0.040914885853420825
train 11, step: 1000, loss: 1.0387989920027652, grad_norm: 0.3276298185932175, ic: 0.0349571421292145
train 11, step: 1500, loss: 0.6925359022458644, grad_norm: 0.001622397593629328, ic: 0.09441493888099635
train 11, step: 2000, loss: 1.140489740937246, grad_norm: 0.05452262004424743, ic: -0.18633071739362145
Epoch 11: 2022-04-04 15:35:38.728196: train loss: 1.6366621765489284
Eval step 0: eval loss: 0.9895642417678712
Eval: 2022-04-04 15:35:44.240473: total loss: 1.083723851314477, mse:4.725455176613548, ic :0.12393299985205006, sharpe5:10.486523936390876, irr5:330.52606201171875, ndcg5:0.8623939633942116, pnl5:4.562113285064697 
train 12, step: 0, loss: 1.3865791349809886, grad_norm: 0.24040305235842893, ic: 0.043574427656187076
train 12, step: 500, loss: 0.8148650039154992, grad_norm: 0.3331570892532288, ic: 0.018913745578366076
train 12, step: 1000, loss: 1.2171502830485241, grad_norm: 0.23584219283577817, ic: 0.5752233363147049
train 12, step: 1500, loss: 1.088003922675363, grad_norm: 0.19593391214805794, ic: -0.10067219532793856
train 12, step: 2000, loss: 1.11435312959427, grad_norm: 0.06037782113862061, ic: 0.10438114179271156
Epoch 12: 2022-04-04 15:36:19.649664: train loss: 1.6373273166909008
Eval step 0: eval loss: 1.000308036302001
Eval: 2022-04-04 15:36:25.159589: total loss: 1.0856786594329817, mse:4.716621717966957, ic :0.12377865583483075, sharpe5:7.622389997541904, irr5:227.74415588378906, ndcg5:0.8543571807528368, pnl5:2.866612672805786 
train 13, step: 0, loss: 1.0827032946754123, grad_norm: 0.038933926359064584, ic: 0.42272104067534644
train 13, step: 500, loss: 1.146481952230439, grad_norm: 0.007004858549583815, ic: -0.16081282764224453
train 13, step: 1000, loss: 1.38512040685238, grad_norm: 0.40051829026722086, ic: 0.05822881940913509
train 13, step: 1500, loss: 0.7762960262675989, grad_norm: 0.0030065491520865732, ic: -0.04929040112164818
train 13, step: 2000, loss: 1.0397873276389689, grad_norm: 0.029313519226836032, ic: 0.05411664258824647
Epoch 13: 2022-04-04 15:37:00.212311: train loss: 1.6372521438261225
Eval step 0: eval loss: 0.9892366639308516
Eval: 2022-04-04 15:37:05.862678: total loss: 1.0854529828392567, mse:4.74280455982233, ic :0.12061467151662585, sharpe5:7.64460175216198, irr5:223.52273559570312, ndcg5:0.8625038061527335, pnl5:3.4306585788726807 
train 14, step: 0, loss: 1.7721050715042372, grad_norm: 0.4952008875607225, ic: 0.1700031858318897
train 14, step: 500, loss: 1.2786453549779573, grad_norm: 0.15227796524051182, ic: 0.18857289785823128
train 14, step: 1000, loss: 1.0748606784284607, grad_norm: 0.13320380426484482, ic: 0.1347016083456838
train 14, step: 1500, loss: 0.9725149153194764, grad_norm: 0.09985468479774229, ic: 0.21634231732767617
train 14, step: 2000, loss: 2.2867545148093393, grad_norm: 0.46056299464643025, ic: -0.0773300068595519
Epoch 14: 2022-04-04 15:37:41.037020: train loss: 1.6368545666602872
Eval step 0: eval loss: 0.9962786232062927
Eval: 2022-04-04 15:37:46.559961: total loss: 1.0895082278643533, mse:4.739194392422607, ic :0.11692268081354847, sharpe5:7.829071455001831, irr5:224.72698974609375, ndcg5:0.8565518080940695, pnl5:3.8418633937835693 
train 15, step: 0, loss: 0.9709018667697527, grad_norm: 0.15235008034014977, ic: 0.1430700794063458
train 15, step: 500, loss: 1.221814906715527, grad_norm: 0.006276034117395391, ic: 0.07903210647817593
train 15, step: 1000, loss: 1.7686614583333333, grad_norm: 0.07344484338745422, ic: -0.1272481015006924
train 15, step: 1500, loss: 5.41956670986804, grad_norm: 0.857450207159707, ic: -0.023474254214343862
train 15, step: 2000, loss: 0.9260471550993217, grad_norm: 0.01484273943505839, ic: -0.021450646733601874
Epoch 15: 2022-04-04 15:38:20.664548: train loss: 1.6380892394098068
Eval step 0: eval loss: 0.9994824064474722
Eval: 2022-04-04 15:38:26.170470: total loss: 1.0857522995716666, mse:4.71679296328298, ic :0.11862764295375727, sharpe5:7.970897880792617, irr5:228.19381713867188, ndcg5:0.845258110647749, pnl5:3.3759379386901855 
train 16, step: 0, loss: 6.311676805312242, grad_norm: 1.005830889580563, ic: -0.03638752690955195
train 16, step: 500, loss: 1.3678585960751488, grad_norm: 0.7809639064523742, ic: -0.01445530248101326
train 16, step: 1000, loss: 0.8240910729124697, grad_norm: 0.09547532460297345, ic: -0.01327170508778126
train 16, step: 1500, loss: 1.2179627538913065, grad_norm: 0.3003477553715401, ic: 0.143328865341851
train 16, step: 2000, loss: 0.9855884219986306, grad_norm: 1.0144350369141606, ic: 0.5317365019015866
Epoch 16: 2022-04-04 15:39:00.288014: train loss: 1.6362828613291627
Eval step 0: eval loss: 0.9925863015896523
Eval: 2022-04-04 15:39:05.818462: total loss: 1.0824548156525104, mse:4.723899805433388, ic :0.1260897416286397, sharpe5:8.933411346673966, irr5:255.82095336914062, ndcg5:0.8549084216354143, pnl5:3.5277271270751953 
train 17, step: 0, loss: 1.1813333897502876, grad_norm: 0.017189736867074465, ic: 0.14011806667207222
train 17, step: 500, loss: 1.0415170492200245, grad_norm: 0.018950277844745796, ic: -0.023218091512829143
train 17, step: 1000, loss: 3.3690789855352725, grad_norm: 0.7127149241793322, ic: -0.02032079664558922
train 17, step: 1500, loss: 0.8841715692316444, grad_norm: 0.049313653466499296, ic: 0.07914824606807103
train 17, step: 2000, loss: 1.0268767696098993, grad_norm: 0.5791024498695123, ic: 0.5540317236900422
Epoch 17: 2022-04-04 15:39:40.975727: train loss: 1.631507431973007
Eval step 0: eval loss: 1.0010447650284688
Eval: 2022-04-04 15:39:46.527836: total loss: 1.08049982978048, mse:4.6854843297617865, ic :0.16083847180712735, sharpe5:15.039023180007934, irr5:511.0814208984375, ndcg5:0.8320457838388188, pnl5:5.522523880004883 
train 18, step: 0, loss: 0.8551046926686547, grad_norm: 0.17125147952358652, ic: 0.003675619950857951
train 18, step: 500, loss: 2.53324685766742, grad_norm: 1.0425574779305624, ic: 0.06725195845674332
train 18, step: 1000, loss: 1.3554875435589029, grad_norm: 0.3333299895083464, ic: 0.5325503136808871
train 18, step: 1500, loss: 1.731017613335101, grad_norm: 0.9127748234640037, ic: 0.3247874598868199
train 18, step: 2000, loss: 1.2562454020887492, grad_norm: 0.31000202664758075, ic: 0.16714007041071646
Epoch 18: 2022-04-04 15:40:21.583642: train loss: 1.629874565357514
Eval step 0: eval loss: 0.9982434474147577
Eval: 2022-04-04 15:40:27.137263: total loss: 1.0816293021628356, mse:4.688642199071798, ic :0.1598473947687625, sharpe5:15.339837961792945, irr5:509.5400390625, ndcg5:0.8613513121519806, pnl5:7.960728645324707 
train 19, step: 0, loss: 2.2337380301979723, grad_norm: 0.9943713829834244, ic: 0.24401376029260163
train 19, step: 500, loss: 1.0232687306958574, grad_norm: 0.063082479632606, ic: 0.0493144181563024
train 19, step: 1000, loss: 0.9950669753213579, grad_norm: 0.3427858029094962, ic: 0.534725054988779
train 19, step: 1500, loss: 1.5779779693226754, grad_norm: 0.2713803698313286, ic: 0.1336875367980258
train 19, step: 2000, loss: 1.7605163621423048, grad_norm: 2.150378634039814, ic: 0.6233359722309675
Epoch 19: 2022-04-04 15:41:03.450622: train loss: 1.6279836573953934
Eval step 0: eval loss: 1.0026505135309702
Eval: 2022-04-04 15:41:09.374581: total loss: 1.0814189279691653, mse:4.692270611848749, ic :0.15679950243989507, sharpe5:12.703077605366706, irr5:400.2456970214844, ndcg5:0.8497927609632705, pnl5:3.895883321762085 
train 20, step: 0, loss: 1.2561564837905237, grad_norm: 0.328894267825706, ic: 0.4554962383827401
train 20, step: 500, loss: 1.2351249445551018, grad_norm: 0.5158726169740423, ic: 0.008908677816059401
train 20, step: 1000, loss: 1.568063666291689, grad_norm: 0.2850721073028566, ic: 0.15464301672940262
train 20, step: 1500, loss: 0.8594220432059325, grad_norm: 0.30254572959564613, ic: 0.5598755795116239
train 20, step: 2000, loss: 1.3507999799477062, grad_norm: 0.09316063049800631, ic: -0.04687863810324016
Epoch 20: 2022-04-04 15:41:44.707114: train loss: 1.626925208482196
Eval step 0: eval loss: 1.0014233179880858
Eval: 2022-04-04 15:41:50.428349: total loss: 1.0811433688557461, mse:4.68735071389621, ic :0.15812819397659433, sharpe5:13.949550402760504, irr5:442.86077880859375, ndcg5:0.8492786799373783, pnl5:4.720868110656738 
train 21, step: 0, loss: 1.4022811133381925, grad_norm: 0.26902280035451526, ic: 0.349054397607673
train 21, step: 500, loss: 1.109149538841335, grad_norm: 0.09522079277579318, ic: 0.05331512077876219
train 21, step: 1000, loss: 0.9088980330731307, grad_norm: 0.20499323915180706, ic: 0.08731305591698676
train 21, step: 1500, loss: 0.7351177249061024, grad_norm: 0.20497463575884584, ic: 0.6270317337582189
train 21, step: 2000, loss: 1.1472983563348935, grad_norm: 0.2880660183408496, ic: 0.24965853758906054
Epoch 21: 2022-04-04 15:42:26.556402: train loss: 1.6266407674201164
Eval step 0: eval loss: 1.0055436249341758
Eval: 2022-04-04 15:42:32.091880: total loss: 1.0812010756209856, mse:4.688313620892999, ic :0.1592798266883362, sharpe5:13.283065334558486, irr5:425.8707275390625, ndcg5:0.851805408836819, pnl5:4.1711554527282715 
train 22, step: 0, loss: 1.0508242297402532, grad_norm: 0.2768644211380544, ic: 0.13620500424589205
train 22, step: 500, loss: 1.0273163562684546, grad_norm: 0.001761975390219649, ic: 0.0075657450861251665
train 22, step: 1000, loss: 0.9143047726783664, grad_norm: 0.04455837914967205, ic: 0.11449688182107054
train 22, step: 1500, loss: 1.009142914293711, grad_norm: 0.06837331966932211, ic: 0.23205337492086187
train 22, step: 2000, loss: 1.0496926950853924, grad_norm: 0.11390332120260671, ic: 0.11382887226318245
Epoch 22: 2022-04-04 15:43:07.567252: train loss: 1.6265510688690623
Eval step 0: eval loss: 1.00583597658307
Eval: 2022-04-04 15:43:13.058435: total loss: 1.0822782420452135, mse:4.687526715288144, ic :0.1531418951536686, sharpe5:12.70832181751728, irr5:390.58819580078125, ndcg5:0.8359848348710747, pnl5:4.826982498168945 
train 23, step: 0, loss: 1.2834132507420035, grad_norm: 0.9011864162637088, ic: -0.01612549383774749
train 23, step: 500, loss: 0.9019463507683724, grad_norm: 0.23587188228973274, ic: 0.5855852927317393
train 23, step: 1000, loss: 2.2953443814381935, grad_norm: 0.9312283500253864, ic: 0.06625964506124299
train 23, step: 1500, loss: 0.7805811630527905, grad_norm: 0.3707689882241616, ic: 0.7101296033964098
train 23, step: 2000, loss: 1.4364749968998016, grad_norm: 0.4309633060396501, ic: 0.4283857758068536
Epoch 23: 2022-04-04 15:43:48.466376: train loss: 1.6260433500036202
Eval step 0: eval loss: 1.0092752867463137
Eval: 2022-04-04 15:43:54.196152: total loss: 1.0883616133647764, mse:4.699853064010208, ic :0.15460761822151903, sharpe5:13.653598625063896, irr5:445.2611083984375, ndcg5:0.8459496577413219, pnl5:4.427138805389404 
train 24, step: 0, loss: 1.1836781795838212, grad_norm: 0.45819810443213693, ic: 0.2557308616294477
train 24, step: 500, loss: 1.2469124870387587, grad_norm: 0.43994454791984516, ic: -0.002218446083744446
train 24, step: 1000, loss: 1.047858633646151, grad_norm: 0.7360249815025648, ic: 0.13705774068721033
train 24, step: 1500, loss: 1.199850055364173, grad_norm: 0.12659216676851465, ic: 0.08858359996942425
train 24, step: 2000, loss: 1.3546382347617165, grad_norm: 0.42497633225969805, ic: 0.450599160720602
Epoch 24: 2022-04-04 15:44:28.001063: train loss: 1.6267087847439823
Eval step 0: eval loss: 1.0027171733066744
Eval: 2022-04-04 15:44:33.432829: total loss: 1.0815272046533408, mse:4.681384924426973, ic :0.16455671592044938, sharpe5:14.692348973751068, irr5:491.3251953125, ndcg5:0.8467259514661553, pnl5:4.297111511230469 
train 25, step: 0, loss: 1.3381719295627852, grad_norm: 0.5451269481366402, ic: 0.2030055361112833
train 25, step: 500, loss: 1.5084054129464286, grad_norm: 1.2022200791837439, ic: 0.10321785169382042
train 25, step: 1000, loss: 1.3615528916133555, grad_norm: 0.2728150421053285, ic: 0.27261272205830034
train 25, step: 1500, loss: 2.890626950288217, grad_norm: 1.0067473703092562, ic: 0.18172571835452106
train 25, step: 2000, loss: 1.2027441097211233, grad_norm: 0.3003165765006543, ic: 0.14003100083769068
Epoch 25: 2022-04-04 15:45:07.195767: train loss: 1.627129205174326
Eval step 0: eval loss: 0.999964259560953
Eval: 2022-04-04 15:45:12.629632: total loss: 1.0802292817170238, mse:4.677853852568513, ic :0.16537213238229667, sharpe5:13.490904132127762, irr5:445.06304931640625, ndcg5:0.8428218362631693, pnl5:4.019454002380371 
train 26, step: 0, loss: 1.6152290482954546, grad_norm: 0.35722385444402005, ic: 0.16840848913025713
train 26, step: 500, loss: 1.0097936098949774, grad_norm: 0.13218432490417545, ic: -0.10089220382672184
train 26, step: 1000, loss: 1.814336848199417, grad_norm: 0.5776917314226827, ic: 0.19741008950789649
train 26, step: 1500, loss: 0.9237042481501058, grad_norm: 0.03344541249816714, ic: 0.0024867483904561106
train 26, step: 2000, loss: 0.9828746885765256, grad_norm: 0.19544433853115506, ic: 0.155567783576524
Epoch 26: 2022-04-04 15:45:47.361625: train loss: 1.6256910141113154
Eval step 0: eval loss: 1.003710963212546
Eval: 2022-04-04 15:45:52.992110: total loss: 1.0809622236431011, mse:4.680977174579746, ic :0.1692818436226336, sharpe5:14.847040935158729, irr5:519.6685791015625, ndcg5:0.843351882709298, pnl5:3.177494764328003 
train 27, step: 0, loss: 1.632403637989458, grad_norm: 0.6067837251792346, ic: 0.6475498975917575
train 27, step: 500, loss: 1.511549787981143, grad_norm: 0.364331332854535, ic: 0.0433316852935495
train 27, step: 1000, loss: 2.636458105696387, grad_norm: 2.363744284459826, ic: 0.4043691398166629
train 27, step: 1500, loss: 0.8585725211170627, grad_norm: 0.5955074902384447, ic: 0.5435520570038176
train 27, step: 2000, loss: 1.351111064858151, grad_norm: 1.9366036204809314, ic: -0.016360298781341015
Epoch 27: 2022-04-04 15:46:27.375854: train loss: 1.6260840338159737
Eval step 0: eval loss: 1.0000554748181607
Eval: 2022-04-04 15:46:32.910537: total loss: 1.0785141584720854, mse:4.676174581540391, ic :0.17150288670919203, sharpe5:14.470304263830185, irr5:502.277099609375, ndcg5:0.8547181482711711, pnl5:4.32597541809082 
train 28, step: 0, loss: 1.1597601557989319, grad_norm: 0.18918043700467244, ic: 0.15308141801987396
train 28, step: 500, loss: 2.9462659355050453, grad_norm: 0.8303353852154881, ic: 0.12645739273015405
train 28, step: 1000, loss: 2.780987732030016, grad_norm: 2.3804719226574678, ic: -0.04086291189014261
train 28, step: 1500, loss: 1.0214731971489392, grad_norm: 0.017759712934391714, ic: 0.20480982278485044
train 28, step: 2000, loss: 1.773029416106468, grad_norm: 0.47185733605404656, ic: 0.03750555031020825
Epoch 28: 2022-04-04 15:47:07.627667: train loss: 1.6250082574504534
Eval step 0: eval loss: 1.007411512843931
Eval: 2022-04-04 15:47:12.975860: total loss: 1.0798735445205305, mse:4.683488554048114, ic :0.1637862099677412, sharpe5:14.21469810962677, irr5:463.97955322265625, ndcg5:0.8479077853432149, pnl5:4.884621620178223 
train 29, step: 0, loss: 1.5186427928354813, grad_norm: 0.22945779509914188, ic: 0.06556928285419175
train 29, step: 500, loss: 2.5579146207655477, grad_norm: 4.816382853889841, ic: -0.00648275964619786
train 29, step: 1000, loss: 1.6905726238105536, grad_norm: 1.5271151438005204, ic: 0.48209500265943334
train 29, step: 1500, loss: 3.9765942133823136, grad_norm: 1.3139992878368068, ic: 0.1320337802152771
train 29, step: 2000, loss: 0.9336191135705247, grad_norm: 0.24140191089016852, ic: 0.4658361454086623
Epoch 29: 2022-04-04 15:47:47.315921: train loss: 1.6264350988853478
Eval step 0: eval loss: 1.006641679214389
Eval: 2022-04-04 15:47:52.865734: total loss: 1.08138350526604, mse:4.685555518415553, ic :0.16052113020924433, sharpe5:13.914778173565864, irr5:462.0018615722656, ndcg5:0.8534627228642157, pnl5:3.987718105316162 
train 30, step: 0, loss: 1.2465211347050056, grad_norm: 0.035179859931976976, ic: 0.9888696907133799
train 30, step: 500, loss: 1.9403074240382714, grad_norm: 2.0943199925051035, ic: 0.17456957963676467
train 30, step: 1000, loss: 3.44067883034534, grad_norm: 0.8777332384863026, ic: 0.3718225146137494
train 30, step: 1500, loss: 1.0808680330670697, grad_norm: 0.23165736923296737, ic: 0.1756298847327637
train 30, step: 2000, loss: 1.1019236543492925, grad_norm: 2.801484783092224, ic: 0.4377667758045425
Epoch 30: 2022-04-04 15:48:26.155085: train loss: 1.6262726392119342
Eval step 0: eval loss: 1.0076732665629935
Eval: 2022-04-04 15:48:31.570539: total loss: 1.081967114860356, mse:4.67438914847821, ic :0.16747535317296497, sharpe5:14.326530176997185, irr5:488.5700988769531, ndcg5:0.8481996716525074, pnl5:2.908568859100342 
train 31, step: 0, loss: 1.1592623454169182, grad_norm: 0.26786494718251763, ic: 0.20414030724454618
train 31, step: 500, loss: 0.8264381928470047, grad_norm: 0.16342599001077757, ic: 0.2046675135815409
train 31, step: 1000, loss: 5.140789533681907, grad_norm: 1.2784528929480872, ic: -0.08733839296107168
train 31, step: 1500, loss: 1.6639647682814915, grad_norm: 0.35993922807285267, ic: 0.2927975329340248
train 31, step: 2000, loss: 0.9814078963122606, grad_norm: 0.6063895360940944, ic: 0.193857050991423
Epoch 31: 2022-04-04 15:49:05.818435: train loss: 1.6267057139394985
Eval step 0: eval loss: 1.0111560952104726
Eval: 2022-04-04 15:49:11.527812: total loss: 1.0816448063491004, mse:4.677279564309186, ic :0.16422745894900115, sharpe5:13.721542577147483, irr5:462.1202697753906, ndcg5:0.8570037799096766, pnl5:3.7357208728790283 
train 32, step: 0, loss: 0.898762897436505, grad_norm: 1.0791349461139301, ic: 0.11309671616880725
train 32, step: 500, loss: 1.09841081572742, grad_norm: 0.33699348791570344, ic: 0.158115694328126
train 32, step: 1000, loss: 1.3780506498598504, grad_norm: 0.03189872135394732, ic: 0.07147680126060084
train 32, step: 1500, loss: 2.0575446255804954, grad_norm: 0.9504304232388057, ic: 0.4351965967605254
train 32, step: 2000, loss: 1.0715446449820591, grad_norm: 0.43502966133537807, ic: 0.46593811823342546
Epoch 32: 2022-04-04 15:49:45.768678: train loss: 1.6232538929221672
Eval step 0: eval loss: 1.0093668234103474
Eval: 2022-04-04 15:49:51.192044: total loss: 1.0797898541610071, mse:4.672991822470649, ic :0.1704188978472102, sharpe5:15.596756114959716, irr5:536.480224609375, ndcg5:0.8571131504358368, pnl5:3.747619390487671 
train 33, step: 0, loss: 1.1628435687129965, grad_norm: 0.02426781999030953, ic: 0.04913978235166029
train 33, step: 500, loss: 3.175940757710415, grad_norm: 0.2872783929032711, ic: 0.5135225492107153
train 33, step: 1000, loss: 5.245414850578114, grad_norm: 2.1451421421972316, ic: 0.028723608564262842
train 33, step: 1500, loss: 1.317064834222561, grad_norm: 1.1133107849417816, ic: 0.007200754348652645
train 33, step: 2000, loss: 1.8751727910004845, grad_norm: 0.3602073258046199, ic: 0.04524876125619646
Epoch 33: 2022-04-04 15:50:25.048486: train loss: 1.6266654057873853
Eval step 0: eval loss: 1.0143640567403895
Eval: 2022-04-04 15:50:30.485101: total loss: 1.087894051664845, mse:4.690889666032259, ic :0.1664690138771803, sharpe5:15.3827886646986, irr5:524.234130859375, ndcg5:0.8500843172319859, pnl5:4.628536224365234 
train 34, step: 0, loss: 0.7228660523041304, grad_norm: 0.43646179135749763, ic: 0.15656444275771098
train 34, step: 500, loss: 1.8053140119554039, grad_norm: 0.895214265593737, ic: 0.8795333987998595
train 34, step: 1000, loss: 0.700123291015625, grad_norm: 0.09027645661103019, ic: 0.4404293398949964
train 34, step: 1500, loss: 1.6694019806690705, grad_norm: 1.216434290634244, ic: 0.6435304598853839
train 34, step: 2000, loss: 2.978100947925247, grad_norm: 0.5677540376980984, ic: 0.0930001720790687
Epoch 34: 2022-04-04 15:51:04.129177: train loss: 1.625502530560194
Eval step 0: eval loss: 1.0075318475595707
Eval: 2022-04-04 15:51:09.617294: total loss: 1.0810906095648718, mse:4.680583032333915, ic :0.16507776101924226, sharpe5:14.343995749354361, irr5:476.0353088378906, ndcg5:0.8413734383677666, pnl5:5.0013227462768555 
train 35, step: 0, loss: 1.0414471203767801, grad_norm: 0.9934261299275176, ic: -0.016463971949302346
train 35, step: 500, loss: 3.310404089725379, grad_norm: 1.6873401911866504, ic: -0.1047729509770002
train 35, step: 1000, loss: 1.3570478194185933, grad_norm: 0.10812575104768138, ic: 0.490835746966926
train 35, step: 1500, loss: 1.632836894067363, grad_norm: 0.350843428291803, ic: 0.06746118928827713
train 35, step: 2000, loss: 1.3027949872798787, grad_norm: 0.15498655762554056, ic: -0.08068981141059285
Epoch 35: 2022-04-04 15:51:43.541032: train loss: 1.6255295478988434
Eval step 0: eval loss: 1.0019737593182265
Eval: 2022-04-04 15:51:49.044096: total loss: 1.0806500154407586, mse:4.6774737447620796, ic :0.168325043132574, sharpe5:14.694087585210799, irr5:493.3061218261719, ndcg5:0.8444644147892768, pnl5:3.5721800327301025 
train 36, step: 0, loss: 8.961542552535517, grad_norm: 1.0749807635306028, ic: -0.22836956042474138
train 36, step: 500, loss: 0.8572560959382097, grad_norm: 0.01053899329009699, ic: 0.15267422395591793
train 36, step: 1000, loss: 1.9966666270896656, grad_norm: 2.6914871919889656, ic: 0.10139606756958261
train 36, step: 1500, loss: 1.0487658875289687, grad_norm: 0.13722579956608208, ic: 0.11049484951102911
train 36, step: 2000, loss: 2.1473899513500587, grad_norm: 1.1579744320064815, ic: 0.3929521823123775
Epoch 36: 2022-04-04 15:52:23.979802: train loss: 1.6252500127920484
Eval step 0: eval loss: 1.01478561393332
Eval: 2022-04-04 15:52:29.367552: total loss: 1.0866542602569862, mse:4.6869733232331106, ic :0.1667203207405348, sharpe5:15.300341779589653, irr5:522.899658203125, ndcg5:0.8550294659275611, pnl5:4.644686222076416 
train 37, step: 0, loss: 1.1818965112220792, grad_norm: 0.19904058556164206, ic: 0.14575465527279802
train 37, step: 500, loss: 2.3365586910010374, grad_norm: 0.04942138596807909, ic: 0.1492747246391931
train 37, step: 1000, loss: 0.7728937937982865, grad_norm: 0.5154575567721233, ic: 0.15722155287844328
train 37, step: 1500, loss: 3.1376841588673856, grad_norm: 0.8838797590133697, ic: 0.19851005342434466
train 37, step: 2000, loss: 3.111752911121673, grad_norm: 2.758324304016084, ic: 0.036688069010635746
Epoch 37: 2022-04-04 15:53:03.895198: train loss: 1.6251248133811107
Eval step 0: eval loss: 1.0097279561199972
Eval: 2022-04-04 15:53:09.322861: total loss: 1.0796667040485497, mse:4.677037767020707, ic :0.1688192379343472, sharpe5:14.877113805413245, irr5:527.6809692382812, ndcg5:0.8462302741955904, pnl5:4.598755836486816 
train 38, step: 0, loss: 1.3672601873224433, grad_norm: 1.8724458491377405, ic: -0.18138807884541006
train 38, step: 500, loss: 1.7332387051841085, grad_norm: 1.4808736708828591, ic: 0.18317962246720157
train 38, step: 1000, loss: 1.8290528494452083, grad_norm: 1.8194299212313723, ic: 0.1391801704183499
train 38, step: 1500, loss: 1.095986044451097, grad_norm: 0.2189224595509689, ic: 0.4639397308137152
train 38, step: 2000, loss: 0.754698283714849, grad_norm: 0.053144930423550285, ic: 0.5704044744435618
Epoch 38: 2022-04-04 15:53:43.020306: train loss: 1.624636368766634
Eval step 0: eval loss: 0.9973438939902579
Eval: 2022-04-04 15:53:48.569586: total loss: 1.078693018329927, mse:4.683474633399463, ic :0.17166483946919564, sharpe5:15.243067869544028, irr5:540.6657104492188, ndcg5:0.850116231640679, pnl5:5.053657054901123 
train 39, step: 0, loss: 0.8685346124296505, grad_norm: 0.06815225351358048, ic: 0.5396700528352366
train 39, step: 500, loss: 1.2487817441547213, grad_norm: 1.4200983551923543, ic: 0.008408412395522119
train 39, step: 1000, loss: 1.3961614435369318, grad_norm: 0.37393340668139935, ic: 0.06792415113278977
train 39, step: 1500, loss: 2.438901983622301, grad_norm: 0.5881854079947542, ic: -0.0666666655093951
train 39, step: 2000, loss: 2.879598608437334, grad_norm: 1.460946708533749, ic: 0.2475374910040572
Epoch 39: 2022-04-04 15:54:23.131097: train loss: 1.6229497629471161
Eval step 0: eval loss: 1.0000869084057398
Eval: 2022-04-04 15:54:28.684849: total loss: 1.0785433809032783, mse:4.676948511883106, ic :0.17053110940220986, sharpe5:15.88600695490837, irr5:555.26220703125, ndcg5:0.8602312405168759, pnl5:5.625967979431152 

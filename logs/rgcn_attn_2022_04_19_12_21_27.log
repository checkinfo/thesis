Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='AdjSeqTimeDataset', dout=0.3, epochs=40, glstm_layers=1, gnn_layers=2, gpu=0, graph_attn=True, hidden_dim=128, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=3, mask_adj=True, mask_type='soft', model_type='RGCNModel', normalize_adj=True, num_days=1, num_heads=1, print_inteval=500, relation_num=1, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_250_0.8/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
9185
RGCNModel(
  (fc1): Linear(in_features=9, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
  (fc4): Linear(in_features=128, out_features=1, bias=True)
  (gnns): ModuleList(
    (0): RGCN(
      (attention): ModuleList(
        (0): GraphAttentionLayer (128 -> 128)
      )
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
    )
    (1): RGCN(
      (attention): ModuleList(
        (0): GraphAttentionLayer (128 -> 128)
      )
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
    )
  )
  (dropout): Dropout(p=0.3, inplace=False)
  (relu): LeakyReLU(negative_slope=0.01)
)
train 0, step: 0, loss: 2.0789137768651185, grad_norm: 0.4957569660993771, ic: -0.10487370803820006
train 0, step: 500, loss: 1.3655660656747537, grad_norm: 0.8590678316911564, ic: -0.04741830393125341
train 0, step: 1000, loss: 1.5059050264998466, grad_norm: 0.03220593184595555, ic: 0.2174157782573472
train 0, step: 1500, loss: 1.1921962823068792, grad_norm: 0.10544134410311368, ic: 0.06311406582758787
train 0, step: 2000, loss: 1.5625612212390434, grad_norm: 0.051120004901358956, ic: 0.04040919947337486
Epoch 0: 2022-04-19 00:21:55.992431: train loss: 1.6475499304850838
Eval step 0: eval loss: 1.009337253982359
Eval: 2022-04-19 00:21:57.912862: total loss: 1.0914169824882216, mse:4.885718862393051, ic :0.032255312136358356, sharpe5:0.009182492564432322, irr5:-0.9110965728759766, ndcg5:0.849362872215348, pnl5:0.9702368378639221 
train 1, step: 0, loss: 0.6374123450553063, grad_norm: 0.04834955019592347, ic: 0.050318385037271436
train 1, step: 500, loss: 1.2697647871983915, grad_norm: 0.3043175603380508, ic: 0.27106494923332514
train 1, step: 1000, loss: 0.878098505270303, grad_norm: 0.06257766018271825, ic: 0.08754960686562596
train 1, step: 1500, loss: 1.8553987828696648, grad_norm: 0.5479711906267086, ic: 0.07557542016211452
train 1, step: 2000, loss: 1.375619791915917, grad_norm: 0.23257954776053633, ic: 0.09408497687433838
Epoch 1: 2022-04-19 00:22:25.307770: train loss: 1.6459681895606695
Eval step 0: eval loss: 1.0049398943522907
Eval: 2022-04-19 00:22:27.819480: total loss: 1.0887549393703666, mse:4.877783357821188, ic :0.052332181433047, sharpe5:1.643069415539503, irr5:17.842639923095703, ndcg5:0.8489907008575718, pnl5:1.1241658926010132 
train 2, step: 0, loss: 1.3330573443562916, grad_norm: 0.4949346529892387, ic: 0.03930885790727098
train 2, step: 500, loss: 0.9424761712822458, grad_norm: 0.24662541125460732, ic: 0.0778380486925182
train 2, step: 1000, loss: 3.2412709764349836, grad_norm: 7.685570416605198, ic: 0.10637784628496931
train 2, step: 1500, loss: 2.2858451099078114, grad_norm: 0.8586199926265171, ic: 0.06545391369356779
train 2, step: 2000, loss: 1.4597140021335855, grad_norm: 0.2778441738305593, ic: -0.10478350448500136
Epoch 2: 2022-04-19 00:22:56.043514: train loss: 1.6451015723904403
Eval step 0: eval loss: 1.0026462066795023
Eval: 2022-04-19 00:22:58.333042: total loss: 1.089049168921537, mse:4.87719490404672, ic :0.050434731887582455, sharpe5:3.0078642766177652, irr5:29.37580108642578, ndcg5:0.8535563232513252, pnl5:1.2891356945037842 
train 3, step: 0, loss: 1.826943710548967, grad_norm: 0.06391259160930367, ic: -0.1461909239103724
train 3, step: 500, loss: 0.7809190046895214, grad_norm: 0.02259345785122752, ic: 0.07114459980297508
train 3, step: 1000, loss: 1.3965040697536149, grad_norm: 0.437381278340032, ic: 0.22459462285869847
train 3, step: 1500, loss: 2.647590088457077, grad_norm: 0.47027219060299297, ic: -0.0763060267476472
train 3, step: 2000, loss: 1.3567861845999054, grad_norm: 0.16436498264829408, ic: 0.0759198721094031
Epoch 3: 2022-04-19 00:23:26.511818: train loss: 1.6448946917431035
Eval step 0: eval loss: 1.0009923757158372
Eval: 2022-04-19 00:23:29.055152: total loss: 1.089742973695551, mse:4.877713915183339, ic :0.050693778841154995, sharpe5:2.198932491838932, irr5:22.75196075439453, ndcg5:0.8444262151402966, pnl5:1.108154296875 
train 4, step: 0, loss: 1.1594537418545472, grad_norm: 0.16065393269888845, ic: 0.0802051402017127
train 4, step: 500, loss: 0.9917961502782932, grad_norm: 0.005446029840157166, ic: 0.1326762060071796
train 4, step: 1000, loss: 1.3360041684544242, grad_norm: 0.06482314804797987, ic: 0.04706208936512182
train 4, step: 1500, loss: 1.0740728916266025, grad_norm: 0.09688037092603968, ic: 0.18131996476576875
train 4, step: 2000, loss: 4.182120070318646, grad_norm: 0.9086865933067809, ic: -0.03743893490587147
Epoch 4: 2022-04-19 00:23:56.836746: train loss: 1.6446086757247664
Eval step 0: eval loss: 1.0029773842729726
Eval: 2022-04-19 00:23:59.232598: total loss: 1.0931527752787986, mse:4.8840625561873505, ic :0.051286087028485514, sharpe5:2.350789986848831, irr5:23.157012939453125, ndcg5:0.8537405329394553, pnl5:1.039710521697998 
train 5, step: 0, loss: 0.9964178452851294, grad_norm: 0.1896097529016706, ic: -0.1307006288565875
train 5, step: 500, loss: 0.7899144852142574, grad_norm: 0.028835767191585985, ic: 0.1456138133660347
train 5, step: 1000, loss: 1.114141694951314, grad_norm: 0.03112000988038617, ic: -0.15276389764659226
train 5, step: 1500, loss: 1.7538389624618902, grad_norm: 0.342683327499152, ic: -0.15452933118393647
train 5, step: 2000, loss: 2.181188906498938, grad_norm: 0.8253622976087654, ic: 0.034840676052525554
Epoch 5: 2022-04-19 00:24:28.419686: train loss: 1.64574184304775
Eval step 0: eval loss: 1.001512026272051
Eval: 2022-04-19 00:24:31.014727: total loss: 1.0905980970146174, mse:4.8786434973270865, ic :0.05184483098718408, sharpe5:1.8688882508128881, irr5:19.810062408447266, ndcg5:0.849059209124309, pnl5:1.04557466506958 
train 6, step: 0, loss: 0.7835318208311943, grad_norm: 0.015213048299630903, ic: -0.08276320967757889
train 6, step: 500, loss: 1.4358649002878288, grad_norm: 0.23669395244302205, ic: 0.07041410775975314
train 6, step: 1000, loss: 1.2285605634909127, grad_norm: 0.18895587210620154, ic: 0.16908361166148728
train 6, step: 1500, loss: 1.071964641067217, grad_norm: 0.32290103030854184, ic: 0.02409910687709142
train 6, step: 2000, loss: 2.285169835566694, grad_norm: 1.00431512716305, ic: 0.09336765213542043
Epoch 6: 2022-04-19 00:24:59.169395: train loss: 1.6445338158772225
Eval step 0: eval loss: 1.0000219199455305
Eval: 2022-04-19 00:25:01.290866: total loss: 1.089061542571255, mse:4.878882201157676, ic :0.0485069728670608, sharpe5:2.1597425530850884, irr5:24.907024383544922, ndcg5:0.848461665135676, pnl5:1.1939752101898193 
train 7, step: 0, loss: 1.4539332381975907, grad_norm: 0.5163782475992986, ic: 0.18639314132420032
train 7, step: 500, loss: 1.321287962767455, grad_norm: 0.026261313922883996, ic: 0.09801220839867923
train 7, step: 1000, loss: 0.6444872775230355, grad_norm: 0.01802422996468297, ic: 0.28480929430172053
train 7, step: 1500, loss: 1.004330638730334, grad_norm: 0.12938993365191842, ic: 0.06966341845364912
train 7, step: 2000, loss: 1.5939995573742076, grad_norm: 0.5859218606722725, ic: 0.130136713800509
Epoch 7: 2022-04-19 00:25:29.928206: train loss: 1.6447342865948202
Eval step 0: eval loss: 0.9903326612073788
Eval: 2022-04-19 00:25:32.488856: total loss: 1.0883942972126917, mse:4.894842780875692, ic :0.050822770158040854, sharpe5:6.9528179007768625, irr5:208.4825897216797, ndcg5:0.8527173787295254, pnl5:2.696225881576538 
train 8, step: 0, loss: 1.2001835490101698, grad_norm: 0.0834272625766475, ic: 0.05773649252476024
train 8, step: 500, loss: 5.533471756220611, grad_norm: 1.1653533920266392, ic: 0.13766281945889408
train 8, step: 1000, loss: 1.8793684486694817, grad_norm: 0.5584463575777731, ic: 0.030657451026712808
train 8, step: 1500, loss: 1.1377892127403846, grad_norm: 0.3342350929109097, ic: 0.13184863544690223
train 8, step: 2000, loss: 1.1440167549328926, grad_norm: 0.5623668992521256, ic: -0.003474726166054626
Epoch 8: 2022-04-19 00:26:00.208634: train loss: 1.6446720136916917
Eval step 0: eval loss: 1.0056363829441481
Eval: 2022-04-19 00:26:02.372779: total loss: 1.0909428924258757, mse:4.879704009233053, ic :0.05431346815008454, sharpe5:7.46332880526781, irr5:211.93423461914062, ndcg5:0.8473434488612505, pnl5:2.830853223800659 
train 9, step: 0, loss: 1.1510669275937724, grad_norm: 0.012764870536295436, ic: 0.04487441924733037
train 9, step: 500, loss: 3.1572035233542617, grad_norm: 0.8956347656604404, ic: 0.1406085512557862
train 9, step: 1000, loss: 0.8626487212154953, grad_norm: 0.08690217769358471, ic: 0.24979831358939325
train 9, step: 1500, loss: 2.1545639656351296, grad_norm: 0.8963795312141428, ic: -0.031354834484326057
train 9, step: 2000, loss: 0.6053346743459874, grad_norm: 0.006039758563845477, ic: 0.06697985882355688
Epoch 9: 2022-04-19 00:26:31.285574: train loss: 1.6428056344624828
Eval step 0: eval loss: 1.006957043592022
Eval: 2022-04-19 00:26:33.817508: total loss: 1.0852851114225563, mse:4.724639537110742, ic :0.12625343548731732, sharpe5:7.853161345124244, irr5:232.92201232910156, ndcg5:0.8568005499658123, pnl5:3.5752289295196533 
train 10, step: 0, loss: 1.3086348094217164, grad_norm: 0.0311009892286783, ic: 0.37757521218394574
train 10, step: 500, loss: 0.8960619876563685, grad_norm: 0.004980181444479483, ic: 0.11175432692848775
train 10, step: 1000, loss: 1.5390332275187344, grad_norm: 0.4976654286541701, ic: 0.06879391985904959
train 10, step: 1500, loss: 3.081729291650275, grad_norm: 1.1824075512478764, ic: 0.048421437731844194
train 10, step: 2000, loss: 1.3830302971837005, grad_norm: 0.1376973172509391, ic: 0.049616319600463046
Epoch 10: 2022-04-19 00:27:01.856910: train loss: 1.6388415588714904
Eval step 0: eval loss: 1.0096914443045681
Eval: 2022-04-19 00:27:04.106231: total loss: 1.087514855278288, mse:4.722593510761662, ic :0.12324061452030556, sharpe5:7.164444657862186, irr5:209.37477111816406, ndcg5:0.8455967450328065, pnl5:3.548459768295288 
train 11, step: 0, loss: 4.9655981235340105, grad_norm: 4.06563006138602, ic: 0.18114883158352268
train 11, step: 500, loss: 0.9936155913978495, grad_norm: 0.06242617932239569, ic: 0.03149499335286828
train 11, step: 1000, loss: 1.0386513157894737, grad_norm: 0.3277381177238154, ic: 0.0408791662690281
train 11, step: 1500, loss: 0.6915116873959964, grad_norm: 0.0009964062510530555, ic: 0.1202869647382301
train 11, step: 2000, loss: 1.1299401290236595, grad_norm: 0.057890517355240506, ic: -0.1859970499045067
Epoch 11: 2022-04-19 00:27:32.689566: train loss: 1.637473415495704
Eval step 0: eval loss: 0.9956755354380594
Eval: 2022-04-19 00:27:35.256870: total loss: 1.084498121637043, mse:4.722984835182553, ic :0.12116044805767212, sharpe5:7.653174203932285, irr5:220.9363250732422, ndcg5:0.8375173928791261, pnl5:3.4357240200042725 
train 12, step: 0, loss: 1.3929205716789448, grad_norm: 0.23739392668927425, ic: 0.050846993678114655
train 12, step: 500, loss: 0.8081408277118686, grad_norm: 0.32458359131487546, ic: 0.05199068361957922
train 12, step: 1000, loss: 1.2121398442653364, grad_norm: 0.33908550374755214, ic: 0.5758068584313516
train 12, step: 1500, loss: 1.0894812720995795, grad_norm: 0.22113951106110957, ic: -0.09040196394892129
train 12, step: 2000, loss: 1.1115581186352552, grad_norm: 0.054198157936744866, ic: 0.10473342470025684
Epoch 12: 2022-04-19 00:28:02.955649: train loss: 1.6378237004641987
Eval step 0: eval loss: 0.9986587050338993
Eval: 2022-04-19 00:28:05.307373: total loss: 1.085213085814451, mse:4.722395220442026, ic :0.12306469501360856, sharpe5:8.108697500824928, irr5:233.79150390625, ndcg5:0.8674874311942072, pnl5:3.2471823692321777 
train 13, step: 0, loss: 1.0867722534876347, grad_norm: 0.04836334598960702, ic: 0.42274018649217804
train 13, step: 500, loss: 1.147330480677481, grad_norm: 0.005277691246926944, ic: -0.15592612994654498
train 13, step: 1000, loss: 1.3857248998082219, grad_norm: 0.4180851754111242, ic: 0.04201326161607139
train 13, step: 1500, loss: 0.7760365107288099, grad_norm: 0.001964330910897323, ic: -0.05472124213097094
train 13, step: 2000, loss: 1.0396573818224366, grad_norm: 0.028144199378775426, ic: 0.043008585262199306
Epoch 13: 2022-04-19 00:28:34.749416: train loss: 1.6377915891639874
Eval step 0: eval loss: 0.9905150274404291
Eval: 2022-04-19 00:28:37.379491: total loss: 1.0872926640495162, mse:4.76458602954295, ic :0.11689740884922535, sharpe5:8.073748383522034, irr5:228.8353729248047, ndcg5:0.8630897911356332, pnl5:3.385939121246338 
train 14, step: 0, loss: 1.7418197373212394, grad_norm: 0.5038870080360442, ic: 0.16746849075664746
train 14, step: 500, loss: 1.2813742229116918, grad_norm: 0.1516940633633818, ic: 0.17636908835261064
train 14, step: 1000, loss: 1.0663915208548553, grad_norm: 0.15089120422314156, ic: 0.13738244952346584
train 14, step: 1500, loss: 0.9790108602169938, grad_norm: 0.08387043442048477, ic: 0.188240649375325
train 14, step: 2000, loss: 2.3227091006703713, grad_norm: 0.6139125519622824, ic: -0.09478948182254843
Epoch 14: 2022-04-19 00:29:05.371509: train loss: 1.637898400577325
Eval step 0: eval loss: 1.0006542557349263
Eval: 2022-04-19 00:29:08.020611: total loss: 1.0866502900399728, mse:4.709378144108175, ic :0.14046222094966132, sharpe5:13.881120244860648, irr5:417.41058349609375, ndcg5:0.8386257264390309, pnl5:6.287957191467285 
train 15, step: 0, loss: 0.9719372724211892, grad_norm: 0.151976942118861, ic: 0.11255361959252902
train 15, step: 500, loss: 1.2255338081610485, grad_norm: 0.007848270013145975, ic: 0.06777150027658577
train 15, step: 1000, loss: 1.757834375, grad_norm: 0.03335500691205076, ic: -0.11145643747508821
train 15, step: 1500, loss: 5.3974258175029, grad_norm: 0.8599959912861641, ic: 0.024567963694247387
train 15, step: 2000, loss: 0.9320709127128322, grad_norm: 0.015159399022246119, ic: -0.12190990424177879
Epoch 15: 2022-04-19 00:29:36.674380: train loss: 1.6371627789165466
Eval step 0: eval loss: 1.0085334797919958
Eval: 2022-04-19 00:29:39.325011: total loss: 1.0843574107795395, mse:4.693438749714516, ic :0.14892513098042823, sharpe5:13.736564823389052, irr5:439.93743896484375, ndcg5:0.8632995593694245, pnl5:5.6042256355285645 
train 16, step: 0, loss: 6.304732584501236, grad_norm: 1.4473037239908542, ic: 0.11258582824880929
train 16, step: 500, loss: 1.3761362227182539, grad_norm: 0.7884440709474929, ic: -0.018232332727126505
train 16, step: 1000, loss: 0.8248953992181204, grad_norm: 0.08886074905535488, ic: -0.027599888773182625
train 16, step: 1500, loss: 1.2344160948259373, grad_norm: 0.6651286034396146, ic: 0.06830792296932706
train 16, step: 2000, loss: 0.9545065565799985, grad_norm: 0.24242334195038456, ic: 0.5474968992422333
Epoch 16: 2022-04-19 00:30:06.525599: train loss: 1.630827409386027
Eval step 0: eval loss: 0.9993175247457543
Eval: 2022-04-19 00:30:09.057434: total loss: 1.0818418736916293, mse:4.701827410078377, ic :0.1538784329509945, sharpe5:14.1046283018589, irr5:469.30426025390625, ndcg5:0.8623612464225676, pnl5:4.684308052062988 
train 17, step: 0, loss: 1.1863781513611964, grad_norm: 0.01678421836399951, ic: 0.12813023986930613
train 17, step: 500, loss: 1.045294060014784, grad_norm: 0.029210463917089546, ic: -0.03218694307779173
train 17, step: 1000, loss: 3.3772268767404086, grad_norm: 1.0914199621368357, ic: -0.017203076723041145
train 17, step: 1500, loss: 0.8822362214616202, grad_norm: 0.013828092434628216, ic: 0.0855647779957038
train 17, step: 2000, loss: 0.9784592596476509, grad_norm: 0.4800202234932461, ic: 0.5607043412342788
Epoch 17: 2022-04-19 00:30:38.515666: train loss: 1.6304637188206015
Eval step 0: eval loss: 0.9990843762342021
Eval: 2022-04-19 00:30:41.164540: total loss: 1.0843402448974413, mse:4.716599940965504, ic :0.1527446365734569, sharpe5:14.497336928844451, irr5:469.7532653808594, ndcg5:0.8514526547996534, pnl5:6.699614524841309 
train 18, step: 0, loss: 0.8513303021000401, grad_norm: 0.03157582715832894, ic: 0.03447000249472551
train 18, step: 500, loss: 2.5071645343313476, grad_norm: 0.9735989642304377, ic: 0.09735903405720964
train 18, step: 1000, loss: 1.37095947265625, grad_norm: 0.32984912017822804, ic: 0.5311561400130572
train 18, step: 1500, loss: 1.7522051620078873, grad_norm: 0.6855352548205524, ic: 0.35036749207434037
train 18, step: 2000, loss: 1.255943717053004, grad_norm: 0.3352851975227458, ic: 0.21467516995441177
Epoch 18: 2022-04-19 00:31:08.344792: train loss: 1.6323595210788961
Eval step 0: eval loss: 1.002878583814672
Eval: 2022-04-19 00:31:10.976245: total loss: 1.0833753684326897, mse:4.689661224570521, ic :0.16443862088324565, sharpe5:15.21405159831047, irr5:501.74853515625, ndcg5:0.8470602604376082, pnl5:6.504719257354736 
train 19, step: 0, loss: 2.1946490053557763, grad_norm: 0.8021359320676158, ic: 0.24888299615902992
train 19, step: 500, loss: 1.0176683292832485, grad_norm: 0.05289853134587148, ic: 0.053841626085323974
train 19, step: 1000, loss: 1.003394311088909, grad_norm: 0.32389411240873534, ic: 0.5341278560526683
train 19, step: 1500, loss: 1.5790319560486592, grad_norm: 0.36836976580640507, ic: 0.14946525503619248
train 19, step: 2000, loss: 1.8342424880969646, grad_norm: 1.2982315698861995, ic: 0.63871612838859
Epoch 19: 2022-04-19 00:31:40.319376: train loss: 1.628053670672499
Eval step 0: eval loss: 1.0013078043748354
Eval: 2022-04-19 00:31:42.952338: total loss: 1.081897304936733, mse:4.7015460388265335, ic :0.16180023400270618, sharpe5:14.76549362540245, irr5:489.94525146484375, ndcg5:0.8452923565526432, pnl5:7.175282001495361 
train 20, step: 0, loss: 1.2519893503545823, grad_norm: 0.3758055408858304, ic: 0.46924045293170774
train 20, step: 500, loss: 1.2187761532538832, grad_norm: 0.4393161278493988, ic: 0.002698490697145497
train 20, step: 1000, loss: 1.5772507982067232, grad_norm: 0.3762343512643327, ic: 0.1846280503736731
train 20, step: 1500, loss: 0.8902674111291822, grad_norm: 0.6745629156654922, ic: 0.5654270024036473
train 20, step: 2000, loss: 1.3525852459327, grad_norm: 0.15152614157217875, ic: -0.028634354882888548
Epoch 20: 2022-04-19 00:32:10.188707: train loss: 1.6270191038973443
Eval step 0: eval loss: 1.0018753445481174
Eval: 2022-04-19 00:32:12.751821: total loss: 1.0812762855843236, mse:4.676164097915632, ic :0.16706725940821587, sharpe5:14.955729691386223, irr5:498.55694580078125, ndcg5:0.8526009801268881, pnl5:5.8247456550598145 
train 21, step: 0, loss: 1.4107927238975948, grad_norm: 0.25442228108569004, ic: 0.3468025358937853
train 21, step: 500, loss: 1.1172089813862853, grad_norm: 0.1419242487239579, ic: 0.053923768554201716
train 21, step: 1000, loss: 0.9061785833504519, grad_norm: 0.48857359943128054, ic: 0.048071458344947304
train 21, step: 1500, loss: 0.735984663155174, grad_norm: 0.17854399414008548, ic: 0.627190353744535
train 21, step: 2000, loss: 1.1275987891198604, grad_norm: 0.15432115013372, ic: 0.2854008802517819
Epoch 21: 2022-04-19 00:32:41.561029: train loss: 1.6264248250135105
Eval step 0: eval loss: 1.000779990085242
Eval: 2022-04-19 00:32:44.114443: total loss: 1.0813236299695432, mse:4.694806693138959, ic :0.1561570451097894, sharpe5:13.660850091576576, irr5:418.978271484375, ndcg5:0.8638477671325151, pnl5:6.39708137512207 
train 22, step: 0, loss: 1.0562649938454582, grad_norm: 0.29546490386825996, ic: 0.08978395938311572
train 22, step: 500, loss: 1.0261775459830216, grad_norm: 0.0011397800813931784, ic: -0.007184793690367407
train 22, step: 1000, loss: 0.9108600922915072, grad_norm: 0.03348455418687345, ic: 0.12816594078633647
train 22, step: 1500, loss: 0.9995622961691978, grad_norm: 0.09011941656715172, ic: 0.2635153472167605
train 22, step: 2000, loss: 1.0519118198128634, grad_norm: 0.10118463831551987, ic: 0.05004524991187361
Epoch 22: 2022-04-19 00:33:10.838368: train loss: 1.62826318616646
Eval step 0: eval loss: 1.0070298100974195
Eval: 2022-04-19 00:33:13.380986: total loss: 1.0837353841837976, mse:4.703014465042264, ic :0.14031758440312062, sharpe5:11.687575272917748, irr5:352.6125793457031, ndcg5:0.8552722877615343, pnl5:5.899324417114258 
train 23, step: 0, loss: 1.2922060500883046, grad_norm: 0.8067617886425643, ic: -0.012374410578916126
train 23, step: 500, loss: 0.9084549788590317, grad_norm: 0.18861518593031942, ic: 0.5862204369918571
train 23, step: 1000, loss: 2.290606273524168, grad_norm: 0.8459288140965736, ic: 0.07996295454148993
train 23, step: 1500, loss: 0.7578073207765584, grad_norm: 0.3250968631018425, ic: 0.7282148216607244
train 23, step: 2000, loss: 1.5004766555059523, grad_norm: 0.3442094199538716, ic: 0.39829461464780125
Epoch 23: 2022-04-19 00:33:41.931411: train loss: 1.6260646879271392
Eval step 0: eval loss: 1.0022157786581753
Eval: 2022-04-19 00:33:44.484632: total loss: 1.0846587708703797, mse:4.69373889546665, ic :0.1538433094530743, sharpe5:12.677217888236045, irr5:405.5304260253906, ndcg5:0.8505764477767183, pnl5:4.7545576095581055 
train 24, step: 0, loss: 1.1768475784909251, grad_norm: 0.3515201195032866, ic: 0.28909504460491164
train 24, step: 500, loss: 1.2557541580258391, grad_norm: 0.3458038669714973, ic: 0.01533951436508909
train 24, step: 1000, loss: 1.040656113043064, grad_norm: 0.354304861612725, ic: 0.09201061852584465
train 24, step: 1500, loss: 1.1998909056656004, grad_norm: 0.0995727716122556, ic: 0.0650044038234671
train 24, step: 2000, loss: 1.3680324142640863, grad_norm: 0.43732787985413635, ic: 0.4420842569112469
Epoch 24: 2022-04-19 00:34:11.940878: train loss: 1.6258551535430559
Eval step 0: eval loss: 1.0139959173619337
Eval: 2022-04-19 00:34:14.589761: total loss: 1.0820167566165972, mse:4.68729670257002, ic :0.1678640279329206, sharpe5:15.437045071721077, irr5:511.93682861328125, ndcg5:0.8500458512304061, pnl5:4.910000801086426 
train 25, step: 0, loss: 1.3148279657657498, grad_norm: 0.7251915493282937, ic: 0.1825703120495965
train 25, step: 500, loss: 1.4567794799804688, grad_norm: 0.5656769654022277, ic: 0.10866795512023208
train 25, step: 1000, loss: 1.3680337792912594, grad_norm: 0.26961488511779835, ic: 0.2600860878137059
train 25, step: 1500, loss: 2.846009320250091, grad_norm: 1.360966093880371, ic: 0.20870895060583045
train 25, step: 2000, loss: 1.189383011830004, grad_norm: 0.20980389419770912, ic: 0.12870146559774048
Epoch 25: 2022-04-19 00:34:44.085663: train loss: 1.6267936436403752
Eval step 0: eval loss: 1.002352183715113
Eval: 2022-04-19 00:34:46.687078: total loss: 1.080725560049239, mse:4.681536868184838, ic :0.1666352186456983, sharpe5:15.237303398251532, irr5:496.8531799316406, ndcg5:0.8544728132734873, pnl5:6.398574352264404 
train 26, step: 0, loss: 1.626672940340909, grad_norm: 0.31698832637453633, ic: 0.19979652811711435
train 26, step: 500, loss: 1.0175252646428203, grad_norm: 0.1796586327216856, ic: -0.0661571100045314
train 26, step: 1000, loss: 1.8071750510642173, grad_norm: 0.6854410139576994, ic: 0.18585137677157793
train 26, step: 1500, loss: 0.9209930226364298, grad_norm: 0.05430196333948502, ic: 0.019111896469846335
train 26, step: 2000, loss: 1.0037467896468997, grad_norm: 0.11064815229200997, ic: 0.10243215552836227
Epoch 26: 2022-04-19 00:35:13.964086: train loss: 1.625754823331266
Eval step 0: eval loss: 1.0004241284475381
Eval: 2022-04-19 00:35:16.572309: total loss: 1.0826947859033442, mse:4.691286337084185, ic :0.16727464752006485, sharpe5:15.757092415094375, irr5:514.6514892578125, ndcg5:0.8576283816743749, pnl5:5.687477111816406 
train 27, step: 0, loss: 1.6290713390672065, grad_norm: 0.39052721779311594, ic: 0.6478178616852495
train 27, step: 500, loss: 1.530763807044615, grad_norm: 0.534231258585072, ic: 0.052566965706287605
train 27, step: 1000, loss: 2.5876838547736987, grad_norm: 0.912956883545589, ic: 0.39819996718564704
train 27, step: 1500, loss: 0.8661126713219985, grad_norm: 0.7187934010764871, ic: 0.5400122666237032
train 27, step: 2000, loss: 1.384026640204973, grad_norm: 1.3154008614570243, ic: -0.02570021318797281
Epoch 27: 2022-04-19 00:35:45.244098: train loss: 1.6236403127743093
Eval step 0: eval loss: 1.0075200197883754
Eval: 2022-04-19 00:35:47.820728: total loss: 1.0815960112779424, mse:4.692306095264429, ic :0.16053185996634634, sharpe5:14.391794321537017, irr5:447.3794860839844, ndcg5:0.8456831828144131, pnl5:5.146770000457764 
train 28, step: 0, loss: 1.1690169900449263, grad_norm: 0.11797932573165062, ic: 0.1422214952069393
train 28, step: 500, loss: 2.9545661134421333, grad_norm: 0.8074760783400253, ic: 0.09210964559006787
train 28, step: 1000, loss: 2.7883825317189967, grad_norm: 2.5707881194824087, ic: -0.03652877799541835
train 28, step: 1500, loss: 1.022547293215208, grad_norm: 0.00498102785734289, ic: 0.2051102662108399
train 28, step: 2000, loss: 1.7797656391942223, grad_norm: 0.36659431064756315, ic: 0.08095936263842136
Epoch 28: 2022-04-19 00:36:15.199209: train loss: 1.6247782540461833
Eval step 0: eval loss: 1.0134321697891981
Eval: 2022-04-19 00:36:17.778213: total loss: 1.0831626320172116, mse:4.6981412901858866, ic :0.156613194921564, sharpe5:14.467523242235183, irr5:452.6189270019531, ndcg5:0.8512246066911184, pnl5:5.565495014190674 
train 29, step: 0, loss: 1.5166039687381538, grad_norm: 0.3229911071401812, ic: 0.09594474275849453
train 29, step: 500, loss: 2.5448709956110998, grad_norm: 1.3077093690040662, ic: 0.014210730432470012
train 29, step: 1000, loss: 1.7062935905060552, grad_norm: 0.9412841796828901, ic: 0.48457967761899
train 29, step: 1500, loss: 3.969960350409286, grad_norm: 1.0896528126274048, ic: 0.13242981145510113
train 29, step: 2000, loss: 0.9296923776097162, grad_norm: 0.26320572085198013, ic: 0.47071510870447625
Epoch 29: 2022-04-19 00:36:46.405855: train loss: 1.6260733722906753
Eval step 0: eval loss: 1.0054639803227026
Eval: 2022-04-19 00:36:49.039954: total loss: 1.0812583426120506, mse:4.686577272673391, ic :0.16033154104636257, sharpe5:14.096836711764334, irr5:462.2539978027344, ndcg5:0.8485086672131271, pnl5:6.57265043258667 
train 30, step: 0, loss: 1.2553353320460352, grad_norm: 0.040852874536391984, ic: 0.9900324629283963
train 30, step: 500, loss: 1.9525629357446599, grad_norm: 0.3670009716639759, ic: 0.15894356757136233
train 30, step: 1000, loss: 3.4072194625743553, grad_norm: 0.8665177455487653, ic: 0.4323218221105942
train 30, step: 1500, loss: 1.0807209443140113, grad_norm: 0.2220940741854328, ic: 0.14296148375237622
train 30, step: 2000, loss: 1.0914538816365227, grad_norm: 0.07130401013405756, ic: 0.4414406835723982
Epoch 30: 2022-04-19 00:37:15.798785: train loss: 1.6248266605852417
Eval step 0: eval loss: 0.9988140088122037
Eval: 2022-04-19 00:37:18.416303: total loss: 1.0824791408609404, mse:4.696904658288137, ic :0.15271013315944335, sharpe5:13.40101470351219, irr5:444.6573181152344, ndcg5:0.850080725021185, pnl5:3.0977885723114014 
train 31, step: 0, loss: 1.1558200019185285, grad_norm: 0.29318017186723055, ic: 0.20557715692826478
train 31, step: 500, loss: 0.8404778082480913, grad_norm: 0.06750777966244025, ic: 0.24311858882749462
train 31, step: 1000, loss: 5.100337047057393, grad_norm: 0.8643883249149402, ic: -0.07976077694160284
train 31, step: 1500, loss: 1.6850433113770285, grad_norm: 0.34225727280702195, ic: 0.2816374159894237
train 31, step: 2000, loss: 0.8645149552502395, grad_norm: 1.156747438506395, ic: 0.19122099373023344
Epoch 31: 2022-04-19 00:37:47.695977: train loss: 1.6280678603098704
Eval step 0: eval loss: 1.0048175669143298
Eval: 2022-04-19 00:37:50.356610: total loss: 1.0820042700736459, mse:4.680188034425118, ic :0.16638826565595555, sharpe5:14.308929337263107, irr5:468.3246765136719, ndcg5:0.8334985737233751, pnl5:5.362377166748047 
train 32, step: 0, loss: 0.87646058655942, grad_norm: 0.5847134760021894, ic: 0.1172158195186042
train 32, step: 500, loss: 1.1141368586842606, grad_norm: 0.41004640310473733, ic: 0.1785002132290443
train 32, step: 1000, loss: 1.3775903932945142, grad_norm: 0.04951106281146886, ic: 0.07736626969681833
train 32, step: 1500, loss: 2.0865820539256, grad_norm: 0.8056875302369205, ic: 0.4477465708159162
train 32, step: 2000, loss: 1.0672134730155243, grad_norm: 0.3381838345953174, ic: 0.46640786894021213
Epoch 32: 2022-04-19 00:38:17.334794: train loss: 1.623944805279522
Eval step 0: eval loss: 1.0080671827688914
Eval: 2022-04-19 00:38:19.900312: total loss: 1.080550522419256, mse:4.672015658971668, ic :0.17195870261121404, sharpe5:15.803007649183273, irr5:527.4628295898438, ndcg5:0.8539605286884152, pnl5:4.647775173187256 
train 33, step: 0, loss: 1.163462219937691, grad_norm: 0.018637997995255052, ic: 0.03799742383694901
train 33, step: 500, loss: 3.1785330394888547, grad_norm: 0.556958649458435, ic: 0.5219896917705897
train 33, step: 1000, loss: 5.233408395165696, grad_norm: 1.8620802749889518, ic: 0.01745730002866156
train 33, step: 1500, loss: 1.2886636873570885, grad_norm: 0.9123469986442291, ic: 0.12624851917946683
train 33, step: 2000, loss: 1.8635403418725776, grad_norm: 0.2821350721089483, ic: 0.09092498612103793
Epoch 33: 2022-04-19 00:38:48.511201: train loss: 1.624757619824238
Eval step 0: eval loss: 1.0110263754155147
Eval: 2022-04-19 00:38:51.111894: total loss: 1.0884889038423213, mse:4.695469060542727, ic :0.1631507410641985, sharpe5:14.35906150817871, irr5:471.5887451171875, ndcg5:0.8222665493723623, pnl5:6.378945350646973 
train 34, step: 0, loss: 0.7154182155989997, grad_norm: 0.3402387557833209, ic: 0.1637544905313372
train 34, step: 500, loss: 1.9032207936962415, grad_norm: 10.509808032551454, ic: 0.7483716552444385
train 34, step: 1000, loss: 0.6898267022494612, grad_norm: 0.02985252491025329, ic: 0.4884071691068556
train 34, step: 1500, loss: 1.6519488994891827, grad_norm: 1.3378971360188097, ic: 0.6457331955097905
train 34, step: 2000, loss: 3.005444697925247, grad_norm: 0.4962354404436901, ic: 0.06478333409055895
Epoch 34: 2022-04-19 00:39:18.280399: train loss: 1.6244710582106943
Eval step 0: eval loss: 1.0091070624136058
Eval: 2022-04-19 00:39:20.947756: total loss: 1.083078751330209, mse:4.688987124473228, ic :0.15921499447225884, sharpe5:13.605038582682608, irr5:434.0324401855469, ndcg5:0.8582069897849045, pnl5:5.202437400817871 
train 35, step: 0, loss: 1.069365585906596, grad_norm: 0.8214750853630344, ic: 0.003479148460728998
train 35, step: 500, loss: 3.3113606770833335, grad_norm: 1.7351722173163164, ic: -0.10095261831719106
train 35, step: 1000, loss: 1.3319162590002938, grad_norm: 0.14575398874312046, ic: 0.518019028734508
train 35, step: 1500, loss: 1.6369657899198915, grad_norm: 0.47254017333976134, ic: 0.07153094262365978
train 35, step: 2000, loss: 1.2823608492410026, grad_norm: 0.09186437494895452, ic: -0.0220244592123284
Epoch 35: 2022-04-19 00:39:49.748613: train loss: 1.625236628929589
Eval step 0: eval loss: 0.9998358253932991
Eval: 2022-04-19 00:39:52.439876: total loss: 1.081367421700544, mse:4.686668377022786, ic :0.16237723502046267, sharpe5:14.791697659492492, irr5:475.26226806640625, ndcg5:0.8353884803721959, pnl5:5.439155578613281 
train 36, step: 0, loss: 8.979145342097475, grad_norm: 1.4894376042847133, ic: -0.1901955820026829
train 36, step: 500, loss: 0.8588414390731454, grad_norm: 0.015234628256061892, ic: 0.11279811532815055
train 36, step: 1000, loss: 1.9848443584963906, grad_norm: 2.368248707166088, ic: 0.06577947241493565
train 36, step: 1500, loss: 1.0564756957017671, grad_norm: 0.15402404350360516, ic: 0.0645914796036589
train 36, step: 2000, loss: 2.1562479882467627, grad_norm: 1.3993206332976882, ic: 0.3836422920465534
Epoch 36: 2022-04-19 00:40:19.504065: train loss: 1.6242048447543302
Eval step 0: eval loss: 1.0122279869750526
Eval: 2022-04-19 00:40:21.982389: total loss: 1.0860178912740845, mse:4.691533722882408, ic :0.16009575424251002, sharpe5:13.589619047641753, irr5:443.46685791015625, ndcg5:0.8535969974153625, pnl5:5.010450839996338 
train 37, step: 0, loss: 1.1944752067225086, grad_norm: 0.233861564415303, ic: 0.15420414305588523
train 37, step: 500, loss: 2.34217736968361, grad_norm: 0.03837307918728848, ic: 0.1498096225708437
train 37, step: 1000, loss: 0.7665291618431805, grad_norm: 0.37679741552501145, ic: 0.15828591830762243
train 37, step: 1500, loss: 3.1514777943567576, grad_norm: 0.6906705563078933, ic: 0.19799803823427595
train 37, step: 2000, loss: 3.1505001633792773, grad_norm: 1.5105897926818808, ic: 0.005324454024883549
Epoch 37: 2022-04-19 00:40:51.251114: train loss: 1.6236503124296222
Eval step 0: eval loss: 1.0036665447891981
Eval: 2022-04-19 00:40:53.823504: total loss: 1.0806319426479565, mse:4.678815611499031, ic :0.1691709539775448, sharpe5:14.692140870094299, irr5:486.36279296875, ndcg5:0.8493259729374752, pnl5:6.353139400482178 
train 38, step: 0, loss: 1.3497937751538827, grad_norm: 0.4207593663076981, ic: -0.19472217970535685
train 38, step: 500, loss: 1.7163648028706395, grad_norm: 0.8566489437551296, ic: 0.15391774635016037
train 38, step: 1000, loss: 1.833363763010605, grad_norm: 0.5554220224757997, ic: 0.1220550920310521
train 38, step: 1500, loss: 1.0767555189663163, grad_norm: 0.17333907483704886, ic: 0.46895692719317045
train 38, step: 2000, loss: 0.7574218415102023, grad_norm: 0.04457586586407565, ic: 0.5616945096692411
Epoch 38: 2022-04-19 00:41:20.992858: train loss: 1.624902362928439
Eval step 0: eval loss: 0.9951189873782254
Eval: 2022-04-19 00:41:23.531834: total loss: 1.0794297594937143, mse:4.696421586257882, ic :0.16487775892522316, sharpe5:14.530325142145156, irr5:478.4005432128906, ndcg5:0.8450253346660894, pnl5:5.404849529266357 
train 39, step: 0, loss: 0.8741331657903831, grad_norm: 0.04082364145075304, ic: 0.5391760987066596
train 39, step: 500, loss: 1.235433595316259, grad_norm: 0.5120789864723622, ic: 0.04288393727822715
train 39, step: 1000, loss: 1.3910692619554925, grad_norm: 0.33544345274551945, ic: 0.07424994669579438
train 39, step: 1500, loss: 2.4351891805959305, grad_norm: 0.412303879206702, ic: -0.06070181691952332
train 39, step: 2000, loss: 2.9263421381273234, grad_norm: 1.5387543855803145, ic: 0.21202526109723313
Epoch 39: 2022-04-19 00:41:51.883602: train loss: 1.6215617786134982
Eval step 0: eval loss: 1.00334108823723
Eval: 2022-04-19 00:41:54.403204: total loss: 1.0797627948819088, mse:4.6906512342239255, ic :0.16146072946864912, sharpe5:13.422231817245482, irr5:453.58441162109375, ndcg5:0.843942771478977, pnl5:3.637874126434326 

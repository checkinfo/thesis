Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', batch_size=1, dataset_type='AdjTimeDataset', dout=0.3, epochs=20, gnn_layers=2, hidden_dim=128, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=3, mask_adj=True, mask_type='soft', model_type='GNNModel', num_days=1, num_heads=1, print_inteval=500, relation_num=1, seed=10086, shuffle=True, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=False)
54533
GNNModel(
  (fc1): Linear(in_features=9, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
  (fc4): Linear(in_features=128, out_features=1, bias=True)
  (gnns): ModuleList(
    (0): GraphConv(128, 128)
    (1): GraphConv(128, 128)
  )
  (dropout): Dropout(p=0.3, inplace=False)
  (relu): LeakyReLU(negative_slope=0.01)
)
train 0, step: 0, loss: 0.8711773880428226, grad_norm: 0.00031938521795782404, ic: 0.0749516970024341
train 0, step: 500, loss: 0.9910432746611446, grad_norm: 0.1475805092852309, ic: 0.006881713549589396
train 0, step: 1000, loss: 1.0695091153479155, grad_norm: 0.02335613203630294, ic: -0.03345996748500403
train 0, step: 1500, loss: 0.9542215378764439, grad_norm: 0.10384186062704573, ic: 0.26201382667216366
train 0, step: 2000, loss: 1.070874151408707, grad_norm: 0.3282510939758028, ic: 0.11327089580779508
Epoch 0: train loss: 1.6477014019471217
Eval step 0: eval loss: 1.0129436956951026
Eval: total loss: 1.0915037516480433, mse:4.887968984139307, ic :0.04001831420656538, sharpe5:6.810894990563392, irr5:206.30801391601562, ndcg5:0.8532839814405953 
train 1, step: 0, loss: 0.9409724737540122, grad_norm: 0.07598013837489455, ic: 0.08468355401649844
train 1, step: 500, loss: 1.6858354721879742, grad_norm: 0.11269822805126428, ic: -0.08781519170525873
train 1, step: 1000, loss: 1.0979026990651002, grad_norm: 0.4180567564431157, ic: 0.1012355041585081
train 1, step: 1500, loss: 0.8960640442195197, grad_norm: 0.1374837245144291, ic: -0.10622725078535472
train 1, step: 2000, loss: 4.6606765997605555, grad_norm: 2.7035676258377572, ic: 0.0641816193616664
Epoch 1: train loss: 1.6454716343095548
Eval step 0: eval loss: 1.0003349701940165
Eval: total loss: 1.0889819955897242, mse:4.877788756022931, ic :0.05074502939913546, sharpe5:7.218987207412719, irr5:213.90594482421875, ndcg5:0.8511673392868008 
train 2, step: 0, loss: 0.9604612865375475, grad_norm: 0.11785420969221651, ic: 0.01287483732903118
train 2, step: 500, loss: 1.3049908262310606, grad_norm: 0.09616797323621064, ic: 0.19826691847468725
train 2, step: 1000, loss: 1.0685603200506626, grad_norm: 0.011514281489514541, ic: 0.006528191951013883
train 2, step: 1500, loss: 0.969002048013664, grad_norm: 0.37060780101601476, ic: -0.031088098205303664
train 2, step: 2000, loss: 1.7262575995653195, grad_norm: 0.09781890267509391, ic: 0.09582045736334449
Epoch 2: train loss: 1.6441960552348331
Eval step 0: eval loss: 0.9913621915522972
Eval: total loss: 1.0901373345182268, mse:4.898834136291664, ic :0.05047903197720543, sharpe5:6.868418624997139, irr5:207.14230346679688, ndcg5:0.8641336885223256 
train 3, step: 0, loss: 0.841473584634397, grad_norm: 0.0685186329911949, ic: 0.2709271669863265
train 3, step: 500, loss: 1.2177476185847589, grad_norm: 0.004909008021255631, ic: 0.16364916771298194
train 3, step: 1000, loss: 0.9010562294407894, grad_norm: 0.025585176765761098, ic: 0.21829434716540033
train 3, step: 1500, loss: 4.37981678822097, grad_norm: 0.8032394564896697, ic: 0.08328804804293964
train 3, step: 2000, loss: 1.662792497360217, grad_norm: 0.4021168752338618, ic: -0.042303490829723685
Epoch 3: train loss: 1.6430226686993423
Eval step 0: eval loss: 0.9976480734103474
Eval: total loss: 1.091894629446078, mse:4.849616898350583, ic :0.09451146051095667, sharpe5:7.136884639263153, irr5:211.6538543701172, ndcg5:0.8369210092979525 
train 4, step: 0, loss: 1.290082167998478, grad_norm: 0.2537845399897699, ic: 0.03270014910047315
train 4, step: 500, loss: 0.8501859456475837, grad_norm: 0.047443385589435214, ic: 0.47541419710308785
train 4, step: 1000, loss: 1.9372096967093553, grad_norm: 0.22200397549516548, ic: 0.15816080658703643
train 4, step: 1500, loss: 1.1686637746116328, grad_norm: 0.013623736816951932, ic: 0.20671097124796528
train 4, step: 2000, loss: 6.636904061558735, grad_norm: 1.0547618535945904, ic: -0.027074324672100393
Epoch 4: train loss: 1.6390462018105614
Eval step 0: eval loss: 0.9995788284952606
Eval: total loss: 1.0850937075472529, mse:4.7128825956654685, ic :0.1251618657989248, sharpe5:7.99791068136692, irr5:230.24871826171875, ndcg5:0.845665219128387 
train 5, step: 0, loss: 3.719676176030585, grad_norm: 0.5282802917832998, ic: 0.3061788035521427
train 5, step: 500, loss: 3.4315686637972607, grad_norm: 0.7133957479453039, ic: -0.05388633546018464
train 5, step: 1000, loss: 1.0436906395490018, grad_norm: 0.05101233425870602, ic: 0.07269001909101733
train 5, step: 1500, loss: 1.5092373964672074, grad_norm: 1.1597567569037481, ic: 0.45878907455494267
train 5, step: 2000, loss: 1.7511146345388577, grad_norm: 0.6379159689960543, ic: 0.033712963725651614
Epoch 5: train loss: 1.6379981641708543
Eval step 0: eval loss: 1.0025740829877565
Eval: total loss: 1.0875176666224229, mse:4.718464918175686, ic :0.1244558847949398, sharpe5:7.531661532819271, irr5:214.62887573242188, ndcg5:0.8606125373027353 
train 6, step: 0, loss: 1.1062867638660454, grad_norm: 0.04138649345107064, ic: 0.43287781352991317
train 6, step: 500, loss: 1.8474776357365008, grad_norm: 0.11902862244196741, ic: 0.19488381640989122
train 6, step: 1000, loss: 0.8678049643208662, grad_norm: 0.18832358062136062, ic: 0.051434904472200324
train 6, step: 1500, loss: 0.8486405402004551, grad_norm: 0.003606405831252931, ic: 0.09378109849172608
train 6, step: 2000, loss: 1.932535046728972, grad_norm: 0.27301178788987857, ic: 0.04911659118325147
Epoch 6: train loss: 1.6373427224066084
Eval step 0: eval loss: 0.9906864658413967
Eval: total loss: 1.0851376924207734, mse:4.738284613769611, ic :0.12208902112840755, sharpe5:8.10145076394081, irr5:224.43441772460938, ndcg5:0.8497714851382161 
train 7, step: 0, loss: 0.8245970747853053, grad_norm: 0.1185552703067206, ic: 0.510599470259198
train 7, step: 500, loss: 1.1373337129142909, grad_norm: 0.01906876711299772, ic: 0.04344952937890136
train 7, step: 1000, loss: 1.098618189975834, grad_norm: 0.026058898698294305, ic: -0.07568471130260943
train 7, step: 1500, loss: 1.105752346256928, grad_norm: 0.0737234928485978, ic: 0.43758536723674896
train 7, step: 2000, loss: 0.7123505444980984, grad_norm: 0.021725005053654513, ic: -0.03372996592857458
Epoch 7: train loss: 1.6371353576205425
Eval step 0: eval loss: 1.0073726868993549
Eval: total loss: 1.101073423006569, mse:4.835567743515654, ic :0.10063471774293162, sharpe5:8.289849842190742, irr5:240.9491729736328, ndcg5:0.8553472772140536 
train 8, step: 0, loss: 2.031761903575226, grad_norm: 0.3690945789298579, ic: -0.1026131126989127
train 8, step: 500, loss: 0.9436171632375776, grad_norm: 0.06604255983006392, ic: 0.49911896442970355
train 8, step: 1000, loss: 0.7366390976838452, grad_norm: 0.03646825758251947, ic: 0.10578115072363312
train 8, step: 1500, loss: 0.8497728044260129, grad_norm: 0.038625294175401184, ic: 0.179449581459593
train 8, step: 2000, loss: 1.4674324461164572, grad_norm: 0.7846006502046917, ic: -0.0025789222750226097
Epoch 8: train loss: 1.6365152981778774
Eval step 0: eval loss: 1.0034858498716428
Eval: total loss: 1.0880710233299815, mse:4.719897269737609, ic :0.12521534522322972, sharpe5:9.595077869296073, irr5:277.67926025390625, ndcg5:0.8502733570192711 
train 9, step: 0, loss: 0.7801726332090192, grad_norm: 0.021883633885489993, ic: 0.5206556688703347
train 9, step: 500, loss: 1.763981768714402, grad_norm: 0.045077067754060465, ic: -0.12797724885193665
train 9, step: 1000, loss: 0.7806166927371405, grad_norm: 0.013069285110568448, ic: 0.16901985185429635
train 9, step: 1500, loss: 1.0661478501751185, grad_norm: 0.07488414324803813, ic: -0.08459616272360763
train 9, step: 2000, loss: 4.468398437499999, grad_norm: 2.448405575223358, ic: 0.24156549143191622
Epoch 9: train loss: 1.633119892200928
Eval step 0: eval loss: 1.0025802539988151
Eval: total loss: 1.0930881691991998, mse:4.772444979439174, ic :0.12643994553926882, sharpe5:13.034525245428085, irr5:373.6296691894531, ndcg5:0.8458413244836651 
train 10, step: 0, loss: 0.7983330620659722, grad_norm: 0.0011264185642505663, ic: 0.09320379319464946
train 10, step: 500, loss: 0.7960989126574851, grad_norm: 0.07973256747295347, ic: -0.025735259007923388
train 10, step: 1000, loss: 1.016329070060484, grad_norm: 0.3966254393014243, ic: -0.009504815809269151
train 10, step: 1500, loss: 1.3266714700838416, grad_norm: 0.14769858870004676, ic: 0.07262287277620641
train 10, step: 2000, loss: 1.2657211526286467, grad_norm: 0.4526933495006838, ic: -0.18063899312534037
Epoch 10: train loss: 1.6302391354760466
Eval step 0: eval loss: 1.003488871095807
Eval: total loss: 1.082356459147279, mse:4.706380019286721, ic :0.15009161589595685, sharpe5:14.139554716944694, irr5:449.1705017089844, ndcg5:0.8463658411099038 
train 11, step: 0, loss: 1.5334288643677016, grad_norm: 0.060910839040016485, ic: 0.17682249706898215
train 11, step: 500, loss: 1.3261386821796368, grad_norm: 0.22920984989084053, ic: 0.1592983467938306
train 11, step: 1000, loss: 2.2673305584725814, grad_norm: 0.7944296611364198, ic: 0.29177849641817966
train 11, step: 1500, loss: 1.3988096128059528, grad_norm: 0.9810724979149731, ic: 0.033535396816242374
train 11, step: 2000, loss: 3.7030847841394716, grad_norm: 3.3531522595827354, ic: 0.2042448615294666
Epoch 11: train loss: 1.6277783753692043
Eval step 0: eval loss: 1.01325218196666
Eval: total loss: 1.0880403958570064, mse:4.694338594785281, ic :0.15606289520488395, sharpe5:14.088647832870482, irr5:460.1507263183594, ndcg5:0.8673351179449198 
train 12, step: 0, loss: 1.004119873046875, grad_norm: 0.09534194994869286, ic: 0.08962103848801892
train 12, step: 500, loss: 1.2149651106013808, grad_norm: 0.13825430949400627, ic: 0.10515766691551878
train 12, step: 1000, loss: 1.1878234935683571, grad_norm: 1.3367877084269018, ic: 0.6059230903439573
train 12, step: 1500, loss: 0.7633022846682985, grad_norm: 0.1230103102573652, ic: 0.600198783306935
train 12, step: 2000, loss: 2.7745148414789247, grad_norm: 0.7540766870269375, ic: -0.05079304675984202
Epoch 12: train loss: 1.628127736074485
Eval step 0: eval loss: 1.0022088362707344
Eval: total loss: 1.081937631954259, mse:4.682529503658952, ic :0.16172169047753243, sharpe5:14.536252312660217, irr5:477.0150451660156, ndcg5:0.8499289573064647 
train 13, step: 0, loss: 1.3552637763201871, grad_norm: 0.6005688073720659, ic: 0.15261589851100008
train 13, step: 500, loss: 1.4297385948796613, grad_norm: 0.1427215172751799, ic: -0.0930951684475202
train 13, step: 1000, loss: 2.200552303019807, grad_norm: 0.9966576915704003, ic: 0.04999910978939057
train 13, step: 1500, loss: 1.5833581263565508, grad_norm: 1.0048482290664096, ic: -0.10792240783595614
train 13, step: 2000, loss: 0.7175024199046737, grad_norm: 0.029280176859251182, ic: -0.04503924471265408
Epoch 13: train loss: 1.6269654284350705
Eval step 0: eval loss: 1.0127990626234202
Eval: total loss: 1.086191697343154, mse:4.689210293467399, ic :0.1592617354461759, sharpe5:14.481751856803893, irr5:474.3473815917969, ndcg5:0.8542630619529179 
train 14, step: 0, loss: 1.9704136098570353, grad_norm: 1.0511253272142365, ic: 0.1842451044660174
train 14, step: 500, loss: 2.763558017369075, grad_norm: 1.6775042443593524, ic: -0.12607928902457688
train 14, step: 1000, loss: 1.0590787346728554, grad_norm: 0.08469301563123137, ic: 0.14812102140489436
train 14, step: 1500, loss: 3.0301229346612963, grad_norm: 1.1972157815310795, ic: 0.14237466764826354
train 14, step: 2000, loss: 0.8032972030057252, grad_norm: 0.035891040358790635, ic: -0.04070105522944309
Epoch 14: train loss: 1.626986990423407
Eval step 0: eval loss: 1.0054752295616114
Eval: total loss: 1.082460291029818, mse:4.678246300588491, ic :0.16523728989531464, sharpe5:15.29217465698719, irr5:498.03564453125, ndcg5:0.8409708589434267 
train 15, step: 0, loss: 1.2348067539657825, grad_norm: 0.25890965328403337, ic: 0.5270574934367902
train 15, step: 500, loss: 1.8244348284841954, grad_norm: 1.3666506210805676, ic: -0.006210553836648484
train 15, step: 1000, loss: 1.740193808951029, grad_norm: 0.6460480160991123, ic: 0.1842549249935333
train 15, step: 1500, loss: 1.4624563116776315, grad_norm: 0.48026001884527303, ic: -0.09021004535016562
train 15, step: 2000, loss: 3.118213232345937, grad_norm: 0.05226963418943241, ic: 0.19129308430049774
Epoch 15: train loss: 1.6256592563258159
Eval step 0: eval loss: 1.0035338037700763
Eval: total loss: 1.082929986730999, mse:4.687761087153835, ic :0.16448049404771206, sharpe5:15.508298817873, irr5:510.714599609375, ndcg5:0.8490878476995234 
train 16, step: 0, loss: 1.7956462250169376, grad_norm: 0.6040837708954049, ic: 0.2120159864504617
train 16, step: 500, loss: 1.3420933993805977, grad_norm: 0.3889146487453022, ic: 0.3424965481957944
train 16, step: 1000, loss: 0.913724085327926, grad_norm: 0.011272315032753118, ic: 0.01337156030957972
train 16, step: 1500, loss: 1.3665876216654649, grad_norm: 1.1529638772103097, ic: 0.22369748663370076
train 16, step: 2000, loss: 1.2500206764047233, grad_norm: 0.09871280265255904, ic: 0.23505193300244503
Epoch 16: train loss: 1.6262037759555716
Eval step 0: eval loss: 1.0094635668649616
Eval: total loss: 1.083473542191926, mse:4.676958037317559, ic :0.16861754723470126, sharpe5:15.301750262975691, irr5:499.1233825683594, ndcg5:0.8438175846163561 
train 17, step: 0, loss: 1.5495401863983131, grad_norm: 0.4247989092360968, ic: 0.1275692035655128
train 17, step: 500, loss: 2.2263744281725284, grad_norm: 0.8886089224828517, ic: 0.16501895548694376
train 17, step: 1000, loss: 0.9591932087322577, grad_norm: 0.007011075930032233, ic: 0.17558284802685006
train 17, step: 1500, loss: 0.8452399364770026, grad_norm: 0.10548005592552694, ic: 0.30070690331581224
train 17, step: 2000, loss: 3.176874474634098, grad_norm: 1.6303357944598833, ic: 0.04024960249018541
Epoch 17: train loss: 1.6259630511232435
Eval step 0: eval loss: 1.012705083267509
Eval: total loss: 1.0869150995079877, mse:4.69162829893135, ic :0.15987788176951603, sharpe5:14.606566754579543, irr5:457.2705383300781, ndcg5:0.852895812110755 
train 18, step: 0, loss: 1.0669060529393817, grad_norm: 0.2145075100829911, ic: 0.016813849100397883
train 18, step: 500, loss: 0.7975711385251976, grad_norm: 0.10107576248851338, ic: -0.020947847287255794
train 18, step: 1000, loss: 1.1602262160017058, grad_norm: 0.9390523069850732, ic: 0.06501861053587833
train 18, step: 1500, loss: 0.9473203263192808, grad_norm: 0.1414905130018194, ic: 0.08804429459583861
train 18, step: 2000, loss: 1.7406976508434255, grad_norm: 0.8859902493885825, ic: 0.4830223295628175
Epoch 18: train loss: 1.6249465620219798
Eval step 0: eval loss: 0.9966484339002435
Eval: total loss: 1.0806785646917156, mse:4.695818497417797, ic :0.16275836510052105, sharpe5:15.068951323628426, irr5:490.29473876953125, ndcg5:0.8571573939844456 
train 19, step: 0, loss: 1.0789953147910558, grad_norm: 0.8887077872531867, ic: 0.07476620288109732
train 19, step: 500, loss: 2.2927526012006454, grad_norm: 0.8619376339457667, ic: 0.19733403487823728
train 19, step: 1000, loss: 1.3075171146296, grad_norm: 0.0783116799322083, ic: 0.5560716989341163
train 19, step: 1500, loss: 1.5194021554237946, grad_norm: 0.526014214835185, ic: 0.4520913320505199
train 19, step: 2000, loss: 1.1586600751796934, grad_norm: 0.34978686361868183, ic: 0.20830190947945754
Epoch 19: train loss: 1.6256920991902002
Eval step 0: eval loss: 1.0141944824990126
Eval: total loss: 1.0875488232291124, mse:4.70258791392458, ic :0.15038078778495598, sharpe5:12.554001604914665, irr5:400.6267395019531, ndcg5:0.8484102494734791 

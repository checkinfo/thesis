Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path='./data/ann_type_2431_1931_25.npz', batch_size=1, dataset_type='AdjAnnTimeDataset', dout=0.3, epochs=40, gnn_layers=2, gpu=0, hidden_dim=128, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=3, mask_adj=True, mask_type='soft', model_type='GNNModel', normalize_adj=False, num_days=1, num_heads=1, print_inteval=500, relation_num=1, seed=10086, shuffle=True, side_info=True, sparse_adj_path='./data/icgraph_window_250_0.8/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=False)
39619
GNNModel(
  (fc1): Linear(in_features=9, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
  (fc4): Linear(in_features=128, out_features=1, bias=True)
  (gnns): ModuleList(
    (0): GraphConv(128, 128)
    (1): GraphConv(128, 128)
  )
  (dropout): Dropout(p=0.3, inplace=False)
  (relu): LeakyReLU(negative_slope=0.01)
  (type_embed): Embedding(89, 128)
  (fuse_type): Linear(in_features=256, out_features=128, bias=True)
)
train 0, step: 0, loss: 2.111610285943676, grad_norm: 2.047599873348743, ic: 0.02462729502575797
train 0, step: 500, loss: 1.3672367353345338, grad_norm: 1.1378678693975457, ic: 0.011215807295870472
train 0, step: 1000, loss: 1.5104033474836334, grad_norm: 0.03556492859547065, ic: 0.02342324538572772
train 0, step: 1500, loss: 1.1834555412603287, grad_norm: 0.10895732855514827, ic: 0.011118486988421925
train 0, step: 2000, loss: 1.5539921086008956, grad_norm: 0.04420578352878246, ic: -0.01496439794611001
Epoch 0: 2022-04-04 02:02:45.800063: train loss: 1.6504000671406074
Eval step 0: eval loss: 1.013477231026198
Eval: 2022-04-04 02:02:48.105200: total loss: 1.091444606427155, mse:4.888883668483543, ic :0.0005636393641405635, sharpe5:2.5830194789171217, irr5:47.682273864746094, ndcg5:0.8616857531066225, pnl5:1.599961280822754 
train 1, step: 0, loss: 0.6418938211875387, grad_norm: 0.051572571322090935, ic: -0.004311783342340543
train 1, step: 500, loss: 1.2715503518766758, grad_norm: 0.29837798384085124, ic: 0.013777559629791613
train 1, step: 1000, loss: 0.8814677674927365, grad_norm: 0.09291237264776388, ic: 0.010976137568813216
train 1, step: 1500, loss: 1.839384683748571, grad_norm: 0.5280753976901575, ic: -0.024316758227484726
train 1, step: 2000, loss: 1.3836431576318435, grad_norm: 0.2257497744850117, ic: 0.005406885206477497
Epoch 1: 2022-04-04 02:03:12.973639: train loss: 1.6474308888502727
Eval step 0: eval loss: 1.013164566465903
Eval: 2022-04-04 02:03:15.401664: total loss: 1.090765264812038, mse:4.8882805126973325, ic :0.0004129438439937633, sharpe5:-0.1540446821786463, irr5:-4.502561569213867, ndcg5:0.8491717054220512, pnl5:1.2553082704544067 
train 2, step: 0, loss: 1.322192184324187, grad_norm: 0.4877252867651746, ic: -0.03039570964314697
train 2, step: 500, loss: 0.9424070783739568, grad_norm: 0.2576350481846201, ic: 0.03397186721980597
train 2, step: 1000, loss: 3.142052120171382, grad_norm: 11.376905683727438, ic: 0.01951940607048015
train 2, step: 1500, loss: 2.2881064600267647, grad_norm: 0.8497654156533837, ic: 0.04925952629684001
train 2, step: 2000, loss: 1.4669005798689188, grad_norm: 0.2814052179402938, ic: 0.0034367819411023157
Epoch 2: 2022-04-04 02:03:40.379701: train loss: 1.646907309532278
Eval step 0: eval loss: 1.0135242849855186
Eval: 2022-04-04 02:03:42.728774: total loss: 1.0916187010079614, mse:4.889098656929376, ic :0.0075257323951433966, sharpe5:6.944432269334793, irr5:195.88230895996094, ndcg5:0.8507055521747051, pnl5:2.8184049129486084 
train 3, step: 0, loss: 1.8173118305279266, grad_norm: 0.053887512763395796, ic: 0.013473617403367139
train 3, step: 500, loss: 0.7869872257286951, grad_norm: 0.024543877966659636, ic: -0.014631611398361388
train 3, step: 1000, loss: 1.4302605987502377, grad_norm: 0.47366690571254905, ic: 0.11838704532541061
train 3, step: 1500, loss: 2.628574309382251, grad_norm: 0.57221401705306, ic: -0.06249371573484866
train 3, step: 2000, loss: 1.3612615411931819, grad_norm: 0.18151416642702503, ic: 0.0016763928348443764
Epoch 3: 2022-04-04 02:04:07.402044: train loss: 1.6475408215680518
Eval step 0: eval loss: 1.015188272404884
Eval: 2022-04-04 02:04:09.750468: total loss: 1.0937493409481553, mse:4.8936191129104385, ic :-0.02145175092294502, sharpe5:-5.736214599609375, irr5:-159.01742553710938, ndcg5:0.8587998587029919, pnl5:0.6615784764289856 
train 4, step: 0, loss: 1.1561035899448249, grad_norm: 0.34527480979148295, ic: -0.034965130459741
train 4, step: 500, loss: 0.9985701844658319, grad_norm: 0.0027533956390936786, ic: 0.06644503919274272
train 4, step: 1000, loss: 1.335960498754529, grad_norm: 0.06150611841977957, ic: 0.06794203119712615
train 4, step: 1500, loss: 1.0935391939603365, grad_norm: 0.07258507501306073, ic: -0.0014967872984276692
train 4, step: 2000, loss: 4.169520416379819, grad_norm: 0.8671101958718421, ic: -0.06967075317520546
Epoch 4: 2022-04-04 02:04:34.388327: train loss: 1.6465107694750325
Eval step 0: eval loss: 1.0139871108149026
Eval: 2022-04-04 02:04:36.700187: total loss: 1.0923521270728807, mse:4.890143586169839, ic :0.024570583385186397, sharpe5:6.64742578446865, irr5:190.04014587402344, ndcg5:0.8443868635528315, pnl5:2.5120413303375244 
train 5, step: 0, loss: 0.9666513761126714, grad_norm: 0.14143329144396824, ic: 0.03068602511833523
train 5, step: 500, loss: 0.7966216992804601, grad_norm: 0.0015521263274927927, ic: 0.0012994849507955396
train 5, step: 1000, loss: 1.1115104187282299, grad_norm: 0.0293049446182478, ic: 0.02911149263568687
train 5, step: 1500, loss: 1.734351975355691, grad_norm: 0.2991704670905874, ic: 0.015361099973363152
train 5, step: 2000, loss: 2.1621519018852893, grad_norm: 1.1982673314188181, ic: 0.007892422215052949
Epoch 5: 2022-04-04 02:05:01.266015: train loss: 1.6474403205668027
Eval step 0: eval loss: 1.0103266727553974
Eval: 2022-04-04 02:05:03.334145: total loss: 1.0916117833977232, mse:4.883959257225445, ic :0.048890838998099366, sharpe5:1.4661772871017456, irr5:15.772680282592773, ndcg5:0.8435029255232581, pnl5:1.0872036218643188 
train 6, step: 0, loss: 0.7767331477797741, grad_norm: 0.01178376355762042, ic: -0.049076928800814566
train 6, step: 500, loss: 1.4436729386536, grad_norm: 0.2479324668864794, ic: 0.08658539193159318
train 6, step: 1000, loss: 1.24131912974913, grad_norm: 0.17719298636747846, ic: 0.11657612614687074
train 6, step: 1500, loss: 1.07451862839033, grad_norm: 0.32263093704491136, ic: 0.044762137644210644
train 6, step: 2000, loss: 2.273519013400164, grad_norm: 1.0857539462300558, ic: 0.1047575367810229
Epoch 6: 2022-04-04 02:05:26.652457: train loss: 1.6456290130706803
Eval step 0: eval loss: 1.0004966378274749
Eval: 2022-04-04 02:05:28.767541: total loss: 1.0893439606275186, mse:4.880304293658826, ic :0.047002844747101584, sharpe5:5.3748742881417275, irr5:123.9164810180664, ndcg5:0.8404288043948008, pnl5:2.5570807456970215 
train 7, step: 0, loss: 1.4507791182943781, grad_norm: 0.6944308906818125, ic: 0.16327767587237868
train 7, step: 500, loss: 1.3245278748208436, grad_norm: 0.028060259889971524, ic: 0.10147047051061506
train 7, step: 1000, loss: 0.648060762832493, grad_norm: 0.05944722907810797, ic: 0.26618157336216963
train 7, step: 1500, loss: 1.0016052761356005, grad_norm: 0.1289262622657524, ic: 0.06682442061128174
train 7, step: 2000, loss: 1.8195870425168383, grad_norm: 14.575177202211398, ic: 0.09302238585057344
Epoch 7: 2022-04-04 02:05:51.340671: train loss: 1.6462537650001874
Eval step 0: eval loss: 0.9986160222074117
Eval: 2022-04-04 02:05:53.469954: total loss: 1.0891669414589888, mse:4.795848526902277, ic :0.11128286394258372, sharpe5:6.785125136375427, irr5:204.5828399658203, ndcg5:0.8487129527257345, pnl5:2.941877603530884 
train 8, step: 0, loss: 1.214753113275079, grad_norm: 0.10212837150827127, ic: 0.02061452159546227
train 8, step: 500, loss: 5.535135203394396, grad_norm: 1.7911748001583474, ic: 0.12261796371618768
train 8, step: 1000, loss: 1.8852903451492538, grad_norm: 0.6104984785375889, ic: 0.0312101041202803
train 8, step: 1500, loss: 1.0695653872809399, grad_norm: 0.40291415504819716, ic: 0.6418177651394092
train 8, step: 2000, loss: 1.1348609924316406, grad_norm: 0.9011986149307986, ic: -0.003243883173299652
Epoch 8: 2022-04-04 02:06:16.863004: train loss: 1.6426784140714767
Eval step 0: eval loss: 1.002093965471136
Eval: 2022-04-04 02:06:19.243986: total loss: 1.0906221558161482, mse:4.7363286342801425, ic :0.12161917967941474, sharpe5:8.043522273302077, irr5:223.28843688964844, ndcg5:0.8416215368998854, pnl5:3.134200096130371 
train 9, step: 0, loss: 1.1081268027775304, grad_norm: 0.05659692650585609, ic: 0.4593548014483403
train 9, step: 500, loss: 3.153599383442732, grad_norm: 4.265950893353963, ic: 0.11748860941578226
train 9, step: 1000, loss: 0.8709930921777115, grad_norm: 0.1477643963670494, ic: 0.24878903383585446
train 9, step: 1500, loss: 2.1258064158731766, grad_norm: 1.5917316343289423, ic: -0.05219235957015972
train 9, step: 2000, loss: 0.6057503953118853, grad_norm: 0.007464728789528233, ic: 0.07893987120878382
Epoch 9: 2022-04-04 02:06:43.950805: train loss: 1.6384618779299487
Eval step 0: eval loss: 0.9957792212801144
Eval: 2022-04-04 02:06:46.358962: total loss: 1.0902711062265966, mse:4.774804489338989, ic :0.11311625285121174, sharpe5:7.698442897796631, irr5:220.14834594726562, ndcg5:0.8367328083306759, pnl5:2.841223955154419 
train 10, step: 0, loss: 1.291171259760411, grad_norm: 0.2925335649307015, ic: 0.40385832056462667
train 10, step: 500, loss: 0.8984466622145091, grad_norm: 0.010346124053576737, ic: 0.08472812477026789
train 10, step: 1000, loss: 1.5391952425712947, grad_norm: 0.6193033973850266, ic: 0.06661174189677696
train 10, step: 1500, loss: 3.0671503890883165, grad_norm: 1.7564793427991194, ic: 0.05558523695874547
train 10, step: 2000, loss: 1.3853025117543694, grad_norm: 0.22413137037302575, ic: 0.015615179421123672
Epoch 10: 2022-04-04 02:07:11.248569: train loss: 1.6369406023891342
Eval step 0: eval loss: 1.0054529882092549
Eval: 2022-04-04 02:07:13.585421: total loss: 1.0881461328934936, mse:4.7217496996865105, ic :0.12303328712269401, sharpe5:7.848849342763423, irr5:217.8521728515625, ndcg5:0.8502660002564922, pnl5:3.906546115875244 
train 11, step: 0, loss: 4.848498048402072, grad_norm: 1.1846138159766537, ic: 0.3607001145977293
train 11, step: 500, loss: 0.9912217194400441, grad_norm: 0.06873468314805989, ic: 0.04061710888517327
train 11, step: 1000, loss: 1.0395041319543765, grad_norm: 0.5963855523827898, ic: 0.036506207643099274
train 11, step: 1500, loss: 0.6929624791992952, grad_norm: 0.0038178874796985576, ic: 0.08328718281242659
train 11, step: 2000, loss: 1.1206898569189174, grad_norm: 0.10196195974708337, ic: -0.17854733578820867
Epoch 11: 2022-04-04 02:07:38.244317: train loss: 1.634252210341033
Eval step 0: eval loss: 0.9969094805242891
Eval: 2022-04-04 02:07:40.551557: total loss: 1.0859571633925071, mse:4.73171678068988, ic :0.12384747360307347, sharpe5:9.641894570589065, irr5:293.6927185058594, ndcg5:0.8639541510365701, pnl5:3.611135482788086 
train 12, step: 0, loss: 1.3841429271625474, grad_norm: 0.4399319235971734, ic: 0.05262368760493224
train 12, step: 500, loss: 0.8086387435563832, grad_norm: 0.43886592808029623, ic: 0.0014477191398931718
train 12, step: 1000, loss: 1.183975340508534, grad_norm: 0.7351365800551369, ic: 0.6245296262130213
train 12, step: 1500, loss: 1.0807215139406536, grad_norm: 0.26485466666076035, ic: 0.10708827861462868
train 12, step: 2000, loss: 1.1183315852696498, grad_norm: 0.08077640368134502, ic: 0.07342776168738016
Epoch 12: 2022-04-04 02:08:05.371222: train loss: 1.6327826981386353
Eval step 0: eval loss: 1.0070258246527777
Eval: 2022-04-04 02:08:07.724040: total loss: 1.085675365917023, mse:4.697944872259847, ic :0.15154202249989301, sharpe5:13.935070171952248, irr5:445.1138610839844, ndcg5:0.8263826296956619, pnl5:4.221358776092529 
train 13, step: 0, loss: 1.079565692870165, grad_norm: 0.1520633900527856, ic: 0.4410733330062624
train 13, step: 500, loss: 1.1467438908933683, grad_norm: 0.021432893324408054, ic: -0.15787560356763936
train 13, step: 1000, loss: 1.3835037195429287, grad_norm: 0.5106078459790994, ic: 0.056200719064812665
train 13, step: 1500, loss: 0.7766036174431602, grad_norm: 0.022187910893771902, ic: -0.022762819239673403
train 13, step: 2000, loss: 1.0364493327572966, grad_norm: 0.03207416707043339, ic: 0.13397225123180392
Epoch 13: 2022-04-04 02:08:32.199228: train loss: 1.631756294044785
Eval step 0: eval loss: 0.999210110584518
Eval: 2022-04-04 02:08:34.491785: total loss: 1.0889043126974682, mse:4.749971524403808, ic :0.11507603399860242, sharpe5:7.950470615029334, irr5:223.5452117919922, ndcg5:0.8484442142140328, pnl5:3.142861843109131 
train 14, step: 0, loss: 1.7594489404710674, grad_norm: 1.2646059680843824, ic: 0.1425393571174376
train 14, step: 500, loss: 1.2594701807609294, grad_norm: 0.36550669155282495, ic: 0.23594886486692843
train 14, step: 1000, loss: 1.06573294647469, grad_norm: 0.14915707251806834, ic: 0.14685857016188683
train 14, step: 1500, loss: 0.9773826922151655, grad_norm: 0.09421694162119199, ic: 0.1976057486132802
train 14, step: 2000, loss: 2.29341640752447, grad_norm: 0.5849130482022451, ic: -0.045409597832737084
Epoch 14: 2022-04-04 02:08:59.072186: train loss: 1.6298384639497632
Eval step 0: eval loss: 1.0073566165580567
Eval: 2022-04-04 02:09:01.428143: total loss: 1.0871235315361558, mse:4.70323163494578, ic :0.1609622764841717, sharpe5:14.456060514450073, irr5:483.1913146972656, ndcg5:0.8616972613870062, pnl5:5.087167739868164 
train 15, step: 0, loss: 0.9754934836080906, grad_norm: 0.2008644710937368, ic: 0.16131776412590615
train 15, step: 500, loss: 1.2175488803475936, grad_norm: 0.023717806865844678, ic: 0.14161676220613673
train 15, step: 1000, loss: 1.7662584635416667, grad_norm: 0.467767148222653, ic: 0.08723441343409646
train 15, step: 1500, loss: 5.417545610680104, grad_norm: 1.1961792085222278, ic: 0.0399941611184496
train 15, step: 2000, loss: 0.9298704026941444, grad_norm: 0.03102303966787907, ic: 0.042780650331923686
Epoch 15: 2022-04-04 02:09:26.715976: train loss: 1.6293380001040048
Eval step 0: eval loss: 1.0105377727586886
Eval: 2022-04-04 02:09:29.190344: total loss: 1.0855694487952894, mse:4.699881388436821, ic :0.16521492268573673, sharpe5:15.479186062216758, irr5:515.268798828125, ndcg5:0.8639662664186529, pnl5:6.458956241607666 
train 16, step: 0, loss: 6.355551270738871, grad_norm: 4.3431630047961045, ic: 0.15870996328188108
train 16, step: 500, loss: 1.3693868970114087, grad_norm: 1.5010702417700506, ic: -0.017279951745156716
train 16, step: 1000, loss: 0.8287830583324939, grad_norm: 0.33109975883581627, ic: 0.004396170538137047
train 16, step: 1500, loss: 1.231674509551932, grad_norm: 0.45708721559842475, ic: 0.08078605026578346
train 16, step: 2000, loss: 0.9654969710514303, grad_norm: 0.4466073619701037, ic: 0.5417969191643829
Epoch 16: 2022-04-04 02:09:54.892186: train loss: 1.6272066683554849
Eval step 0: eval loss: 0.9998628235666798
Eval: 2022-04-04 02:09:57.191174: total loss: 1.0831264375544973, mse:4.72111901595028, ic :0.15048146274708762, sharpe5:13.299675790071486, irr5:418.6759033203125, ndcg5:0.8368731455775146, pnl5:4.698042392730713 
train 17, step: 0, loss: 1.1840614365653759, grad_norm: 0.03422485044747454, ic: 0.13257638930617963
train 17, step: 500, loss: 1.0389046847917516, grad_norm: 0.0644829313595568, ic: -0.023485789953560106
train 17, step: 1000, loss: 3.3704205503558167, grad_norm: 1.3246818498397754, ic: -0.013584819734586914
train 17, step: 1500, loss: 0.8885650140953681, grad_norm: 0.004054492900810291, ic: 0.006076077304900687
train 17, step: 2000, loss: 0.9738087903733221, grad_norm: 0.8023303021714457, ic: 0.5860078221568633
Epoch 17: 2022-04-04 02:10:23.100741: train loss: 1.6298100491692435
Eval step 0: eval loss: 1.0026468494931542
Eval: 2022-04-04 02:10:25.445068: total loss: 1.0885287211500743, mse:4.708054432792852, ic :0.14300023869226794, sharpe5:13.375843620300293, irr5:407.39862060546875, ndcg5:0.8547776059131312, pnl5:6.396700382232666 
train 18, step: 0, loss: 0.8563918639108861, grad_norm: 0.026640324950241566, ic: 0.05196741681423283
train 18, step: 500, loss: 2.5084239549096137, grad_norm: 1.1197926558752032, ic: 0.09517971786986733
train 18, step: 1000, loss: 1.3574784313174462, grad_norm: 0.3937500933227263, ic: 0.5360158281934687
train 18, step: 1500, loss: 1.7616586857104986, grad_norm: 0.9125027262084827, ic: 0.32993885848036164
train 18, step: 2000, loss: 1.2646498479022241, grad_norm: 0.6960089122867524, ic: 0.2011885441266451
Epoch 18: 2022-04-04 02:10:50.531460: train loss: 1.6286922101187546
Eval step 0: eval loss: 1.0018097775556214
Eval: 2022-04-04 02:10:52.833786: total loss: 1.0864595075646162, mse:4.711890790128947, ic :0.13207394631780894, sharpe5:12.61315317749977, irr5:377.7239074707031, ndcg5:0.8400722648421621, pnl5:5.134739875793457 
train 19, step: 0, loss: 2.211222175066947, grad_norm: 1.0217805648743927, ic: 0.2025180159450067
train 19, step: 500, loss: 1.0172579033430234, grad_norm: 0.12006180870131265, ic: 0.03823375075097524
train 19, step: 1000, loss: 0.9826826725496456, grad_norm: 0.3375843822607427, ic: 0.5530177711417634
train 19, step: 1500, loss: 1.5874128930362654, grad_norm: 0.20340965844390854, ic: 0.1357175017247282
train 19, step: 2000, loss: 1.8385620589230474, grad_norm: 1.335330228180657, ic: 0.6473564576872048
Epoch 19: 2022-04-04 02:11:17.587393: train loss: 1.6273064997961977
Eval step 0: eval loss: 1.0036097843437335
Eval: 2022-04-04 02:11:19.926054: total loss: 1.0832088803586601, mse:4.6900231353093975, ic :0.15490344903025424, sharpe5:14.147529816627502, irr5:453.7353210449219, ndcg5:0.8394525717308755, pnl5:6.250491619110107 
train 20, step: 0, loss: 1.229497666965399, grad_norm: 0.4523811281766176, ic: 0.47829235071182463
train 20, step: 500, loss: 1.2302345476114755, grad_norm: 0.5150362026923752, ic: 0.01833763999573962
train 20, step: 1000, loss: 1.564720400178666, grad_norm: 0.4393930114399034, ic: 0.15318327488285013
train 20, step: 1500, loss: 0.8453910666918371, grad_norm: 1.18076329283541, ic: 0.594983828897101
train 20, step: 2000, loss: 1.3274553402258487, grad_norm: 0.4208507938605393, ic: -0.014264729136434152
Epoch 20: 2022-04-04 02:11:44.890108: train loss: 1.6264206141597157
Eval step 0: eval loss: 1.0015527806575828
Eval: 2022-04-04 02:11:47.490166: total loss: 1.1007831941528516, mse:4.802749275293362, ic :0.14452666202346387, sharpe5:14.752188234329223, irr5:502.1756591796875, ndcg5:0.8355072838511143, pnl5:6.28714656829834 
train 21, step: 0, loss: 1.3537001184402333, grad_norm: 0.8887496514776676, ic: 0.24598359513279802
train 21, step: 500, loss: 1.1174787128801644, grad_norm: 0.21251661931632254, ic: 0.09329091954560018
train 21, step: 1000, loss: 0.9168493542009039, grad_norm: 0.20149298991916015, ic: 0.10365375537891224
train 21, step: 1500, loss: 0.7257211132680622, grad_norm: 0.19370953740551877, ic: 0.6345611815112411
train 21, step: 2000, loss: 1.1251022630150973, grad_norm: 0.20013205306288773, ic: 0.29059240705664735
Epoch 21: 2022-04-04 02:12:12.437949: train loss: 1.6265015626457449
Eval step 0: eval loss: 1.0012362592153765
Eval: 2022-04-04 02:12:14.786726: total loss: 1.0841924625593569, mse:4.702722185831913, ic :0.1469769898665315, sharpe5:11.73081448316574, irr5:360.5069885253906, ndcg5:0.8533263531873946, pnl5:4.249271869659424 
train 22, step: 0, loss: 1.0563690087419615, grad_norm: 0.28905772821229897, ic: 0.07464895785566215
train 22, step: 500, loss: 1.029989215520423, grad_norm: 0.008190486341879586, ic: 0.0030525979884945403
train 22, step: 1000, loss: 0.9161529190775631, grad_norm: 0.017575671066617973, ic: 0.12740916530452318
train 22, step: 1500, loss: 1.0028608565761292, grad_norm: 0.03771756810576547, ic: 0.26491651870197674
train 22, step: 2000, loss: 1.054423345521439, grad_norm: 0.22075444734828, ic: 0.10853982678529127
Epoch 22: 2022-04-04 02:12:39.456007: train loss: 1.6265570170433814
Eval step 0: eval loss: 1.0078664320653963
Eval: 2022-04-04 02:12:41.901399: total loss: 1.0865425671087612, mse:4.702037360301059, ic :0.1466362681399597, sharpe5:12.061130796074867, irr5:359.929931640625, ndcg5:0.8550573140664252, pnl5:4.127066135406494 
train 23, step: 0, loss: 1.2829202744799844, grad_norm: 1.2194666709627044, ic: -0.032076172946472026
train 23, step: 500, loss: 0.9279236007522751, grad_norm: 0.39612548103438217, ic: 0.5834797932213045
train 23, step: 1000, loss: 2.266745106354002, grad_norm: 1.3965214197428175, ic: 0.11669522682407776
train 23, step: 1500, loss: 0.756214749408453, grad_norm: 0.5039788682375707, ic: 0.7168786589704008
train 23, step: 2000, loss: 1.4978913114725056, grad_norm: 0.3500788931824184, ic: 0.3897927958657235
Epoch 23: 2022-04-04 02:13:06.606357: train loss: 1.62547179170915
Eval step 0: eval loss: 1.0023276282336098
Eval: 2022-04-04 02:13:09.002043: total loss: 1.090918602386205, mse:4.725637404361534, ic :0.13088019203486848, sharpe5:10.224846830964088, irr5:300.4546203613281, ndcg5:0.8540872748201476, pnl5:3.6352486610412598 
train 24, step: 0, loss: 1.1920643433474825, grad_norm: 0.17002217551319182, ic: 0.2013827012711662
train 24, step: 500, loss: 1.2651524547399409, grad_norm: 0.4871050308805464, ic: 0.014519921344126135
train 24, step: 1000, loss: 1.0618211699695121, grad_norm: 0.43502515104240524, ic: 0.12362411586681868
train 24, step: 1500, loss: 1.1934469388225886, grad_norm: 0.13718699057721542, ic: 0.10424739884119483
train 24, step: 2000, loss: 1.3485678883211558, grad_norm: 0.47688496291267213, ic: 0.4503076111740911
Epoch 24: 2022-04-04 02:13:33.761412: train loss: 1.6279310838086893
Eval step 0: eval loss: 1.0129579661581753
Eval: 2022-04-04 02:13:36.148765: total loss: 1.0848254056357443, mse:4.690834259460673, ic :0.16207078153731092, sharpe5:15.110060309171676, irr5:494.1344299316406, ndcg5:0.849071582797334, pnl5:5.502438068389893 
train 25, step: 0, loss: 1.2874595789980046, grad_norm: 1.2163459828812377, ic: 0.22835400471296943
train 25, step: 500, loss: 1.4471040205522019, grad_norm: 0.9711055713988973, ic: 0.12153746184785078
train 25, step: 1000, loss: 1.3823375559319293, grad_norm: 0.3580868600405298, ic: 0.26397591640970874
train 25, step: 1500, loss: 2.8593462775735294, grad_norm: 2.418534323435154, ic: 0.2477576433297285
train 25, step: 2000, loss: 1.1959855284871934, grad_norm: 0.17135866208321432, ic: 0.1304693370385748
Epoch 25: 2022-04-04 02:14:01.454132: train loss: 1.6259851242771592
Eval step 0: eval loss: 1.0052449737114928
Eval: 2022-04-04 02:14:03.768314: total loss: 1.083496034022408, mse:4.68420449331115, ic :0.16508036547614313, sharpe5:14.557040922045706, irr5:471.4685363769531, ndcg5:0.8646874250054372, pnl5:5.915917873382568 
train 26, step: 0, loss: 1.6255699573863636, grad_norm: 0.32729403595317963, ic: 0.19043558597290905
train 26, step: 500, loss: 1.0382401051830834, grad_norm: 0.25041233437326765, ic: -0.02861000477678822
train 26, step: 1000, loss: 1.8478969348459617, grad_norm: 0.6971896253953119, ic: 0.11844357720784082
train 26, step: 1500, loss: 0.9248209463365487, grad_norm: 0.01964940110229262, ic: -0.028158058863570132
train 26, step: 2000, loss: 0.9947152205339567, grad_norm: 0.09943232817624893, ic: 0.120658078351384
Epoch 26: 2022-04-04 02:14:28.449651: train loss: 1.628663337298102
Eval step 0: eval loss: 0.9956903201520536
Eval: 2022-04-04 02:14:30.757202: total loss: 1.0861963799330008, mse:4.717651950053482, ic :0.12990892338328555, sharpe5:8.131677820086479, irr5:230.6169891357422, ndcg5:0.8478684572607819, pnl5:3.624330759048462 
train 27, step: 0, loss: 1.6818832948983435, grad_norm: 0.6572465262331507, ic: 0.6832674576332798
train 27, step: 500, loss: 1.5183283923017108, grad_norm: 1.1554879205813882, ic: 0.07183211045955762
train 27, step: 1000, loss: 2.5640828355672105, grad_norm: 1.0677842084718128, ic: 0.3997159574582659
train 27, step: 1500, loss: 0.8386391421972588, grad_norm: 0.5668846997891355, ic: 0.5470220342721939
train 27, step: 2000, loss: 1.3934806202596965, grad_norm: 1.3035528737587925, ic: -0.03280971912722622
Epoch 27: 2022-04-04 02:14:55.094371: train loss: 1.626806859524332
Eval step 0: eval loss: 1.0010366012950895
Eval: 2022-04-04 02:14:57.587288: total loss: 1.0814632604690695, mse:4.689302051713566, ic :0.16154539212363161, sharpe5:13.994230257868766, irr5:450.2828674316406, ndcg5:0.8523472999784208, pnl5:4.630012512207031 
train 28, step: 0, loss: 1.1470465186561778, grad_norm: 0.18550305396779476, ic: 0.08946069864388559
train 28, step: 500, loss: 2.913446718621293, grad_norm: 1.1995785717678566, ic: 0.14339003186940064
train 28, step: 1000, loss: 2.83341413500938, grad_norm: 4.718790232083782, ic: -0.056068837794914735
train 28, step: 1500, loss: 1.0276238096951773, grad_norm: 0.01479196056256154, ic: 0.19436643051376828
train 28, step: 2000, loss: 1.7785433392192043, grad_norm: 0.40688846029631015, ic: 0.10577359205560592
Epoch 28: 2022-04-04 02:15:22.110068: train loss: 1.6253969868931752
Eval step 0: eval loss: 1.0083995817083002
Eval: 2022-04-04 02:15:24.402704: total loss: 1.0837382547283296, mse:4.684072852374275, ic :0.16189850695366004, sharpe5:14.505102978944779, irr5:477.2442626953125, ndcg5:0.8415237871473079, pnl5:5.835522651672363 
train 29, step: 0, loss: 1.5125325212341263, grad_norm: 0.2049201344913005, ic: 0.06258381497318984
train 29, step: 500, loss: 2.5501723061676276, grad_norm: 1.2602205232956105, ic: 0.010271270579851513
train 29, step: 1000, loss: 1.7156783899221453, grad_norm: 1.2317245244347699, ic: 0.4904202967067922
train 29, step: 1500, loss: 3.949843582259796, grad_norm: 1.844373247676583, ic: 0.141199735369614
train 29, step: 2000, loss: 0.954580608808937, grad_norm: 0.2361869311169775, ic: 0.4616833149642824
Epoch 29: 2022-04-04 02:15:49.621567: train loss: 1.6250885297023077
Eval step 0: eval loss: 1.0023964735757305
Eval: 2022-04-04 02:15:52.248936: total loss: 1.082975022698849, mse:4.690300673781569, ic :0.16067773060794804, sharpe5:13.591774812340736, irr5:440.6549072265625, ndcg5:0.8450080964749316, pnl5:6.14370584487915 
train 30, step: 0, loss: 1.2634691329366956, grad_norm: 0.07198316309712531, ic: 0.9769867851445766
train 30, step: 500, loss: 1.9035812571078916, grad_norm: 0.3551433285812605, ic: 0.15483076156315734
train 30, step: 1000, loss: 3.464395809236616, grad_norm: 1.00052232493953, ic: 0.401663224076939
train 30, step: 1500, loss: 1.091404872580239, grad_norm: 0.3930855827250384, ic: 0.13229137262120824
train 30, step: 2000, loss: 1.0901552643213972, grad_norm: 0.20872250088151814, ic: 0.4457768832277261
Epoch 30: 2022-04-04 02:16:17.203126: train loss: 1.6245908176931771
Eval step 0: eval loss: 1.0059966799960505
Eval: 2022-04-04 02:16:19.603286: total loss: 1.0827427562676812, mse:4.681756781747596, ic :0.1683828041765609, sharpe5:14.783356486558914, irr5:484.18701171875, ndcg5:0.8325175933443076, pnl5:5.950179576873779 
train 31, step: 0, loss: 1.16310520141405, grad_norm: 0.5801580119062907, ic: 0.19007414554712
train 31, step: 500, loss: 0.8187312258344753, grad_norm: 0.21306084547749832, ic: 0.24733175103949828
train 31, step: 1000, loss: 5.068104024805447, grad_norm: 0.662909707561516, ic: -0.004853944098527421
train 31, step: 1500, loss: 1.7030787755385433, grad_norm: 0.43798664117930514, ic: 0.2662249282832655
train 31, step: 2000, loss: 0.9497972978029214, grad_norm: 1.354730944041992, ic: 0.16496459098499622
Epoch 31: 2022-04-04 02:16:44.246942: train loss: 1.6226750806188228
Eval step 0: eval loss: 1.010581355524289
Eval: 2022-04-04 02:16:46.544964: total loss: 1.0871502408901905, mse:4.70046763318953, ic :0.16456304498608096, sharpe5:14.516751108169554, irr5:473.0675354003906, ndcg5:0.8508268419051629, pnl5:5.499478816986084 
train 32, step: 0, loss: 0.8666695109635614, grad_norm: 0.4436521744364459, ic: 0.1143300354594839
train 32, step: 500, loss: 1.117221739233994, grad_norm: 0.68827198644356, ic: 0.19857592793204568
train 32, step: 1000, loss: 1.387873627702883, grad_norm: 0.2688478682806183, ic: 0.08173563742317647
train 32, step: 1500, loss: 2.0681736240446016, grad_norm: 0.3655884033762732, ic: 0.4356471503730783
train 32, step: 2000, loss: 1.0922202237111893, grad_norm: 0.9662292306198371, ic: 0.44788223133831834
Epoch 32: 2022-04-04 02:17:11.563133: train loss: 1.6218457532984498
Eval step 0: eval loss: 1.0102306363958002
Eval: 2022-04-04 02:17:13.844237: total loss: 1.0842803408473947, mse:4.687847760854452, ic :0.16687581391325837, sharpe5:15.80033919274807, irr5:515.0223999023438, ndcg5:0.8432499943584462, pnl5:6.554062843322754 
train 33, step: 0, loss: 1.1664168996789057, grad_norm: 0.026978306195535155, ic: 0.018671177664424547
train 33, step: 500, loss: 3.164680263979631, grad_norm: 0.536898668686709, ic: 0.5223445637969097
train 33, step: 1000, loss: 5.2343266341951935, grad_norm: 2.2835838849547776, ic: 0.018581333710596427
train 33, step: 1500, loss: 1.2963899938071646, grad_norm: 1.30596670091251, ic: 0.06591025659626638
train 33, step: 2000, loss: 1.8609375, grad_norm: 0.5290775761383709, ic: 0.1056406846521477
Epoch 33: 2022-04-04 02:17:38.585515: train loss: 1.62574832287523
Eval step 0: eval loss: 1.0147032052231437
Eval: 2022-04-04 02:17:40.965928: total loss: 1.0881114062065829, mse:4.6934817615864866, ic :0.17018942785879723, sharpe5:14.640150901079178, irr5:482.10498046875, ndcg5:0.8499623898971133, pnl5:6.12415885925293 
train 34, step: 0, loss: 0.7425427807114204, grad_norm: 0.26923776384868037, ic: 0.16746219433123385
train 34, step: 500, loss: 1.780493657091436, grad_norm: 0.35987730830190007, ic: 0.8479343781201905
train 34, step: 1000, loss: 0.6851035072063577, grad_norm: 0.05369632346566602, ic: 0.4840483943128948
train 34, step: 1500, loss: 1.629834453876202, grad_norm: 1.3760086276052608, ic: 0.6415637212967302
train 34, step: 2000, loss: 2.966068073002471, grad_norm: 0.5975770942314047, ic: 0.12140346782281777
Epoch 34: 2022-04-04 02:18:05.448649: train loss: 1.622383350850224
Eval step 0: eval loss: 1.0080603046628158
Eval: 2022-04-04 02:18:07.772118: total loss: 1.0857213184100833, mse:4.689816964754066, ic :0.16427826204102597, sharpe5:13.804758499860762, irr5:441.95513916015625, ndcg5:0.8431256402718852, pnl5:4.621128559112549 
train 35, step: 0, loss: 1.069129847273042, grad_norm: 0.7221957729384729, ic: -0.01114462337023785
train 35, step: 500, loss: 3.306613251657197, grad_norm: 1.2077478235427588, ic: -0.0404924093233337
train 35, step: 1000, loss: 1.3374506552764989, grad_norm: 0.09281992266452485, ic: 0.5032841407894895
train 35, step: 1500, loss: 1.651937248861077, grad_norm: 0.4458150662508564, ic: 0.06462871805831144
train 35, step: 2000, loss: 1.2716627348561393, grad_norm: 0.07283197148495256, ic: 0.061192699269946624
Epoch 35: 2022-04-04 02:18:33.162886: train loss: 1.6212088734355234
Eval step 0: eval loss: 1.007432597131714
Eval: 2022-04-04 02:18:35.454374: total loss: 1.0885260525359806, mse:4.704738862805529, ic :0.1529872594600682, sharpe5:13.294825083017349, irr5:403.8789978027344, ndcg5:0.8427564731653756, pnl5:4.109678268432617 
train 36, step: 0, loss: 9.05494493636543, grad_norm: 1.6647028080103572, ic: -0.011822361239635995
train 36, step: 500, loss: 0.858648122575227, grad_norm: 0.008996830166823025, ic: 0.13723937200700084
train 36, step: 1000, loss: 1.9750319831639438, grad_norm: 3.2336534194309574, ic: 0.04770535997225622
train 36, step: 1500, loss: 1.0807809133518613, grad_norm: 0.5958846940994742, ic: 0.09575268382644717
train 36, step: 2000, loss: 2.159252685403178, grad_norm: 1.8950234231705603, ic: 0.35102151363018635
Epoch 36: 2022-04-04 02:19:00.667464: train loss: 1.6228393663821996
Eval step 0: eval loss: 1.0149536454219326
Eval: 2022-04-04 02:19:03.082847: total loss: 1.088975760861471, mse:4.706594646162156, ic :0.15709277892808768, sharpe5:13.25904733479023, irr5:424.3991394042969, ndcg5:0.8392617724178032, pnl5:4.532577037811279 
train 37, step: 0, loss: 1.195140930385524, grad_norm: 0.1883168008812292, ic: 0.1540855059677827
train 37, step: 500, loss: 2.342465881094398, grad_norm: 0.08645819852741947, ic: 0.14140180018615114
train 37, step: 1000, loss: 0.7420839046714045, grad_norm: 0.37552125935211134, ic: 0.15259027509709724
train 37, step: 1500, loss: 3.1108968512055837, grad_norm: 2.0701029916475844, ic: 0.21399619823390542
train 37, step: 2000, loss: 3.1846638842680606, grad_norm: 1.6259232223550224, ic: -0.015573809300520707
Epoch 37: 2022-04-04 02:19:28.138410: train loss: 1.6238224254761726
Eval step 0: eval loss: 1.0060401341989205
Eval: 2022-04-04 02:19:30.450034: total loss: 1.0832448773549137, mse:4.68385134435736, ic :0.16522000947680957, sharpe5:14.622569925785063, irr5:478.66619873046875, ndcg5:0.8497095478986615, pnl5:5.863236904144287 
train 38, step: 0, loss: 1.3625042539654355, grad_norm: 0.6145070037539208, ic: -0.246804866875219
train 38, step: 500, loss: 1.7244727319525193, grad_norm: 0.9050178330621067, ic: 0.18718879493681576
train 38, step: 1000, loss: 1.8452225150972115, grad_norm: 0.7827395648674684, ic: 0.1265986315970279
train 38, step: 1500, loss: 1.0605503454786, grad_norm: 0.27710822164890164, ic: 0.5035765617063845
train 38, step: 2000, loss: 0.7588084028581532, grad_norm: 0.5398386048373589, ic: 0.5682734808396759
Epoch 38: 2022-04-04 02:19:55.983085: train loss: 1.6213333164769874
Eval step 0: eval loss: 1.0026679337809372
Eval: 2022-04-04 02:19:58.288176: total loss: 1.083096042595829, mse:4.701621845925145, ic :0.15340602040409862, sharpe5:12.643331991434097, irr5:401.6098327636719, ndcg5:0.8554403593227208, pnl5:3.7855770587921143 
train 39, step: 0, loss: 0.8702874688363942, grad_norm: 0.05651601358998219, ic: 0.5403632763302921
train 39, step: 500, loss: 1.2371453206445469, grad_norm: 0.3937747769129347, ic: 0.057183638830696576
train 39, step: 1000, loss: 1.4043811220111269, grad_norm: 0.6022998623739805, ic: 0.07234034140667496
train 39, step: 1500, loss: 2.454299267740345, grad_norm: 0.5823407607451133, ic: -0.04738442797765577
train 39, step: 2000, loss: 2.914643095708311, grad_norm: 2.315730893443962, ic: 0.23615239641131827
Epoch 39: 2022-04-04 02:20:23.625345: train loss: 1.618954825092111
Eval step 0: eval loss: 1.0003012224772907
Eval: 2022-04-04 02:20:25.951104: total loss: 1.0809069150187782, mse:4.680949014097168, ic :0.1667704359853155, sharpe5:14.744455291628837, irr5:477.2949523925781, ndcg5:0.853694691660604, pnl5:5.32275390625 

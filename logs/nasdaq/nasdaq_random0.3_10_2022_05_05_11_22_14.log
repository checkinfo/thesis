Namespace(adj_path='./data/graphs/NASDAQ_random0.3_1026_1026.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='NASDAQAdjSeqTimeDataset', dout=0.3, epochs=40, glstm_layers=1, gnn_layers=1, gpu=0, graph_attn=True, hidden_dim=128, inner_prod=False, input_dim=5, input_graph=True, label_cnt=1, lr=0.0004, lstm_layers=1, market='NASDAQ', mask_adj=True, mask_type='soft', model_type='BiGLSTM', normalize_adj=True, num_days=8, num_heads=1, print_inteval=500, rank_loss=True, relation_num=1, rsr_data_path='../Temporal_Relational_Stock_Ranking/data/2013-01-01', seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_250_0.8/', stock_num=1026, test_mask_path='./data/NASDAQ/test_mask_237_1026.npy', test_path='./data/NASDAQ/test_237_1026_6.npy', top_stocks=5, train_mask_path='./data/NASDAQ/train_mask_756_1026.npy', train_path='./data/NASDAQ/train_756_1026_6.npy', use_adj=True)
#tickers selected: 1026
single EOD data shape: (1245, 6)
(1026, 1245, 5) (1026, 1245) (1026, 1245) (1026, 1245)
#tickers selected: 1026
single EOD data shape: (1245, 6)
(1026, 1245, 5) (1026, 1245) (1026, 1245) (1026, 1245)
7320
BiGLSTM(
  (input_to_hidden): Linear(in_features=5, out_features=128, bias=True)
  (forward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (attention): ModuleList(
            (0): GraphAttentionLayer (128 -> 128)
          )
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
          (lin_gate): Linear(in_features=128, out_features=128, bias=True)
        )
      )
    )
  )
  (backward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (attention): ModuleList(
            (0): GraphAttentionLayer (128 -> 128)
          )
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
          (lin_gate): Linear(in_features=128, out_features=128, bias=True)
        )
      )
    )
  )
  (fc0): ModuleList(
    (0): Linear(in_features=256, out_features=128, bias=True)
  )
  (w_out): Linear(in_features=128, out_features=1, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
)
norm clip needed:  tensor(91.6938, device='cuda:0') input_to_hidden.weight torch.Size([128, 5])
norm clip needed:  tensor(57.9225, device='cuda:0') input_to_hidden.bias torch.Size([128])
norm clip needed:  tensor(121.1052, device='cuda:0') forward_cells.0.Wh.weight torch.Size([640, 128])
norm clip needed:  tensor(75.4585, device='cuda:0') forward_cells.0.Wn.weight torch.Size([640, 128])
norm clip needed:  tensor(121.5880, device='cuda:0') forward_cells.0.Wt.weight torch.Size([640, 128])
norm clip needed:  tensor(323.1169, device='cuda:0') forward_cells.0.U.weight torch.Size([640, 128])
norm clip needed:  tensor(44.3419, device='cuda:0') forward_cells.0.gnn.0.attention.0.lin_value.weight torch.Size([128, 128])
norm clip needed:  tensor(24.4411, device='cuda:0') forward_cells.0.gnn.0.attention.0.lin_value.bias torch.Size([128])
norm clip needed:  tensor(45.9813, device='cuda:0') forward_cells.0.gnn.0.attention.0.lin_skip.weight torch.Size([128, 128])
norm clip needed:  tensor(24.4089, device='cuda:0') forward_cells.0.gnn.0.attention.0.lin_skip.bias torch.Size([128])
norm clip needed:  tensor(106.6835, device='cuda:0') backward_cells.0.Wh.weight torch.Size([640, 128])
norm clip needed:  tensor(63.6737, device='cuda:0') backward_cells.0.Wn.weight torch.Size([640, 128])
norm clip needed:  tensor(107.0369, device='cuda:0') backward_cells.0.Wt.weight torch.Size([640, 128])
norm clip needed:  tensor(263.5398, device='cuda:0') backward_cells.0.U.weight torch.Size([640, 128])
norm clip needed:  tensor(44.1540, device='cuda:0') backward_cells.0.gnn.0.attention.0.lin_value.weight torch.Size([128, 128])
norm clip needed:  tensor(22.7666, device='cuda:0') backward_cells.0.gnn.0.attention.0.lin_value.bias torch.Size([128])
norm clip needed:  tensor(45.2609, device='cuda:0') backward_cells.0.gnn.0.attention.0.lin_skip.weight torch.Size([128, 128])
norm clip needed:  tensor(22.7642, device='cuda:0') backward_cells.0.gnn.0.attention.0.lin_skip.bias torch.Size([128])
norm clip needed:  tensor(518.2007, device='cuda:0') fc0.0.weight torch.Size([128, 256])
norm clip needed:  tensor(173.6255, device='cuda:0') fc0.0.bias torch.Size([128])
norm clip needed:  tensor(377.9320, device='cuda:0') w_out.weight torch.Size([1, 128])
norm clip needed:  tensor(289.7520, device='cuda:0') w_out.bias torch.Size([1])
27.516170501708984 0.8079705238342285
train 0, step: 0, loss: 35.59587478637695, grad_norm: 783432.0820587564, ic: 0.03645323673124436
0.3268910348415375 0.044354937970638275
train 0, step: 500, loss: 0.7704404592514038, grad_norm: 303.8247985660168, ic: -0.00892425049975879
Epoch 0: 2022-05-05 23:24:26.597112: train loss: 1.7877464239052272
Eval step 0: eval loss: 0.0001478141057305038
Eval: 2022-05-05 23:24:37.179495: total loss: 0.00018908398290846994, mse:0.0003781679627567921, ic :0.02477824532954885, sharpe5:-1.2422001691907643, irr5:-0.30413493514060974, ndcg5:0.8517249135791753, pnl5:0.8688609004020691 
0.21938444674015045 0.02327003702521324
train 1, step: 0, loss: 0.45208483934402466, grad_norm: 118.49536443972693, ic: 0.0006039096032403705
norm clip needed:  tensor(28.4086, device='cuda:0') w_out.bias torch.Size([1])
0.5110853910446167 0.011187436990439892
train 1, step: 500, loss: 0.6229597330093384, grad_norm: 879.9707839584853, ic: -0.0055661505511299765
Epoch 1: 2022-05-05 23:25:32.239975: train loss: 0.7260141352958539
Eval step 0: eval loss: 0.00014578951231669635
Eval: 2022-05-05 23:25:42.405323: total loss: 0.00018889850854983463, mse:0.00037779701492599623, ic :0.02094262750800166, sharpe5:-1.8520980694144964, irr5:-0.44618287682533264, ndcg5:0.8539534289294011, pnl5:0.8503120541572571 
0.5146077275276184 0.007868217304348946
train 2, step: 0, loss: 0.5932899117469788, grad_norm: 52.49409307978294, ic: 0.016888324318183837
0.2228442281484604 0.003397646825760603
train 2, step: 500, loss: 0.2568207085132599, grad_norm: 0.8690387171365598, ic: -0.002127827607523912
Epoch 2: 2022-05-05 23:26:37.672500: train loss: 0.6076811009191255
Eval step 0: eval loss: 0.00013892374408897012
Eval: 2022-05-05 23:26:48.103593: total loss: 0.00018871905715901234, mse:0.0003774381109737367, ic :0.02007512715966074, sharpe5:-1.9193419182300566, irr5:-0.46288254857063293, ndcg5:0.8672816439870913, pnl5:0.8271645307540894 
0.2735905051231384 0.0027175969444215298
train 3, step: 0, loss: 0.3007664680480957, grad_norm: 1.0902923161091538, ic: 0.009628664875242167
norm clip needed:  tensor(28.5694, device='cuda:0') w_out.bias torch.Size([1])
0.5824860334396362 0.001462435000576079
train 3, step: 500, loss: 0.597110390663147, grad_norm: 826.790491813766, ic: 0.014880910458939491
Epoch 3: 2022-05-05 23:27:41.078991: train loss: 0.5711563428575024
Eval step 0: eval loss: 0.00013096534530632198
Eval: 2022-05-05 23:27:51.024766: total loss: 0.00018994323699582597, mse:0.00037988647346460884, ic :0.029192762917945682, sharpe5:0.28134573876857755, irr5:0.07945335656404495, ndcg5:0.8552391891265538, pnl5:1.0214954614639282 
0.8701124787330627 0.0007793635595589876
train 4, step: 0, loss: 0.8779061436653137, grad_norm: 1.3853948853107236, ic: 0.03609325961884004
0.49897995591163635 0.0001878596085589379
train 4, step: 500, loss: 0.5008585453033447, grad_norm: 318.34010916609185, ic: 0.05524264120143868
Epoch 4: 2022-05-05 23:28:44.485087: train loss: 0.5586177201413693
Eval step 0: eval loss: 0.00014860060764476657
Eval: 2022-05-05 23:28:54.776416: total loss: 0.0001892211072896221, mse:0.0003784422114541587, ic :-0.027146795585534497, sharpe5:-0.8467007066309452, irr5:-0.1825556457042694, ndcg5:0.852877635085246, pnl5:0.8985788226127625 
0.4743347465991974 0.00016199180390685797
train 5, step: 0, loss: 0.47595465183258057, grad_norm: 366.79082804857023, ic: 0.02801375501892305
norm clip needed:  tensor(45.3937, device='cuda:0') w_out.bias torch.Size([1])
1.186892032623291 9.65473591350019e-05
train 5, step: 500, loss: 1.1878575086593628, grad_norm: 2070.6645460360055, ic: 0.028017439353235574
Epoch 5: 2022-05-05 23:29:49.355260: train loss: 0.5562946230352404
Eval step 0: eval loss: 0.00016402272740378976
Eval: 2022-05-05 23:29:59.994753: total loss: 0.00019249439073139882, mse:0.000384988780593263, ic :-0.02987012101336899, sharpe5:0.4161773690767586, irr5:0.04238387569785118, ndcg5:0.8551186424079306, pnl5:1.469865083694458 
norm clip needed:  tensor(24.8421, device='cuda:0') w_out.bias torch.Size([1])
0.36619752645492554 8.940853149397299e-05
train 6, step: 0, loss: 0.3670916259288788, grad_norm: 618.067764884539, ic: -0.0589724489815608
0.24293898046016693 0.0002165600744774565
train 6, step: 500, loss: 0.24510458111763, grad_norm: 193.9213426050864, ic: 0.003830388848052542
Epoch 6: 2022-05-05 23:30:54.695421: train loss: 0.5564922034282257
Eval step 0: eval loss: 0.00013548697461374104
Eval: 2022-05-05 23:31:04.719727: total loss: 0.00018902334946235155, mse:0.0003780466968965864, ic :0.02410775370571035, sharpe5:1.4641593910753725, irr5:0.2632554769515991, ndcg5:0.8585928716271468, pnl5:1.1274510622024536 
0.43545854091644287 9.451948426431045e-05
train 7, step: 0, loss: 0.43640372157096863, grad_norm: 79.4897027656199, ic: -0.014723043165233575
norm clip needed:  tensor(21.6959, device='cuda:0') w_out.bias torch.Size([1])
0.722653865814209 0.00011317425378365442
train 7, step: 500, loss: 0.7237855792045593, grad_norm: 472.62176634137484, ic: 0.05186719100064211
Epoch 7: 2022-05-05 23:31:54.293285: train loss: 0.5563153527218868
Eval step 0: eval loss: 0.00013853552809450775
Eval: 2022-05-05 23:32:03.094094: total loss: 0.00018875261466984748, mse:0.0003775052257136076, ic :-0.029219597741016713, sharpe5:-0.8755851394683122, irr5:-0.18273118138313293, ndcg5:0.8495761991843254, pnl5:0.9752365946769714 
0.3140915632247925 0.00013854081043973565
train 8, step: 0, loss: 0.3154769837856293, grad_norm: 38.9146055428998, ic: 0.08184888355918393
0.5608774423599243 3.786774323089048e-05
train 8, step: 500, loss: 0.5612561106681824, grad_norm: 178.0950158468824, ic: 0.01907712545028896
Epoch 8: 2022-05-05 23:32:50.467250: train loss: 0.5552888614409429
Eval step 0: eval loss: 0.00014699638995807618
Eval: 2022-05-05 23:33:00.091457: total loss: 0.00018903421942529971, mse:0.00037806843316252, ic :-0.026951726341535077, sharpe5:-0.43398873640224334, irr5:-0.09216814488172531, ndcg5:0.8619039313665181, pnl5:1.0012577772140503 
0.32914450764656067 0.00010563470277702436
train 9, step: 0, loss: 0.33020085096359253, grad_norm: 59.49165959811681, ic: -0.0021348982938417596
0.16567692160606384 1.697947118373122e-05
train 9, step: 500, loss: 0.16584672033786774, grad_norm: 5.460862937209075, ic: -0.010155111614586437
Epoch 9: 2022-05-05 23:33:47.910966: train loss: 0.5546789698920307
Eval step 0: eval loss: 0.00014251930406317115
Eval: 2022-05-05 23:33:56.596434: total loss: 0.00018872050764816956, mse:0.000377441016424699, ic :0.010556161726149016, sharpe5:-1.07529819868505, irr5:-0.23350387811660767, ndcg5:0.8529307288396404, pnl5:0.9281436204910278 
0.19383488595485687 1.682781112322118e-05
train 10, step: 0, loss: 0.194003164768219, grad_norm: 23.259491470611806, ic: -0.024510302425384968
0.7598421573638916 2.0712051991722547e-05
train 10, step: 500, loss: 0.7600492835044861, grad_norm: 377.37897912865577, ic: -0.03362424886520446
Epoch 10: 2022-05-05 23:34:44.867976: train loss: 0.5544540191537397
Eval step 0: eval loss: 0.0001559218653710559
Eval: 2022-05-05 23:34:52.887268: total loss: 0.00019048047321263952, mse:0.00038096094138935304, ic :-0.019104468723199278, sharpe5:-2.079596868753433, irr5:-0.13730117678642273, ndcg5:0.8675426598779739, pnl5:0.6672884821891785 
0.4761323928833008 4.4795353460358456e-05
train 11, step: 0, loss: 0.47658035159111023, grad_norm: 1.9560011532353874, ic: -0.023765113029088607
1.0828300714492798 1.9785544282058254e-05
train 11, step: 500, loss: 1.083027958869934, grad_norm: 3.795591342884848, ic: 0.009916885551440621
Epoch 11: 2022-05-05 23:35:36.827921: train loss: 0.5553209373458503
Eval step 0: eval loss: 0.0001451571297366172
Eval: 2022-05-05 23:35:44.958222: total loss: 0.0001888660512336908, mse:0.00037773209637428825, ic :-0.030540890318536754, sharpe5:-0.32079252591356633, irr5:-0.07483848929405212, ndcg5:0.8552870939566777, pnl5:1.020916223526001 
0.31304845213890076 9.445182513445616e-06
train 12, step: 0, loss: 0.31314289569854736, grad_norm: 184.03721066572086, ic: 0.013055987599124855
0.5113308429718018 9.032725756696891e-06
train 12, step: 500, loss: 0.5114211440086365, grad_norm: 34.862100730093395, ic: 0.022560238985137884
Epoch 12: 2022-05-05 23:36:30.336196: train loss: 0.554564997653432
Eval step 0: eval loss: 0.0001461246720282361
Eval: 2022-05-05 23:36:38.320840: total loss: 0.00018894798642783893, mse:0.0003778959678275636, ic :0.017471234761772106, sharpe5:-1.3748116231709717, irr5:-0.30416733026504517, ndcg5:0.8517183193499197, pnl5:0.8928407430648804 
0.35071346163749695 9.760020475368947e-06
train 13, step: 0, loss: 0.35081106424331665, grad_norm: 71.50067084337586, ic: 0.03903959179176621
2.2518978118896484 6.375665634550387e-06
train 13, step: 500, loss: 2.2519614696502686, grad_norm: 42.43316809724167, ic: -0.004770570252639831
Epoch 13: 2022-05-05 23:37:24.569032: train loss: 0.5549996029784813
Eval step 0: eval loss: 0.00015322511899285018
Eval: 2022-05-05 23:37:32.609206: total loss: 0.000189945754286524, mse:0.00037989150518725253, ic :-0.0023219224919981286, sharpe5:-0.3932037008553743, irr5:-0.11295682936906815, ndcg5:0.8477241487880995, pnl5:1.1691079139709473 
0.4200671315193176 8.725765837880317e-06
train 14, step: 0, loss: 0.4201543927192688, grad_norm: 15.76285341214782, ic: -0.002440156171606528
1.0793217420578003 2.5971094146370888e-05
train 14, step: 500, loss: 1.0795814990997314, grad_norm: 0.03536021984907946, ic: -0.01916332079441581
Epoch 14: 2022-05-05 23:38:16.713713: train loss: 0.5542598476205121
Eval step 0: eval loss: 0.0001348875230178237
Eval: 2022-05-05 23:38:24.905128: total loss: 0.00018910753044912868, mse:0.0003782150592802599, ic :-0.008805916664382208, sharpe5:-1.4065275663882493, irr5:-0.24002067744731903, ndcg5:0.862431819931389, pnl5:0.8348881006240845 
0.2849120795726776 1.2721925486403052e-05
train 15, step: 0, loss: 0.2850393056869507, grad_norm: 15.909843830847548, ic: -0.012464954012849925
0.771902859210968 3.824754458037205e-06
train 15, step: 500, loss: 0.7719411253929138, grad_norm: 15.900098557478183, ic: 0.007180791358691704
Epoch 15: 2022-05-05 23:39:09.551313: train loss: 0.5545569528392292
Eval step 0: eval loss: 0.00012449081987142563
Eval: 2022-05-05 23:39:18.201703: total loss: 0.00019305167306930346, mse:0.0003861033460674621, ic :0.0024593908871650546, sharpe5:-0.3190901256725192, irr5:-0.07915780693292618, ndcg5:0.8685429268798354, pnl5:1.004286766052246 
0.4342445135116577 1.3773814316664357e-05
train 16, step: 0, loss: 0.43438225984573364, grad_norm: 81.45791163135631, ic: -0.026542143397593657
0.26543521881103516 4.368549707578495e-05
train 16, step: 500, loss: 0.265872061252594, grad_norm: 88.31474766446556, ic: -0.01593036822867596
Epoch 16: 2022-05-05 23:40:02.460904: train loss: 0.5552394044172159
Eval step 0: eval loss: 0.00014800112694501877
Eval: 2022-05-05 23:40:10.227266: total loss: 0.00018914699705427422, mse:0.00037829399258777627, ic :-0.008167974456797764, sharpe5:0.4472504966519773, irr5:0.08110932260751724, ndcg5:0.8548113519339058, pnl5:1.1041162014007568 
0.30385062098503113 6.117094926594291e-06
train 17, step: 0, loss: 0.30391180515289307, grad_norm: 8.128920182327343, ic: -0.07126809757000059
0.27143406867980957 1.403566898261488e-06
train 17, step: 500, loss: 0.2714481055736542, grad_norm: 0.17998663380459118, ic: 0.01092213505460897
Epoch 17: 2022-05-05 23:40:55.733323: train loss: 0.5546725863580876
Eval step 0: eval loss: 0.00014603696763515472
Eval: 2022-05-05 23:41:04.812677: total loss: 0.00018893999993642509, mse:0.0003778799960321912, ic :0.003660329562250861, sharpe5:-0.24320385614410042, irr5:-0.047322362661361694, ndcg5:0.846287285947949, pnl5:0.9871876835823059 
norm clip needed:  tensor(32.4968, device='cuda:0') w_out.bias torch.Size([1])
0.7379107475280762 6.71014186082175e-06
train 18, step: 0, loss: 0.7379778623580933, grad_norm: 1056.0729385575, ic: -0.01775534452263869
norm clip needed:  tensor(28.6859, device='cuda:0') w_out.bias torch.Size([1])
0.8675686717033386 8.970098861027509e-06
train 18, step: 500, loss: 0.8676583766937256, grad_norm: 822.9138202894003, ic: -0.0017864058901011053
Epoch 18: 2022-05-05 23:41:49.617113: train loss: 0.555217565809262
Eval step 0: eval loss: 0.00014028637087903917
Eval: 2022-05-05 23:41:57.504268: total loss: 0.0001886970213653548, mse:0.00037739403732246784, ic :-0.0063292463835380765, sharpe5:1.2586409492790698, irr5:0.20515507459640503, ndcg5:0.85411901623589, pnl5:1.114282250404358 
norm clip needed:  tensor(27.8940, device='cuda:0') w_out.bias torch.Size([1])
0.47029080986976624 0.00013178797962609679
train 19, step: 0, loss: 0.4716086983680725, grad_norm: 778.4497312569433, ic: 0.03874883487699151
0.42472508549690247 8.159530295870354e-08
train 19, step: 500, loss: 0.42472589015960693, grad_norm: 2.9171562791973265, ic: -0.008933762190492953
Epoch 19: 2022-05-05 23:42:42.625422: train loss: 0.554475660460757
Eval step 0: eval loss: 0.0001478481717640534
Eval: 2022-05-05 23:42:50.500316: total loss: 0.00018912888872086407, mse:0.00037825777382658853, ic :0.01683795524350347, sharpe5:-0.8123287222534418, irr5:-0.1804744303226471, ndcg5:0.8571476461282719, pnl5:0.9364929795265198 
0.47093459963798523 1.9532259898369375e-07
train 20, step: 0, loss: 0.4709365665912628, grad_norm: 35.27001407996097, ic: -0.01887636720395163
0.21162833273410797 1.346861893125606e-07
train 20, step: 500, loss: 0.21162967383861542, grad_norm: 3.6211976327997513, ic: -0.004572219269891037
Epoch 20: 2022-05-05 23:43:36.589930: train loss: 0.5541845061442751
Eval step 0: eval loss: 0.00014606288459617645
Eval: 2022-05-05 23:43:44.359839: total loss: 0.00018894236042864791, mse:0.0003778847157299268, ic :0.016083987828803475, sharpe5:-0.8236937240883707, irr5:-0.1786975860595703, ndcg5:0.8551406433242199, pnl5:0.9538465738296509 
norm clip needed:  tensor(39.2390, device='cuda:0') w_out.bias torch.Size([1])
0.7659239768981934 9.469949873164296e-07
train 21, step: 0, loss: 0.7659334540367126, grad_norm: 1539.7065816175816, ic: -0.008386816526824704
0.38811546564102173 3.558570597306243e-06
train 21, step: 500, loss: 0.38815104961395264, grad_norm: 192.32033053087193, ic: 0.021295555493380334
Epoch 21: 2022-05-05 23:44:30.346720: train loss: 0.5548684601796502
Eval step 0: eval loss: 0.0001598965172888711
Eval: 2022-05-05 23:44:38.034942: total loss: 0.00019139826104454656, mse:0.00038279652062637147, ic :0.006430617883532256, sharpe5:-0.9046528454124927, irr5:-0.21946924924850464, ndcg5:0.8532414271187744, pnl5:0.9992786645889282 
0.8074009418487549 0.0002383655810263008
train 22, step: 0, loss: 0.8097845911979675, grad_norm: 36.015998750839856, ic: -0.01713128368851562
0.5225142240524292 7.105094823600666e-08
train 22, step: 500, loss: 0.5225149393081665, grad_norm: 175.6650014874184, ic: -0.03461703787879539
Epoch 22: 2022-05-05 23:45:23.253468: train loss: 0.5540556150941766
Eval step 0: eval loss: 0.00013224780559539795
Eval: 2022-05-05 23:45:31.121463: total loss: 0.0001896159703638425, mse:0.00037923193622546304, ic :0.012867232280221958, sharpe5:-1.8237006700783966, irr5:-0.4265727698802948, ndcg5:0.8613015132112255, pnl5:0.8708633184432983 
0.5908045768737793 1.3840028145750694e-07
train 23, step: 0, loss: 0.5908059477806091, grad_norm: 274.52543786025717, ic: 0.01957376707046095
0.30749747157096863 5.345448698790278e-06
train 23, step: 500, loss: 0.30755093693733215, grad_norm: 142.09316995129197, ic: 0.01216364020133255
Epoch 23: 2022-05-05 23:46:16.270593: train loss: 0.5557130695206118
Eval step 0: eval loss: 0.00014217820717021823
Eval: 2022-05-05 23:46:24.055952: total loss: 0.00018871073536986616, mse:0.0003774214676003804, ic :0.014276510377944038, sharpe5:-1.174767489954829, irr5:-0.2599259912967682, ndcg5:0.8561361106361127, pnl5:0.9247246384620667 
0.34922391176223755 1.1721243708961993e-06
train 24, step: 0, loss: 0.3492356240749359, grad_norm: 14.005348293475262, ic: -0.013821242791212517
0.4466765820980072 0.00019658835662994534
train 24, step: 500, loss: 0.44864246249198914, grad_norm: 191.59112283093776, ic: -0.008223698150945136
Epoch 24: 2022-05-05 23:47:08.610974: train loss: 0.5544421103070764
Eval step 0: eval loss: 0.00014812617155257612
Eval: 2022-05-05 23:47:16.592009: total loss: 0.00018916203690348113, mse:0.000378324068383116, ic :0.011281267430459244, sharpe5:-1.0138897655904293, irr5:-0.21694409847259521, ndcg5:0.8514485792597865, pnl5:0.9375585317611694 
1.463477373123169 1.1754661954910262e-06
train 25, step: 0, loss: 1.4634891748428345, grad_norm: 261.25727646187994, ic: -0.04829543241261505
norm clip needed:  tensor(21.9869, device='cuda:0') w_out.bias torch.Size([1])
0.4306493103504181 1.7803339460442658e-06
train 25, step: 500, loss: 0.43066710233688354, grad_norm: 483.42675128445006, ic: -0.02479495122289599
Epoch 25: 2022-05-05 23:48:02.018243: train loss: 0.5551563528550659
Eval step 0: eval loss: 0.00013531334116123617
Eval: 2022-05-05 23:48:10.025389: total loss: 0.000189046874126637, mse:0.00037809374291579326, ic :-0.0010913090401054543, sharpe5:-1.8123756927251815, irr5:-0.32129961252212524, ndcg5:0.8469983004563137, pnl5:0.9135220050811768 
0.2948070168495178 6.548454257426783e-05
train 26, step: 0, loss: 0.29546186327934265, grad_norm: 94.98355447984316, ic: -0.07423966632770773
0.1431349366903305 1.1621071280387696e-05
train 26, step: 500, loss: 0.14325115084648132, grad_norm: 53.116598207395434, ic: -0.07179252218778909
Epoch 26: 2022-05-05 23:48:53.750189: train loss: 0.5548254258054144
Eval step 0: eval loss: 0.00015594740398228168
Eval: 2022-05-05 23:49:01.639428: total loss: 0.00019048588461874005, mse:0.0003809717658181352, ic :0.012533996938977988, sharpe5:-0.9495383802428841, irr5:-0.20632323622703552, ndcg5:0.8609190592797887, pnl5:0.9452158808708191 
0.39936330914497375 5.777498699899297e-06
train 27, step: 0, loss: 0.3994210958480835, grad_norm: 259.1774522784067, ic: 0.055832500504688645
0.35003313422203064 2.4188309453165857e-06
train 27, step: 500, loss: 0.35005733370780945, grad_norm: 106.7008979010371, ic: -0.01835851895227237
Epoch 27: 2022-05-05 23:49:45.108872: train loss: 0.5552855564610046
Eval step 0: eval loss: 0.0001408856041962281
Eval: 2022-05-05 23:49:52.941332: total loss: 0.0001886936170750554, mse:0.00037738723411962036, ic :0.01040763549169847, sharpe5:-0.9063003524020313, irr5:-0.19703561067581177, ndcg5:0.8558979730316324, pnl5:0.9850851893424988 
1.3782256841659546 0.00010202200792264193
train 28, step: 0, loss: 1.3792458772659302, grad_norm: 0.42988941771594247, ic: -0.010252993452160488
0.38600149750709534 1.918557472890825e-06
train 28, step: 500, loss: 0.386020690202713, grad_norm: 235.92785764044044, ic: 0.0207166734825802
Epoch 28: 2022-05-05 23:50:38.666599: train loss: 0.554747131249723
Eval step 0: eval loss: 0.0001396839797962457
Eval: 2022-05-05 23:50:46.492812: total loss: 0.0001887080310648165, mse:0.00037741605706801215, ic :0.007884853397836743, sharpe5:-1.1074214811623095, irr5:-0.24808767437934875, ndcg5:0.8557235975335624, pnl5:0.8869380354881287 
0.5483084321022034 1.0556760571489576e-05
train 29, step: 0, loss: 0.5484139919281006, grad_norm: 30.64493693453754, ic: 0.007501824569739227
0.2525615692138672 1.400509790983051e-05
train 29, step: 500, loss: 0.25270161032676697, grad_norm: 42.374270606154774, ic: -0.03835775502215745
Epoch 29: 2022-05-05 23:51:31.621780: train loss: 0.5546857677001685
Eval step 0: eval loss: 0.0001536015624878928
Eval: 2022-05-05 23:51:39.758985: total loss: 0.000190015775274829, mse:0.00038003154697233393, ic :-0.006815683522693314, sharpe5:-3.609740963280201, irr5:-0.43835943937301636, ndcg5:0.8478284150817423, pnl5:0.6499548554420471 
0.4029730558395386 6.68215307086939e-07
train 30, step: 0, loss: 0.4029797315597534, grad_norm: 155.10050234979315, ic: -0.03868784731199228
0.6131600737571716 3.356036540935747e-05
train 30, step: 500, loss: 0.6134956479072571, grad_norm: 22.33760656124213, ic: -0.037121885353240174
Epoch 30: 2022-05-05 23:52:25.047857: train loss: 0.5552101402000629
Eval step 0: eval loss: 0.00016438613238278776
Eval: 2022-05-05 23:52:33.009344: total loss: 0.00019259786295072138, mse:0.0003851957228795102, ic :0.006640360175742644, sharpe5:-0.43270552905276416, irr5:-0.1020500510931015, ndcg5:0.8436040627479714, pnl5:1.0170724391937256 
0.34754300117492676 1.70291186805116e-05
train 31, step: 0, loss: 0.34771329164505005, grad_norm: 235.03214758844626, ic: -0.005159453108835677
0.24980363249778748 1.531972202428733e-07
train 31, step: 500, loss: 0.24980516731739044, grad_norm: 40.110475704189284, ic: 0.034189387081001235
Epoch 31: 2022-05-05 23:53:18.260442: train loss: 0.5545951083880216
Eval step 0: eval loss: 0.00013128903810866177
Eval: 2022-05-05 23:53:26.282066: total loss: 0.00018986423807950716, mse:0.0003797284696769928, ic :0.010978115661097533, sharpe5:0.2757275607995689, irr5:0.06539227813482285, ndcg5:0.8522017202275717, pnl5:0.9530792236328125 
0.8389286398887634 1.0302566799680335e-08
train 32, step: 0, loss: 0.838928759098053, grad_norm: 150.96219384077995, ic: 0.048241379511124054
0.6574115753173828 1.719036663416773e-05
train 32, step: 500, loss: 0.657583475112915, grad_norm: 4.192401499567811, ic: 0.048182791516988996
Epoch 32: 2022-05-05 23:54:12.171871: train loss: 0.5551629823976182
Eval step 0: eval loss: 0.00014251175161916763
Eval: 2022-05-05 23:54:20.200139: total loss: 0.00018872033969746235, mse:0.00037744067591308786, ic :-0.008475113781830352, sharpe5:-3.2645625020563602, irr5:-0.14896738529205322, ndcg5:0.8575157183423092, pnl5:0.31387513875961304 
0.3578954041004181 4.402316699270159e-05
train 33, step: 0, loss: 0.3583356440067291, grad_norm: 1.8351179118275252, ic: -0.027853258020153496
0.22151091694831848 1.1860683116537984e-05
train 33, step: 500, loss: 0.2216295301914215, grad_norm: 5.400570355876284, ic: -0.017482310458314495
Epoch 33: 2022-05-05 23:55:05.911740: train loss: 0.555014489268396
Eval step 0: eval loss: 0.00015332235489040613
Eval: 2022-05-05 23:55:14.595689: total loss: 0.0001899636978147283, mse:0.0003799273955871344, ic :-0.0014372444199950746, sharpe5:1.2368909246474504, irr5:0.16280822455883026, ndcg5:0.8531019647777132, pnl5:0.9908096790313721 
0.3522320091724396 5.0105516180565246e-08
train 34, step: 0, loss: 0.35223251581192017, grad_norm: 1.4512788928917755, ic: -0.02550965492806518
0.26931190490722656 1.4929119060980156e-05
train 34, step: 500, loss: 0.26946118474006653, grad_norm: 104.1930643232083, ic: -0.0007117616483770422
Epoch 34: 2022-05-05 23:55:59.680610: train loss: 0.5543205424406152
Eval step 0: eval loss: 0.00013653050700668246
Eval: 2022-05-05 23:56:07.650105: total loss: 0.00018890269829405627, mse:0.00037780539160674735, ic :0.006486470046575621, sharpe5:-0.622414980456233, irr5:-0.14437469840049744, ndcg5:0.8547752311846999, pnl5:0.9497096538543701 
norm clip needed:  tensor(42.7072, device='cuda:0') w_out.bias torch.Size([1])
0.7758836150169373 5.429219891084358e-05
train 35, step: 0, loss: 0.7764265537261963, grad_norm: 1824.0327429818456, ic: 0.007562461655775933
norm clip needed:  tensor(26.0842, device='cuda:0') w_out.bias torch.Size([1])
0.9896674156188965 5.013880581827834e-07
train 35, step: 500, loss: 0.9896724224090576, grad_norm: 680.3897624989412, ic: 0.001643006372139726
Epoch 35: 2022-05-05 23:56:51.331475: train loss: 0.5547282445159826
Eval step 0: eval loss: 0.00013806742208544165
Eval: 2022-05-05 23:56:59.454649: total loss: 0.00018877764494899522, mse:0.00037755528695043115, ic :-0.01480111206681975, sharpe5:-0.3796725586988032, irr5:-0.045047156512737274, ndcg5:0.8570496652706473, pnl5:0.9784904718399048 
norm clip needed:  tensor(24.0871, device='cuda:0') w_out.bias torch.Size([1])
0.48542630672454834 1.6580207207184117e-09
train 36, step: 0, loss: 0.4854263365268707, grad_norm: 580.1863219317539, ic: 0.0026856785760995946
norm clip needed:  tensor(23.9954, device='cuda:0') w_out.bias torch.Size([1])
0.942704439163208 3.0336129164254544e-09
train 36, step: 500, loss: 0.9427044987678528, grad_norm: 575.7785645457093, ic: -0.009138514320598687
Epoch 36: 2022-05-05 23:57:43.587536: train loss: 0.5540621451993677
Eval step 0: eval loss: 0.0001686361647443846
Eval: 2022-05-05 23:57:51.464579: total loss: 0.00019387201775006714, mse:0.00038774403391251747, ic :nan, sharpe5:2.632136671543121, irr5:0.4219798743724823, ndcg5:0.851633256091798, pnl5:1.1316845417022705 
norm clip needed:  tensor(37.4918, device='cuda:0') w_out.bias torch.Size([1])
0.6656950116157532 7.29872118299113e-09
train 37, step: 0, loss: 0.665695071220398, grad_norm: 1405.636146016016, ic: 0.041961288606399666
0.7006275057792664 5.1513503422029316e-05
train 37, step: 500, loss: 0.7011426687240601, grad_norm: 25.888833391069078, ic: -0.015556012486746623
Epoch 37: 2022-05-05 23:58:34.459199: train loss: 0.5556973179872023
Eval step 0: eval loss: 0.0001467948459321633
Eval: 2022-05-05 23:58:42.708826: total loss: 0.00018901320925571115, mse:0.0003780264178582963, ic :-0.004033762563819132, sharpe5:-1.840771200209856, irr5:-0.0931740328669548, ndcg5:0.8588190575024417, pnl5:0.47328346967697144 
0.32330405712127686 5.838183278683573e-05
train 38, step: 0, loss: 0.3238878846168518, grad_norm: 0.4670243360548049, ic: 0.0240385034724901
0.624152660369873 4.604524406204291e-08
train 38, step: 500, loss: 0.6241531372070312, grad_norm: 32.00743061229261, ic: -0.009540994678384068
Epoch 38: 2022-05-05 23:59:30.221148: train loss: 0.5539965249876925
Eval step 0: eval loss: 0.000136591013870202
Eval: 2022-05-05 23:59:39.345076: total loss: 0.00018889660723726002, mse:0.000377793213428538, ic :-0.002082665036244838, sharpe5:-0.16085515516810117, irr5:-0.03615814447402954, ndcg5:0.8537737527047365, pnl5:0.9475552439689636 
norm clip needed:  tensor(29.7489, device='cuda:0') w_out.bias torch.Size([1])
0.696232259273529 2.7024714910339753e-08
train 39, step: 0, loss: 0.6962325572967529, grad_norm: 884.9963929137663, ic: -0.01530927804538398
0.5583440065383911 1.2839495866501238e-05
train 39, step: 500, loss: 0.5584723949432373, grad_norm: 89.30612280527816, ic: 0.01582684045068665
Epoch 39: 2022-05-06 00:00:25.717474: train loss: 0.5542452706392595
Eval step 0: eval loss: 0.00015147986414376646
Eval: 2022-05-06 00:00:34.061850: total loss: 0.00018964195141048216, mse:0.00037928389557097465, ic :0.006113436283095462, sharpe5:-1.0503263510763645, irr5:-0.22774803638458252, ndcg5:0.8512339652814546, pnl5:0.8943991661071777 

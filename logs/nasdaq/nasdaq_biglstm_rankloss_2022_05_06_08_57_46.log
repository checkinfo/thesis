Namespace(adj_path='./data/graphs/NASDAQ_1026_1026.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='NASDAQAdjSeqTimeDataset', dout=0.3, epochs=60, glstm_layers=1, gnn_layers=1, gpu=0, graph_attn=True, hidden_dim=128, inner_prod=False, input_dim=5, input_graph=True, label_cnt=1, lr=0.001, lstm_layers=1, market='NASDAQ', mask_adj=True, mask_type='soft', model_type='BiGLSTM', normalize_adj=True, num_days=8, num_heads=1, print_inteval=500, rank_loss=True, relation_num=1, rsr_data_path='../Temporal_Relational_Stock_Ranking/data/2013-01-01', seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_250_0.8/', stock_num=1026, test_mask_path='./data/NASDAQ/test_mask_237_1026.npy', test_path='./data/NASDAQ/test_237_1026_6.npy', top_stocks=5, train_mask_path='./data/NASDAQ/train_mask_756_1026.npy', train_path='./data/NASDAQ/train_756_1026_6.npy', use_adj=True)
#tickers selected: 1026
single EOD data shape: (1245, 6)
(1026, 1245, 5) (1026, 1245) (1026, 1245) (1026, 1245)
#tickers selected: 1026
single EOD data shape: (1245, 6)
(1026, 1245, 5) (1026, 1245) (1026, 1245) (1026, 1245)
28851
BiGLSTM(
  (input_to_hidden): Linear(in_features=5, out_features=128, bias=True)
  (forward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (attention): ModuleList(
            (0): GraphAttentionLayer (128 -> 128)
          )
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
          (lin_gate): Linear(in_features=128, out_features=128, bias=True)
        )
      )
    )
  )
  (backward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (attention): ModuleList(
            (0): GraphAttentionLayer (128 -> 128)
          )
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
          (lin_gate): Linear(in_features=128, out_features=128, bias=True)
        )
      )
    )
  )
  (fc0): ModuleList(
    (0): Linear(in_features=256, out_features=128, bias=True)
  )
  (w_out): Linear(in_features=128, out_features=1, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
)
norm clip needed:  tensor(90.4520, device='cuda:0') input_to_hidden.weight torch.Size([128, 5])
norm clip needed:  tensor(57.4472, device='cuda:0') input_to_hidden.bias torch.Size([128])
norm clip needed:  tensor(119.5087, device='cuda:0') forward_cells.0.Wh.weight torch.Size([640, 128])
norm clip needed:  tensor(75.4876, device='cuda:0') forward_cells.0.Wn.weight torch.Size([640, 128])
norm clip needed:  tensor(119.8867, device='cuda:0') forward_cells.0.Wt.weight torch.Size([640, 128])
norm clip needed:  tensor(318.5352, device='cuda:0') forward_cells.0.U.weight torch.Size([640, 128])
norm clip needed:  tensor(44.4975, device='cuda:0') forward_cells.0.gnn.0.attention.0.lin_value.weight torch.Size([128, 128])
norm clip needed:  tensor(24.2291, device='cuda:0') forward_cells.0.gnn.0.attention.0.lin_value.bias torch.Size([128])
norm clip needed:  tensor(45.0157, device='cuda:0') forward_cells.0.gnn.0.attention.0.lin_skip.weight torch.Size([128, 128])
norm clip needed:  tensor(24.0111, device='cuda:0') forward_cells.0.gnn.0.attention.0.lin_skip.bias torch.Size([128])
norm clip needed:  tensor(106.2572, device='cuda:0') backward_cells.0.Wh.weight torch.Size([640, 128])
norm clip needed:  tensor(64.1578, device='cuda:0') backward_cells.0.Wn.weight torch.Size([640, 128])
norm clip needed:  tensor(106.5437, device='cuda:0') backward_cells.0.Wt.weight torch.Size([640, 128])
norm clip needed:  tensor(262.1014, device='cuda:0') backward_cells.0.U.weight torch.Size([640, 128])
norm clip needed:  tensor(44.9417, device='cuda:0') backward_cells.0.gnn.0.attention.0.lin_value.weight torch.Size([128, 128])
norm clip needed:  tensor(22.8867, device='cuda:0') backward_cells.0.gnn.0.attention.0.lin_value.bias torch.Size([128])
norm clip needed:  tensor(45.0508, device='cuda:0') backward_cells.0.gnn.0.attention.0.lin_skip.weight torch.Size([128, 128])
norm clip needed:  tensor(22.7546, device='cuda:0') backward_cells.0.gnn.0.attention.0.lin_skip.bias torch.Size([128])
norm clip needed:  tensor(517.3047, device='cuda:0') fc0.0.weight torch.Size([128, 256])
norm clip needed:  tensor(173.6500, device='cuda:0') fc0.0.bias torch.Size([128])
norm clip needed:  tensor(374.1568, device='cuda:0') w_out.weight torch.Size([1, 128])
norm clip needed:  tensor(290.0494, device='cuda:0') w_out.bias torch.Size([1])
27.69439697265625 0.8193110227584839
train 0, step: 0, loss: 31.790952682495117, grad_norm: 774896.8628952631, ic: 0.034132549935573096
0.3072408139705658 0.049472689628601074
train 0, step: 500, loss: 0.5546042919158936, grad_norm: 157.52060347574186, ic: 0.008834620141043407
Epoch 0: 2022-05-06 20:59:58.121974: train loss: 1.7565927475611156
Eval step 0: eval loss: 0.0001661458081798628
Eval: 2022-05-06 21:00:07.287411: total loss: 0.00019317383385582636, mse:0.0003863476635279072, ic :0.0241150575084233, sharpe5:-1.0921966885775327, irr5:-0.2660321295261383, ndcg5:0.852423200759765, pnl5:0.8936673402786255 
0.24695244431495667 0.02833780087530613
train 1, step: 0, loss: 0.38864144682884216, grad_norm: 236.3213406534946, ic: -0.005783961566750895
norm clip needed:  tensor(20.1418, device='cuda:0') w_out.bias torch.Size([1])
0.41380253434181213 0.015865135937929153
train 1, step: 500, loss: 0.4931282103061676, grad_norm: 466.51932844056114, ic: 0.02393782476396795
Epoch 1: 2022-05-06 21:00:57.384947: train loss: 0.6802296600040586
Eval step 0: eval loss: 0.0001611690822755918
Eval: 2022-05-06 21:01:05.543795: total loss: 0.00019173067663979257, mse:0.00038346135070562397, ic :0.019271180275658214, sharpe5:-1.189622189104557, irr5:-0.2631362974643707, ndcg5:0.8555816630435972, pnl5:0.894999623298645 
0.5336353778839111 0.013519843108952045
train 2, step: 0, loss: 0.6012346148490906, grad_norm: 124.78051794841303, ic: -0.027837683781848983
0.22261850535869598 0.006140840705484152
train 2, step: 500, loss: 0.2533227205276489, grad_norm: 0.7244489489389625, ic: 0.028827840477813907
Epoch 2: 2022-05-06 21:01:54.021490: train loss: 0.6074962679515866
Eval step 0: eval loss: 0.00013306626351550221
Eval: 2022-05-06 21:02:03.514982: total loss: 0.00018938440904117852, mse:0.00037876881628353456, ic :0.02272174010641452, sharpe5:-1.776613906994462, irr5:-0.41711339354515076, ndcg5:0.8617785724193847, pnl5:0.8193982839584351 
0.275052547454834 0.005584901664406061
train 3, step: 0, loss: 0.302977055311203, grad_norm: 6.126373589702835, ic: 0.0054209571327753555
norm clip needed:  tensor(25.6276, device='cuda:0') w_out.bias torch.Size([1])
0.5433169007301331 0.003817893797531724
train 3, step: 500, loss: 0.5624063611030579, grad_norm: 692.5874537818372, ic: 0.03700849433454459
Epoch 3: 2022-05-06 21:02:53.873980: train loss: 0.5815500325179673
Eval step 0: eval loss: 0.00015723833348602057
Eval: 2022-05-06 21:03:03.239066: total loss: 0.00019076774164975325, mse:0.00038153548008311303, ic :0.021229580447840127, sharpe5:-1.4594100163131951, irr5:-0.3416552245616913, ndcg5:0.8475998423918281, pnl5:0.8633756637573242 
0.8799887299537659 0.00269312527962029
train 4, step: 0, loss: 0.893454372882843, grad_norm: 49.342552884969095, ic: 0.033064904281744155
0.49232718348503113 0.0012398989638313651
train 4, step: 500, loss: 0.4985266923904419, grad_norm: 298.3737733928422, ic: 0.007248196298460704
Epoch 4: 2022-05-06 21:03:53.969387: train loss: 0.5668010368026832
Eval step 0: eval loss: 0.00013300037244334817
Eval: 2022-05-06 21:04:03.338930: total loss: 0.00018944017175792443, mse:0.0003788803419779653, ic :0.019664264452352996, sharpe5:-1.239082871004939, irr5:-0.27994170784950256, ndcg5:0.8546065357302868, pnl5:0.9017078280448914 
0.43636512756347656 0.001515351701527834
train 5, step: 0, loss: 0.4439418911933899, grad_norm: 213.52038886035012, ic: 0.008688530450224365
norm clip needed:  tensor(49.1209, device='cuda:0') w_out.bias torch.Size([1])
1.272678017616272 0.001554405316710472
train 5, step: 500, loss: 1.2804499864578247, grad_norm: 2480.9183280369625, ic: 0.016824078018058006
Epoch 5: 2022-05-06 21:04:55.627099: train loss: 0.5613747460438925
Eval step 0: eval loss: 0.0001812373666325584
Eval: 2022-05-06 21:05:04.906127: total loss: 0.0001983168895491582, mse:0.00039663377512900815, ic :0.023859394948263803, sharpe5:-1.1731723044812679, irr5:-0.3100736439228058, ndcg5:0.8515581424489347, pnl5:0.9446074962615967 
norm clip needed:  tensor(28.1898, device='cuda:0') w_out.bias torch.Size([1])
0.4093060791492462 0.0007167313015088439
train 6, step: 0, loss: 0.4128897488117218, grad_norm: 812.0471748557949, ic: 0.049908568538025895
0.23574598133563995 0.0009053210960701108
train 6, step: 500, loss: 0.24027258157730103, grad_norm: 165.92421367209033, ic: -0.020309792525891338
Epoch 6: 2022-05-06 21:05:57.028996: train loss: 0.5538135708215084
Eval step 0: eval loss: 0.000156469686771743
Eval: 2022-05-06 21:06:06.382100: total loss: 0.0001906295107511344, mse:0.0003812590180162088, ic :0.02265136161800333, sharpe5:-1.3495686496049164, irr5:-0.2907921373844147, ndcg5:0.8575994240353496, pnl5:0.9225013852119446 
0.41882267594337463 0.0025753104127943516
train 7, step: 0, loss: 0.4316992163658142, grad_norm: 10.313379608476064, ic: -0.006280534406873928
0.7043209671974182 0.001373873557895422
train 7, step: 500, loss: 0.7111903429031372, grad_norm: 414.6417222484879, ic: 0.06218652232256653
Epoch 7: 2022-05-06 21:06:58.103492: train loss: 0.5107510088081347
Eval step 0: eval loss: 0.0001335681154159829
Eval: 2022-05-06 21:07:07.602231: total loss: 0.00018934223174466242, mse:0.0003786844611622363, ic :0.006569107543856651, sharpe5:-1.3783913607895373, irr5:-0.29494616389274597, ndcg5:0.8621605335668371, pnl5:0.8706204891204834 
0.3194255828857422 0.001537699019536376
train 8, step: 0, loss: 0.327114075422287, grad_norm: 77.03451216065517, ic: 0.04771399295024612
0.3353448510169983 0.0023943178821355104
train 8, step: 500, loss: 0.3473164439201355, grad_norm: 201.3020924312492, ic: -0.03496270750433698
Epoch 8: 2022-05-06 21:08:00.164258: train loss: 0.4822606473045553
Eval step 0: eval loss: 0.00011862145765917376
Eval: 2022-05-06 21:08:09.432956: total loss: 0.00020036725704197255, mse:0.00040073450750338467, ic :-0.005255605596064853, sharpe5:0.43962216742336746, irr5:0.08531506359577179, ndcg5:0.8583940532722353, pnl5:1.274566411972046 
0.31641390919685364 0.0034800823777914047
train 9, step: 0, loss: 0.3338143229484558, grad_norm: 20.24394943259071, ic: 0.028039694771606002
0.16588354110717773 0.0006706808926537633
train 9, step: 500, loss: 0.1692369431257248, grad_norm: 8.29131616823425, ic: 0.028392110580536555
Epoch 9: 2022-05-06 21:09:01.798067: train loss: 0.4680159180699026
Eval step 0: eval loss: 0.0001247096515726298
Eval: 2022-05-06 21:09:11.657301: total loss: 0.0001930351394882393, mse:0.0003860702726120108, ic :0.01586061874837488, sharpe5:-1.0061914674192667, irr5:-0.22218573093414307, ndcg5:0.8538625931654313, pnl5:0.9322518110275269 
0.18903914093971252 0.0013010991970077157
train 10, step: 0, loss: 0.19554463028907776, grad_norm: 3.682395250825735, ic: -0.04097294810455633
norm clip needed:  tensor(21.6825, device='cuda:0') w_out.bias torch.Size([1])
0.4862282872200012 0.001425309805199504
train 10, step: 500, loss: 0.49335482716560364, grad_norm: 489.217254651553, ic: -0.030799707925052742
Epoch 10: 2022-05-06 21:10:03.649926: train loss: 0.4659824039846818
Eval step 0: eval loss: 0.0001772376854205504
Eval: 2022-05-06 21:10:13.280682: total loss: 0.0001969544116143792, mse:0.00039390882093513427, ic :0.009549682659475698, sharpe5:0.5670793313160538, irr5:0.15311381220817566, ndcg5:0.8546159506299292, pnl5:1.1111037731170654 
0.48392370343208313 0.001653146231546998
train 11, step: 0, loss: 0.4921894371509552, grad_norm: 38.70078596075797, ic: -0.03720116168021786
0.5298804044723511 0.0017250082455575466
train 11, step: 500, loss: 0.5385054349899292, grad_norm: 61.79183363293917, ic: 0.0010143642217861869
Epoch 11: 2022-05-06 21:11:04.818472: train loss: 0.46147096157073975
Eval step 0: eval loss: 0.00013621250400319695
Eval: 2022-05-06 21:11:14.487066: total loss: 0.00018915710501158284, mse:0.00037831420534732604, ic :0.015026786351020916, sharpe5:0.6840506722033024, irr5:0.17040513455867767, ndcg5:0.8496948288494519, pnl5:1.082288146018982 
0.33180513978004456 0.0005817294004373252
train 12, step: 0, loss: 0.33471378684043884, grad_norm: 267.90980919478517, ic: 0.07071857131308423
0.27940279245376587 0.0009259719518013299
train 12, step: 500, loss: 0.2840326428413391, grad_norm: 23.4620013976783, ic: -0.004575547811802022
Epoch 12: 2022-05-06 21:12:05.592087: train loss: 0.4619901433567153
Eval step 0: eval loss: 0.0001479639468016103
Eval: 2022-05-06 21:12:15.355540: total loss: 0.00018925763984103017, mse:0.0003785152765764371, ic :-0.0026755225883638334, sharpe5:0.921178936176002, irr5:0.1524544358253479, ndcg5:0.8590927213528318, pnl5:0.9687720537185669 
0.34870684146881104 0.00040598309715278447
train 13, step: 0, loss: 0.3507367670536041, grad_norm: 66.059765804563, ic: 0.034262379152662975
1.2039092779159546 0.0015903341118246317
train 13, step: 500, loss: 1.2118608951568604, grad_norm: 41.58856179951874, ic: 0.11771782168348996
Epoch 13: 2022-05-06 21:13:07.310555: train loss: 0.4591555983664837
Eval step 0: eval loss: 0.00015959983284119517
Eval: 2022-05-06 21:13:16.654514: total loss: 0.00019180315620277084, mse:0.0003836063063328074, ic :0.02547692113623969, sharpe5:1.2751553933322428, irr5:0.37703630328178406, ndcg5:0.8484965148928861, pnl5:1.075075626373291 
0.4167869985103607 0.0010457659373059869
train 14, step: 0, loss: 0.42201581597328186, grad_norm: 7.099922289929828, ic: 0.1038407857256517
0.7826129794120789 0.0005785500979982316
train 14, step: 500, loss: 0.7855057120323181, grad_norm: 20.61442053783462, ic: -0.038095857505127326
Epoch 14: 2022-05-06 21:14:07.740750: train loss: 0.4590920598051924
Eval step 0: eval loss: 0.0001258288393728435
Eval: 2022-05-06 21:14:16.979156: total loss: 0.00019225078601492812, mse:0.00038450157004811894, ic :0.00402639158938396, sharpe5:-3.375055138617754, irr5:-0.5373491644859314, ndcg5:0.8509035094648812, pnl5:0.6935072541236877 
0.2807380259037018 0.0012830558698624372
train 15, step: 0, loss: 0.28715330362319946, grad_norm: 0.5736104183348956, ic: 0.07045726525924408
0.21902719140052795 0.0022409437224268913
train 15, step: 500, loss: 0.23023191094398499, grad_norm: 31.26009403303178, ic: 0.0027406439188986907
Epoch 15: 2022-05-06 21:15:07.149159: train loss: 0.4539122060937359
Eval step 0: eval loss: 0.00011933495989069343
Eval: 2022-05-06 21:15:16.582584: total loss: 0.00019896487635763678, mse:0.0003979297504739645, ic :-0.017781881947011986, sharpe5:-2.1466358064115045, irr5:-0.39047524333000183, ndcg5:0.8509157276140017, pnl5:0.8281561136245728 
0.4225299060344696 0.0005415839841589332
train 16, step: 0, loss: 0.42523783445358276, grad_norm: 34.08989445358995, ic: 0.023104795620226624
0.2592580020427704 0.0004652304924093187
train 16, step: 500, loss: 0.26158416271209717, grad_norm: 65.0833726773496, ic: 0.12362008331599447
Epoch 16: 2022-05-06 21:16:07.986704: train loss: 0.4559036595995892
Eval step 0: eval loss: 0.0002029397728620097
Eval: 2022-05-06 21:16:17.306137: total loss: 0.00020766659786819998, mse:0.00041533319150037306, ic :0.017333946571509162, sharpe5:0.880596772134304, irr5:0.14443141222000122, ndcg5:0.8558073279570568, pnl5:1.0729649066925049 
0.3164818286895752 0.002159316558390856
train 17, step: 0, loss: 0.32727840542793274, grad_norm: 63.89923318512781, ic: -0.029104224762017766
0.16907797753810883 0.0008010788587853312
train 17, step: 500, loss: 0.1730833649635315, grad_norm: 12.859232080987642, ic: 0.011240620135353534
Epoch 17: 2022-05-06 21:17:10.084063: train loss: 0.4531499664174682
Eval step 0: eval loss: 0.00017425432452000678
Eval: 2022-05-06 21:17:19.659153: total loss: 0.0001958317810470771, mse:0.00039166355607185067, ic :0.018860088763881063, sharpe5:1.077191941961646, irr5:0.2133873552083969, ndcg5:0.8401702137199155, pnl5:1.1190578937530518 
norm clip needed:  tensor(38.7455, device='cuda:0') w_out.bias torch.Size([1])
0.8468508720397949 0.002533863764256239
train 18, step: 0, loss: 0.8595201969146729, grad_norm: 1522.9715526458267, ic: -0.047677409356411196
norm clip needed:  tensor(37.8442, device='cuda:0') w_out.bias torch.Size([1])
0.8205536603927612 0.0034881925676018
train 18, step: 500, loss: 0.8379946351051331, grad_norm: 1530.6649554391643, ic: -0.011248111638241687
Epoch 18: 2022-05-06 21:18:11.337235: train loss: 0.45488588252966417
Eval step 0: eval loss: 0.0001409907272318378
Eval: 2022-05-06 21:18:20.704564: total loss: 0.00018881825743803315, mse:0.00037763651216727505, ic :0.021737027693222243, sharpe5:0.6088618159666657, irr5:0.1512201875448227, ndcg5:0.8455318992326433, pnl5:1.1394351720809937 
norm clip needed:  tensor(27.6812, device='cuda:0') w_out.bias torch.Size([1])
0.4675537645816803 0.0005812513991259038
train 19, step: 0, loss: 0.47046002745628357, grad_norm: 774.497417008304, ic: -0.0016177557600522141
0.42419594526290894 0.0003956987347919494
train 19, step: 500, loss: 0.42617443203926086, grad_norm: 1.3610082571792113, ic: 0.021084042642829474
Epoch 19: 2022-05-06 21:19:13.419785: train loss: 0.45033537480920394
Eval step 0: eval loss: 0.00013763259630650282
Eval: 2022-05-06 21:19:22.900179: total loss: 0.00018883877611509627, mse:0.000377677549652986, ic :0.006934005457551778, sharpe5:-0.5643155137449503, irr5:-0.10275336354970932, ndcg5:0.8592608952576792, pnl5:0.8988641500473022 
0.46466171741485596 0.0003643453528638929
train 20, step: 0, loss: 0.4664834439754486, grad_norm: 10.069377853399294, ic: -0.0372525874515503
0.21361513435840607 0.0005466668517328799
train 20, step: 500, loss: 0.21634846925735474, grad_norm: 12.87434956294912, ic: 0.02309981401607447
Epoch 20: 2022-05-06 21:20:13.232538: train loss: 0.45225112532629047
Eval step 0: eval loss: 0.00014387746341526508
Eval: 2022-05-06 21:20:22.505971: total loss: 0.0001888525577637725, mse:0.0003777051141588994, ic :0.009536869906732312, sharpe5:-1.8885598401725292, irr5:-0.3264160454273224, ndcg5:0.849456396962316, pnl5:1.0365033149719238 
norm clip needed:  tensor(39.8302, device='cuda:0') w_out.bias torch.Size([1])
0.7774824500083923 0.0007332006935030222
train 21, step: 0, loss: 0.7811484336853027, grad_norm: 1596.7770706196522, ic: -0.070889780242271
0.36643996834754944 0.0005867201834917068
train 21, step: 500, loss: 0.3693735599517822, grad_norm: 107.06074060855094, ic: 0.06806374179539813
Epoch 21: 2022-05-06 21:21:13.432148: train loss: 0.44997230710033426
Eval step 0: eval loss: 0.0001584370620548725
Eval: 2022-05-06 21:21:22.301835: total loss: 0.00019109671597122968, mse:0.00038219342686981973, ic :0.02848699858985427, sharpe5:0.7010760343819856, irr5:0.16736015677452087, ndcg5:0.855135253765017, pnl5:0.9203212857246399 
0.3222706913948059 0.000749648897908628
train 22, step: 0, loss: 0.32601892948150635, grad_norm: 61.87647030858599, ic: -0.00625654680633813
0.2866138219833374 0.00039037433452904224
train 22, step: 500, loss: 0.2885656952857971, grad_norm: 166.14042350934008, ic: 0.025345119588212922
Epoch 22: 2022-05-06 21:22:12.791301: train loss: 0.4500946897993432
Eval step 0: eval loss: 0.00013087500701658428
Eval: 2022-05-06 21:22:22.594793: total loss: 0.00019009750429566292, mse:0.0003801950031720134, ic :-0.011689483137283853, sharpe5:-1.8440990851074457, irr5:-0.2893297076225281, ndcg5:0.8634511229495372, pnl5:0.9070141911506653 
0.42487281560897827 0.0005512890638783574
train 23, step: 0, loss: 0.4276292622089386, grad_norm: 274.95547621999435, ic: -0.021615156849044838
0.2288120985031128 0.0008533278596587479
train 23, step: 500, loss: 0.233078733086586, grad_norm: 188.79413794546542, ic: 0.038031163057371156
Epoch 23: 2022-05-06 21:23:14.460242: train loss: 0.45582041105524423
Eval step 0: eval loss: 0.00014162162551656365
Eval: 2022-05-06 21:23:24.166758: total loss: 0.0001887469725301042, mse:0.0003774939416905927, ic :0.027697812608014703, sharpe5:-0.9763334996625781, irr5:-0.21066105365753174, ndcg5:0.8620261169803167, pnl5:0.9388167858123779 
0.3485131561756134 0.0005496818339452147
train 24, step: 0, loss: 0.35126155614852905, grad_norm: 14.22204380647108, ic: -0.006515521071459439
0.47772613167762756 0.0007387817022390664
train 24, step: 500, loss: 0.48142004013061523, grad_norm: 322.4684511319679, ic: -0.027254485764034386
Epoch 24: 2022-05-06 21:24:16.032468: train loss: 0.45052652178521463
Eval step 0: eval loss: 0.00016284945013467222
Eval: 2022-05-06 21:24:25.250329: total loss: 0.00019241455682745512, mse:0.00038482911102442495, ic :0.019469745613626736, sharpe5:1.8986257904022932, irr5:0.4885241687297821, ndcg5:0.8617957841782076, pnl5:1.2209316492080688 
norm clip needed:  tensor(22.3521, device='cuda:0') w_out.bias torch.Size([1])
0.3448455333709717 0.0006536802975460887
train 25, step: 0, loss: 0.34811392426490784, grad_norm: 512.5644417642541, ic: -0.06187406981559399
norm clip needed:  tensor(23.6491, device='cuda:0') w_out.bias torch.Size([1])
0.3868907690048218 0.00019835203420370817
train 25, step: 500, loss: 0.3878825306892395, grad_norm: 563.1925844158884, ic: 0.03855993863914571
Epoch 25: 2022-05-06 21:25:16.874770: train loss: 0.45200871323598896
Eval step 0: eval loss: 0.0001334516127826646
Eval: 2022-05-06 21:25:26.218969: total loss: 0.00018957120905387293, mse:0.0003791424136644032, ic :0.02255696325370215, sharpe5:-1.0654640002548694, irr5:-0.2528124153614044, ndcg5:0.8439800693865208, pnl5:0.9277267456054688 
0.29192090034484863 0.00043668795842677355
train 26, step: 0, loss: 0.29410433769226074, grad_norm: 84.89009328042127, ic: -0.004252978721940814
0.13787101209163666 0.0003621901851147413
train 26, step: 500, loss: 0.13968196511268616, grad_norm: 31.85447455941, ic: -0.04999791232249213
Epoch 26: 2022-05-06 21:26:19.181577: train loss: 0.4496866143184072
Eval step 0: eval loss: 0.00015148920647334307
Eval: 2022-05-06 21:26:28.480147: total loss: 0.00018989100391284143, mse:0.0003797820045114236, ic :-0.007899791175086459, sharpe5:-5.5241957563161845, irr5:-0.8368232846260071, ndcg5:0.8611161461520714, pnl5:0.6089285016059875 
0.4086039960384369 0.0010799352312460542
train 27, step: 0, loss: 0.4140036702156067, grad_norm: 294.38945111309494, ic: -0.024237171353414893
0.35122501850128174 0.0007154261111281812
train 27, step: 500, loss: 0.3548021614551544, grad_norm: 124.03746000652197, ic: 0.10326226296010557
Epoch 27: 2022-05-06 21:27:19.327270: train loss: 0.44972739470275963
Eval step 0: eval loss: 0.00013183265400584787
Eval: 2022-05-06 21:27:28.776818: total loss: 0.0001899020255588536, mse:0.0003798040487121514, ic :0.020834235729513203, sharpe5:-0.21945971664972602, irr5:-0.04506296291947365, ndcg5:0.8621586119452238, pnl5:0.9544184803962708 
0.6703867316246033 0.00121691997628659
train 28, step: 0, loss: 0.6764713525772095, grad_norm: 3.178818026674043, ic: -0.03785624090050538
0.4005614221096039 0.00044040707871317863
train 28, step: 500, loss: 0.4027634561061859, grad_norm: 297.8692948443941, ic: 0.060148246880962916
Epoch 28: 2022-05-06 21:28:19.148103: train loss: 0.44660442995833843
Eval step 0: eval loss: 0.00014664656191598624
Eval: 2022-05-06 21:28:29.000440: total loss: 0.00018913779983080426, mse:0.0003782755965137433, ic :-0.019564207898214878, sharpe5:-3.6882823576033115, irr5:-0.62518310546875, ndcg5:0.8575063110420371, pnl5:0.7631295919418335 
0.3934885859489441 0.0004356460412964225
train 29, step: 0, loss: 0.39566680788993835, grad_norm: 15.985408726683607, ic: 0.0350604839856238
0.2462930828332901 0.001140786916948855
train 29, step: 500, loss: 0.2519970238208771, grad_norm: 16.40717360327745, ic: -0.025812927110195717
Epoch 29: 2022-05-06 21:29:20.235664: train loss: 0.4500549035595063
Eval step 0: eval loss: 0.0001659326662775129
Eval: 2022-05-06 21:29:29.443737: total loss: 0.0001932160204935282, mse:0.0003864320355330547, ic :0.024925260890845468, sharpe5:1.492695132046938, irr5:0.43669840693473816, ndcg5:0.853529722769298, pnl5:1.340341329574585 
0.38360410928726196 0.0005292094429023564
train 30, step: 0, loss: 0.38625016808509827, grad_norm: 238.02287629685407, ic: 0.00029492786782214786
0.45983144640922546 0.001034542452543974
train 30, step: 500, loss: 0.4650041460990906, grad_norm: 5.763200781616973, ic: -0.03010341107752193
Epoch 30: 2022-05-06 21:30:20.968677: train loss: 0.4509561588778534
Eval step 0: eval loss: 0.00018305082630831748
Eval: 2022-05-06 21:30:30.230965: total loss: 0.00019920154333731777, mse:0.00039840307962007293, ic :0.024679653277660765, sharpe5:-0.9890780750289558, irr5:-0.2154676616191864, ndcg5:0.8441497194390547, pnl5:0.9208970665931702 
0.31127476692199707 0.0009252868476323783
train 31, step: 0, loss: 0.3159011900424957, grad_norm: 383.13918925169503, ic: -0.027630317481908848
0.273730605840683 0.0012126668589189649
train 31, step: 500, loss: 0.27979394793510437, grad_norm: 138.48094125795006, ic: -0.039188797622189575
Epoch 31: 2022-05-06 21:31:21.742686: train loss: 0.4499384614833217
Eval step 0: eval loss: 0.00012432380754034966
Eval: 2022-05-06 21:31:31.146387: total loss: 0.00019318219755321749, mse:0.00038636439052787907, ic :0.0034480279233078427, sharpe5:-1.4576432635635137, irr5:-0.2970479726791382, ndcg5:0.8468583114789514, pnl5:0.9247899055480957 
0.40391337871551514 0.0002887099690269679
train 32, step: 0, loss: 0.40535691380500793, grad_norm: 126.7725450522733, ic: 0.008333185489782305
0.36354100704193115 0.0006345076835714281
train 32, step: 500, loss: 0.3667135536670685, grad_norm: 16.697392891989022, ic: 0.06472222019189244
Epoch 32: 2022-05-06 21:32:23.286606: train loss: 0.4477184233579406
Eval step 0: eval loss: 0.00012417168181855232
Eval: 2022-05-06 21:32:32.840713: total loss: 0.00019342870960255076, mse:0.0003868574132300609, ic :0.016530173058061013, sharpe5:-0.9357868669554591, irr5:-0.20073625445365906, ndcg5:0.8568272128798133, pnl5:0.9643611907958984 
0.37314918637275696 0.0013770462246611714
train 33, step: 0, loss: 0.3800344169139862, grad_norm: 65.84993303186138, ic: 0.017001156208325673
0.17304077744483948 0.0006743870908394456
train 33, step: 500, loss: 0.17641271650791168, grad_norm: 25.273005827145163, ic: 0.005313801556164574
Epoch 33: 2022-05-06 21:33:24.783598: train loss: 0.4496060055307048
Eval step 0: eval loss: 0.0001615531073184684
Eval: 2022-05-06 21:33:34.206973: total loss: 0.00019230688555449792, mse:0.0003846137658124237, ic :0.02438957089486992, sharpe5:0.535727983340621, irr5:0.13767309486865997, ndcg5:0.8552410923044935, pnl5:1.1392033100128174 
0.35193583369255066 0.0003579577023629099
train 34, step: 0, loss: 0.3537256121635437, grad_norm: 0.6131832414664521, ic: 0.013832061797897708
0.25893649458885193 0.0004734181857202202
train 34, step: 500, loss: 0.261303573846817, grad_norm: 62.744735933688474, ic: 0.09160421154391313
Epoch 34: 2022-05-06 21:34:25.525420: train loss: 0.44762370331003704
Eval step 0: eval loss: 0.00012622402573470026
Eval: 2022-05-06 21:34:34.738435: total loss: 0.00019205519362702544, mse:0.0003841103852827531, ic :0.024637446325425628, sharpe5:-1.2062230671197176, irr5:-0.2611387073993683, ndcg5:0.8449370988729484, pnl5:0.9157577157020569 
norm clip needed:  tensor(38.8107, device='cuda:0') w_out.bias torch.Size([1])
0.698390007019043 0.00047914739116095006
train 35, step: 0, loss: 0.700785756111145, grad_norm: 1514.667449844549, ic: 0.058128750499936356
norm clip needed:  tensor(30.0753, device='cuda:0') w_out.bias torch.Size([1])
0.7195087671279907 0.0025725183077156544
train 35, step: 500, loss: 0.7323713302612305, grad_norm: 918.4722296197427, ic: -0.039795913667802
Epoch 35: 2022-05-06 21:35:26.276766: train loss: 0.4479834580007084
Eval step 0: eval loss: 0.00013752738595940173
Eval: 2022-05-06 21:35:34.976144: total loss: 0.00018899602792378287, mse:0.00037799205337980243, ic :0.021025693659307333, sharpe5:-0.37365522963926195, irr5:-0.08619718253612518, ndcg5:0.8436873081042516, pnl5:0.9774662256240845 
norm clip needed:  tensor(23.9205, device='cuda:0') w_out.bias torch.Size([1])
0.4835623800754547 0.0004317219427321106
train 36, step: 0, loss: 0.48572099208831787, grad_norm: 573.9122335618134, ic: -0.06503958838543253
norm clip needed:  tensor(26.7335, device='cuda:0') w_out.bias torch.Size([1])
0.9765779972076416 0.0016278356779366732
train 36, step: 500, loss: 0.9847171902656555, grad_norm: 724.3271295968452, ic: -0.003251714531853484
Epoch 36: 2022-05-06 21:36:26.548509: train loss: 0.4451374782119843
Eval step 0: eval loss: 0.00017909753660205752
Eval: 2022-05-06 21:36:35.929396: total loss: 0.00019756681708376, mse:0.0003951336242689269, ic :0.022091633762849103, sharpe5:-0.5054076943919062, irr5:-0.1184445172548294, ndcg5:0.8507800280260852, pnl5:0.9696527719497681 
norm clip needed:  tensor(39.5750, device='cuda:0') w_out.bias torch.Size([1])
0.6957303285598755 0.00018583510245662183
train 37, step: 0, loss: 0.696659505367279, grad_norm: 1576.4916831312212, ic: 0.17878774410469908
0.3457562327384949 0.001959568355232477
train 37, step: 500, loss: 0.35555407404899597, grad_norm: 35.37697437459107, ic: -0.012930484721568884
Epoch 37: 2022-05-06 21:37:28.176162: train loss: 0.44834363660750226
Eval step 0: eval loss: 0.00014170503709465265
Eval: 2022-05-06 21:37:37.691967: total loss: 0.00018902107116620882, mse:0.00037804214018057096, ic :0.01844955059573503, sharpe5:-0.1778359701577574, irr5:-0.04089732468128204, ndcg5:0.8526135982362743, pnl5:0.959229052066803 
0.3239365518093109 0.0005311524728313088
train 38, step: 0, loss: 0.3265923261642456, grad_norm: 4.534240857153461, ic: 0.05483395093764299
0.6532557010650635 0.0015597962774336338
train 38, step: 500, loss: 0.6610546708106995, grad_norm: 153.96281363132178, ic: -0.013079179646650202
Epoch 38: 2022-05-06 21:38:29.556727: train loss: 0.446514731004117
Eval step 0: eval loss: 0.0001358484587399289
Eval: 2022-05-06 21:38:39.003114: total loss: 0.0001891163468127562, mse:0.0003782326921426107, ic :0.027963498505994867, sharpe5:-0.5732300359010696, irr5:-0.121100053191185, ndcg5:0.8521256133543654, pnl5:0.8964883685112 
norm clip needed:  tensor(29.5091, device='cuda:0') w_out.bias torch.Size([1])
0.6928462386131287 0.0013240126427263021
train 39, step: 0, loss: 0.6994662880897522, grad_norm: 885.3264414171285, ic: -0.01370280088412822
0.4118454158306122 0.0005038173985667527
train 39, step: 500, loss: 0.4143645167350769, grad_norm: 73.49169575009604, ic: 0.02478576463618648
Epoch 39: 2022-05-06 21:39:31.000323: train loss: 0.4473965112119913
Eval step 0: eval loss: 0.00016815477283671498
Eval: 2022-05-06 21:39:40.558421: total loss: 0.00019378871912407124, mse:0.0003875774347572107, ic :0.00998049106577861, sharpe5:-4.457006151080131, irr5:-0.8060651421546936, ndcg5:0.8568580628601385, pnl5:0.6775586605072021 
0.46421951055526733 0.0007249844493344426
train 40, step: 0, loss: 0.4678444266319275, grad_norm: 192.75330697329815, ic: -0.016303933717212303
0.6508231163024902 0.0010421897750347853
train 40, step: 500, loss: 0.6560340523719788, grad_norm: 192.22598196488946, ic: -0.037619746678295235
Epoch 40: 2022-05-06 21:40:31.555304: train loss: 0.44730558187606184
Eval step 0: eval loss: 0.00011743920185836032
Eval: 2022-05-06 21:40:41.081906: total loss: 0.00020372092720160798, mse:0.00040744185305897137, ic :0.03463142461959334, sharpe5:-0.6215852853655814, irr5:-0.12840229272842407, ndcg5:0.8591221229670033, pnl5:0.8652855753898621 
0.37194496393203735 0.0018585907528176904
train 41, step: 0, loss: 0.3812379240989685, grad_norm: 155.07915500709328, ic: -0.008369843373887343
0.29938042163848877 0.0002297164173796773
train 41, step: 500, loss: 0.30052900314331055, grad_norm: 276.6647599666168, ic: 0.002218836326863183
Epoch 41: 2022-05-06 21:41:32.052264: train loss: 0.4469866422527933
Eval step 0: eval loss: 0.00017211477097589523
Eval: 2022-05-06 21:41:41.425302: total loss: 0.00019510718386983255, mse:0.00039021436669321063, ic :-0.01598383168917952, sharpe5:-6.074237369298935, irr5:-1.2094279527664185, ndcg5:0.8519316224051848, pnl5:0.6795787811279297 
0.24576407670974731 0.0004889746196568012
train 42, step: 0, loss: 0.24820895493030548, grad_norm: 175.0968561068997, ic: -0.02528105074426841
0.616884708404541 0.0003092613478656858
train 42, step: 500, loss: 0.618431031703949, grad_norm: 2.4447369477190994, ic: 0.006629562934894528
Epoch 42: 2022-05-06 21:42:30.463483: train loss: 0.44835106125051644
Eval step 0: eval loss: 0.00012862682342529297
Eval: 2022-05-06 21:42:39.800541: total loss: 0.00019089843900914927, mse:0.0003817968698691636, ic :0.017372564763603278, sharpe5:-0.9433961889892816, irr5:-0.20392858982086182, ndcg5:0.8465313352810112, pnl5:0.9132674336433411 
norm clip needed:  tensor(20.2802, device='cuda:0') w_out.bias torch.Size([1])
0.3707873225212097 0.0020293681882321835
train 43, step: 0, loss: 0.3809341788291931, grad_norm: 417.41193542133254, ic: -0.009882065075416113
0.41497254371643066 0.0002011773904087022
train 43, step: 500, loss: 0.41597843170166016, grad_norm: 386.01665927975824, ic: 0.04108604142126417
Epoch 43: 2022-05-06 21:43:31.463833: train loss: 0.4493891030430475
Eval step 0: eval loss: 0.00013869894610252231
Eval: 2022-05-06 21:43:41.149924: total loss: 0.00018876458285757702, mse:0.0003775291637620543, ic :0.03219051695362018, sharpe5:-1.1488514902442692, irr5:-0.24699339270591736, ndcg5:0.8570665934621461, pnl5:0.9589146971702576 
0.46086421608924866 0.001141923014074564
train 44, step: 0, loss: 0.4665738344192505, grad_norm: 39.109499965469524, ic: -0.0348207328304118
0.34527847170829773 0.0003941909526474774
train 44, step: 500, loss: 0.34724941849708557, grad_norm: 245.33264233997596, ic: 0.05720044260713217
Epoch 44: 2022-05-06 21:44:33.473505: train loss: 0.44587458973939725
Eval step 0: eval loss: 0.00012494168186094612
Eval: 2022-05-06 21:44:43.020318: total loss: 0.00019285623258687393, mse:0.00038571245751317136, ic :0.03462146967173983, sharpe5:-1.2116395559906958, irr5:-0.26128509640693665, ndcg5:0.8554569119398783, pnl5:0.9487181305885315 
0.7469757199287415 0.0011450567981228232
train 45, step: 0, loss: 0.7527009844779968, grad_norm: 49.33364299927463, ic: -0.01108098339960043
0.22777323424816132 0.00053490384016186
train 45, step: 500, loss: 0.23044775426387787, grad_norm: 0.6960958152381181, ic: 0.048957629524632534
Epoch 45: 2022-05-06 21:45:34.908987: train loss: 0.44726374963507615
Eval step 0: eval loss: 0.0001617098751012236
Eval: 2022-05-06 21:45:44.270143: total loss: 0.0001922711906913977, mse:0.00038454237621304567, ic :0.02929024806628316, sharpe5:-1.0567478860169648, irr5:-0.23232197761535645, ndcg5:0.852622884326685, pnl5:0.9417338371276855 
norm clip needed:  tensor(22.7661, device='cuda:0') w_out.bias torch.Size([1])
0.5562921166419983 0.0022242481354624033
train 46, step: 0, loss: 0.567413330078125, grad_norm: 526.5909056847814, ic: 0.011792165656243131
0.2074340283870697 0.0006509926170110703
train 46, step: 500, loss: 0.2106889933347702, grad_norm: 10.118251467568884, ic: -0.001452887296799682
Epoch 46: 2022-05-06 21:46:36.643011: train loss: 0.4465384150153016
Eval step 0: eval loss: 0.00014174745592754334
Eval: 2022-05-06 21:46:45.990985: total loss: 0.00018886939140659955, mse:0.0003777387793762825, ic :0.029246407799821482, sharpe5:-1.2657602226734161, irr5:-0.27200576663017273, ndcg5:0.860325879508887, pnl5:0.9555811882019043 
norm clip needed:  tensor(23.4062, device='cuda:0') w_out.bias torch.Size([1])
0.540765643119812 0.00021926566842012107
train 47, step: 0, loss: 0.5418619513511658, grad_norm: 627.9369251393259, ic: 0.03284138281910824
0.2780773639678955 0.000397829688154161
train 47, step: 500, loss: 0.28006651997566223, grad_norm: 0.19122579609764057, ic: 0.024558948998615784
Epoch 47: 2022-05-06 21:47:39.331006: train loss: 0.44963105881516946
Eval step 0: eval loss: 0.00014664472837466747
Eval: 2022-05-06 21:47:48.735181: total loss: 0.00018916392884309725, mse:0.0003783278516437975, ic :0.01758586391886996, sharpe5:0.09964481960982084, irr5:0.017941325902938843, ndcg5:0.8439291841023419, pnl5:0.9563049077987671 
0.4490046799182892 0.0009210427524521947
train 48, step: 0, loss: 0.4536098837852478, grad_norm: 275.31384146048475, ic: -0.04152446973423875
0.3269960582256317 0.0006149370456114411
train 48, step: 500, loss: 0.33007073402404785, grad_norm: 56.210773273432935, ic: 0.01757385477721568
Epoch 48: 2022-05-06 21:48:40.528391: train loss: 0.4466495659939427
Eval step 0: eval loss: 0.00014242230099625885
Eval: 2022-05-06 21:48:50.038581: total loss: 0.0001888734436701723, mse:0.00037774688610639555, ic :0.027953318309080273, sharpe5:-0.8522459005191921, irr5:-0.19047172367572784, ndcg5:0.8437365491424657, pnl5:0.897780179977417 
0.363371878862381 0.0023049707524478436
train 49, step: 0, loss: 0.37489673495292664, grad_norm: 0.84627024730304, ic: -0.02480401072182062
0.15713542699813843 0.00035094658960588276
train 49, step: 500, loss: 0.15889015793800354, grad_norm: 5.665291078270149, ic: -0.04451434355908383
Epoch 49: 2022-05-06 21:49:40.340592: train loss: 0.4450049073420425
Eval step 0: eval loss: 0.00013446847151499242
Eval: 2022-05-06 21:49:49.758463: total loss: 0.00018927276830441077, mse:0.00037854553026859546, ic :0.03018898668509699, sharpe5:-1.5170729383081196, irr5:-0.33201757073402405, ndcg5:0.8466598528149063, pnl5:0.8543044924736023 
norm clip needed:  tensor(21.9202, device='cuda:0') w_out.bias torch.Size([1])
0.7513130307197571 0.0010322214802727103
train 50, step: 0, loss: 0.7564741373062134, grad_norm: 482.85120340462487, ic: 0.010189086975065868
0.37885618209838867 0.0017005447298288345
train 50, step: 500, loss: 0.3873589038848877, grad_norm: 347.6927633429982, ic: -0.001085775255677584
Epoch 50: 2022-05-06 21:50:40.249253: train loss: 0.4486004170627996
Eval step 0: eval loss: 0.0001512846938567236
Eval: 2022-05-06 21:50:49.651471: total loss: 0.00018961048597575665, mse:0.0003792209718995511, ic :0.019968737870690152, sharpe5:-1.586132728010416, irr5:-0.33569812774658203, ndcg5:0.8433434966014415, pnl5:0.9162740111351013 
0.29364287853240967 0.0008809308055788279
train 51, step: 0, loss: 0.2980475425720215, grad_norm: 233.81062565994014, ic: 0.016973620183180677
0.22127781808376312 0.0014283093623816967
train 51, step: 500, loss: 0.22841936349868774, grad_norm: 11.416793869074308, ic: 0.012067848270821859
Epoch 51: 2022-05-06 21:51:41.587995: train loss: 0.44645386267911624
Eval step 0: eval loss: 0.00014373729936778545
Eval: 2022-05-06 21:51:50.993141: total loss: 0.00018887802345655844, mse:0.0003777560471002526, ic :0.02832446109278423, sharpe5:-0.8829149404540657, irr5:-0.19967657327651978, ndcg5:0.8528823904158863, pnl5:0.904639720916748 
0.45353424549102783 0.0007289854693226516
train 52, step: 0, loss: 0.45717915892601013, grad_norm: 4.9728681609302985, ic: 0.025625702789513913
norm clip needed:  tensor(31.9212, device='cuda:0') w_out.bias torch.Size([1])
0.871837854385376 0.0007369990344159305
train 52, step: 500, loss: 0.8755228519439697, grad_norm: 1024.1665543272095, ic: 0.06891545545908134
Epoch 52: 2022-05-06 21:52:43.220543: train loss: 0.4475454075092619
Eval step 0: eval loss: 0.00015318857913371176
Eval: 2022-05-06 21:52:52.625445: total loss: 0.0001900189482913491, mse:0.00038003789316444616, ic :0.03211075430889415, sharpe5:-0.6883359521627426, irr5:-0.16182798147201538, ndcg5:0.8626727270373955, pnl5:0.9880982637405396 
norm clip needed:  tensor(21.1093, device='cuda:0') w_out.bias torch.Size([1])
0.44699475169181824 0.002169509418308735
train 53, step: 0, loss: 0.45784229040145874, grad_norm: 447.6833053283263, ic: -0.03808443346189738

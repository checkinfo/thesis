Namespace(adj_path='./data/graphs/NASDAQ_1026_1026.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='NASDAQAdjSeqTimeDataset', dout=0.3, epochs=40, glstm_layers=1, gnn_layers=1, gpu=0, graph_attn=True, hidden_dim=128, inner_prod=False, input_dim=5, input_graph=True, label_cnt=1, lr=0.0004, lstm_layers=1, market='NASDAQ', mask_adj=True, mask_type='soft', model_type='BiGLSTM', normalize_adj=True, num_days=8, num_heads=1, print_inteval=100, rank_loss=False, relation_num=1, rsr_data_path='../Temporal_Relational_Stock_Ranking/data/2013-01-01', seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_250_0.8/', stock_num=1931, test_mask_path='./data/NASDAQ/test_mask_237_1026.npy', test_path='./data/NASDAQ/test_237_1026_6.npy', top_stocks=5, train_mask_path='./data/NASDAQ/train_mask_756_1026.npy', train_path='./data/NASDAQ/train_756_1026_6.npy', use_adj=True)
#tickers selected: 1026
single EOD data shape: (1245, 6)
(1026, 1245, 5) (1026, 1245) (1026, 1245) (1026, 1245)
#tickers selected: 1026
single EOD data shape: (1245, 6)
(1026, 1245, 5) (1026, 1245) (1026, 1245) (1026, 1245)
14158
BiGLSTM(
  (input_to_hidden): Linear(in_features=5, out_features=128, bias=True)
  (forward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (attention): ModuleList(
            (0): GraphAttentionLayer (128 -> 128)
          )
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
          (lin_gate): Linear(in_features=128, out_features=128, bias=True)
        )
      )
    )
  )
  (backward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (attention): ModuleList(
            (0): GraphAttentionLayer (128 -> 128)
          )
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
          (lin_gate): Linear(in_features=128, out_features=128, bias=True)
        )
      )
    )
  )
  (fc0): ModuleList(
    (0): Linear(in_features=256, out_features=128, bias=True)
  )
  (w_out): Linear(in_features=128, out_features=1, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
)
train 0, step: 0, loss: 0.013495445251464844, grad_norm: 0.18257718841530407, ic: 0.034132549935573096
train 0, step: 100, loss: 0.00032152479980140924, grad_norm: 2.734646193449534e-06, ic: 0.016207708015733735
train 0, step: 200, loss: 0.00022107793483883142, grad_norm: 1.7558244787799172e-05, ic: 0.05330037299802255
train 0, step: 300, loss: 0.0002878156956285238, grad_norm: 2.6904730612548934e-05, ic: -0.015439690829764732
train 0, step: 400, loss: 0.00017100655531976372, grad_norm: 1.9436353761946327e-05, ic: 0.028782458979905435
train 0, step: 500, loss: 0.0001696884137345478, grad_norm: 8.466200090126234e-06, ic: 0.0047550024624613205
train 0, step: 600, loss: 0.0002222751936642453, grad_norm: 8.124378695807227e-05, ic: 0.004126326554708886
train 0, step: 700, loss: 0.00023975479416549206, grad_norm: 8.54975409066095e-06, ic: -0.006890556337701012
Epoch 0: 2022-05-05 17:13:52.719576: train loss: 0.00041881561150936534
Eval step 0: eval loss: 0.00016378391592297703
Eval step 100: eval loss: 0.0003474509285297245
Eval step 200: eval loss: 0.00027853884967043996
Eval: 2022-05-05 17:14:02.308958: total loss: 0.00019246883508998404, mse:0.00038493766735812624, ic :0.03174862449618927, sharpe5:0.9053863516822457, irr5:0.22380560636520386, ndcg5:0.8493843538337422, pnl5:1.0035187005996704 
train 1, step: 0, loss: 0.0001394768332829699, grad_norm: 6.186940506679985e-05, ic: 0.013948079632834825
train 1, step: 100, loss: 0.000228727119974792, grad_norm: 5.172604703239419e-06, ic: 0.0069919362372373
train 1, step: 200, loss: 0.00013010232942178845, grad_norm: 3.697241142823588e-07, ic: -0.02515031176145087
train 1, step: 300, loss: 0.00010617968655424193, grad_norm: 1.6442888435813564e-05, ic: 0.028102242840534926
train 1, step: 400, loss: 9.486568887950853e-05, grad_norm: 2.9683083877848067e-05, ic: 0.03885402112018002
train 1, step: 500, loss: 0.00017025823763106018, grad_norm: 8.775059882616404e-05, ic: -0.01637905296234069
train 1, step: 600, loss: 0.00028144571115262806, grad_norm: 1.9787161348504194e-05, ic: -0.00240334105610069
train 1, step: 700, loss: 0.00048398468061350286, grad_norm: 0.0006420960453890363, ic: 0.043222157016672196
Epoch 1: 2022-05-05 17:14:53.778461: train loss: 0.0002317476731096737
Eval step 0: eval loss: 0.00016448220412712544
Eval step 100: eval loss: 0.0003496210847515613
Eval step 200: eval loss: 0.00027544028125703335
Eval: 2022-05-05 17:15:03.398563: total loss: 0.0001929009868750678, mse:0.00038580196982758967, ic :0.01887686914529059, sharpe5:-0.7434434558451175, irr5:-0.15724945068359375, ndcg5:0.8562098048405564, pnl5:1.0354840755462646 
train 2, step: 0, loss: 0.00016049672558438033, grad_norm: 4.030556620070005e-05, ic: 0.015667239646374117
train 2, step: 100, loss: 0.0002731525164563209, grad_norm: 0.00019371390685517497, ic: -0.10349689894118638
train 2, step: 200, loss: 0.00025677168741822243, grad_norm: 0.0002920245658310497, ic: 0.05836241631021742
train 2, step: 300, loss: 0.0005498902755789459, grad_norm: 0.0006490238324103102, ic: -0.0034256256852364473
train 2, step: 400, loss: 8.004970732145011e-05, grad_norm: 2.1161700071371407e-05, ic: 0.0015539590640218648
train 2, step: 500, loss: 0.00011541128333192319, grad_norm: 4.275534447395572e-08, ic: 0.010541479699169971
train 2, step: 600, loss: 0.00018432065553497523, grad_norm: 7.456592814033901e-05, ic: -0.023809952800727723
train 2, step: 700, loss: 0.00015017989790067077, grad_norm: 2.295303691587702e-05, ic: 0.0031058434422924913
Epoch 2: 2022-05-05 17:15:55.312106: train loss: 0.00022025429096048321
Eval step 0: eval loss: 0.00012856915418524295
Eval step 100: eval loss: 0.00029647466726601124
Eval step 200: eval loss: 0.0003275881172157824
Eval: 2022-05-05 17:16:03.681266: total loss: 0.00019046448815617035, mse:0.00038092897310322354, ic :0.019220418375778255, sharpe5:-0.9863552278652786, irr5:-0.21452876925468445, ndcg5:0.8463978805585012, pnl5:0.9904244542121887 
train 3, step: 0, loss: 0.0001405528892064467, grad_norm: 4.839398810798186e-06, ic: 0.014701994236229789
train 3, step: 100, loss: 0.0002004003617912531, grad_norm: 0.0001708311892127215, ic: -0.012745208406857233
train 3, step: 200, loss: 0.00022919887851458043, grad_norm: 3.989182050889619e-06, ic: -0.036138022949730175
train 3, step: 300, loss: 0.00018013738736044616, grad_norm: 2.395658365120911e-05, ic: -0.02182109379063961
train 3, step: 400, loss: 0.0002804789401125163, grad_norm: 0.00034046787725635795, ic: -0.05414699045095694
train 3, step: 500, loss: 0.0002608363574836403, grad_norm: 0.00016194498494880857, ic: 0.04359926950489795
train 3, step: 600, loss: 0.00015062621969264, grad_norm: 6.17920090476549e-05, ic: 0.003101797384524144
train 3, step: 700, loss: 0.00033459020778536797, grad_norm: 0.0002719030640733466, ic: -0.0453179554836423
Epoch 3: 2022-05-05 17:16:57.313539: train loss: 0.0002171062668904514
Eval step 0: eval loss: 0.00017338586621917784
Eval step 100: eval loss: 0.00036137571441940963
Eval step 200: eval loss: 0.00026933723711408675
Eval: 2022-05-05 17:17:06.848313: total loss: 0.00019570854195728125, mse:0.0003914170784370449, ic :0.017958409261636894, sharpe5:-1.0317845517396926, irr5:-0.22339147329330444, ndcg5:0.8547177037163732, pnl5:0.9812489151954651 
train 4, step: 0, loss: 0.00015562589396722615, grad_norm: 3.1217710500942344e-05, ic: 0.0019035900423441023
train 4, step: 100, loss: 0.00012201281788293272, grad_norm: 4.4046614745321825e-06, ic: -0.0015085529730879859
train 4, step: 200, loss: 0.00019040169718209654, grad_norm: 8.531972247200579e-05, ic: -0.02010065482787086
train 4, step: 300, loss: 0.0004979387740604579, grad_norm: 0.0002286056479804854, ic: -0.04900972285983224
train 4, step: 400, loss: 0.00046872958773747087, grad_norm: 0.0003181493298675703, ic: -0.021571825376012627
train 4, step: 500, loss: 0.00024293060414493084, grad_norm: 7.364220891466767e-05, ic: -0.029645214830513557
train 4, step: 600, loss: 0.0002615410485304892, grad_norm: 0.00022906818859174562, ic: 0.011716011561414913
train 4, step: 700, loss: 0.0002225518401246518, grad_norm: 0.00017285174533713594, ic: -0.004852467057052411
Epoch 4: 2022-05-05 17:17:58.668934: train loss: 0.0002128053596422243
Eval step 0: eval loss: 0.00012713011528830975
Eval step 100: eval loss: 0.00029369338881224394
Eval step 200: eval loss: 0.00033266551326960325
Eval: 2022-05-05 17:18:08.271377: total loss: 0.00019110826755478353, mse:0.00038221653112425525, ic :0.018582381974540298, sharpe5:-1.0694255371391772, irr5:-0.2306233048439026, ndcg5:0.8567123440358404, pnl5:0.9739316701889038 
train 5, step: 0, loss: 0.00020747874805238098, grad_norm: 3.6975461661872404e-05, ic: 0.0014428155256565687
train 5, step: 100, loss: 0.00021322074462659657, grad_norm: 4.549990084784624e-06, ic: 0.054350341085875706
train 5, step: 200, loss: 9.524470806354657e-05, grad_norm: 1.574169625148452e-05, ic: -0.014743563737915924
train 5, step: 300, loss: 0.00019683111167978495, grad_norm: 1.7456321689492356e-05, ic: 0.03832095161440027
train 5, step: 400, loss: 0.000512467697262764, grad_norm: 0.0004337667032153126, ic: -0.033361861615866475
train 5, step: 500, loss: 0.0006575194420292974, grad_norm: 0.000684609552578233, ic: -0.011411287222710453
train 5, step: 600, loss: 0.00017651828238740563, grad_norm: 4.2650628565908664e-06, ic: -0.04651744102297012
train 5, step: 700, loss: 0.00014575525710824877, grad_norm: 1.837939418100115e-05, ic: -0.029889854642808175
Epoch 5: 2022-05-05 17:19:00.077541: train loss: 0.0002106601731305183
Eval step 0: eval loss: 0.00018999249732587487
Eval step 100: eval loss: 0.00038316159043461084
Eval step 200: eval loss: 0.00025956323952414095
Eval: 2022-05-05 17:19:09.626673: total loss: 0.00020221351991193043, mse:0.0004044270353928257, ic :0.017470366811016623, sharpe5:-1.092948344796896, irr5:-0.2349841594696045, ndcg5:0.8496735466193777, pnl5:0.986877977848053 
train 6, step: 0, loss: 0.00020743263303302228, grad_norm: 0.00021595686519441102, ic: 0.050423927249982986
train 6, step: 100, loss: 0.00011045340943383053, grad_norm: 7.680835960943036e-07, ic: 0.023278433852114002
train 6, step: 200, loss: 0.00019667505694087595, grad_norm: 5.6500096540697025e-05, ic: 0.04555675808659485
train 6, step: 300, loss: 0.00021163983910810202, grad_norm: 4.362557647327637e-05, ic: -0.03095453820612468
train 6, step: 400, loss: 0.00035030339495278895, grad_norm: 4.9961179400647005e-05, ic: 0.03211767218395775
train 6, step: 500, loss: 0.00010401766485301778, grad_norm: 1.92940972588127e-05, ic: 0.06886985898179968
train 6, step: 600, loss: 0.00013044223305769265, grad_norm: 1.1189938620874693e-06, ic: 0.01004263068331408
train 6, step: 700, loss: 0.00014552952779922634, grad_norm: 5.7299459803030206e-05, ic: 0.02767336027874942
Epoch 6: 2022-05-05 17:20:01.451792: train loss: 0.000209824721778545
Eval step 0: eval loss: 0.00014356289466377348
Eval step 100: eval loss: 0.00031941200722940266
Eval step 200: eval loss: 0.00030076998518779874
Eval: 2022-05-05 17:20:11.035745: total loss: 0.00018871300496027792, mse:0.0003774260058914811, ic :0.01787224890445692, sharpe5:-1.129772286862135, irr5:-0.24282929301261902, ndcg5:0.8536889401597009, pnl5:0.9976474046707153 
train 7, step: 0, loss: 0.0002075762313324958, grad_norm: 1.1460993631330634e-05, ic: 0.09160259866631937
train 7, step: 100, loss: 0.00043945605284534395, grad_norm: 0.0005743201428027702, ic: -0.09256908717176258
train 7, step: 200, loss: 0.00027574654086492956, grad_norm: 0.00010959221870082814, ic: -0.02460018168171796
train 7, step: 300, loss: 0.00017548979667481035, grad_norm: 0.00011550970681926105, ic: 0.0062389107697017505
train 7, step: 400, loss: 0.00015917234122753143, grad_norm: 5.484535623609354e-07, ic: -0.042012778207435146
train 7, step: 500, loss: 0.0003789789916481823, grad_norm: 0.00017001166237434596, ic: 0.074834773292742
train 7, step: 600, loss: 0.0001189577451441437, grad_norm: 8.869686683965912e-06, ic: 0.07408734219184024
train 7, step: 700, loss: 0.000285584683297202, grad_norm: 6.943816701356566e-05, ic: 0.0326123292680979
Epoch 7: 2022-05-05 17:21:02.784514: train loss: 0.0002088039375941302
Eval step 0: eval loss: 0.00014124622975941747
Eval step 100: eval loss: 0.00031604719697497785
Eval step 200: eval loss: 0.000304001965560019
Eval: 2022-05-05 17:21:12.410000: total loss: 0.00018862066441596847, mse:0.0003772413237218914, ic :0.01814070354237545, sharpe5:-1.0858460980653761, irr5:-0.23351514339447021, ndcg5:0.8441621432967643, pnl5:0.9882744550704956 
train 8, step: 0, loss: 0.00015189249825198203, grad_norm: 7.263659111508497e-06, ic: 0.057616213786085245
train 8, step: 100, loss: 0.00015684240497648716, grad_norm: 9.41881897651951e-05, ic: 0.004822592374308349
train 8, step: 200, loss: 0.00014551181811839342, grad_norm: 7.572627096093941e-05, ic: 0.0917822947290409
train 8, step: 300, loss: 0.00014472432667389512, grad_norm: 6.123590371067476e-08, ic: -0.06172966927094997
train 8, step: 400, loss: 0.00011058383825002238, grad_norm: 1.058272956489609e-05, ic: 0.035319731147595984
train 8, step: 500, loss: 0.00016050972044467926, grad_norm: 4.931882144750542e-05, ic: 0.0345237468451062
train 8, step: 600, loss: 0.00012164989311713725, grad_norm: 1.5625139735430333e-05, ic: -0.01573588567995575
train 8, step: 700, loss: 0.00010537773778196424, grad_norm: 9.18817160893808e-06, ic: 0.08207049601526066
Epoch 8: 2022-05-05 17:22:03.478533: train loss: 0.00020803409515695464
Eval step 0: eval loss: 0.0001469047856517136
Eval step 100: eval loss: 0.0003246990963816643
Eval step 200: eval loss: 0.00029501033714041114
Eval: 2022-05-05 17:22:12.978219: total loss: 0.00018903552417289546, mse:0.0003780710417627097, ic :0.018531223264649954, sharpe5:-1.0190286252647638, irr5:-0.22044014930725098, ndcg5:0.8527558125774679, pnl5:0.9665912389755249 
train 9, step: 0, loss: 0.00013876959565095603, grad_norm: 1.4800604000756361e-05, ic: 0.03001416273232197
train 9, step: 100, loss: 0.00015123776393011212, grad_norm: 0.00011154923666594515, ic: 0.1253894389234535
train 9, step: 200, loss: 7.295695104403421e-05, grad_norm: 9.189846683611976e-06, ic: 0.014817256318610594
train 9, step: 300, loss: 0.0003153893048875034, grad_norm: 0.00018011148475443893, ic: -0.05280171078434683
train 9, step: 400, loss: 0.00024359415692742914, grad_norm: 0.0001114128824702089, ic: 0.06992639490307676
train 9, step: 500, loss: 8.072799391811714e-05, grad_norm: 9.123435802165497e-07, ic: 0.03215697827064171
train 9, step: 600, loss: 0.00017362959624733776, grad_norm: 9.803288598760464e-05, ic: -0.04416022765547556
train 9, step: 700, loss: 0.0004714694805443287, grad_norm: 0.00048804235259239875, ic: 0.052839927886584925
Epoch 9: 2022-05-05 17:23:03.678971: train loss: 0.0002072392450540512
Eval step 0: eval loss: 0.0001375379943056032
Eval step 100: eval loss: 0.00031081921770237386
Eval step 200: eval loss: 0.0003089542733505368
Eval: 2022-05-05 17:23:13.214559: total loss: 0.00018869081344841836, mse:0.0003773816233113203, ic :0.019140993476955217, sharpe5:-0.9453401845693588, irr5:-0.2038615643978119, ndcg5:0.848847292452473, pnl5:0.9788857102394104 
train 10, step: 0, loss: 9.266106644645333e-05, grad_norm: 1.8179439407277245e-06, ic: 0.04509950431072088
train 10, step: 100, loss: 0.00020946681615896523, grad_norm: 5.139635956401849e-05, ic: 0.043049356367964614
train 10, step: 200, loss: 0.0001684369781287387, grad_norm: 4.811093384083788e-06, ic: -0.023966298574735548
train 10, step: 300, loss: 0.00027428605244494975, grad_norm: 5.353041686239914e-05, ic: 0.05723012741542673
train 10, step: 400, loss: 0.0002544033050071448, grad_norm: 9.125277624827703e-05, ic: 0.165492978341165
train 10, step: 500, loss: 0.0002250560646643862, grad_norm: 9.312715843621775e-05, ic: 0.03882797633345219
train 10, step: 600, loss: 0.00024466196191497147, grad_norm: 0.00016802327136403042, ic: 0.04474027301043641
train 10, step: 700, loss: 0.0002849611919373274, grad_norm: 0.00023363554195205853, ic: -0.004657965305461333
Epoch 10: 2022-05-05 17:24:03.599339: train loss: 0.00020712041411429636
Eval step 0: eval loss: 0.0001653590879868716
Eval step 100: eval loss: 0.00035103046684525907
Eval step 200: eval loss: 0.00027435043011792004
Eval: 2022-05-05 17:24:13.448206: total loss: 0.00019319747086852284, mse:0.0003863949360044048, ic :0.021129467325593534, sharpe5:-0.9731281121447682, irr5:-0.21197029948234558, ndcg5:0.8547875634627385, pnl5:0.992455244064331 
train 11, step: 0, loss: 0.00023478713410440832, grad_norm: 1.4854269356446924e-06, ic: -0.04603963408717031
train 11, step: 100, loss: 9.802699059946463e-05, grad_norm: 4.434022474698929e-06, ic: 0.06630147537297033
train 11, step: 200, loss: 0.00017183966701850295, grad_norm: 1.9766347779634884e-05, ic: 0.01668427911734594
train 11, step: 300, loss: 0.0005376596818678081, grad_norm: 8.495568852701087e-07, ic: 0.07126413725135679
train 11, step: 400, loss: 8.21141293272376e-05, grad_norm: 6.089281006918263e-06, ic: 0.03742503864875343
train 11, step: 500, loss: 0.0002213482221122831, grad_norm: 2.3222399683066273e-06, ic: 0.0490305916938642
train 11, step: 600, loss: 0.00037861132295802236, grad_norm: 9.291711012793937e-05, ic: -0.04098855457543467
train 11, step: 700, loss: 0.000474206026410684, grad_norm: 0.0005367583386065335, ic: -0.0318194775018969
Epoch 11: 2022-05-05 17:25:05.674089: train loss: 0.00020757452183263624
Eval step 0: eval loss: 0.0001336336717940867
Eval step 100: eval loss: 0.0003039308649022132
Eval step 200: eval loss: 0.0003192518779542297
Eval: 2022-05-05 17:25:15.415136: total loss: 0.00018920519654959335, mse:0.0003784103890391223, ic :0.015635080414313107, sharpe5:-0.9172448902577162, irr5:-0.20249289274215698, ndcg5:0.8471271699514578, pnl5:0.9009324908256531 
train 12, step: 0, loss: 0.00016596059140283614, grad_norm: 7.187474687793273e-05, ic: 0.08052812418345462
train 12, step: 100, loss: 0.00012462159793358296, grad_norm: 4.956299958460352e-05, ic: -0.012829348434134975
train 12, step: 200, loss: 0.0003461036831140518, grad_norm: 0.00013091303400964552, ic: -0.04014555677723483
train 12, step: 300, loss: 0.00023344490909948945, grad_norm: 0.00011020826556124303, ic: 0.062536262851934
train 12, step: 400, loss: 0.00037581208744086325, grad_norm: 2.2135379088190096e-05, ic: 0.031364363770649606
train 12, step: 500, loss: 0.00013519356434699148, grad_norm: 4.24386102006109e-06, ic: 0.039513237554776766
train 12, step: 600, loss: 0.00024122984905261546, grad_norm: 7.738439640208102e-06, ic: -0.05527789259378164
train 12, step: 700, loss: 0.0005192484240978956, grad_norm: 7.327099126565574e-05, ic: 0.13428001726254413
Epoch 12: 2022-05-05 17:26:06.097802: train loss: 0.00020728387972730633
Eval step 0: eval loss: 0.000144407240441069
Eval step 100: eval loss: 0.0003200461796950549
Eval step 200: eval loss: 0.00030123439501039684
Eval: 2022-05-05 17:26:15.654712: total loss: 0.000188777044380651, mse:0.000377554085429904, ic :0.020673608535846363, sharpe5:-0.8740697664767503, irr5:-0.18954402208328247, ndcg5:0.8548710567512325, pnl5:0.9743510484695435 
train 13, step: 0, loss: 0.00017139392730314285, grad_norm: 1.863201261376937e-05, ic: 0.07765404678849623
train 13, step: 100, loss: 0.00020420984947122633, grad_norm: 1.6726303360177248e-06, ic: 0.1619377799809909
train 13, step: 200, loss: 0.00036278890911489725, grad_norm: 0.00016438568308523095, ic: -0.0251344677369182
train 13, step: 300, loss: 0.00012832241191063076, grad_norm: 2.6580790950259915e-05, ic: -0.04733362852719401
train 13, step: 400, loss: 0.0001232193608302623, grad_norm: 6.804792389760056e-05, ic: 0.049917448091706756
train 13, step: 500, loss: 0.00012385999434627593, grad_norm: 3.767100824015728e-07, ic: -0.018276936792656528
train 13, step: 600, loss: 0.00015520679880864918, grad_norm: 2.6394844630906728e-05, ic: 0.04211930195453114
train 13, step: 700, loss: 0.00017976753588300198, grad_norm: 3.097059990948628e-05, ic: 0.07559423803648269
Epoch 13: 2022-05-05 17:27:07.468230: train loss: 0.00020748620944964217
Eval step 0: eval loss: 0.00015600796905346215
Eval step 100: eval loss: 0.00033772483584471047
Eval step 200: eval loss: 0.00028422492323443294
Eval: 2022-05-05 17:27:17.289706: total loss: 0.00019061075155313154, mse:0.00038122149814587454, ic :0.019733105994649138, sharpe5:-0.9418502507731318, irr5:-0.20473673939704895, ndcg5:0.8547687970125412, pnl5:0.9452883005142212 
train 14, step: 0, loss: 0.00020456337369978428, grad_norm: 3.6158302726848857e-06, ic: 0.07153113828862004
train 14, step: 100, loss: 0.00012042276648571715, grad_norm: 2.3693744737834022e-05, ic: -0.005497429193800498
train 14, step: 200, loss: 0.00017419953655917197, grad_norm: 3.2070086130690524e-06, ic: 0.038924861575831846
train 14, step: 300, loss: 0.0002813219907693565, grad_norm: 6.753186018453718e-05, ic: 0.07981330062954889
train 14, step: 400, loss: 0.00012915339902974665, grad_norm: 4.361800519947095e-05, ic: 0.06332349563201586
train 14, step: 500, loss: 0.00017256267892662436, grad_norm: 1.0280650971677734e-06, ic: -0.04684151756391204
train 14, step: 600, loss: 0.0001117122228606604, grad_norm: 2.0592498299915594e-05, ic: 0.07511087899733579
train 14, step: 700, loss: 0.00013020569167565554, grad_norm: 4.7638479247708874e-05, ic: 0.03433100895112651
Epoch 14: 2022-05-05 17:28:08.557889: train loss: 0.0002071811145299611
Eval step 0: eval loss: 0.00013350401422940195
Eval step 100: eval loss: 0.0003034286783076823
Eval step 200: eval loss: 0.0003200026403646916
Eval: 2022-05-05 17:28:18.323516: total loss: 0.00018923203301373016, mse:0.00037846406353665745, ic :0.028455638545129017, sharpe5:0.9842568690329789, irr5:0.2755947709083557, ndcg5:0.8522234000402368, pnl5:1.0576353073120117 
train 15, step: 0, loss: 0.00013828737428411841, grad_norm: 3.030891564117881e-06, ic: 0.028071136524580542
train 15, step: 100, loss: 0.0003126600058749318, grad_norm: 0.00010428293853845189, ic: 0.005496832935470215
train 15, step: 200, loss: 0.00013679501716978848, grad_norm: 3.9709459595582324e-05, ic: -0.007559746331267485
train 15, step: 300, loss: 0.0005695571890100837, grad_norm: 8.580404908294402e-05, ic: 0.11882605721209852
train 15, step: 400, loss: 0.00013109295105095953, grad_norm: 2.5304434760280467e-05, ic: 0.05106521956993987
train 15, step: 500, loss: 0.00010487218241905794, grad_norm: 3.3576253123213996e-06, ic: 0.004694707055873451
train 15, step: 600, loss: 0.00022392682149074972, grad_norm: 7.226047825549355e-05, ic: 0.06305346568265657
train 15, step: 700, loss: 9.746100113261491e-05, grad_norm: 2.4594974007596696e-05, ic: -0.024967088364998634
Epoch 15: 2022-05-05 17:29:10.253532: train loss: 0.000207277635409046
Eval step 0: eval loss: 0.00012156511365901679
Eval step 100: eval loss: 0.00028274746728129685
Eval step 200: eval loss: 0.0003544726059772074
Eval: 2022-05-05 17:29:19.904680: total loss: 0.00019536092745848854, mse:0.0003907218513711045, ic :0.015722687334175235, sharpe5:-1.303670087456703, irr5:-0.27660879492759705, ndcg5:0.8545081737683633, pnl5:0.898072361946106 
train 16, step: 0, loss: 0.00020853063324466348, grad_norm: 1.24135243656231e-05, ic: 0.03676816802754485
train 16, step: 100, loss: 0.00011082668788731098, grad_norm: 3.678718045293877e-06, ic: 0.06819768657320059
train 16, step: 200, loss: 0.00016469259571749717, grad_norm: 9.408982456088754e-07, ic: 0.037356743296486236
train 16, step: 300, loss: 0.0001676222018431872, grad_norm: 0.00011842647908591953, ic: 0.06317726993120226
train 16, step: 400, loss: 0.0002596311387605965, grad_norm: 8.149101839194653e-05, ic: 0.037993362771675254
train 16, step: 500, loss: 0.00012861291179433465, grad_norm: 1.959791873679292e-05, ic: 0.03533939666584697
train 16, step: 600, loss: 8.683711348567158e-05, grad_norm: 8.364535489196978e-07, ic: -0.021927655763358138
train 16, step: 700, loss: 0.00015015737153589725, grad_norm: 1.7535281175124512e-05, ic: -0.01729596465013485
Epoch 16: 2022-05-05 17:30:10.252685: train loss: 0.00020752189147045972
Eval step 0: eval loss: 0.0001534650509711355
Eval step 100: eval loss: 0.00033359864028170705
Eval step 200: eval loss: 0.0002885388385038823
Eval: 2022-05-05 17:30:19.262208: total loss: 0.00019002745725371056, mse:0.00038005491200440055, ic :0.013284052636911957, sharpe5:-1.327989601045847, irr5:-0.2851189076900482, ndcg5:0.8652320305598885, pnl5:0.8970358967781067 
train 17, step: 0, loss: 0.00014205147454049438, grad_norm: 1.2897830753905798e-06, ic: 0.10282702602916807
train 17, step: 100, loss: 0.00027137366123497486, grad_norm: 0.0002652951176208608, ic: -0.11262235385915204
train 17, step: 200, loss: 0.0002375208423472941, grad_norm: 9.90902387417674e-05, ic: 0.079136179589691
train 17, step: 300, loss: 0.0002316212048754096, grad_norm: 0.00016972739045031067, ic: 0.024101457851542468
train 17, step: 400, loss: 0.00016806366329547018, grad_norm: 0.00011566384780981525, ic: 0.013807195909560057
train 17, step: 500, loss: 8.045164577197284e-05, grad_norm: 3.9958240511219803e-08, ic: -0.002277963708234982
train 17, step: 600, loss: 0.0004961883532814682, grad_norm: 0.0005232500761514574, ic: 0.15252465807678234
train 17, step: 700, loss: 7.149112207116559e-05, grad_norm: 5.347962187990759e-07, ic: -0.05008819389172472
Epoch 17: 2022-05-05 17:31:10.330369: train loss: 0.00020746941581479102
Eval step 0: eval loss: 0.00014687141811009496
Eval step 100: eval loss: 0.00032402490614913404
Eval step 200: eval loss: 0.00029696812271140516
Eval: 2022-05-05 17:31:19.972749: total loss: 0.0001890052758247742, mse:0.00037801054590555353, ic :0.013768348516576816, sharpe5:-1.1982305860519409, irr5:-0.2595982849597931, ndcg5:0.8602388814195571, pnl5:0.9033012986183167 
train 18, step: 0, loss: 0.00036034666118212044, grad_norm: 0.00025157589318248433, ic: 0.09891844438214278
train 18, step: 100, loss: 0.00024716288316994905, grad_norm: 0.00010372601466367867, ic: -0.038844175242175566
train 18, step: 200, loss: 0.00019352356321178377, grad_norm: 4.3210660658297005e-05, ic: 0.08439228937467763
train 18, step: 300, loss: 0.00012417809921316803, grad_norm: 4.197526570112599e-08, ic: 0.05405390501502794
train 18, step: 400, loss: 8.664765482535586e-05, grad_norm: 2.3056082281196413e-07, ic: 0.059381912411889774
train 18, step: 500, loss: 0.00027542668976821005, grad_norm: 0.00021381923240414025, ic: 0.08687313527908866
train 18, step: 600, loss: 0.00012786875595338643, grad_norm: 1.017668790415749e-06, ic: 0.04784991206130572
train 18, step: 700, loss: 0.00017925869906321168, grad_norm: 8.247266443787231e-05, ic: 0.050641316295374494
Epoch 18: 2022-05-05 17:32:11.600757: train loss: 0.00020734572266286081
Eval step 0: eval loss: 0.00014299924077931792
Eval step 100: eval loss: 0.0003185179957654327
Eval step 200: eval loss: 0.0003021527372766286
Eval: 2022-05-05 17:32:21.266005: total loss: 0.00018874371703154932, mse:0.00037748743437211296, ic :0.010621908750681707, sharpe5:-1.202876027226448, irr5:-0.26025447249412537, ndcg5:0.848492833100818, pnl5:0.9020372629165649 
train 19, step: 0, loss: 0.0002346820110687986, grad_norm: 0.0001983893853791923, ic: -0.05545015228512219
train 19, step: 100, loss: 0.0002106198517140001, grad_norm: 1.3434530155013357e-05, ic: 0.01960918915065486
train 19, step: 200, loss: 0.00016130896983668208, grad_norm: 1.7484241580461271e-06, ic: 0.1100866886427284
train 19, step: 300, loss: 0.0001448901166440919, grad_norm: 4.305580263363706e-06, ic: -0.12169401548267492
train 19, step: 400, loss: 0.00014479461242444813, grad_norm: 1.8400712861539414e-05, ic: 0.17796772400457814
train 19, step: 500, loss: 0.0002057055535260588, grad_norm: 3.3443610087544456e-07, ic: 0.0960438835248627
train 19, step: 600, loss: 0.0002526928437873721, grad_norm: 5.031473556920318e-06, ic: 0.015570878843388007
train 19, step: 700, loss: 0.00027626805240288377, grad_norm: 0.00016242232222290015, ic: -0.059262986744261864
Epoch 19: 2022-05-05 17:33:12.738639: train loss: 0.00020704766362823795
Eval step 0: eval loss: 0.0001449777337256819
Eval step 100: eval loss: 0.0003210853901691735
Eval step 200: eval loss: 0.00030001570121385157
Eval: 2022-05-05 17:33:22.384408: total loss: 0.00018882496091440589, mse:0.000377649918046984, ic :0.012713688887944403, sharpe5:-1.1014623856544494, irr5:-0.24063226580619812, ndcg5:0.8534430724307348, pnl5:0.902587354183197 
train 20, step: 0, loss: 0.0002295048616360873, grad_norm: 5.971486638154217e-06, ic: -0.07170191354236814
train 20, step: 100, loss: 0.0001367328077321872, grad_norm: 4.1195035218208396e-05, ic: 0.049774088420317796
train 20, step: 200, loss: 0.00025519754854030907, grad_norm: 7.497357637542263e-07, ic: 0.06095100797337354
train 20, step: 300, loss: 0.00022447775700129569, grad_norm: 1.794258442616391e-06, ic: 0.06267019628155752
train 20, step: 400, loss: 0.00014946141163818538, grad_norm: 3.8216255586191386e-05, ic: 0.02581308122630251
train 20, step: 500, loss: 0.00010370426025474444, grad_norm: 8.71993268407387e-07, ic: -0.04300508610648179
train 20, step: 600, loss: 0.00013855738507118076, grad_norm: 1.838904014722858e-05, ic: 0.003953162128941416
train 20, step: 700, loss: 0.0003759398532565683, grad_norm: 0.00038396436613529546, ic: 0.012683273566163514
Epoch 20: 2022-05-05 17:34:14.087400: train loss: 0.0002070832739546095
Eval step 0: eval loss: 0.00014668636140413582
Eval step 100: eval loss: 0.000324066641042009
Eval step 200: eval loss: 0.00029651413206011057
Eval: 2022-05-05 17:34:23.702040: total loss: 0.0001890297681596496, mse:0.00037805953163351204, ic :0.01205639417227003, sharpe5:-1.175820423513651, irr5:-0.25417205691337585, ndcg5:0.8507380006456913, pnl5:0.8902943730354309 
train 21, step: 0, loss: 0.00037459403392858803, grad_norm: 0.0003687688800734109, ic: 0.02800310223348186
train 21, step: 100, loss: 0.00017739202303346246, grad_norm: 3.6376311681509424e-05, ic: 0.02197534838892446
train 21, step: 200, loss: 0.0001295355468755588, grad_norm: 4.0409214574509035e-06, ic: 0.028596611379905483
train 21, step: 300, loss: 0.00012346234871074557, grad_norm: 3.785552743556366e-07, ic: 0.04753830145355972
train 21, step: 400, loss: 0.0001586043363204226, grad_norm: 9.266917313394643e-06, ic: 0.006964968431589266
train 21, step: 500, loss: 0.0001871896965894848, grad_norm: 4.2339878426698096e-05, ic: 0.09609864245805412
train 21, step: 600, loss: 0.0003277185605838895, grad_norm: 8.173421196688717e-06, ic: 0.1417161450444937
train 21, step: 700, loss: 0.00027490200591273606, grad_norm: 8.875272376903106e-05, ic: 0.05911940061023129
Epoch 21: 2022-05-05 17:35:15.024463: train loss: 0.000207126776715504
Eval step 0: eval loss: 0.0001615902583580464
Eval step 100: eval loss: 0.00034456359571777284
Eval step 200: eval loss: 0.0002809578145388514
Eval: 2022-05-05 17:35:24.603224: total loss: 0.00019186265904768513, mse:0.00038372531275602487, ic :0.012917578029040882, sharpe5:-1.2381919272243975, irr5:-0.2684324085712433, ndcg5:0.8465796125317159, pnl5:0.8970738053321838 
train 22, step: 0, loss: 0.00013013012357987463, grad_norm: 1.3883534130812433e-05, ic: 0.033724514863044584
train 22, step: 100, loss: 0.00011511529010022059, grad_norm: 4.9224461506112355e-06, ic: 0.04088246662036811
train 22, step: 200, loss: 0.0002276402956340462, grad_norm: 9.062565701895622e-05, ic: 0.09392098230536389
train 22, step: 300, loss: 0.00015893590170890093, grad_norm: 3.087340215515947e-05, ic: 0.03547573745713144
train 22, step: 400, loss: 0.00023990249610505998, grad_norm: 3.2077162571089316e-06, ic: -0.03334848910550491
train 22, step: 500, loss: 0.00012548165977932513, grad_norm: 4.7351162717111033e-05, ic: 0.040622015314978374
train 22, step: 600, loss: 0.0001705604518065229, grad_norm: 0.00011742947657021232, ic: -0.027898518259533447
train 22, step: 700, loss: 0.00011215899576200172, grad_norm: 1.3797069822894864e-06, ic: -0.007632752840893768
Epoch 22: 2022-05-05 17:36:15.963408: train loss: 0.00020696205362636487
Eval step 0: eval loss: 0.00012990750838071108
Eval step 100: eval loss: 0.0002975485986098647
Eval step 200: eval loss: 0.00032862729858607054
Eval: 2022-05-05 17:36:25.590272: total loss: 0.00019021941750899048, mse:0.0003804388337735089, ic :0.01081964838079571, sharpe5:-1.136130326539278, irr5:-0.2461879551410675, ndcg5:0.8483512618128731, pnl5:0.8977909684181213 
train 23, step: 0, loss: 0.00020141186541877687, grad_norm: 6.805624918081841e-05, ic: 0.10922469380455127
train 23, step: 100, loss: 0.0001398674212396145, grad_norm: 2.314061002814667e-06, ic: 0.03132694308006739
train 23, step: 200, loss: 0.0003068491059821099, grad_norm: 0.00010616711263047832, ic: 0.03236240213908614
train 23, step: 300, loss: 0.00031402846798300743, grad_norm: 0.00034047258080988795, ic: -0.059208987502874844
train 23, step: 400, loss: 0.0001588904415257275, grad_norm: 2.930417525983148e-05, ic: 0.06163730572945397
train 23, step: 500, loss: 0.00010271977225784212, grad_norm: 2.6709810232122044e-05, ic: 0.02183904313201162
train 23, step: 600, loss: 0.0001960823283297941, grad_norm: 0.00011817425761540025, ic: -0.07157673812443469
train 23, step: 700, loss: 0.00015744357369840145, grad_norm: 7.12833140897809e-05, ic: 0.0048157636059019855
Epoch 23: 2022-05-05 17:37:15.747552: train loss: 0.0002076467428955061
Eval step 0: eval loss: 0.00014040958194527775
Eval step 100: eval loss: 0.00031437218422070146
Eval step 200: eval loss: 0.0003068872320000082
Eval: 2022-05-05 17:37:25.411057: total loss: 0.0001886978762427154, mse:0.0003773957449713635, ic :0.00784725749323419, sharpe5:-1.035885967388749, irr5:-0.22657406330108643, ndcg5:0.8499377986045584, pnl5:0.8979512453079224 
train 24, step: 0, loss: 0.0001628840109333396, grad_norm: 2.257671543129129e-06, ic: 0.002976715277718504
train 24, step: 100, loss: 0.0002691880217753351, grad_norm: 0.00022489089761967832, ic: 0.0636682757861758
train 24, step: 200, loss: 0.00015415551024489105, grad_norm: 3.664691683107994e-05, ic: 0.06318655869797804
train 24, step: 300, loss: 8.61381777212955e-05, grad_norm: 6.520329248863051e-06, ic: 0.03363870504168187
train 24, step: 400, loss: 0.00013730005593970418, grad_norm: 6.978422215118346e-05, ic: 0.02368513198332779
train 24, step: 500, loss: 0.00021816404478158802, grad_norm: 4.517877365436043e-05, ic: -0.008704670751080642
train 24, step: 600, loss: 0.0001184322900371626, grad_norm: 9.140229919259047e-06, ic: -0.03525770166192752
train 24, step: 700, loss: 8.743882062844932e-05, grad_norm: 3.073777492839628e-05, ic: -0.11964538279890269
Epoch 24: 2022-05-05 17:38:16.655255: train loss: 0.00020711168764881387
Eval step 0: eval loss: 0.00014935714716557413
Eval step 100: eval loss: 0.00032804260263219476
Eval step 200: eval loss: 0.0002923921565525234
Eval: 2022-05-05 17:38:26.181070: total loss: 0.00018933348226265404, mse:0.00037866696173710293, ic :0.01871864081993791, sharpe5:-1.220125692039728, irr5:-0.2655400335788727, ndcg5:0.8567670474976146, pnl5:0.8851136565208435 
train 25, step: 0, loss: 0.00013666397717315704, grad_norm: 8.048025093291846e-05, ic: 0.1069018490279034
train 25, step: 100, loss: 0.0002591936499811709, grad_norm: 7.885120390161709e-05, ic: 0.18815147598583049
train 25, step: 200, loss: 0.00024047204351518303, grad_norm: 0.00010466598846195656, ic: 0.06678642565174578
train 25, step: 300, loss: 0.00015417004760820419, grad_norm: 7.544703426557447e-07, ic: -0.004734639707753854
train 25, step: 400, loss: 0.00022639389499090612, grad_norm: 0.0001431054513813248, ic: 0.053019131538132244
train 25, step: 500, loss: 0.00017965369625017047, grad_norm: 0.0001233129020203131, ic: 0.03276677480848937
train 25, step: 600, loss: 0.00015425236779265106, grad_norm: 9.94291561129696e-05, ic: -0.013373480958154396
train 25, step: 700, loss: 0.00028765402385033667, grad_norm: 2.7927739589141584e-08, ic: -0.003152713476480027
Epoch 25: 2022-05-05 17:39:17.513981: train loss: 0.00020758363812602962
Eval step 0: eval loss: 0.0001353656844003126
Eval step 100: eval loss: 0.00030665783560834825
Eval step 200: eval loss: 0.00031569282873533666
Eval: 2022-05-05 17:39:27.054072: total loss: 0.00018899455897466332, mse:0.0003779891121403158, ic :0.010164360919373509, sharpe5:-1.1226530134677886, irr5:-0.24599716067314148, ndcg5:0.8623714725730013, pnl5:0.9003222584724426 
train 26, step: 0, loss: 0.00014280910545494407, grad_norm: 2.104073480089157e-05, ic: 0.05454477385969505
train 26, step: 100, loss: 0.0001169921233667992, grad_norm: 8.63211789000226e-09, ic: 0.06658910225738238
train 26, step: 200, loss: 0.00013450131518766284, grad_norm: 3.046734821389048e-07, ic: 0.06982448666065344
train 26, step: 300, loss: 0.00017523985297884792, grad_norm: 1.3671367980054552e-06, ic: -0.06418565860822406
train 26, step: 400, loss: 0.00020400513312779367, grad_norm: 3.484301441361691e-06, ic: -0.016799959896609228
train 26, step: 500, loss: 6.921928434167057e-05, grad_norm: 1.0921666986271228e-05, ic: -0.00700727755665706
train 26, step: 600, loss: 0.00016538452473469079, grad_norm: 5.595448451760535e-05, ic: 0.09446406305262037
train 26, step: 700, loss: 0.0001729842188069597, grad_norm: 1.9461516755444363e-05, ic: -0.039157174498702665
Epoch 26: 2022-05-05 17:40:18.021502: train loss: 0.00020714957158062246
Eval step 0: eval loss: 0.00015573341806884855
Eval step 100: eval loss: 0.0003374823136255145
Eval step 200: eval loss: 0.00028447952354326844
Eval: 2022-05-05 17:40:27.762128: total loss: 0.00019059316384785008, mse:0.0003811863237523473, ic :0.016042376427385187, sharpe5:-1.1341065184772015, irr5:-0.24919745326042175, ndcg5:0.8410495784777201, pnl5:0.8831114768981934 
train 27, step: 0, loss: 0.00019693993090186268, grad_norm: 6.562088335187308e-05, ic: 0.012823209312142021
train 27, step: 100, loss: 0.00016685802256688476, grad_norm: 5.120945381081942e-06, ic: 0.030099497445075365
train 27, step: 200, loss: 0.00014277735317591578, grad_norm: 8.316161353201377e-05, ic: 0.033503202375518355
train 27, step: 300, loss: 0.00040368654299527407, grad_norm: 0.0004084655354540532, ic: 0.026045551560192927
train 27, step: 400, loss: 0.0002441136457491666, grad_norm: 7.520689092906435e-05, ic: 0.06939543936738836
train 27, step: 500, loss: 0.00017268292140215635, grad_norm: 2.658000287092983e-05, ic: -0.06834034037234138
train 27, step: 600, loss: 0.0006299321539700031, grad_norm: 0.0006468170327878276, ic: -0.06241302616166637
train 27, step: 700, loss: 0.0002466007135808468, grad_norm: 9.013854460437642e-05, ic: 0.003485246014860978
Epoch 27: 2022-05-05 17:41:19.233384: train loss: 0.00020765413124137463
Eval step 0: eval loss: 0.00014221311721485108
Eval step 100: eval loss: 0.00031697325175628066
Eval step 200: eval loss: 0.0003042167518287897
Eval: 2022-05-05 17:41:28.740280: total loss: 0.00018868032799917783, mse:0.00037736064862516555, ic :0.010846806765620519, sharpe5:-1.1873287922143936, irr5:-0.25777432322502136, ndcg5:0.8542439574684274, pnl5:0.8746906518936157 
train 28, step: 0, loss: 0.00031347558251582086, grad_norm: 4.311958963883066e-06, ic: -0.07904909220493317
train 28, step: 100, loss: 0.00012196988245705143, grad_norm: 4.928815509637085e-05, ic: 0.10749790437810089
train 28, step: 200, loss: 8.374955359613523e-05, grad_norm: 4.542154652463521e-06, ic: -0.012450695987793067
train 28, step: 300, loss: 0.0002283298526890576, grad_norm: 3.5338209459808472e-06, ic: -0.0697832138908426
train 28, step: 400, loss: 0.0004143468977417797, grad_norm: 9.802614743773634e-05, ic: 0.12739593158723295
train 28, step: 500, loss: 0.0001858406758401543, grad_norm: 5.049640474013712e-05, ic: 0.05652508969651955
train 28, step: 600, loss: 0.00034512620186433196, grad_norm: 0.00018996948411147948, ic: 0.021222619281519098
train 28, step: 700, loss: 0.0002142325829481706, grad_norm: 4.372980282850391e-06, ic: 0.0752165629367002
Epoch 28: 2022-05-05 17:42:19.930848: train loss: 0.0002070591649328739
Eval step 0: eval loss: 0.000142309203511104
Eval step 100: eval loss: 0.00031797061092220247
Eval step 200: eval loss: 0.0003018789866473526
Eval: 2022-05-05 17:42:29.688559: total loss: 0.00018870411040393563, mse:0.00037740821927898123, ic :0.015295428041418127, sharpe5:-1.2218282400816678, irr5:-0.26813629269599915, ndcg5:0.8524888921579025, pnl5:0.8842235803604126 
train 29, step: 0, loss: 0.000181271432666108, grad_norm: 4.136115575127184e-06, ic: 0.07898654226124008
train 29, step: 100, loss: 0.0001062166629708372, grad_norm: 9.907785008566506e-06, ic: 0.012159142199480093
train 29, step: 200, loss: 0.00030657535535283387, grad_norm: 1.0461147871865305e-05, ic: -0.006773409013564826
train 29, step: 300, loss: 0.00018754367192741483, grad_norm: 2.101526945992057e-06, ic: -0.0598418639934814
train 29, step: 400, loss: 0.00010324042523279786, grad_norm: 1.2396046814780835e-05, ic: -0.05363531501866777
train 29, step: 500, loss: 0.0001225620071636513, grad_norm: 1.0027238409850856e-05, ic: 0.10465419617218313
train 29, step: 600, loss: 0.0001559987140353769, grad_norm: 1.434909444011153e-06, ic: 0.12174864644529526
train 29, step: 700, loss: 0.00019690929912030697, grad_norm: 1.844059040446668e-05, ic: 0.07578174614320529
Epoch 29: 2022-05-05 17:43:21.202424: train loss: 0.00020712720432392208
Eval step 0: eval loss: 0.00015564319619443268
Eval step 100: eval loss: 0.0003366344317328185
Eval step 200: eval loss: 0.00028610252775251865
Eval: 2022-05-05 17:43:30.649049: total loss: 0.00019045523189894822, mse:0.00038091045933950814, ic :0.018429013838357516, sharpe5:-1.3520530052483082, irr5:-0.29494914412498474, ndcg5:0.8593028733594492, pnl5:0.8636997938156128 
train 30, step: 0, loss: 0.00015363864076789469, grad_norm: 4.0297523102197643e-05, ic: 0.08282289174717991
train 30, step: 100, loss: 0.00029323549824766815, grad_norm: 1.3722236738538041e-05, ic: 0.13782377494464287
train 30, step: 200, loss: 0.00013522119843401015, grad_norm: 1.754224545295842e-07, ic: -0.014557508935239515
train 30, step: 300, loss: 0.0004014347796328366, grad_norm: 0.00016223769523175126, ic: -0.023511146298537716
train 30, step: 400, loss: 0.00014029783778823912, grad_norm: 3.2332510834205334e-06, ic: 0.035014171856366974
train 30, step: 500, loss: 0.0002188567304983735, grad_norm: 4.433231965248567e-06, ic: 0.055795447017837056
train 30, step: 600, loss: 0.0001762080646585673, grad_norm: 9.344132168455209e-05, ic: 0.06325065477775657
train 30, step: 700, loss: 0.00022378026915248483, grad_norm: 7.042501058967497e-05, ic: 0.06007007371266493
Epoch 30: 2022-05-05 17:44:20.822640: train loss: 0.00020728218613630864
Eval step 0: eval loss: 0.00016588912694714963
Eval step 100: eval loss: 0.00035105456481687725
Eval step 200: eval loss: 0.00027579496963880956
Eval: 2022-05-05 17:44:30.377560: total loss: 0.00019318051566318995, mse:0.0003863610315791855, ic :0.019730886869158738, sharpe5:-1.2258526810258625, irr5:-0.2713656723499298, ndcg5:0.8548990835846022, pnl5:0.8671596050262451 
train 31, step: 0, loss: 0.00013272649084683508, grad_norm: 5.686076933281411e-05, ic: 0.05973860247464282
train 31, step: 100, loss: 0.00019333389354869723, grad_norm: 6.214077303165791e-07, ic: 0.04909199627914968
train 31, step: 200, loss: 0.00027488378691487014, grad_norm: 4.3429064385319057e-07, ic: 0.01749942276995654
train 31, step: 300, loss: 0.00013331836089491844, grad_norm: 2.6757888115114106e-05, ic: 0.08943809716836744
train 31, step: 400, loss: 0.00010004075738834217, grad_norm: 9.684401637476343e-07, ic: 0.10129142477394601
train 31, step: 500, loss: 0.0001311999949393794, grad_norm: 2.74022262274032e-05, ic: 0.009594190045968263
train 31, step: 600, loss: 0.00022248955792747438, grad_norm: 0.00017100080813262322, ic: -0.06531960582576883
train 31, step: 700, loss: 0.00014033216575626284, grad_norm: 1.7762355479835025e-05, ic: 0.03063130377457346
Epoch 31: 2022-05-05 17:45:21.121050: train loss: 0.00020743122835979605
Eval step 0: eval loss: 0.00012895377585664392
Eval step 100: eval loss: 0.0002959162520710379
Eval step 200: eval loss: 0.00033120575244538486
Eval: 2022-05-05 17:45:30.941372: total loss: 0.00019057683396182638, mse:0.0003811536636321003, ic :0.009481125750334338, sharpe5:-1.113766987323761, irr5:-0.24403688311576843, ndcg5:0.8556439157563547, pnl5:0.9016315340995789 
train 32, step: 0, loss: 0.0001838197495089844, grad_norm: 4.1433892076816626e-05, ic: 0.13530229840308386
train 32, step: 100, loss: 9.292485628975555e-05, grad_norm: 2.047815798331564e-05, ic: 0.09694973485508891
train 32, step: 200, loss: 0.00018201030616182834, grad_norm: 1.846966151786739e-05, ic: 0.05048242423310676
train 32, step: 300, loss: 0.00019000023894477636, grad_norm: 4.107542901061244e-05, ic: 0.12625295740734005
train 32, step: 400, loss: 0.00019102734222542495, grad_norm: 4.8660178708682196e-05, ic: 0.036301740946591485
train 32, step: 500, loss: 0.0001756829587975517, grad_norm: 4.550918716062629e-07, ic: 0.04142853170973797
train 32, step: 600, loss: 0.0002169230574509129, grad_norm: 6.812886011858838e-05, ic: 0.09005833667197875
train 32, step: 700, loss: 0.00010597544314805418, grad_norm: 3.4633086223652936e-06, ic: 0.1450267003799496
Epoch 32: 2022-05-05 17:46:22.604837: train loss: 0.00020740541042669745
Eval step 0: eval loss: 0.00014102511340752244
Eval step 100: eval loss: 0.00031559544731862843
Eval step 200: eval loss: 0.00030507336487062275
Eval: 2022-05-05 17:46:32.084976: total loss: 0.00018866261564943467, mse:0.00037732522965477433, ic :0.012527931043013576, sharpe5:-1.1473279586434364, irr5:-0.25201544165611267, ndcg5:0.856344318511637, pnl5:0.8808644413948059 
train 33, step: 0, loss: 0.00017498055240139365, grad_norm: 1.1859537278421402e-06, ic: 0.039894167230090316
train 33, step: 100, loss: 0.00010899053449975327, grad_norm: 8.564967180110932e-08, ic: 0.027006158058237875
train 33, step: 200, loss: 0.0001698897103779018, grad_norm: 7.662049791770673e-09, ic: -0.08536542157289867
train 33, step: 300, loss: 0.00023024201800581068, grad_norm: 1.0531731941943916e-06, ic: 0.06096764165283109
train 33, step: 400, loss: 0.0002079051628243178, grad_norm: 0.00013432878293931415, ic: -0.016910167049230623
train 33, step: 500, loss: 8.208482904592529e-05, grad_norm: 1.5897307083047387e-06, ic: 0.02358495517940979
train 33, step: 600, loss: 0.00017987785395234823, grad_norm: 3.1787653817723444e-05, ic: 0.05911485221542878
train 33, step: 700, loss: 0.00013562384992837906, grad_norm: 8.223153474652706e-06, ic: 0.04500809400108012
Epoch 33: 2022-05-05 17:47:23.559842: train loss: 0.00020724129749177662
Eval step 0: eval loss: 0.00015416881069540977
Eval step 100: eval loss: 0.0003352877974975854
Eval step 200: eval loss: 0.0002860932727344334
Eval: 2022-05-05 17:47:33.458799: total loss: 0.00019024004465819023, mse:0.00038048008282441355, ic :0.018510533383099402, sharpe5:-1.3053732267022131, irr5:-0.2893836200237274, ndcg5:0.8411117243634061, pnl5:0.8704132437705994 
train 34, step: 0, loss: 0.00017302017658948898, grad_norm: 1.1386261380265989e-06, ic: 0.031292240837400405
train 34, step: 100, loss: 0.0001461509964428842, grad_norm: 1.9460191661877894e-05, ic: 0.11807718699662192
train 34, step: 200, loss: 0.00017189906793646514, grad_norm: 3.76437361841926e-05, ic: 0.13563162379097704
train 34, step: 300, loss: 0.0004936481709592044, grad_norm: 0.00038380574241986227, ic: 0.01715442396946589
train 34, step: 400, loss: 0.00013220221444498748, grad_norm: 7.382510612985426e-07, ic: 0.008524617924476827
train 34, step: 500, loss: 0.00012832558422815055, grad_norm: 1.9009798723326106e-05, ic: 0.03856768844223772
train 34, step: 600, loss: 0.00010963706881739199, grad_norm: 1.2399973951315753e-05, ic: -0.03974956216295769
train 34, step: 700, loss: 0.00011128082405775785, grad_norm: 4.5746611116436995e-05, ic: -0.0859907975233058
Epoch 34: 2022-05-05 17:48:25.168897: train loss: 0.00020688765766984661
Eval step 0: eval loss: 0.00013455127191264182
Eval step 100: eval loss: 0.0003055919660255313
Eval step 200: eval loss: 0.00031661958200857043
Eval: 2022-05-05 17:48:34.690468: total loss: 0.0001890430627957568, mse:0.00037808611896543334, ic :0.014897947252368354, sharpe5:-1.1813879057765007, irr5:-0.25954470038414, ndcg5:0.8476768853311986, pnl5:0.8911669254302979 
train 35, step: 0, loss: 0.0003664689138531685, grad_norm: 0.0004109026731154625, ic: 0.050862810957162025
train 35, step: 100, loss: 0.0001038243281072937, grad_norm: 4.923291526988404e-06, ic: 0.04919700705376909
train 35, step: 200, loss: 0.0004908363334834576, grad_norm: 0.00048602594697004384, ic: -0.020222450610134945
train 35, step: 300, loss: 0.0002529461635276675, grad_norm: 0.0001674492010984145, ic: -0.03918241854937267
train 35, step: 400, loss: 0.0007835718570277095, grad_norm: 0.0005364442861189176, ic: 0.0913809959673343
train 35, step: 500, loss: 0.0003140710759907961, grad_norm: 0.00014834642044474948, ic: 0.018362006400891043
train 35, step: 600, loss: 0.0002305211528437212, grad_norm: 1.4467132697424695e-07, ic: 0.02495450242768527
train 35, step: 700, loss: 0.0001278480631299317, grad_norm: 1.6170486507129263e-05, ic: 0.1077406958916019
Epoch 35: 2022-05-05 17:49:26.774410: train loss: 0.0002069883020422739
Eval step 0: eval loss: 0.00014036525681149215
Eval step 100: eval loss: 0.0003150783886667341
Eval step 200: eval loss: 0.0003045378834940493
Eval: 2022-05-05 17:49:36.382716: total loss: 0.00018861268208678365, mse:0.00037722535926813734, ic :0.01906998964702609, sharpe5:-1.2760762520134448, irr5:-0.2829602062702179, ndcg5:0.8645460589192249, pnl5:0.8599651455879211 
train 36, step: 0, loss: 0.0002382279053563252, grad_norm: 0.00014138789764612858, ic: 0.03352072313051979
train 36, step: 100, loss: 0.0002476605586707592, grad_norm: 3.6819714110156246e-06, ic: 0.0795369792734269
train 36, step: 200, loss: 0.0003384148876648396, grad_norm: 0.0003188126103326989, ic: 0.015136979658708338
train 36, step: 300, loss: 0.00014492210175376385, grad_norm: 4.6619272662187616e-05, ic: 0.03666306865421621
train 36, step: 400, loss: 0.0002060401311609894, grad_norm: 1.0943034883276245e-07, ic: 0.08491164612506406
train 36, step: 500, loss: 0.0004669044865295291, grad_norm: 0.00014718913682143378, ic: -0.013620443114554869
train 36, step: 600, loss: 5.8452253142604604e-05, grad_norm: 5.80155913910625e-07, ic: 0.13373785035008565
train 36, step: 700, loss: 0.00018991743854712695, grad_norm: 6.13759847304598e-05, ic: 0.037626250631883545
Epoch 36: 2022-05-05 17:50:27.329378: train loss: 0.00020692835834079185
Eval step 0: eval loss: 0.00017450589803047478
Eval step 100: eval loss: 0.00036334278411231935
Eval step 200: eval loss: 0.00026786234229803085
Eval: 2022-05-05 17:50:35.767006: total loss: 0.00019622323544635987, mse:0.00039244646761081445, ic :0.023393575340304493, sharpe5:-1.0672508539259433, irr5:-0.23296397924423218, ndcg5:0.8608790045535857, pnl5:0.9097570776939392 
train 37, step: 0, loss: 0.0003169455158058554, grad_norm: 0.00033655813966979595, ic: 0.0792814579931655
train 37, step: 100, loss: 0.00019913275900762528, grad_norm: 5.437745659072808e-05, ic: 0.06142231511913088
train 37, step: 200, loss: 0.00015142552729230374, grad_norm: 8.490826232230732e-07, ic: 0.10215478717327411
train 37, step: 300, loss: 0.0001504097890574485, grad_norm: 4.530615178666607e-05, ic: 0.022025219059535577
train 37, step: 400, loss: 0.00014995028323028237, grad_norm: 1.3021255109088979e-05, ic: -0.10575588909108857
train 37, step: 500, loss: 0.00015646396786905825, grad_norm: 9.75569621843604e-07, ic: 0.05887633657615164
train 37, step: 600, loss: 0.0003199662023689598, grad_norm: 0.00023634923500092625, ic: 0.0016700004418317392
train 37, step: 700, loss: 0.00019589380826801062, grad_norm: 5.168478300601207e-05, ic: -0.0007258561198344787
Epoch 37: 2022-05-05 17:51:26.736910: train loss: 0.00020763482466779892
Eval step 0: eval loss: 0.0001494129974162206
Eval step 100: eval loss: 0.0003278390795458108
Eval step 200: eval loss: 0.0002930604387074709
Eval: 2022-05-05 17:51:36.305539: total loss: 0.00018932021955815124, mse:0.0003786404394668832, ic :0.01869236564630718, sharpe5:-1.069387936592102, irr5:-0.23589366674423218, ndcg5:0.8552101598392177, pnl5:0.8930892944335938 
train 38, step: 0, loss: 0.0001582019031047821, grad_norm: 1.7517358824294878e-09, ic: -0.01682283288376537
train 38, step: 100, loss: 0.00012549686653073877, grad_norm: 9.667286378106502e-06, ic: -0.014068397877007602
train 38, step: 200, loss: 0.00015413541404996067, grad_norm: 1.3722465044171109e-06, ic: -0.0039273180588934135
train 38, step: 300, loss: 9.742193651618436e-05, grad_norm: 2.9530691652918648e-05, ic: 0.14041188484021636
train 38, step: 400, loss: 0.00013520120410248637, grad_norm: 3.031761750092078e-07, ic: -0.11675992162429918
train 38, step: 500, loss: 0.0003061121387872845, grad_norm: 9.636005793409396e-06, ic: -0.015323128059264883
train 38, step: 600, loss: 0.0001476877077948302, grad_norm: 1.52392422864419e-05, ic: 0.017598015525204
train 38, step: 700, loss: 0.00014912799815647304, grad_norm: 1.5405835236719207e-05, ic: 0.056817051399371564
Epoch 38: 2022-05-05 17:52:27.342466: train loss: 0.00020683882368932713
Eval step 0: eval loss: 0.00013460493937600404
Eval step 100: eval loss: 0.00030559429433196783
Eval step 200: eval loss: 0.0003165295929647982
Eval: 2022-05-05 17:52:36.923697: total loss: 0.00018899531236989017, mse:0.0003779906175484344, ic :0.020003527567448443, sharpe5:-1.0516353940218686, irr5:-0.2327466607093811, ndcg5:0.8529434288639424, pnl5:0.8802032470703125 
train 39, step: 0, loss: 0.00033403196721337736, grad_norm: 0.00019890506912887085, ic: 0.09653183073099403
train 39, step: 100, loss: 0.00045285295345820487, grad_norm: 0.00037010683964268566, ic: 0.013862154510514636
train 39, step: 200, loss: 0.00023842506925575435, grad_norm: 2.336173901778623e-06, ic: 0.022611910155949058
train 39, step: 300, loss: 0.0002409522421658039, grad_norm: 0.00015358613580992674, ic: 0.03472848880245072
train 39, step: 400, loss: 9.317828516941518e-05, grad_norm: 2.1057132612149466e-06, ic: -0.07337463482383837
train 39, step: 500, loss: 0.0001842401979956776, grad_norm: 1.8951788544467125e-05, ic: -0.12553370360136537
train 39, step: 600, loss: 0.00016075785970315337, grad_norm: 2.1290380027891635e-06, ic: -0.13109923396754777
train 39, step: 700, loss: 0.00019935700402129441, grad_norm: 3.071096312208754e-05, ic: 0.025959327887713615
Epoch 39: 2022-05-05 17:53:28.081378: train loss: 0.00020689021872424547
Eval step 0: eval loss: 0.0001616507361177355
Eval step 100: eval loss: 0.0003453016106504947
Eval step 200: eval loss: 0.00027938696439377964
Eval: 2022-05-05 17:53:38.113329: total loss: 0.00019196911326581082, mse:0.00038393822308085284, ic :0.02014555978234092, sharpe5:-1.0034643635898828, irr5:-0.2214721441268921, ndcg5:0.8549820637286101, pnl5:0.8875991702079773 

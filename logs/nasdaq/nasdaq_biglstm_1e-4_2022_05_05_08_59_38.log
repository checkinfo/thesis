Namespace(adj_path='./data/graphs/NASDAQ_1026_1026.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='NASDAQAdjSeqTimeDataset', dout=0.3, epochs=60, glstm_layers=1, gnn_layers=1, gpu=0, graph_attn=True, hidden_dim=128, inner_prod=False, input_dim=5, input_graph=True, label_cnt=1, lr=0.0001, lstm_layers=1, market='NASDAQ', mask_adj=True, mask_type='soft', model_type='BiGLSTM', normalize_adj=True, num_days=8, num_heads=1, print_inteval=100, rank_loss=False, relation_num=1, rsr_data_path='../Temporal_Relational_Stock_Ranking/data/2013-01-01', seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_250_0.8/', stock_num=1931, test_mask_path='./data/NASDAQ/test_mask_237_1026.npy', test_path='./data/NASDAQ/test_237_1026_6.npy', top_stocks=5, train_mask_path='./data/NASDAQ/train_mask_756_1026.npy', train_path='./data/NASDAQ/train_756_1026_6.npy', use_adj=True)
#tickers selected: 1026
single EOD data shape: (1245, 6)
(1026, 1245, 5) (1026, 1245) (1026, 1245) (1026, 1245)
#tickers selected: 1026
single EOD data shape: (1245, 6)
(1026, 1245, 5) (1026, 1245) (1026, 1245) (1026, 1245)
39250
BiGLSTM(
  (input_to_hidden): Linear(in_features=5, out_features=128, bias=True)
  (forward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (attention): ModuleList(
            (0): GraphAttentionLayer (128 -> 128)
          )
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
          (lin_gate): Linear(in_features=128, out_features=128, bias=True)
        )
      )
    )
  )
  (backward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (attention): ModuleList(
            (0): GraphAttentionLayer (128 -> 128)
          )
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
          (lin_gate): Linear(in_features=128, out_features=128, bias=True)
        )
      )
    )
  )
  (fc0): ModuleList(
    (0): Linear(in_features=256, out_features=128, bias=True)
  )
  (w_out): Linear(in_features=128, out_features=1, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
)
train 0, step: 0, loss: 0.013495445251464844, grad_norm: 0.18257718841530407, ic: 0.034132549935573096
train 0, step: 100, loss: 0.000692828674800694, grad_norm: 0.0001286439020637554, ic: 0.03467348463725876
train 0, step: 200, loss: 0.0004041356733068824, grad_norm: 6.241043459387837e-06, ic: 0.05846268708425967
train 0, step: 300, loss: 0.0004109163419343531, grad_norm: 4.013007009213834e-05, ic: -0.0028000227346561667
train 0, step: 400, loss: 0.00027231068816035986, grad_norm: 1.8917547333625636e-05, ic: 0.03647984340695083
train 0, step: 500, loss: 0.00026536177028901875, grad_norm: 2.3161372480141712e-05, ic: -0.010748206945450901
train 0, step: 600, loss: 0.00029188962071202695, grad_norm: 8.412264313489624e-05, ic: 0.0033401930727059125
train 0, step: 700, loss: 0.0002934934454970062, grad_norm: 1.0570977018397936e-05, ic: 0.014789851216034943
Epoch 0: 2022-05-05 21:01:48.703462: train loss: 0.0006110478729082154
Eval step 0: eval loss: 0.00015426974277943373
Eval step 100: eval loss: 0.0003341579285915941
Eval step 200: eval loss: 0.0002872834447771311
Eval: 2022-05-05 21:01:58.103039: total loss: 0.00019014013476677922, mse:0.00038028026437622803, ic :0.02883427706085378, sharpe5:1.7503606847673654, irr5:0.3365008533000946, ndcg5:0.8592238385934442, pnl5:1.289689302444458 
train 1, step: 0, loss: 0.00018995472055394202, grad_norm: 6.580835661919189e-05, ic: 0.033417139175155514
train 1, step: 100, loss: 0.00028704889700748026, grad_norm: 6.0712296563690146e-06, ic: 0.011922837747289129
train 1, step: 200, loss: 0.0001792173570720479, grad_norm: 1.8510165154606e-06, ic: -0.013924108373871997
train 1, step: 300, loss: 0.00014802500663790852, grad_norm: 1.6159356262019664e-05, ic: 0.029420566622916325
train 1, step: 400, loss: 0.00012850244820583612, grad_norm: 1.602161078106023e-05, ic: 0.021685565011304593
train 1, step: 500, loss: 0.00022630920284427702, grad_norm: 0.00013875577888656165, ic: -0.04460971518038912
train 1, step: 600, loss: 0.0003210690338164568, grad_norm: 4.7556889183965367e-05, ic: 0.0048603777368398954
train 1, step: 700, loss: 0.0005429243319667876, grad_norm: 0.0007970244458709963, ic: 0.020862027923284173
Epoch 1: 2022-05-05 21:02:47.823020: train loss: 0.00027264612844371967
Eval step 0: eval loss: 0.0001628938043722883
Eval step 100: eval loss: 0.000347906636307016
Eval step 200: eval loss: 0.0002751291904132813
Eval: 2022-05-05 21:02:57.250643: total loss: 0.00019254024210055542, mse:0.0003850804823492388, ic :0.024158269495273395, sharpe5:-0.493543864544481, irr5:-0.11068765074014664, ndcg5:0.8474733192851576, pnl5:0.907321572303772 
train 2, step: 0, loss: 0.0001926057884702459, grad_norm: 4.729963087182312e-05, ic: -0.008137567789818272
train 2, step: 100, loss: 0.00030858072568662465, grad_norm: 0.00023327808347750113, ic: -0.07809223014048006
train 2, step: 200, loss: 0.0002832598693203181, grad_norm: 0.00033014330072478955, ic: 0.04945140262762694
train 2, step: 300, loss: 0.0005541841965168715, grad_norm: 0.0006811633095484845, ic: 0.01297279810908241
train 2, step: 400, loss: 0.00010237263632006943, grad_norm: 2.0397446583202033e-05, ic: -0.0028607462447959413
train 2, step: 500, loss: 0.00013475365994963795, grad_norm: 6.681956105565267e-07, ic: 0.014200092646654375
train 2, step: 600, loss: 0.00020150367345195264, grad_norm: 6.542027632376814e-05, ic: -0.04089965366430856
train 2, step: 700, loss: 0.00016758532728999853, grad_norm: 3.07098337469213e-05, ic: 0.022255502611069816
Epoch 2: 2022-05-05 21:03:48.641283: train loss: 0.00024257319625726974
Eval step 0: eval loss: 0.0001332545798504725
Eval step 100: eval loss: 0.00030440156115218997
Eval step 200: eval loss: 0.00031486302032135427
Eval: 2022-05-05 21:03:57.663786: total loss: 0.00018908256495459916, mse:0.0003781651239811894, ic :0.023614706635753897, sharpe5:-0.9907685033977032, irr5:-0.22086071968078613, ndcg5:0.8554322151147401, pnl5:0.9092295169830322 
train 3, step: 0, loss: 0.00015267783601302654, grad_norm: 9.85470109427525e-07, ic: 0.03887254882124537
train 3, step: 100, loss: 0.0002278780739288777, grad_norm: 0.00021450531277114203, ic: -0.017315944693748288
train 3, step: 200, loss: 0.0002516426320653409, grad_norm: 2.3043000056780457e-06, ic: -0.054046324296082346
train 3, step: 300, loss: 0.00020132068311795592, grad_norm: 3.6205757896107265e-05, ic: -0.006104873833505799
train 3, step: 400, loss: 0.00026659827562980354, grad_norm: 0.0003023037038449335, ic: -0.02491963250338569
train 3, step: 500, loss: 0.00029816804453730583, grad_norm: 0.00023800062773683564, ic: 0.025287887256642463
train 3, step: 600, loss: 0.00015828994219191372, grad_norm: 5.439692967040554e-05, ic: 0.0018528550477253485
train 3, step: 700, loss: 0.00033983198227360845, grad_norm: 0.00027876837395508937, ic: -0.039907866518789886
Epoch 3: 2022-05-05 21:04:50.535501: train loss: 0.0002310088771009565
Eval step 0: eval loss: 0.00016544379468541592
Eval step 100: eval loss: 0.0003514526761136949
Eval step 200: eval loss: 0.00027345443959347904
Eval: 2022-05-05 21:04:59.842275: total loss: 0.00019332851127819992, mse:0.0003866570210562544, ic :0.02053381562672488, sharpe5:-0.638686853684485, irr5:-0.13503915071487427, ndcg5:0.857386627633894, pnl5:0.9839910864830017 
train 4, step: 0, loss: 0.0001649623445700854, grad_norm: 2.268530046742032e-05, ic: -0.01683362404346366
train 4, step: 100, loss: 0.00013399554882198572, grad_norm: 9.679484698842355e-08, ic: -0.013745852642238418
train 4, step: 200, loss: 0.00019784158212132752, grad_norm: 8.368499101836964e-05, ic: -0.00413077080041882
train 4, step: 300, loss: 0.0005024539423175156, grad_norm: 0.00023291435452247355, ic: -0.043142994932733394
train 4, step: 400, loss: 0.00048063552821986377, grad_norm: 0.0003602225240681276, ic: -0.0070774983978070145
train 4, step: 500, loss: 0.00025556134642101824, grad_norm: 8.020791198827669e-05, ic: -0.03596324543120896
train 4, step: 600, loss: 0.000283177534583956, grad_norm: 0.00027880121618414363, ic: -0.02316722135064021
train 4, step: 700, loss: 0.00023692425747867674, grad_norm: 0.00020409785591717224, ic: 0.0006389650889906257
Epoch 4: 2022-05-05 21:05:51.494560: train loss: 0.00022269451220833914
Eval step 0: eval loss: 0.00012998621969018131
Eval step 100: eval loss: 0.0002988716005347669
Eval step 200: eval loss: 0.0003236103511881083
Eval: 2022-05-05 21:06:00.483712: total loss: 0.0001899279174194102, mse:0.0003798558283182384, ic :0.020816730176158385, sharpe5:-0.6912341503053904, irr5:-0.14670860767364502, ndcg5:0.8552229188539929, pnl5:1.0093257427215576 
train 5, step: 0, loss: 0.0002185268676839769, grad_norm: 4.9081395066874085e-05, ic: 0.02268662821576434
train 5, step: 100, loss: 0.0002177937130909413, grad_norm: 2.7737402430506447e-06, ic: 0.05500298374273452
train 5, step: 200, loss: 0.00010357509745517746, grad_norm: 1.2334719063478913e-05, ic: -0.037636133092912354
train 5, step: 300, loss: 0.0002036980731645599, grad_norm: 1.8101316683179793e-05, ic: 0.030405158446532472
train 5, step: 400, loss: 0.0005409896257333457, grad_norm: 0.0005288532302882077, ic: -0.02877622460814163
train 5, step: 500, loss: 0.0006575433071702719, grad_norm: 0.0007469932502944075, ic: -0.0002611540154912745
train 5, step: 600, loss: 0.0001831042318372056, grad_norm: 4.292224837952618e-06, ic: -0.007737679608983902
train 5, step: 700, loss: 0.00015122565673664212, grad_norm: 1.817037702492637e-05, ic: 0.0018085340154745146
Epoch 5: 2022-05-05 21:06:49.811821: train loss: 0.00021841251441522845
Eval step 0: eval loss: 0.00018978040316142142
Eval step 100: eval loss: 0.000383281905669719
Eval step 200: eval loss: 0.0002588947827462107
Eval: 2022-05-05 21:06:59.044595: total loss: 0.0002022705393358882, mse:0.000404541076211325, ic :0.01744747926019254, sharpe5:-0.9904962541535496, irr5:-0.21422597765922546, ndcg5:0.8567574160281658, pnl5:0.9717082381248474 
train 6, step: 0, loss: 0.00021136103896424174, grad_norm: 0.0002353482280291038, ic: 0.033295427576155896
train 6, step: 100, loss: 0.00011536580132087693, grad_norm: 6.978192182810432e-07, ic: 0.04185430006423177
train 6, step: 200, loss: 0.00020117193344049156, grad_norm: 5.82638202792396e-05, ic: 0.018937946494523704
train 6, step: 300, loss: 0.0002171778178308159, grad_norm: 4.862956273633304e-05, ic: -0.005570652871085863
train 6, step: 400, loss: 0.00035885570105165243, grad_norm: 5.594891941747588e-05, ic: -0.010126999041459878
train 6, step: 500, loss: 0.00010848419333342463, grad_norm: 2.0262009911588914e-05, ic: 0.050356448905847555
train 6, step: 600, loss: 0.00013638967357110232, grad_norm: 9.64966020203612e-07, ic: 0.0015238172312538227
train 6, step: 700, loss: 0.00015077531861606985, grad_norm: 6.707398598526278e-05, ic: 0.04883977748829113
Epoch 6: 2022-05-05 21:07:49.406340: train loss: 0.00021590159450622493
Eval step 0: eval loss: 0.0001456587779102847
Eval step 100: eval loss: 0.0003228325513191521
Eval step 200: eval loss: 0.00029665083275176585
Eval: 2022-05-05 21:07:58.685610: total loss: 0.0001888992623581071, mse:0.00037779852653377924, ic :0.01843166719146537, sharpe5:-0.9304686361178756, irr5:-0.19784945249557495, ndcg5:0.8622568727649655, pnl5:0.9836235642433167 
train 7, step: 0, loss: 0.00020758106256835163, grad_norm: 1.116849010880946e-05, ic: 0.0950443591104056
train 7, step: 100, loss: 0.0004471715074032545, grad_norm: 0.0006425624147643036, ic: -0.06536224939500473
train 7, step: 200, loss: 0.0002837666543200612, grad_norm: 0.0001270637776605346, ic: -0.016346755220293448
train 7, step: 300, loss: 0.00019279474508948624, grad_norm: 0.00015471303890737286, ic: -0.023281553983240857
train 7, step: 400, loss: 0.00016716720710974187, grad_norm: 3.30145834873532e-07, ic: -0.06606625653557216
train 7, step: 500, loss: 0.00037954439176246524, grad_norm: 0.000184237498561065, ic: 0.047361322884712356
train 7, step: 600, loss: 0.00012245780089870095, grad_norm: 8.095759416787548e-06, ic: 0.037152286006830126
train 7, step: 700, loss: 0.0002878898521885276, grad_norm: 7.17298390566332e-05, ic: 0.005626299765619646
Epoch 7: 2022-05-05 21:08:48.271970: train loss: 0.00021397800408784652
Eval step 0: eval loss: 0.00014350561832543463
Eval step 100: eval loss: 0.0003196967882104218
Eval step 200: eval loss: 0.0002997281844727695
Eval: 2022-05-05 21:08:57.898595: total loss: 0.00018872930980938198, mse:0.00037745861927240305, ic :0.0183270372818465, sharpe5:-1.0767043172568083, irr5:-0.23265886306762695, ndcg5:0.8595753323121781, pnl5:1.008213758468628 
train 8, step: 0, loss: 0.00015452301886398345, grad_norm: 6.449407189295952e-06, ic: 0.03497467575068914
train 8, step: 100, loss: 0.0001665350137045607, grad_norm: 0.00011692042325555904, ic: 0.0024980830999675532
train 8, step: 200, loss: 0.00014842921518720686, grad_norm: 8.341102633120187e-05, ic: 0.052178624432837786
train 8, step: 300, loss: 0.00015087448991835117, grad_norm: 1.1833072149585167e-07, ic: -0.05487778282050179
train 8, step: 400, loss: 0.00011744147195713595, grad_norm: 1.8327612663313314e-05, ic: 0.004085144119919412
train 8, step: 500, loss: 0.00016462604980915785, grad_norm: 5.282095638532063e-05, ic: -0.011179465954805907
train 8, step: 600, loss: 0.0001232254144269973, grad_norm: 1.0744042421590113e-05, ic: -0.018732026890317194
train 8, step: 700, loss: 0.00010975778423016891, grad_norm: 1.302434896041322e-05, ic: 0.04552958153311343
Epoch 8: 2022-05-05 21:09:49.517175: train loss: 0.0002126972888516048
Eval step 0: eval loss: 0.00013979389041196555
Eval step 100: eval loss: 0.0003146564413327724
Eval step 200: eval loss: 0.0003041012678295374
Eval: 2022-05-05 21:09:58.893897: total loss: 0.000188708282291877, mse:0.0003774165637145799, ic :0.017765033284105895, sharpe5:-1.0816587214171887, irr5:-0.23382115364074707, ndcg5:0.8492511859623192, pnl5:0.9728577136993408 
train 9, step: 0, loss: 0.00013810029486194253, grad_norm: 8.233835835919243e-06, ic: 0.024389533632537028
train 9, step: 100, loss: 0.00016007198428269476, grad_norm: 0.00013800989849550773, ic: 0.08946178686950024
train 9, step: 200, loss: 7.624889258295298e-05, grad_norm: 1.1269907675708585e-05, ic: 0.026538813290983503
train 9, step: 300, loss: 0.0003220831276848912, grad_norm: 0.0002029331980629818, ic: -0.03928391869774919
train 9, step: 400, loss: 0.00024887468316592276, grad_norm: 0.00012735552450009654, ic: 0.015469277395439476
train 9, step: 500, loss: 8.579699351685122e-05, grad_norm: 2.423808924619437e-06, ic: -0.029709302028532218
train 9, step: 600, loss: 0.0001744463515933603, grad_norm: 0.00010305200389257839, ic: -0.0012355285403785228
train 9, step: 700, loss: 0.00045220175525173545, grad_norm: 0.00048475234365693014, ic: 0.004458659813892962
Epoch 9: 2022-05-05 21:10:49.815136: train loss: 0.00021101367108100207
Eval step 0: eval loss: 0.0001296792324865237
Eval step 100: eval loss: 0.0002986195613630116
Eval step 200: eval loss: 0.00032419251510873437
Eval: 2022-05-05 21:10:59.892008: total loss: 0.00019016705644540652, mse:0.00038033411466704015, ic :0.017565131352501432, sharpe5:-1.0087834221124647, irr5:-0.217515230178833, ndcg5:0.8590592376505536, pnl5:0.9849610924720764 
train 10, step: 0, loss: 9.5936338766478e-05, grad_norm: 1.5448096333398971e-07, ic: -0.010034343301755472
train 10, step: 100, loss: 0.00020283057529013604, grad_norm: 3.6592140710900036e-05, ic: 0.02424380448483139
train 10, step: 200, loss: 0.00016991230950225145, grad_norm: 4.726376496364103e-06, ic: 0.02098371054872718
train 10, step: 300, loss: 0.00027454871451482177, grad_norm: 5.45510383290238e-05, ic: 0.0342997626111359
train 10, step: 400, loss: 0.000250994082307443, grad_norm: 9.9361536617977e-05, ic: 0.15291745415138028
train 10, step: 500, loss: 0.0002247728843940422, grad_norm: 9.448665596998383e-05, ic: 0.005978297115619842
train 10, step: 600, loss: 0.00023776150192134082, grad_norm: 0.00016465014874120207, ic: 0.04688300943074747
train 10, step: 700, loss: 0.0002868259616661817, grad_norm: 0.0002528406113289681, ic: 0.009939209654538438
Epoch 10: 2022-05-05 21:11:51.266114: train loss: 0.00021083884585484892
Eval step 0: eval loss: 0.00017469954036641866
Eval step 100: eval loss: 0.0003630718565545976
Eval step 200: eval loss: 0.0002686404623091221
Eval: 2022-05-05 21:12:01.479572: total loss: 0.00019615284672035434, mse:0.0003923056921612392, ic :0.015910126404280012, sharpe5:-1.0368056436628104, irr5:-0.22400778532028198, ndcg5:0.8502262847204212, pnl5:0.9807721972465515 
train 11, step: 0, loss: 0.000237833519349806, grad_norm: 5.34102517861363e-06, ic: -0.005703616596414572
train 11, step: 100, loss: 0.00010109207505593076, grad_norm: 7.704233218792078e-06, ic: 0.054488199481773476
train 11, step: 200, loss: 0.00017350073903799057, grad_norm: 1.9775445935769772e-05, ic: 0.002074942697138189
train 11, step: 300, loss: 0.0005403741961345077, grad_norm: 9.921864919426992e-07, ic: 0.007013068509273777
train 11, step: 400, loss: 8.654363045934588e-05, grad_norm: 1.245562635844764e-05, ic: 0.033719921280981696
train 11, step: 500, loss: 0.0002271344856126234, grad_norm: 5.051029059572362e-06, ic: -0.02824353093754072
train 11, step: 600, loss: 0.00038345626671798527, grad_norm: 0.00010744573231372631, ic: 0.005551696116499275
train 11, step: 700, loss: 0.00048195806448347867, grad_norm: 0.0005905305997874696, ic: 0.014226124447112971
Epoch 11: 2022-05-05 21:12:52.906912: train loss: 0.00021071520834259458
Eval step 0: eval loss: 0.0001389581011608243
Eval step 100: eval loss: 0.0003123432397842407
Eval step 200: eval loss: 0.0003084949858020991
Eval: 2022-05-05 21:13:02.867484: total loss: 0.00018864073122111373, mse:0.00037728145846288775, ic :0.017229140608063562, sharpe5:-0.9896756044775247, irr5:-0.21563762426376343, ndcg5:0.8639636815431062, pnl5:0.9890690445899963 
train 12, step: 0, loss: 0.0001612938940525055, grad_norm: 6.188752966987907e-05, ic: 0.013141495909200267
train 12, step: 100, loss: 0.00012833953951485455, grad_norm: 5.386286761856544e-05, ic: -0.05068700933906671
train 12, step: 200, loss: 0.00034744731965474784, grad_norm: 0.00014845016959960045, ic: 0.07394794598031226
train 12, step: 300, loss: 0.00022493164578918368, grad_norm: 9.892049024558213e-05, ic: 0.05598568747650462
train 12, step: 400, loss: 0.0003770424809772521, grad_norm: 3.0114427988492896e-05, ic: 0.07598173871467692
train 12, step: 500, loss: 0.00013732370280195028, grad_norm: 3.4002054634807015e-06, ic: 5.5243346586826905e-05
train 12, step: 600, loss: 0.0002449185703881085, grad_norm: 8.310068522499254e-06, ic: -0.05214592176548764
train 12, step: 700, loss: 0.0005215274286456406, grad_norm: 7.637191168248293e-05, ic: 0.015171415509488537
Epoch 12: 2022-05-05 21:13:54.526766: train loss: 0.00020967956330170568
Eval step 0: eval loss: 0.00014781711797695607
Eval step 100: eval loss: 0.0003255462215747684
Eval step 200: eval loss: 0.0002951819042209536
Eval: 2022-05-05 21:14:04.131717: total loss: 0.00018911381697182556, mse:0.00037822763392788856, ic :0.01616661723179945, sharpe5:-1.0007218884676694, irr5:-0.21510949730873108, ndcg5:0.8617883771453988, pnl5:0.9682818055152893 
train 13, step: 0, loss: 0.00017132694483734667, grad_norm: 1.7144003979653003e-05, ic: 0.022760093045862805
train 13, step: 100, loss: 0.0002057145902654156, grad_norm: 1.5612540011931962e-06, ic: 0.06760276260395473
train 13, step: 200, loss: 0.00036217638989910483, grad_norm: 0.00016986840288188407, ic: -0.009809392667811728
train 13, step: 300, loss: 0.0001245033781742677, grad_norm: 1.791748381577466e-05, ic: -0.0020800182170248992
train 13, step: 400, loss: 0.0001280277647310868, grad_norm: 7.82283541115374e-05, ic: 0.0021307950356416142
train 13, step: 500, loss: 0.00012397200043778867, grad_norm: 1.9072375174193908e-06, ic: 0.07193210484513185
train 13, step: 600, loss: 0.00015902440645731986, grad_norm: 2.8833564893184123e-05, ic: -0.052286788410304944
train 13, step: 700, loss: 0.00018104405899066478, grad_norm: 3.0657102021640635e-05, ic: -0.010266672935326446
Epoch 13: 2022-05-05 21:14:55.114379: train loss: 0.00020935299033878052
Eval step 0: eval loss: 0.00016297755064442754
Eval step 100: eval loss: 0.00034709658939391375
Eval step 200: eval loss: 0.00027822720585390925
Eval: 2022-05-05 21:15:04.484402: total loss: 0.0001923404224765971, mse:0.0003846808435583224, ic :0.01582725068137321, sharpe5:-0.9828166380152106, irr5:-0.2115614414215088, ndcg5:0.8608578484245697, pnl5:1.006696105003357 
train 14, step: 0, loss: 0.00020457238133531064, grad_norm: 1.2820307815495763e-06, ic: 0.029367730487955827
train 14, step: 100, loss: 0.00012138790771132335, grad_norm: 2.3028108539200408e-05, ic: -0.020494513178199752
train 14, step: 200, loss: 0.00017559561820235103, grad_norm: 2.318800458334613e-06, ic: 0.004496002219165231
train 14, step: 300, loss: 0.00028767288313247263, grad_norm: 8.260519101238925e-05, ic: 0.030159412987488247
train 14, step: 400, loss: 0.00012567474914249033, grad_norm: 3.528266037971417e-05, ic: -0.002779715768576165
train 14, step: 500, loss: 0.00017506207223050296, grad_norm: 2.3021003763489433e-06, ic: -0.020775243069665765
train 14, step: 600, loss: 0.0001100053486879915, grad_norm: 1.398606479224457e-05, ic: 0.021497615444694362
train 14, step: 700, loss: 0.0001326654601143673, grad_norm: 5.364868012453762e-05, ic: 0.02861063692711232
Epoch 14: 2022-05-05 21:15:54.324206: train loss: 0.00020883137921358827
Eval step 0: eval loss: 0.00013791662058793008
Eval step 100: eval loss: 0.00031121724168770015
Eval step 200: eval loss: 0.00030904749291948974
Eval: 2022-05-05 21:16:03.945373: total loss: 0.00018870278077828392, mse:0.0003774055619032788, ic :0.016341451680432682, sharpe5:-0.9746198961138725, irr5:-0.2102087438106537, ndcg5:0.8583392988456179, pnl5:0.9912405610084534 
train 15, step: 0, loss: 0.0001395084836985916, grad_norm: 6.113790323942494e-06, ic: 0.06298281486698391
train 15, step: 100, loss: 0.0003144956426694989, grad_norm: 0.000110592515397441, ic: -0.002484280878996912
train 15, step: 200, loss: 0.00014363622176460922, grad_norm: 5.210305406019543e-05, ic: -0.022551137558797424
train 15, step: 300, loss: 0.0005686343065463006, grad_norm: 8.825144470199603e-05, ic: 0.04469926829408301
train 15, step: 400, loss: 0.00013332902744878083, grad_norm: 2.6138193036150954e-05, ic: -0.03598694556275139
train 15, step: 500, loss: 0.00010526245750952512, grad_norm: 1.0929317541054619e-06, ic: -0.008643325723092255
train 15, step: 600, loss: 0.00022553263988811523, grad_norm: 7.77651137243181e-05, ic: 0.030574426112741922
train 15, step: 700, loss: 9.482060704613104e-05, grad_norm: 1.888141637940903e-05, ic: 0.02510352639010263
Epoch 15: 2022-05-05 21:16:55.838927: train loss: 0.00020849674450908103
Eval step 0: eval loss: 0.00012066819908795878
Eval step 100: eval loss: 0.00028158960049040616
Eval step 200: eval loss: 0.00035575160291045904
Eval: 2022-05-05 21:17:05.585750: total loss: 0.0001962764143720615, mse:0.0003925528230517725, ic :0.016894780081382347, sharpe5:-1.0772045937180519, irr5:-0.2317710518836975, ndcg5:0.8605339884013283, pnl5:0.9888575673103333 
train 16, step: 0, loss: 0.0002076826203847304, grad_norm: 9.855064737139372e-06, ic: 0.034396176112530305
train 16, step: 100, loss: 0.00011363693920429796, grad_norm: 6.544161896598507e-06, ic: 0.02221464266352379
train 16, step: 200, loss: 0.00016559950017835945, grad_norm: 1.5998637714838234e-06, ic: 0.03373108240704504
train 16, step: 300, loss: 0.00015925357001833618, grad_norm: 0.00010646573293421925, ic: 0.05736122500483225
train 16, step: 400, loss: 0.00026602644356898963, grad_norm: 9.879395586869392e-05, ic: 0.04208677784543305
train 16, step: 500, loss: 0.0001295590482186526, grad_norm: 2.1239817758908984e-05, ic: 0.033110678300892975
train 16, step: 600, loss: 8.534243534086272e-05, grad_norm: 4.856425689720661e-07, ic: 0.11844468058025721
train 16, step: 700, loss: 0.00015131729014683515, grad_norm: 1.7531834510781565e-05, ic: -0.012981588247962264
Epoch 16: 2022-05-05 21:17:58.965052: train loss: 0.00020884996147433802
Eval step 0: eval loss: 0.0001615312066860497
Eval step 100: eval loss: 0.00034489744575694203
Eval step 200: eval loss: 0.0002799851936288178
Eval: 2022-05-05 21:18:08.887549: total loss: 0.00019190182918138744, mse:0.0003838036530210302, ic :0.015514800957447518, sharpe5:-1.0135951097309588, irr5:-0.2200947403907776, ndcg5:0.8507246445043911, pnl5:0.9849494695663452 
train 17, step: 0, loss: 0.00014078148524276912, grad_norm: 4.747831807325727e-08, ic: 0.1057148793204919
train 17, step: 100, loss: 0.0002723058860283345, grad_norm: 0.0002763097101577514, ic: -0.09116344413137535
train 17, step: 200, loss: 0.0002340672363061458, grad_norm: 9.708932288593982e-05, ic: 0.06276087957352286
train 17, step: 300, loss: 0.00022819696459919214, grad_norm: 0.00017170803044890513, ic: 0.06083681407267237
train 17, step: 400, loss: 0.0001659775443840772, grad_norm: 0.00011657712862886539, ic: 0.041729760003138175
train 17, step: 500, loss: 8.06332755018957e-05, grad_norm: 8.123640535815261e-09, ic: 0.04181398321113107
train 17, step: 600, loss: 0.0005042590200901031, grad_norm: 0.0005674232410042263, ic: 0.11275526674620118
train 17, step: 700, loss: 7.294752140296623e-05, grad_norm: 7.730194120223652e-07, ic: -0.037847907525152866
Epoch 17: 2022-05-05 21:19:00.764883: train loss: 0.0002086082199323215
Eval step 0: eval loss: 0.00015098770381882787
Eval step 100: eval loss: 0.0003303858102299273
Eval step 200: eval loss: 0.00029052566969767213
Eval: 2022-05-05 21:19:10.642864: total loss: 0.0001896052923400207, mse:0.00037921058385402654, ic :0.016159991401387873, sharpe5:-0.8785592481493949, irr5:-0.18916285037994385, ndcg5:0.861952398553799, pnl5:0.9901593327522278 
train 18, step: 0, loss: 0.00036588063812814653, grad_norm: 0.0002765959695540607, ic: 0.08782863945898105
train 18, step: 100, loss: 0.0002469017053954303, grad_norm: 0.000101933923548596, ic: -0.08943007678984022
train 18, step: 200, loss: 0.00019474700093269348, grad_norm: 4.6187101274490296e-05, ic: 0.03388253404733997
train 18, step: 300, loss: 0.00012386441812850535, grad_norm: 1.6952066607811998e-07, ic: 0.07954623366773833
train 18, step: 400, loss: 8.760049968259409e-05, grad_norm: 5.886681853046723e-07, ic: 0.01656151015369895
train 18, step: 500, loss: 0.0002643081534188241, grad_norm: 0.00019835184542787946, ic: 0.02489887904700878
train 18, step: 600, loss: 0.0001300073927268386, grad_norm: 5.835542810686062e-06, ic: 0.061729550623811434
train 18, step: 700, loss: 0.0001787160144886002, grad_norm: 8.708135650529759e-05, ic: 0.09250162125961398
Epoch 18: 2022-05-05 21:20:02.909039: train loss: 0.00020795573378408223
Eval step 0: eval loss: 0.00014217139687389135
Eval step 100: eval loss: 0.00031782189034856856
Eval step 200: eval loss: 0.00030158579465933144
Eval: 2022-05-05 21:20:13.247931: total loss: 0.0001886976443334812, mse:0.00037739528678194215, ic :0.016527272935408906, sharpe5:-1.0112747539579867, irr5:-0.218053936958313, ndcg5:0.8572673300805439, pnl5:1.0021017789840698 
train 19, step: 0, loss: 0.00023898891231510788, grad_norm: 0.0002140274667254248, ic: -0.0345029391351931
train 19, step: 100, loss: 0.00021305994596332312, grad_norm: 1.4901169846271889e-05, ic: -0.03031931754571749
train 19, step: 200, loss: 0.0001627140591153875, grad_norm: 1.8366902722076004e-06, ic: 0.02369559787894504
train 19, step: 300, loss: 0.00014637205458711833, grad_norm: 3.716681898392907e-06, ic: -0.07923790281081518
train 19, step: 400, loss: 0.00014558556722477078, grad_norm: 2.0033801044286908e-05, ic: 0.08119715174691797
train 19, step: 500, loss: 0.0002057875826722011, grad_norm: 4.453164339418666e-07, ic: 0.07560726115673332
train 19, step: 600, loss: 0.00025402751634828746, grad_norm: 6.2738010411473006e-06, ic: 0.005274195164344917
train 19, step: 700, loss: 0.00026883886312134564, grad_norm: 0.00015157817623787806, ic: -0.023832335076026938
Epoch 19: 2022-05-05 21:21:04.527207: train loss: 0.00020780414190162957
Eval step 0: eval loss: 0.00014435667253565043
Eval step 100: eval loss: 0.000320926628774032
Eval step 200: eval loss: 0.00029873044695705175
Eval: 2022-05-05 21:21:14.480214: total loss: 0.00018879728422014198, mse:0.00037759456669392126, ic :0.017061754051335712, sharpe5:-0.995549093708396, irr5:-0.2135474681854248, ndcg5:0.8516802202213608, pnl5:0.9856451153755188 
train 20, step: 0, loss: 0.00023002071247901767, grad_norm: 5.060097318255232e-06, ic: -0.022503020521593555
train 20, step: 100, loss: 0.0001358558947686106, grad_norm: 4.1052101437198315e-05, ic: 0.04898708961938325
train 20, step: 200, loss: 0.0002561335568316281, grad_norm: 1.7942957907480215e-06, ic: 0.04904987935882276
train 20, step: 300, loss: 0.00022344790340866894, grad_norm: 1.8493000584655677e-06, ic: 0.08567927189735089
train 20, step: 400, loss: 0.00014962056593503803, grad_norm: 3.664283405467027e-05, ic: -0.03203220407053932
train 20, step: 500, loss: 0.00010499080235604197, grad_norm: 1.245286084892709e-06, ic: -0.03750672496331171
train 20, step: 600, loss: 0.00014187800115905702, grad_norm: 2.36687131395882e-05, ic: -0.017621720613923312
train 20, step: 700, loss: 0.00037720409454777837, grad_norm: 0.00040016228236270453, ic: 0.015016912366093715
Epoch 20: 2022-05-05 21:22:08.081462: train loss: 0.00020772956315126708
Eval step 0: eval loss: 0.00014791087596677244
Eval step 100: eval loss: 0.00032666351762600243
Eval step 200: eval loss: 0.0002925458538811654
Eval: 2022-05-05 21:22:17.743537: total loss: 0.0001892671388102183, mse:0.0003785342744948822, ic :0.017307567763871823, sharpe5:-1.0630135796964169, irr5:-0.22813063859939575, ndcg5:0.8612582090283621, pnl5:1.0090477466583252 
train 21, step: 0, loss: 0.00037363122100941837, grad_norm: 0.00038123647573204145, ic: 0.04758896925822875
train 21, step: 100, loss: 0.00017654510156717151, grad_norm: 3.562907698106165e-05, ic: 0.03973794294739174
train 21, step: 200, loss: 0.00013002949708607048, grad_norm: 4.320803013905306e-06, ic: 0.025365058687303065
train 21, step: 300, loss: 0.0001234945812029764, grad_norm: 4.6366790334077526e-07, ic: 0.059039567660682725
train 21, step: 400, loss: 0.00015907215129118413, grad_norm: 8.883520072645164e-06, ic: -0.006671058018866389
train 21, step: 500, loss: 0.0001874816371127963, grad_norm: 4.357458516720534e-05, ic: 0.027069412896196483
train 21, step: 600, loss: 0.00032738925074227154, grad_norm: 8.552290289659891e-06, ic: 0.07804814569214905
train 21, step: 700, loss: 0.0002749775885604322, grad_norm: 9.198727480326972e-05, ic: 0.02805547473439674
Epoch 21: 2022-05-05 21:23:10.527406: train loss: 0.00020766308480330692
Eval step 0: eval loss: 0.00016514172602910548
Eval step 100: eval loss: 0.0003500129096210003
Eval step 200: eval loss: 0.00027633761055767536
Eval: 2022-05-05 21:23:20.057939: total loss: 0.0001929547632871578, mse:0.00038590952193883165, ic :0.018139872591469992, sharpe5:-0.8534340423345566, irr5:-0.18473565578460693, ndcg5:0.8553949233410353, pnl5:0.9774640798568726 
train 22, step: 0, loss: 0.0001307311758864671, grad_norm: 1.634910127784151e-05, ic: 0.06261677126208764
train 22, step: 100, loss: 0.0001148655210272409, grad_norm: 4.1680905579074005e-06, ic: 0.0357921554173926
train 22, step: 200, loss: 0.00022872863337397575, grad_norm: 9.466859742506036e-05, ic: 0.028993803072551852
train 22, step: 300, loss: 0.00016094236343633384, grad_norm: 3.4737839325036484e-05, ic: 0.016547991153627897
train 22, step: 400, loss: 0.00023965629225131124, grad_norm: 4.283287227000226e-06, ic: 0.02895742023885588
train 22, step: 500, loss: 0.00012679246719926596, grad_norm: 4.937354316734333e-05, ic: -0.008021505475297494
train 22, step: 600, loss: 0.00017746194498613477, grad_norm: 0.00013685552842675598, ic: 0.053907412626189186
train 22, step: 700, loss: 0.00011362761142663658, grad_norm: 3.813527138219995e-06, ic: 0.012749051313016723
Epoch 22: 2022-05-05 21:24:11.737703: train loss: 0.00020740277776053396
Eval step 0: eval loss: 0.00013151149323675781
Eval step 100: eval loss: 0.00030119434813968837
Eval step 200: eval loss: 0.0003211999428458512
Eval: 2022-05-05 21:24:22.071008: total loss: 0.0001895604533457002, mse:0.0003791209053044294, ic :0.01902854849805794, sharpe5:-0.8480412607267499, irr5:-0.18351152539253235, ndcg5:0.8405588372448386, pnl5:0.978025496006012 
train 23, step: 0, loss: 0.00020077625231351703, grad_norm: 7.004219363674641e-05, ic: 0.07324500387256208
train 23, step: 100, loss: 0.0001410946570103988, grad_norm: 2.626066293705505e-06, ic: -0.006358435854385322
train 23, step: 200, loss: 0.0003069062950089574, grad_norm: 0.0001103566980814181, ic: 0.05281234694856746
train 23, step: 300, loss: 0.0003247754939366132, grad_norm: 0.00037125431402983453, ic: -0.07723959148276252
train 23, step: 400, loss: 0.00015784251445438713, grad_norm: 3.1120639462777076e-05, ic: 0.11739488139091514
train 23, step: 500, loss: 0.00010507609113119543, grad_norm: 2.9351326464435892e-05, ic: -0.04807141031781302
train 23, step: 600, loss: 0.00020741214393638074, grad_norm: 0.00014586736017773762, ic: 0.019426554333290817
train 23, step: 700, loss: 0.00015633716247975826, grad_norm: 7.362761860977711e-05, ic: 0.09566976666968896
Epoch 23: 2022-05-05 21:25:14.838952: train loss: 0.00020808928332463988
Eval step 0: eval loss: 0.00014203021419234574
Eval step 100: eval loss: 0.0003176091122440994
Eval step 200: eval loss: 0.00030157220317050815
Eval: 2022-05-05 21:25:24.884489: total loss: 0.00018865954131904713, mse:0.00037731907695528463, ic :0.0189168930029444, sharpe5:-0.9125325248390436, irr5:-0.19656068086624146, ndcg5:0.8515051736879792, pnl5:0.9834184050559998 
train 24, step: 0, loss: 0.00016430954565294087, grad_norm: 2.7802163275883717e-06, ic: -0.027997170964024046
train 24, step: 100, loss: 0.0002687962260097265, grad_norm: 0.00023281323572890258, ic: 0.08491438891220202
train 24, step: 200, loss: 0.0001526500709587708, grad_norm: 3.419888326604925e-05, ic: 0.04285416638887747
train 24, step: 300, loss: 8.574993262300268e-05, grad_norm: 6.1239503054667e-06, ic: 0.05508908917105939
train 24, step: 400, loss: 0.00013763931929133832, grad_norm: 7.215233099666458e-05, ic: 0.02560676104571216
train 24, step: 500, loss: 0.00021819569519720972, grad_norm: 4.5567925223094746e-05, ic: -0.005492519857073698
train 24, step: 600, loss: 0.0001192114723380655, grad_norm: 9.427925864555965e-06, ic: -0.02985675509837236
train 24, step: 700, loss: 8.959478145698085e-05, grad_norm: 3.1592029240984334e-05, ic: -0.14698528592677768
Epoch 24: 2022-05-05 21:26:17.893724: train loss: 0.00020737035850089113
Eval step 0: eval loss: 0.00015103898476809263
Eval step 100: eval loss: 0.00033089693170040846
Eval step 200: eval loss: 0.00028890310204587877
Eval: 2022-05-05 21:26:28.123813: total loss: 0.00018965703329502494, mse:0.0003793140616012525, ic :0.020613790847242734, sharpe5:-0.9642372972518205, irr5:-0.20908766984939575, ndcg5:0.8498397251652706, pnl5:0.9931754469871521 
train 25, step: 0, loss: 0.00013666393351741135, grad_norm: 8.378384911397476e-05, ic: 0.11411527091468837
train 25, step: 100, loss: 0.00026181258726865053, grad_norm: 8.528547262713504e-05, ic: 0.07318971953390675
train 25, step: 200, loss: 0.00024154828861355782, grad_norm: 0.00010856116434284464, ic: 0.011512287929346608
train 25, step: 300, loss: 0.0001542513637105003, grad_norm: 1.124999301495538e-06, ic: 0.01818382193386054
train 25, step: 400, loss: 0.00022685693693347275, grad_norm: 0.0001472150780242802, ic: 0.009901593565695505
train 25, step: 500, loss: 0.00018078892026096582, grad_norm: 0.00012908334009982777, ic: 0.03809809588139732
train 25, step: 600, loss: 0.00015704073302913457, grad_norm: 0.00010940585231987263, ic: 0.03335394066685775
train 25, step: 700, loss: 0.0002887896844185889, grad_norm: 3.791021978942129e-06, ic: 0.04460512778740039
Epoch 25: 2022-05-05 21:27:21.065006: train loss: 0.00020763138614069356
Eval step 0: eval loss: 0.00013517271145246923
Eval step 100: eval loss: 0.00030702759977430105
Eval step 200: eval loss: 0.00031338640837930143
Eval: 2022-05-05 21:27:31.238040: total loss: 0.00018887555760592752, mse:0.00037775111317002826, ic :0.020451940799209197, sharpe5:-0.9985176450759172, irr5:-0.21677270531654358, ndcg5:0.846021110114381, pnl5:0.9874420166015625 
train 26, step: 0, loss: 0.00014278525486588478, grad_norm: 2.075925175705551e-05, ic: 0.02665760484145393
train 26, step: 100, loss: 0.0001173612181446515, grad_norm: 4.69461804062519e-08, ic: 0.024565236344549705
train 26, step: 200, loss: 0.00013456615852192044, grad_norm: 4.182467217820777e-07, ic: 0.05291110048305288
train 26, step: 300, loss: 0.0001748845388647169, grad_norm: 1.0266912280838143e-06, ic: 0.018507620216912397
train 26, step: 400, loss: 0.00020499031234066933, grad_norm: 3.7416989006859297e-06, ic: -0.03170719592134556
train 26, step: 500, loss: 7.038380863377824e-05, grad_norm: 1.25121591346695e-05, ic: -0.024145008112629186
train 26, step: 600, loss: 0.00016446584777440876, grad_norm: 5.623841064519216e-05, ic: 0.07659382801631251
train 26, step: 700, loss: 0.00017409410793334246, grad_norm: 2.026982642382065e-05, ic: -0.06776307756332614
Epoch 26: 2022-05-05 21:28:23.860783: train loss: 0.00020729393285374222
Eval step 0: eval loss: 0.00015759696543682367
Eval step 100: eval loss: 0.00034061301266774535
Eval step 200: eval loss: 0.0002806163392961025
Eval: 2022-05-05 21:28:34.389472: total loss: 0.00019114294839086516, mse:0.0003822858964687941, ic :0.02115715856635688, sharpe5:-0.8022734136879444, irr5:-0.17342132329940796, ndcg5:0.852693135697891, pnl5:0.9864449501037598 
train 27, step: 0, loss: 0.00019686733139678836, grad_norm: 6.636381947646222e-05, ic: 0.005197885838706282
train 27, step: 100, loss: 0.00016764833708293736, grad_norm: 6.163407384204468e-06, ic: 0.01815185637720165
train 27, step: 200, loss: 0.00011549258488230407, grad_norm: 3.0200691426132476e-05, ic: 0.07931483050980337
train 27, step: 300, loss: 0.0003875235852319747, grad_norm: 0.0003881837577730197, ic: 0.04461940605777467
train 27, step: 400, loss: 0.00024804880376905203, grad_norm: 8.663969889657417e-05, ic: 0.0627290316324675
train 27, step: 500, loss: 0.0001731950178509578, grad_norm: 2.6954275052435682e-05, ic: -0.03527197648540276
train 27, step: 600, loss: 0.0006310848984867334, grad_norm: 0.0006627249251920671, ic: -0.08039361287884594
train 27, step: 700, loss: 0.0002480877737980336, grad_norm: 9.67456968491096e-05, ic: 0.052228949464269404
Epoch 27: 2022-05-05 21:29:27.276111: train loss: 0.0002075181718511282
Eval step 0: eval loss: 0.00014317758905235678
Eval step 100: eval loss: 0.0003193930024281144
Eval step 200: eval loss: 0.0002993647940456867
Eval: 2022-05-05 21:29:37.547082: total loss: 0.0001887036657444299, mse:0.0003774073247222551, ic :0.0207659470229968, sharpe5:-0.8022735910490155, irr5:-0.17342132329940796, ndcg5:0.8510501956955848, pnl5:0.9864452481269836 
train 28, step: 0, loss: 0.00031424409826286137, grad_norm: 4.490661685103567e-06, ic: -0.03960035568648962
train 28, step: 100, loss: 0.00012168084504082799, grad_norm: 4.960839081196073e-05, ic: 0.052758506510330566
train 28, step: 200, loss: 8.416232594754547e-05, grad_norm: 5.347475464736186e-06, ic: 0.022891624725109846
train 28, step: 300, loss: 0.00023029797011986375, grad_norm: 4.258107026732188e-06, ic: -0.09189982252734086
train 28, step: 400, loss: 0.0004095102194696665, grad_norm: 9.082151683088472e-05, ic: 0.09869376964344992
train 28, step: 500, loss: 0.00018642083159647882, grad_norm: 5.320728406853874e-05, ic: 0.05443626986273256
train 28, step: 600, loss: 0.00034621870145201683, grad_norm: 0.0001972384833868234, ic: 0.03704389367848637
train 28, step: 700, loss: 0.00021332486358005553, grad_norm: 3.96280703457666e-06, ic: 0.08696146702812906
Epoch 28: 2022-05-05 21:30:31.253954: train loss: 0.00020711233146406336
Eval step 0: eval loss: 0.00014209210348781198
Eval step 100: eval loss: 0.0003181050415150821
Eval step 200: eval loss: 0.0002999142452608794
Eval: 2022-05-05 21:30:41.511319: total loss: 0.00018867999276499098, mse:0.0003773599817064453, ic :0.021572214212672445, sharpe5:-0.8767494557797908, irr5:-0.1897478997707367, ndcg5:0.8537443524144388, pnl5:0.9904694557189941 
train 29, step: 0, loss: 0.0001817093725549057, grad_norm: 4.527277974448875e-06, ic: 0.05407213215252301
train 29, step: 100, loss: 0.0001057259360095486, grad_norm: 8.488932587353154e-06, ic: 0.00990826911231721
train 29, step: 200, loss: 0.00030506227631121874, grad_norm: 7.88738197454541e-06, ic: 0.019028399706337205
train 29, step: 300, loss: 0.00018770105089060962, grad_norm: 2.306347472738022e-06, ic: -0.03183181312817784
train 29, step: 400, loss: 0.00010276443208567798, grad_norm: 1.1392058045691057e-05, ic: -0.03287584631759183
train 29, step: 500, loss: 0.00012300694652367383, grad_norm: 1.0350415760556754e-05, ic: 0.0566683267385409
train 29, step: 600, loss: 0.0001553430629428476, grad_norm: 1.3184439806868171e-06, ic: 0.09612581229762021
train 29, step: 700, loss: 0.00019458873430266976, grad_norm: 1.4840797514792578e-05, ic: 0.06899212688366928
Epoch 29: 2022-05-05 21:31:34.800978: train loss: 0.00020705642802986308
Eval step 0: eval loss: 0.00015275544137693942
Eval step 100: eval loss: 0.00033342023380100727
Eval step 200: eval loss: 0.0002864676062017679
Eval: 2022-05-05 21:31:44.980474: total loss: 0.00018997232913391414, mse:0.0003799446549223065, ic :0.023217592915038464, sharpe5:-0.90676521576941, irr5:-0.19686609506607056, ndcg5:0.858076568825277, pnl5:0.9522311091423035 
train 30, step: 0, loss: 0.0001496714394306764, grad_norm: 3.3806812337656887e-05, ic: 0.0834867706915381
train 30, step: 100, loss: 0.00029255947447381914, grad_norm: 1.3762650227900656e-05, ic: 0.11572812456908027
train 30, step: 200, loss: 0.00013567565474659204, grad_norm: 3.233199886091121e-07, ic: -0.01678935342192798
train 30, step: 300, loss: 0.0003992544661741704, grad_norm: 0.0001619828911608785, ic: 0.014614260644343006
train 30, step: 400, loss: 0.00014097988605499268, grad_norm: 2.753652877598523e-06, ic: -0.017871159951655266
train 30, step: 500, loss: 0.0002185810008086264, grad_norm: 5.155144792704952e-06, ic: 0.07805501251394979
train 30, step: 600, loss: 0.00017914948693942279, grad_norm: 0.00010079393457701484, ic: 0.022817851760416532
train 30, step: 700, loss: 0.00022590263688471168, grad_norm: 7.446408266425088e-05, ic: 0.010520249025982609
Epoch 30: 2022-05-05 21:32:37.741559: train loss: 0.00020708301035678145
Eval step 0: eval loss: 0.00016572601452935487
Eval step 100: eval loss: 0.0003517565201036632
Eval step 200: eval loss: 0.00027311700978316367
Eval: 2022-05-05 21:32:48.428347: total loss: 0.0001933852900236471, mse:0.0003867705781795566, ic :0.024008808926327608, sharpe5:-0.836266081854701, irr5:-0.1810344159603119, ndcg5:0.8566212135847934, pnl5:0.980549156665802 
train 31, step: 0, loss: 0.00013045748346485198, grad_norm: 5.388787236083687e-05, ic: 0.07868931422567255
train 31, step: 100, loss: 0.00019308357150293887, grad_norm: 1.5740756320509043e-07, ic: 0.049583775945264946
train 31, step: 200, loss: 0.0002751294814515859, grad_norm: 7.030994185832403e-07, ic: 0.016969283870711286
train 31, step: 300, loss: 0.00013143096293788403, grad_norm: 2.0785498949492537e-05, ic: -0.01471577018446556
train 31, step: 400, loss: 9.988437523134053e-05, grad_norm: 1.1490321877507517e-06, ic: 0.09796871525955486
train 31, step: 500, loss: 0.0001245737075805664, grad_norm: 1.2458625140522323e-05, ic: -0.04416034450892085
train 31, step: 600, loss: 0.00022235498181544244, grad_norm: 0.00017105669843370957, ic: -0.09853386465170229
train 31, step: 700, loss: 0.00013910798588767648, grad_norm: 1.6087527995227377e-05, ic: 0.04676520485591101
Epoch 31: 2022-05-05 21:33:41.624168: train loss: 0.00020700954540183968
Eval step 0: eval loss: 0.00013391159882303327
Eval step 100: eval loss: 0.00030511306249536574
Eval step 200: eval loss: 0.00031533141736872494
Eval: 2022-05-05 21:33:50.991281: total loss: 0.00018901680523095507, mse:0.00037803360687694014, ic :0.02236912055297335, sharpe5:-0.8070288778468966, irr5:-0.17550787329673767, ndcg5:0.8521693342053299, pnl5:0.9854496121406555 
train 32, step: 0, loss: 0.0001872636639745906, grad_norm: 5.205453212478633e-05, ic: 0.13713257931260475
train 32, step: 100, loss: 9.40527388593182e-05, grad_norm: 2.4649281812073224e-05, ic: 0.1267290740526014
train 32, step: 200, loss: 0.00018324550183024257, grad_norm: 2.1045834239180346e-05, ic: 0.026729087348643755
train 32, step: 300, loss: 0.000196369961486198, grad_norm: 5.5833299354062134e-05, ic: 0.083021466247331
train 32, step: 400, loss: 0.0002015473583014682, grad_norm: 7.081168989710991e-05, ic: 0.01793733546904817
train 32, step: 500, loss: 0.0001753440301399678, grad_norm: 3.620677812070185e-07, ic: 0.0536946770938628
train 32, step: 600, loss: 0.0002119214623235166, grad_norm: 5.923410007002457e-05, ic: 0.07666543578287033
train 32, step: 700, loss: 0.00010468211985426024, grad_norm: 1.5128462027353752e-06, ic: 0.10364571945538252
Epoch 32: 2022-05-05 21:34:41.951154: train loss: 0.00020709768802059547
Eval step 0: eval loss: 0.00014516300871036947
Eval step 100: eval loss: 0.0003227198321837932
Eval step 200: eval loss: 0.000295075005851686
Eval: 2022-05-05 21:34:51.219731: total loss: 0.0001888936531666959, mse:0.00037778729652829485, ic :0.02303883486194091, sharpe5:-0.8855284149572252, irr5:-0.19204384088516235, ndcg5:0.8468978942769898, pnl5:0.9893981218338013 
train 33, step: 0, loss: 0.00017374820890836418, grad_norm: 4.584263279875254e-07, ic: 0.08718040003470919
train 33, step: 100, loss: 0.000109119777334854, grad_norm: 1.8569278975852226e-07, ic: 0.030313229349254494
train 33, step: 200, loss: 0.00017093219503294677, grad_norm: 7.34179853712517e-08, ic: -0.10645780798432672
train 33, step: 300, loss: 0.0002311233401997015, grad_norm: 2.2988228648079215e-06, ic: 0.048354139263690143
train 33, step: 400, loss: 0.00020031843450851738, grad_norm: 0.00012120824195969368, ic: -0.003053625192105551
train 33, step: 500, loss: 8.28287229523994e-05, grad_norm: 2.1614099260588175e-06, ic: -0.010675544247341429
train 33, step: 600, loss: 0.00017927181033883244, grad_norm: 2.8884948426323127e-05, ic: -0.025874741648049156
train 33, step: 700, loss: 0.0001355971908196807, grad_norm: 8.295810063620192e-06, ic: 0.04584549051348796
Epoch 33: 2022-05-05 21:35:41.804370: train loss: 0.0002069831887366067
Eval step 0: eval loss: 0.00015161692863330245
Eval step 100: eval loss: 0.0003319842799101025
Eval step 200: eval loss: 0.00028709814068861306
Eval: 2022-05-05 21:35:51.300667: total loss: 0.00018979430932746834, mse:0.0003795886147823649, ic :0.02387886987434092, sharpe5:-0.9779639208689331, irr5:-0.2123132050037384, ndcg5:0.8572719983170751, pnl5:0.990448534488678 
train 34, step: 0, loss: 0.00017371840658597648, grad_norm: 2.264997056576613e-06, ic: 0.023515450371766784
train 34, step: 100, loss: 0.00014481048856396228, grad_norm: 1.7785766869422707e-05, ic: 0.09397427756944315
train 34, step: 200, loss: 0.00017437932547181845, grad_norm: 4.442212228361711e-05, ic: 0.095426575493474
train 34, step: 300, loss: 0.0005114134401082993, grad_norm: 0.000427563033352153, ic: 0.010885991953446611
train 34, step: 400, loss: 0.00013246024900581688, grad_norm: 2.4032205441309115e-07, ic: -0.01553830735734237
train 34, step: 500, loss: 0.00013324331666808575, grad_norm: 2.974764647250774e-05, ic: 0.05443343008011501
train 34, step: 600, loss: 0.00011134015949210152, grad_norm: 1.558692501938828e-05, ic: -0.032413035464013175
train 34, step: 700, loss: 0.0001173711716546677, grad_norm: 5.718410312145309e-05, ic: -0.11703898729791491
Epoch 34: 2022-05-05 21:36:40.348807: train loss: 0.00020658466939280247
Eval step 0: eval loss: 0.00014269475650507957
Eval step 100: eval loss: 0.00031920874607749283
Eval step 200: eval loss: 0.00029820273630321026
Eval: 2022-05-05 21:36:49.591176: total loss: 0.0001887330243604941, mse:0.0003774660437367636, ic :0.02267031259021143, sharpe5:-0.8201036404073238, irr5:-0.17849335074424744, ndcg5:0.8628192052135775, pnl5:1.0006948709487915 
train 35, step: 0, loss: 0.0003848439664579928, grad_norm: 0.00045611597326149054, ic: 0.07404856187446585
train 35, step: 100, loss: 0.00010219238174613565, grad_norm: 6.824440875269863e-07, ic: -0.004065660654412471
train 35, step: 200, loss: 0.0004926157998852432, grad_norm: 0.0004975926009123396, ic: -0.030431944018371737
train 35, step: 300, loss: 0.00025570113211870193, grad_norm: 0.00017548056945388324, ic: -0.023312037032624234
train 35, step: 400, loss: 0.0007872420246712863, grad_norm: 0.0005534553988325852, ic: 0.13746530072429508
train 35, step: 500, loss: 0.0003138601023238152, grad_norm: 0.00014977725417188983, ic: 0.00902934359636883
train 35, step: 600, loss: 0.00023056984355207533, grad_norm: 1.2116671608250906e-06, ic: 0.04868816114730405
train 35, step: 700, loss: 0.00012813342618755996, grad_norm: 1.5834069020613773e-05, ic: 0.05672523154177872
Epoch 35: 2022-05-05 21:37:39.660717: train loss: 0.00020657811953295844
Eval step 0: eval loss: 0.00013885794032830745
Eval step 100: eval loss: 0.0003133703430648893
Eval step 200: eval loss: 0.0003042018215637654
Eval: 2022-05-05 21:37:48.977082: total loss: 0.00018862181115772485, mse:0.0003772436185919397, ic :0.02357471447283284, sharpe5:-0.8754008613154292, irr5:-0.18956714868545532, ndcg5:0.8496877034696643, pnl5:0.9907881021499634 
train 36, step: 0, loss: 0.00023407615663018078, grad_norm: 0.00013527094704482312, ic: 0.04158316746346506
train 36, step: 100, loss: 0.0002469671017024666, grad_norm: 2.8118655191908985e-06, ic: 0.07040237140478636
train 36, step: 200, loss: 0.000336893746862188, grad_norm: 0.00031901200622758857, ic: -0.0156079943637025
train 36, step: 300, loss: 0.00014653954713139683, grad_norm: 5.1270551127875706e-05, ic: 0.06168959506825272
train 36, step: 400, loss: 0.00020555518858600408, grad_norm: 1.220466151072708e-07, ic: 0.09138238525775377
train 36, step: 500, loss: 0.00046349765034392476, grad_norm: 0.00014165892513870576, ic: -0.009141447754605344
train 36, step: 600, loss: 5.8113670093007386e-05, grad_norm: 9.32580539359952e-08, ic: 0.12417732827954525
train 36, step: 700, loss: 0.0001874489098554477, grad_norm: 5.7183444957944e-05, ic: 0.04008678619484601
Epoch 36: 2022-05-05 21:38:38.609813: train loss: 0.0002065602902268224
Eval step 0: eval loss: 0.0001624906581128016
Eval step 100: eval loss: 0.0003473714168649167
Eval step 200: eval loss: 0.00027563684852793813
Eval: 2022-05-05 21:38:47.877796: total loss: 0.00019243304176316047, mse:0.00038486608101084613, ic :0.025137582240197614, sharpe5:-0.9353737930208444, irr5:-0.20321249961853027, ndcg5:0.854195708501928, pnl5:0.963718831539154 
train 37, step: 0, loss: 0.0002927280147559941, grad_norm: 0.0002909407336493616, ic: 0.08010122518772246
train 37, step: 100, loss: 0.00019548369164112955, grad_norm: 4.911456964020898e-05, ic: 0.1044938589094867
train 37, step: 200, loss: 0.00015087632345966995, grad_norm: 1.2888287540556925e-07, ic: 0.10049886528230467
train 37, step: 300, loss: 0.00014868589641992003, grad_norm: 4.21401491630573e-05, ic: 0.01888628517173302
train 37, step: 400, loss: 0.00014849717263132334, grad_norm: 9.260764592325977e-06, ic: -0.12203039440866288
train 37, step: 500, loss: 0.00015804203576408327, grad_norm: 3.908639961065359e-06, ic: 0.04715274164008081
train 37, step: 600, loss: 0.0003351037739776075, grad_norm: 0.00026774881598225865, ic: 0.010350323111622197
train 37, step: 700, loss: 0.00019584699475672096, grad_norm: 5.117014312522515e-05, ic: -0.015411153144675484
Epoch 37: 2022-05-05 21:39:39.629337: train loss: 0.00020699289023390919
Eval step 0: eval loss: 0.00015058659482747316
Eval step 100: eval loss: 0.0003303021367173642
Eval step 200: eval loss: 0.00028872524853795767
Eval: 2022-05-05 21:39:48.888558: total loss: 0.00018956570658709763, mse:0.0003791314098871307, ic :0.025248703830729507, sharpe5:-0.8189968482032418, irr5:-0.17763423919677734, ndcg5:0.8631451536511985, pnl5:0.9498431086540222 
train 38, step: 0, loss: 0.0001580946845933795, grad_norm: 3.811259182797707e-09, ic: 0.012162821833326721
train 38, step: 100, loss: 0.00012517978029791266, grad_norm: 8.225000350748649e-06, ic: -0.040268673640530606
train 38, step: 200, loss: 0.0001537452480988577, grad_norm: 2.839882733978083e-07, ic: -0.0034083635485002654
train 38, step: 300, loss: 9.729775047162548e-05, grad_norm: 3.0662493770566764e-05, ic: 0.15785914952528454
train 38, step: 400, loss: 0.00013535746256820858, grad_norm: 1.6681187877879516e-07, ic: -0.12008710454920618
train 38, step: 500, loss: 0.00030504894675686955, grad_norm: 6.632500022548592e-06, ic: -0.022723969676964967
train 38, step: 600, loss: 0.0001479905185988173, grad_norm: 1.5361683299883778e-05, ic: 0.007670657631125472
train 38, step: 700, loss: 0.00014621877926401794, grad_norm: 9.408211968045044e-06, ic: 0.049411740097427714
Epoch 38: 2022-05-05 21:40:39.518874: train loss: 0.00020637572700685211
Eval step 0: eval loss: 0.00014026061398908496
Eval step 100: eval loss: 0.00031555796158500016
Eval step 200: eval loss: 0.0003016570408362895
Eval: 2022-05-05 21:40:48.872350: total loss: 0.00018861171657674007, mse:0.00037722343386704504, ic :0.024401336771732438, sharpe5:-0.8754010977968573, irr5:-0.18956714868545532, ndcg5:0.8439135160098761, pnl5:0.9907881021499634 
train 39, step: 0, loss: 0.0003420925640966743, grad_norm: 0.000220007054843558, ic: 0.13327427394894853
train 39, step: 100, loss: 0.0004565193667076528, grad_norm: 0.0003818562948634503, ic: 0.0382211712954521
train 39, step: 200, loss: 0.00023785786470398307, grad_norm: 8.470589256091871e-07, ic: 0.012812326595203427
train 39, step: 300, loss: 0.00023098460223991424, grad_norm: 0.00013522458110982246, ic: 0.04162754253452322
train 39, step: 400, loss: 9.371532360091805e-05, grad_norm: 3.531988313125352e-06, ic: -0.054381337340891525
train 39, step: 500, loss: 0.00018317258218303323, grad_norm: 1.5058901827548943e-05, ic: -0.12027708594005326
train 39, step: 600, loss: 0.00016005171346478164, grad_norm: 7.252133480559895e-07, ic: -0.14682111085363436
train 39, step: 700, loss: 0.00019658631936181337, grad_norm: 2.498726496063887e-05, ic: 0.024242561995884634
Epoch 39: 2022-05-05 21:41:39.711008: train loss: 0.00020641704182503782
Eval step 0: eval loss: 0.00015145215729717165
Eval step 100: eval loss: 0.0003315418725833297
Eval step 200: eval loss: 0.0002878964878618717
Eval: 2022-05-05 21:41:49.079871: total loss: 0.00018971865538174214, mse:0.00037943730738346535, ic :0.024503933557720556, sharpe5:-0.9035864324122667, irr5:-0.19596385955810547, ndcg5:0.8582875750751043, pnl5:0.9690687656402588 
train 40, step: 0, loss: 0.0001828943204600364, grad_norm: 2.1927140677356898e-05, ic: 0.07464297974650654
train 40, step: 100, loss: 0.00022750458447262645, grad_norm: 0.00015147386707942633, ic: 0.046455970251008234
train 40, step: 200, loss: 0.00013394579582381994, grad_norm: 6.581938336672666e-05, ic: -0.09016942251030852
train 40, step: 300, loss: 0.00010661537817213684, grad_norm: 4.719334391043457e-07, ic: -0.04529420366564051
train 40, step: 400, loss: 0.00021226420358289033, grad_norm: 1.7306302252657795e-05, ic: 0.16425759954351443
train 40, step: 500, loss: 0.0003184381639584899, grad_norm: 5.127130632228058e-05, ic: 0.1252710311783815
train 40, step: 600, loss: 8.920851541915908e-05, grad_norm: 1.4296793876164903e-05, ic: -0.038290718983643425
train 40, step: 700, loss: 0.00010974486212944612, grad_norm: 8.836963026576308e-06, ic: 0.07464989897769758
Epoch 40: 2022-05-05 21:42:38.946004: train loss: 0.00020686552439646498
Eval step 0: eval loss: 0.00014009552251081914
Eval step 100: eval loss: 0.0003153107827529311
Eval step 200: eval loss: 0.0003020166768692434
Eval: 2022-05-05 21:42:47.171640: total loss: 0.00018861319820318313, mse:0.0003772263928748198, ic :0.024138175048773542, sharpe5:-0.9353737339004874, irr5:-0.20321249961853027, ndcg5:0.8560711682072258, pnl5:0.9637187123298645 
train 41, step: 0, loss: 0.00016289293125737458, grad_norm: 1.3842645291017037e-06, ic: 0.09422541990639693
train 41, step: 100, loss: 0.000247316958848387, grad_norm: 6.22314209220165e-06, ic: 0.03539788450609347
train 41, step: 200, loss: 0.00016726032481528819, grad_norm: 5.470979647573996e-05, ic: 0.1869980954426823
train 41, step: 300, loss: 0.00024267456319648772, grad_norm: 0.0001298232691284202, ic: 0.1640799274112461
train 41, step: 400, loss: 0.00019825008348561823, grad_norm: 0.00018176279598596944, ic: -0.00673105483144365
train 41, step: 500, loss: 0.00014065160939935595, grad_norm: 4.998311124421538e-05, ic: -0.12570298098749103
train 41, step: 600, loss: 0.0001787419751053676, grad_norm: 5.015611886177945e-05, ic: 0.004130335167432395
train 41, step: 700, loss: 0.00018249139247927815, grad_norm: 3.8044928119573277e-06, ic: -0.005090612515056146
Epoch 41: 2022-05-05 21:43:37.135758: train loss: 0.00020639014251246603
Eval step 0: eval loss: 0.0001556042261654511
Eval step 100: eval loss: 0.0003378276596777141
Eval step 200: eval loss: 0.0002821545349434018
Eval: 2022-05-05 21:43:46.456709: total loss: 0.00019065022851619056, mse:0.0003813004527795858, ic :0.0257723271454511, sharpe5:-1.0101729869842528, irr5:-0.2193279266357422, ndcg5:0.8481630725472848, pnl5:0.9689137935638428 
train 42, step: 0, loss: 0.00010881569323828444, grad_norm: 1.903778949465955e-05, ic: 0.03883927320536627
train 42, step: 100, loss: 0.00012460880680009723, grad_norm: 1.3437361619604785e-05, ic: 0.06496798762194489
train 42, step: 200, loss: 0.00017990806372836232, grad_norm: 4.790983774275469e-06, ic: 0.10574103662887951
train 42, step: 300, loss: 0.00018000556156039238, grad_norm: 5.197217614396517e-05, ic: 0.014741692524150448
train 42, step: 400, loss: 0.00025532220024615526, grad_norm: 0.00023588885083434223, ic: 0.13099405978998724
train 42, step: 500, loss: 0.0003020712756551802, grad_norm: 6.802062786282678e-07, ic: -0.019889365259451786
train 42, step: 600, loss: 0.00012862157018389553, grad_norm: 2.0840696074175022e-05, ic: 0.19965421606428652
train 42, step: 700, loss: 0.00015172924031503499, grad_norm: 4.821906290951423e-05, ic: 0.10368518816800565
Epoch 42: 2022-05-05 21:44:37.148204: train loss: 0.0002063472380823587
Eval step 0: eval loss: 0.00015237194020301104
Eval step 100: eval loss: 0.0003325830912217498
Eval step 200: eval loss: 0.00028772131190635264
Eval: 2022-05-05 21:44:46.426722: total loss: 0.0001898465702433737, mse:0.00037969313638487807, ic :0.02439254188109214, sharpe5:-1.039789329841733, irr5:-0.22699761390686035, ndcg5:0.8497543707563852, pnl5:0.982443630695343 
train 43, step: 0, loss: 0.00015410476771648973, grad_norm: 4.336442528304009e-05, ic: -0.03068875879146644
train 43, step: 100, loss: 0.00021150351676624268, grad_norm: 0.00014155974039640253, ic: -0.01442801167592444
train 43, step: 200, loss: 0.00019325065659359097, grad_norm: 0.00021350015675603747, ic: -0.09980192291283205
train 43, step: 300, loss: 0.00031476220465265214, grad_norm: 4.4253726542305415e-05, ic: 0.1326588438676159
train 43, step: 400, loss: 0.00011129471386084333, grad_norm: 4.442491769505518e-05, ic: 0.05815577398559739
train 43, step: 500, loss: 0.00021765400015283376, grad_norm: 0.0001248831921719833, ic: 0.07724660446203499
train 43, step: 600, loss: 0.0003065162745770067, grad_norm: 0.00023406671482394136, ic: -0.07753694669191111
train 43, step: 700, loss: 0.0002279628097312525, grad_norm: 0.00011835431294369735, ic: 0.07410661632749072
Epoch 43: 2022-05-05 21:45:37.008537: train loss: 0.00020646932767353948
Eval step 0: eval loss: 0.00014543243742082268
Eval step 100: eval loss: 0.0003226773696951568
Eval step 200: eval loss: 0.00029617894324474037
Eval: 2022-05-05 21:45:46.443036: total loss: 0.00018885273918612172, mse:0.00037770547784826935, ic :0.023431944680887683, sharpe5:-1.0526380752772093, irr5:-0.22898948192596436, ndcg5:0.8576887699438694, pnl5:0.9452817440032959 
train 44, step: 0, loss: 0.00018111965619027615, grad_norm: 2.609694491112945e-06, ic: 0.03505692456529894
train 44, step: 100, loss: 0.0002239776513306424, grad_norm: 8.095834341501995e-05, ic: -0.12454316012897877
train 44, step: 200, loss: 0.00011028086009901017, grad_norm: 5.397536163651777e-06, ic: 0.12446270508183174
train 44, step: 300, loss: 0.00018643186194822192, grad_norm: 0.00016369237420656683, ic: -0.03891842906186848
train 44, step: 400, loss: 0.00010405843204353005, grad_norm: 1.7859748755317291e-06, ic: 0.07434083001490681
train 44, step: 500, loss: 0.00016340118600055575, grad_norm: 5.5958453736449816e-05, ic: 0.15388353667276167
train 44, step: 600, loss: 0.00011015428754035383, grad_norm: 1.8650617395104014e-05, ic: 0.07973632679101068
train 44, step: 700, loss: 0.0001721531298244372, grad_norm: 2.884536473256743e-06, ic: 0.08904081583609796
Epoch 44: 2022-05-05 21:46:36.708088: train loss: 0.00020628839811835596
Eval step 0: eval loss: 0.0001366468786727637
Eval step 100: eval loss: 0.0003095334395766258
Eval step 200: eval loss: 0.0003095987194683403
Eval: 2022-05-05 21:46:46.163704: total loss: 0.00018867284103879283, mse:0.0003773456776990318, ic :0.02445854914380833, sharpe5:-1.0432252867519856, irr5:-0.22642582654953003, ndcg5:0.8529006035598485, pnl5:0.9630743861198425 
train 45, step: 0, loss: 0.0003587854444049299, grad_norm: 1.8497203185826122e-06, ic: 0.053126377691607066
train 45, step: 100, loss: 0.00022305207676254213, grad_norm: 6.482436012142046e-05, ic: -0.037014690317665286
train 45, step: 200, loss: 0.00018094830738846213, grad_norm: 2.73177290562148e-06, ic: 0.05005378329427617
train 45, step: 300, loss: 0.0004514610336627811, grad_norm: 0.00012237617535364276, ic: -0.0994148142346375
train 45, step: 400, loss: 0.0001693220401648432, grad_norm: 0.0001508585001735747, ic: -0.0630505528939471
train 45, step: 500, loss: 0.00011226306378375739, grad_norm: 2.5143174469237832e-06, ic: 0.05945308787820515
train 45, step: 600, loss: 0.00017558901163283736, grad_norm: 7.535018559334428e-06, ic: -0.08182779753192179
train 45, step: 700, loss: 0.0004753456450998783, grad_norm: 0.00034676077377262285, ic: -0.002130461816563199
Epoch 45: 2022-05-05 21:47:36.957727: train loss: 0.00020624537450553387
Eval step 0: eval loss: 0.0001431630807928741
Eval step 100: eval loss: 0.00031957076862454414
Eval step 200: eval loss: 0.0002984877210110426
Eval: 2022-05-05 21:47:46.440334: total loss: 0.00018867398272868344, mse:0.00037734796410814585, ic :0.025097772570779716, sharpe5:-0.9608878925442695, irr5:-0.2104422152042389, ndcg5:0.8585601683050912, pnl5:0.9603895545005798 
train 46, step: 0, loss: 0.00023512729967478663, grad_norm: 6.905005844953144e-05, ic: 0.07651273441319831
train 46, step: 100, loss: 0.00015968615480232984, grad_norm: 3.0156740797335483e-05, ic: 0.0038899334069105104
train 46, step: 200, loss: 0.0003682441310957074, grad_norm: 7.173345570904575e-05, ic: -0.011456834751093263
train 46, step: 300, loss: 0.00018227279360871762, grad_norm: 3.691242794986256e-05, ic: 0.08086892248166311
train 46, step: 400, loss: 0.00019219249952584505, grad_norm: 1.266662644539504e-05, ic: 0.10206159281303573
train 46, step: 500, loss: 0.00010247441241517663, grad_norm: 6.6744241662006644e-06, ic: 0.11880606084768072
train 46, step: 600, loss: 0.000348826521076262, grad_norm: 0.0003057857536337621, ic: -0.02108983209351404
train 46, step: 700, loss: 0.00021588416711892933, grad_norm: 7.973013647385462e-06, ic: 0.07466587017145083
Epoch 46: 2022-05-05 21:48:37.539919: train loss: 0.00020632737862841285
Eval step 0: eval loss: 0.00014082294364925474
Eval step 100: eval loss: 0.0003159770567435771
Eval step 200: eval loss: 0.00030215471633709967
Eval: 2022-05-05 21:48:46.909476: total loss: 0.00018855718006537494, mse:0.0003771143595715866, ic :0.025899415401703742, sharpe5:-0.9292257488518952, irr5:-0.20203572511672974, ndcg5:0.855257001272451, pnl5:0.9480483531951904 
train 47, step: 0, loss: 0.00019625537970568985, grad_norm: 0.00011921058628117022, ic: 0.17509356990668604
train 47, step: 100, loss: 0.00013743832823820412, grad_norm: 6.836629154854128e-05, ic: -0.02466583775056276
train 47, step: 200, loss: 0.0001661587884882465, grad_norm: 6.675998601913467e-05, ic: 0.06586990815584098
train 47, step: 300, loss: 0.0006129889516159892, grad_norm: 0.0006123570620880646, ic: -0.08238880803434441
train 47, step: 400, loss: 0.0002953283837996423, grad_norm: 0.00013001972359122705, ic: 0.1322688935341419
train 47, step: 500, loss: 0.0001353000698145479, grad_norm: 1.0195070998713536e-06, ic: 0.0974834391885829
train 47, step: 600, loss: 0.00019227266602683812, grad_norm: 6.080086242350014e-05, ic: 0.14687971171316108
train 47, step: 700, loss: 0.00041633527143858373, grad_norm: 0.0003251379806828262, ic: 0.06974255745888538
Epoch 47: 2022-05-05 21:49:37.829712: train loss: 0.0002064246222834236
Eval step 0: eval loss: 0.00014305025979410857
Eval step 100: eval loss: 0.00032034219475463033
Eval step 200: eval loss: 0.00029550251201726496
Eval: 2022-05-05 21:49:46.884727: total loss: 0.00018881569197986024, mse:0.00037763138046864044, ic :0.026366088679678077, sharpe5:-0.9224544578790664, irr5:-0.20075812935829163, ndcg5:0.8534244556711164, pnl5:0.9492660760879517 
train 48, step: 0, loss: 0.0002293554280186072, grad_norm: 9.593869384120571e-05, ic: -0.01875215165652136
train 48, step: 100, loss: 0.00023277921718545258, grad_norm: 5.7140599626328223e-05, ic: 0.11184137276142715
train 48, step: 200, loss: 0.00011494803038658574, grad_norm: 1.4183111465196749e-05, ic: -0.0052278373353210235
train 48, step: 300, loss: 0.0002896893711294979, grad_norm: 0.00010542497326672372, ic: 0.0928900980037246
train 48, step: 400, loss: 0.0005164145259186625, grad_norm: 6.68758585592882e-05, ic: 0.1118947710208817
train 48, step: 500, loss: 0.00015438903938047588, grad_norm: 7.523604291643001e-06, ic: 0.03577477820083656
train 48, step: 600, loss: 0.00016971823060885072, grad_norm: 3.568867044738043e-05, ic: 0.06648035720863059
train 48, step: 700, loss: 0.00018658647604752332, grad_norm: 0.00018185614005108522, ic: -0.02062299875286605
Epoch 48: 2022-05-05 21:50:37.451176: train loss: 0.00020634908087425997
Eval step 0: eval loss: 0.0001337019493803382
Eval step 100: eval loss: 0.0003054458647966385
Eval step 200: eval loss: 0.0003133837308268994
Eval: 2022-05-05 21:50:46.847257: total loss: 0.00018902776390339522, mse:0.00037805552365074676, ic :0.024082330557298356, sharpe5:-1.0408130579441786, irr5:-0.22793680429458618, ndcg5:0.8535541181625634, pnl5:0.9469410181045532 
train 49, step: 0, loss: 0.00018138607265427709, grad_norm: 4.083084007096852e-06, ic: -0.100013101076277
train 49, step: 100, loss: 0.00013099647185299546, grad_norm: 2.7529700245281766e-05, ic: -0.00783941202588806
train 49, step: 200, loss: 0.00011132432700833306, grad_norm: 7.951848977417402e-06, ic: 0.008248070413983784
train 49, step: 300, loss: 0.00012704792607109994, grad_norm: 7.520832893694478e-06, ic: 0.045885124574524566
train 49, step: 400, loss: 0.00022575263574253768, grad_norm: 4.3925761934336496e-05, ic: 0.028734143142213737
train 49, step: 500, loss: 7.592913607368246e-05, grad_norm: 1.062803441449345e-05, ic: 0.04085599987668727
train 49, step: 600, loss: 0.00040229884325526655, grad_norm: 0.00012640604585710148, ic: 0.12216690811056112
train 49, step: 700, loss: 0.00018397654639557004, grad_norm: 9.165674528893544e-05, ic: 0.0797783128380512
Epoch 49: 2022-05-05 21:51:37.869267: train loss: 0.0002062819682096768
Eval step 0: eval loss: 0.0001433219003956765
Eval step 100: eval loss: 0.0003196681500412524
Eval step 200: eval loss: 0.00029852031730115414
Eval: 2022-05-05 21:51:47.247885: total loss: 0.00018866615659429175, mse:0.00037733231303356654, ic :0.026002332953140802, sharpe5:-1.0031180365383625, irr5:-0.2192593812942505, ndcg5:0.8559376102969014, pnl5:0.9698730111122131 
train 50, step: 0, loss: 0.0003782391140703112, grad_norm: 0.0001405056266117933, ic: 0.159939811094225
train 50, step: 100, loss: 0.00010926906543318182, grad_norm: 2.5587731615465134e-05, ic: 0.03228757798766367
train 50, step: 200, loss: 0.0002548343036323786, grad_norm: 6.073576620667582e-05, ic: 0.08703325616245836
train 50, step: 300, loss: 0.0001982742251129821, grad_norm: 2.0379265873445217e-05, ic: 0.027362005747041215
train 50, step: 400, loss: 0.0001857009483501315, grad_norm: 0.00011388012951778685, ic: 0.1401017295987201
train 50, step: 500, loss: 0.0001590708998264745, grad_norm: 2.923113907747883e-05, ic: -0.0002407460630367217
train 50, step: 600, loss: 0.00014384834503289312, grad_norm: 1.059399922684622e-06, ic: 0.01503928204184597
train 50, step: 700, loss: 0.0003032320528291166, grad_norm: 1.7885370306904769e-06, ic: -0.021422462693947864
Epoch 50: 2022-05-05 21:52:36.748979: train loss: 0.00020628207562246016
Eval step 0: eval loss: 0.00014653820835519582
Eval step 100: eval loss: 0.0003231953887734562
Eval step 200: eval loss: 0.0002978124830406159
Eval: 2022-05-05 21:52:45.988038: total loss: 0.00018894395411754735, mse:0.00037788790553537675, ic :0.029061708319523448, sharpe5:-0.8981374273449182, irr5:-0.1956671178340912, ndcg5:0.8552694639827326, pnl5:0.9552640318870544 
train 51, step: 0, loss: 0.00013865737128071487, grad_norm: 4.5681671324214906e-05, ic: 0.02342912057641024
train 51, step: 100, loss: 0.00016159542428795248, grad_norm: 3.455458705150366e-05, ic: 0.013738550833933983
train 51, step: 200, loss: 0.00010404967179056257, grad_norm: 1.2507146079909046e-06, ic: -0.03065000132059786
train 51, step: 300, loss: 0.00029404350789263844, grad_norm: 0.00020997253884762107, ic: -0.08038784349841722
train 51, step: 400, loss: 0.00013247407332528383, grad_norm: 1.1390632640169983e-05, ic: 0.06529948533979606
train 51, step: 500, loss: 0.0001094218241632916, grad_norm: 1.5691115021100452e-05, ic: -0.008448797899768688
train 51, step: 600, loss: 0.00022594776237383485, grad_norm: 9.943160178036756e-07, ic: 0.09119686422821831
train 51, step: 700, loss: 0.00016872561536729336, grad_norm: 3.038117674767231e-05, ic: -0.09796391588368956
Epoch 51: 2022-05-05 21:53:36.049719: train loss: 0.0002063577386364154
Eval step 0: eval loss: 0.0001430545817129314
Eval step 100: eval loss: 0.0003196783072780818
Eval step 200: eval loss: 0.0002976519463118166
Eval: 2022-05-05 21:53:45.222531: total loss: 0.00018869246416938732, mse:0.00037738492559409424, ic :0.025697168518980296, sharpe5:-0.9838089140877128, irr5:-0.21427428722381592, ndcg5:0.8514704983051183, pnl5:0.9391932487487793 
train 52, step: 0, loss: 0.00022244808496907353, grad_norm: 2.4433429983844343e-06, ic: 0.001525056470642194
train 52, step: 100, loss: 0.00023775786394253373, grad_norm: 0.00014424941098756206, ic: -0.04571926611956681
train 52, step: 200, loss: 0.0004548845754470676, grad_norm: 0.00013061851475554284, ic: -0.10252043830288769
train 52, step: 300, loss: 0.00010765308979898691, grad_norm: 1.3044135921439637e-05, ic: 0.08044642356471073
train 52, step: 400, loss: 0.00020543545542750508, grad_norm: 5.432249494125422e-05, ic: -0.04393614704523421
train 52, step: 500, loss: 0.00043966356315650046, grad_norm: 0.00027545537111472177, ic: 0.017467198419500132
train 52, step: 600, loss: 0.00029244396137073636, grad_norm: 0.0001928024344926476, ic: -0.06725881295023453
train 52, step: 700, loss: 0.0002847714931704104, grad_norm: 0.0001510028661994466, ic: 0.15033520180062515
Epoch 52: 2022-05-05 21:54:35.691503: train loss: 0.00020634987195469702
Eval step 0: eval loss: 0.00013716157991439104
Eval step 100: eval loss: 0.0003104155184701085
Eval step 200: eval loss: 0.0003085806965827942
Eval: 2022-05-05 21:54:45.146507: total loss: 0.0001886639853722851, mse:0.0003773279638474378, ic :0.022864285514268754, sharpe5:-0.8811474782600999, irr5:-0.1924823820590973, ndcg5:0.8460748931902871, pnl5:0.9557814598083496 
train 53, step: 0, loss: 0.00024748934083618224, grad_norm: 0.00016295731286278595, ic: -0.03912632572296898
train 53, step: 100, loss: 7.226020534290001e-05, grad_norm: 1.0843256749705446e-06, ic: -0.04447485199681567
train 53, step: 200, loss: 0.000540027569513768, grad_norm: 7.930819413898798e-06, ic: 0.09735271002106002
train 53, step: 300, loss: 0.00026854375028051436, grad_norm: 0.00019426198595913662, ic: 0.0760538085406084
train 53, step: 400, loss: 0.00014080698019824922, grad_norm: 6.59642714333398e-05, ic: 0.13851740420695413
train 53, step: 500, loss: 0.00020225935440976173, grad_norm: 7.55017096041708e-05, ic: 0.002772170558994256
train 53, step: 600, loss: 0.0001803797931643203, grad_norm: 5.057676164802627e-05, ic: 0.032143737466846636
train 53, step: 700, loss: 0.0002469940809533, grad_norm: 0.00018114621425370864, ic: 0.10919461113333123
Epoch 53: 2022-05-05 21:55:36.456255: train loss: 0.0002062389536188476
Eval step 0: eval loss: 0.00014713230484630913
Eval step 100: eval loss: 0.00032540023676119745
Eval step 200: eval loss: 0.0002927547902800143
Eval: 2022-05-05 21:55:45.994431: total loss: 0.00018904677680673233, mse:0.0003780935513783183, ic :0.027016452301790353, sharpe5:-1.0135283037275076, irr5:-0.22069764137268066, ndcg5:0.8510851184664099, pnl5:0.9506126642227173 
train 54, step: 0, loss: 0.00019062752835452557, grad_norm: 6.433446037743036e-05, ic: 0.07945625148691425
train 54, step: 100, loss: 0.0001424717193003744, grad_norm: 8.258267767398435e-06, ic: 0.02634604486769068
train 54, step: 200, loss: 0.00017251264944206923, grad_norm: 6.257078398340754e-07, ic: -0.04124328599111684
train 54, step: 300, loss: 0.00033377663930878043, grad_norm: 5.2726313277799965e-05, ic: 0.0805180282363425
train 54, step: 400, loss: 0.00011639800504781306, grad_norm: 2.6577218445646273e-05, ic: -0.0428123716671378
train 54, step: 500, loss: 0.0001391842233715579, grad_norm: 1.344526212357281e-05, ic: 0.08077315425861115
train 54, step: 600, loss: 0.00017960021796170622, grad_norm: 1.5736609237489098e-05, ic: 0.09677180550811593
train 54, step: 700, loss: 0.0003982407506555319, grad_norm: 0.0004289694454733803, ic: 0.04998035414336345
Epoch 54: 2022-05-05 21:56:37.389656: train loss: 0.0002064963622333234
Eval step 0: eval loss: 0.0001443176734028384
Eval step 100: eval loss: 0.00032054621260613203
Eval step 200: eval loss: 0.0002990643261000514
Eval: 2022-05-05 21:56:46.712229: total loss: 0.00018872639316710638, mse:0.00037745277908100117, ic :0.025056038701820788, sharpe5:-1.0135283037275076, irr5:-0.22069764137268066, ndcg5:0.8529157486441755, pnl5:0.9506126642227173 
train 55, step: 0, loss: 9.393990330863744e-05, grad_norm: 2.340756978276597e-05, ic: 0.1753931515369892
train 55, step: 100, loss: 0.0002463125274516642, grad_norm: 0.00016574736043239885, ic: 0.09803279654040897
train 55, step: 200, loss: 0.0002619533916004002, grad_norm: 5.2263714311374005e-05, ic: 0.06223832175344744
train 55, step: 300, loss: 0.00014455280324909836, grad_norm: 7.34735013691574e-06, ic: 0.10720553997641143
train 55, step: 400, loss: 0.00013175317144487053, grad_norm: 4.565677277549569e-05, ic: -0.01732557380398103
train 55, step: 500, loss: 0.00029027805430814624, grad_norm: 9.096062645037804e-06, ic: 0.15506712497013528
train 55, step: 600, loss: 0.0001545899431221187, grad_norm: 4.9531031345157966e-05, ic: 0.03209792383924614
train 55, step: 700, loss: 0.0005051818443462253, grad_norm: 0.0005411031590392964, ic: 0.19326817089119305
Epoch 55: 2022-05-05 21:57:38.564466: train loss: 0.00020635751513903557
Eval step 0: eval loss: 0.00013860590115655214
Eval step 100: eval loss: 0.00031199114164337516
Eval step 200: eval loss: 0.0003080369788222015
Eval: 2022-05-05 21:57:47.961951: total loss: 0.00018860340463714348, mse:0.00037720680561258667, ic :0.022733687232888527, sharpe5:-1.0731025868654251, irr5:-0.2350197434425354, ndcg5:0.8561634574023871, pnl5:0.9406756162643433 
train 56, step: 0, loss: 0.00021605932852253318, grad_norm: 9.37416064147788e-05, ic: 0.06457746709348287
train 56, step: 100, loss: 0.0002547632611822337, grad_norm: 8.191097582360616e-05, ic: 0.16025585726837435
train 56, step: 200, loss: 0.00011432630708441138, grad_norm: 5.721261617517234e-06, ic: -0.01012727687166724
train 56, step: 300, loss: 9.573346324032173e-05, grad_norm: 7.237134397328549e-06, ic: -0.059392620747939065
train 56, step: 400, loss: 0.000173597814864479, grad_norm: 0.00012593424462867278, ic: 0.02201621461731124
train 56, step: 500, loss: 0.00020405705436132848, grad_norm: 6.51539903812287e-05, ic: 0.15227094863952567
train 56, step: 600, loss: 0.00014406637637875974, grad_norm: 1.525810039493832e-06, ic: 0.0019286985018772476
train 56, step: 700, loss: 0.00017017619393300265, grad_norm: 5.151753333333281e-05, ic: 0.00142489550524659
Epoch 56: 2022-05-05 21:58:39.643272: train loss: 0.00020633141203314366
Eval step 0: eval loss: 0.00014656253915745765
Eval step 100: eval loss: 0.00032447389094159007
Eval step 200: eval loss: 0.0002940984850283712
Eval: 2022-05-05 21:58:48.758668: total loss: 0.00018898318830509487, mse:0.0003779663717130467, ic :0.02428779478246717, sharpe5:-0.9615136815235018, irr5:-0.2097141444683075, ndcg5:0.8511686379503047, pnl5:0.9597560167312622 
train 57, step: 0, loss: 0.00013294871314428747, grad_norm: 4.212226523064473e-05, ic: -0.03794674905931775
train 57, step: 100, loss: 0.00012427131878212094, grad_norm: 3.107627091267135e-05, ic: 0.002535203695930688
train 57, step: 200, loss: 0.0001352952531306073, grad_norm: 2.7130508293096792e-06, ic: 0.04270350120444952
train 57, step: 300, loss: 0.0001857124880189076, grad_norm: 5.396457578493501e-05, ic: 0.05810532954932535
train 57, step: 400, loss: 0.00020270762615837157, grad_norm: 3.277362028958285e-05, ic: 0.01922319084535358
train 57, step: 500, loss: 0.0003744241257663816, grad_norm: 1.9633787777320824e-05, ic: 0.03654410811559776
train 57, step: 600, loss: 0.00011676238500513136, grad_norm: 2.223617591393035e-06, ic: 0.025314464402415474
train 57, step: 700, loss: 0.0003303079283796251, grad_norm: 0.0001943172068540085, ic: 0.0033989567207601927
Epoch 57: 2022-05-05 21:59:38.792751: train loss: 0.00020645699554306166
Eval step 0: eval loss: 0.00014454206393565983
Eval step 100: eval loss: 0.00032189060584641993
Eval step 200: eval loss: 0.00029598738183267415
Eval: 2022-05-05 21:59:47.935139: total loss: 0.0001888631590881983, mse:0.00037772631256448064, ic :0.021978795639914003, sharpe5:-1.0802113368362187, irr5:-0.23685598373413086, ndcg5:0.858573225390469, pnl5:0.9572603106498718 
train 58, step: 0, loss: 0.00018726410053204745, grad_norm: 0.00016267046006535803, ic: 0.10828373774489847
train 58, step: 100, loss: 0.00011378186900401488, grad_norm: 3.5820049892494e-05, ic: 0.001699917300149385
train 58, step: 200, loss: 0.00040392400114797056, grad_norm: 0.0002133279955709743, ic: 0.1760444856311758
train 58, step: 300, loss: 0.00015739025548100471, grad_norm: 9.412094261849306e-09, ic: 0.025627780829429323
train 58, step: 400, loss: 0.00013748896890319884, grad_norm: 4.530384187240229e-05, ic: -0.1167278633043752
train 58, step: 500, loss: 9.91283159237355e-05, grad_norm: 5.361478619623591e-07, ic: 0.128157313552145
train 58, step: 600, loss: 0.0002435195492580533, grad_norm: 1.0612320301787395e-05, ic: -0.036169916519381146
train 58, step: 700, loss: 0.00013181567192077637, grad_norm: 5.969790180912784e-07, ic: 0.03781365698345013
Epoch 58: 2022-05-05 22:00:37.941023: train loss: 0.00020635423899807514
Eval step 0: eval loss: 0.00014284213830251247
Eval step 100: eval loss: 0.00031836217385716736
Eval step 200: eval loss: 0.0003012609959114343
Eval: 2022-05-05 22:00:47.576860: total loss: 0.00018863185989064486, mse:0.00037726371656163205, ic :0.02518556509678016, sharpe5:-0.9769549137353897, irr5:-0.21286675333976746, ndcg5:0.8542787104317017, pnl5:0.9569088220596313 
train 59, step: 0, loss: 0.00014525045116897672, grad_norm: 3.82372111491609e-06, ic: -0.005182053206214685
train 59, step: 100, loss: 0.00013047932588960975, grad_norm: 5.743296479639145e-05, ic: 0.12841508226257964
train 59, step: 200, loss: 0.00025699526304379106, grad_norm: 0.00015776716045579298, ic: 0.06681612583843241
train 59, step: 300, loss: 0.0002596048288978636, grad_norm: 6.12648999110302e-05, ic: 0.035071958013456694
train 59, step: 400, loss: 0.00013550050789490342, grad_norm: 1.734122793949951e-05, ic: 0.056585466893821657
train 59, step: 500, loss: 0.00010252170613966882, grad_norm: 6.324779301191818e-06, ic: 0.034988171771696656
train 59, step: 600, loss: 0.0001010590058285743, grad_norm: 3.6075320803750846e-07, ic: 0.04048625055643186
train 59, step: 700, loss: 0.00016020370821934193, grad_norm: 5.0119814036131335e-05, ic: 0.11913694390199844
Epoch 59: 2022-05-05 22:01:38.223806: train loss: 0.00020624041508928838
Eval step 0: eval loss: 0.00014955649385228753
Eval step 100: eval loss: 0.00032927218126133084
Eval step 200: eval loss: 0.00028865481726825237
Eval: 2022-05-05 22:01:47.275825: total loss: 0.00018947279213177341, mse:0.000378945580235525, ic :0.025940245365606806, sharpe5:-1.0045846943557262, irr5:-0.21873730421066284, ndcg5:0.8571310205913775, pnl5:0.952018678188324 

Namespace(adj_path='./data/graphs/NASDAQ_1026_1026.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='NASDAQAdjSeqTimeDataset', dout=0.3, epochs=60, glstm_layers=1, gnn_layers=2, gpu=0, graph_attn=True, hidden_dim=128, inner_prod=False, input_dim=5, input_graph=True, label_cnt=1, lr=0.001, lstm_layers=1, market='NASDAQ', mask_adj=True, mask_type='soft', model_type='BiGLSTM', normalize_adj=True, num_days=8, num_heads=1, print_inteval=500, rank_loss=False, relation_num=1, rsr_data_path='../Temporal_Relational_Stock_Ranking/data/2013-01-01', seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_250_0.8/', stock_num=1931, test_mask_path='./data/NASDAQ/test_mask_237_1026.npy', test_path='./data/NASDAQ/test_237_1026_6.npy', top_stocks=5, train_mask_path='./data/NASDAQ/train_mask_756_1026.npy', train_path='./data/NASDAQ/train_756_1026_6.npy', use_adj=True)
#tickers selected: 1026
single EOD data shape: (1245, 6)
(1026, 1245, 5) (1026, 1245) (1026, 1245) (1026, 1245)
#tickers selected: 1026
single EOD data shape: (1245, 6)
(1026, 1245, 5) (1026, 1245) (1026, 1245) (1026, 1245)
40606
BiGLSTM(
  (input_to_hidden): Linear(in_features=5, out_features=128, bias=True)
  (forward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (attention): ModuleList(
            (0): GraphAttentionLayer (128 -> 128)
          )
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
          (lin_gate): Linear(in_features=128, out_features=128, bias=True)
        )
        (1): RGCN(
          (attention): ModuleList(
            (0): GraphAttentionLayer (128 -> 128)
          )
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
          (lin_gate): Linear(in_features=128, out_features=128, bias=True)
        )
      )
    )
  )
  (backward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (attention): ModuleList(
            (0): GraphAttentionLayer (128 -> 128)
          )
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
          (lin_gate): Linear(in_features=128, out_features=128, bias=True)
        )
        (1): RGCN(
          (attention): ModuleList(
            (0): GraphAttentionLayer (128 -> 128)
          )
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
          (lin_gate): Linear(in_features=128, out_features=128, bias=True)
        )
      )
    )
  )
  (fc0): ModuleList(
    (0): Linear(in_features=256, out_features=128, bias=True)
  )
  (w_out): Linear(in_features=128, out_features=1, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
)
train 0, step: 0, loss: 0.02336038090288639, grad_norm: 0.4225927032800961, ic: 0.02883611465608312
train 0, step: 500, loss: 0.00016276359383482486, grad_norm: 4.2623141388868745e-07, ic: 0.04829797497680901
Epoch 0: 2022-05-06 16:48:52.502528: train loss: 0.0006600295293566965
Eval step 0: eval loss: 0.00016386646893806756
Eval: 2022-05-06 16:49:08.624026: total loss: 0.00019269998953093094, mse:0.0003853999768967619, ic :0.03077821445963062, sharpe5:-0.051891999193467195, irr5:-0.014663494192063808, ndcg5:0.8546648214713184, pnl5:0.9489896893501282 
train 1, step: 0, loss: 0.00014389617717824876, grad_norm: 6.487638411467203e-05, ic: -0.007094531650070547
train 1, step: 500, loss: 0.00017283250053878874, grad_norm: 9.264665056161752e-05, ic: -0.04663716857783176
Epoch 1: 2022-05-06 16:51:10.682345: train loss: 0.00023557975051750587
Eval step 0: eval loss: 0.0001394659047946334
Eval: 2022-05-06 16:51:26.807303: total loss: 0.00018861927810774742, mse:0.0003772385525776569, ic :0.019025927557660433, sharpe5:-0.8297114669904112, irr5:-0.1762828528881073, ndcg5:0.8412061515415561, pnl5:0.983045756816864 
train 2, step: 0, loss: 0.00015262208762578666, grad_norm: 9.2997338276734e-06, ic: -0.021289149865529808
train 2, step: 500, loss: 0.00011573188385227695, grad_norm: 1.4884487666788054e-07, ic: 0.020997082469226342
Epoch 2: 2022-05-06 16:53:28.781878: train loss: 0.00022454010489609036
Eval step 0: eval loss: 0.0001188199530588463
Eval: 2022-05-06 16:53:44.066147: total loss: 0.0001991807381336793, mse:0.0003983614729957941, ic :0.01829588538519467, sharpe5:-1.2522099550813437, irr5:-0.2666199505329132, ndcg5:0.8463300481504629, pnl5:0.9755911827087402 
train 3, step: 0, loss: 0.00015596779121551663, grad_norm: 2.707126343692635e-05, ic: -0.06487607700545364
train 3, step: 500, loss: 0.0002122875739587471, grad_norm: 4.718537665759158e-05, ic: -0.012513824601237004
Epoch 3: 2022-05-06 16:55:46.082107: train loss: 0.0002205594158108081
Eval step 0: eval loss: 0.00015220310888253152
Eval: 2022-05-06 16:56:02.356550: total loss: 0.00018976807219253886, mse:0.00037953614283592774, ic :0.01752560712793559, sharpe5:-1.1198740019649267, irr5:-0.24184778332710266, ndcg5:0.851629481986149, pnl5:0.9653714895248413 
train 4, step: 0, loss: 0.00014625475159846246, grad_norm: 1.3575251128163086e-05, ic: 0.040742042743561455
train 4, step: 500, loss: 0.0002274915314046666, grad_norm: 5.006951403686106e-05, ic: 0.05240653933683998
Epoch 4: 2022-05-06 16:58:04.033133: train loss: 0.00021654709445116207
Eval step 0: eval loss: 0.00013595707423519343
Eval: 2022-05-06 16:58:20.254284: total loss: 0.0001888438278219996, mse:0.0003776876524273279, ic :0.017438503679279602, sharpe5:-1.0749110785871743, irr5:-0.22928351163864136, ndcg5:0.8513014582354667, pnl5:0.9391627311706543 
train 5, step: 0, loss: 0.0002168918726965785, grad_norm: 6.421038215669554e-05, ic: 0.053161675637368636
train 5, step: 500, loss: 0.0006563981296494603, grad_norm: 0.0007051743082200289, ic: 0.006375656578146888
Epoch 5: 2022-05-06 17:00:21.036659: train loss: 0.00021242627311666946
Eval step 0: eval loss: 0.00018716827617026865
Eval: 2022-05-06 17:00:36.983642: total loss: 0.0002008093763806239, mse:0.0004016187493867443, ic :0.017196367133390077, sharpe5:-1.235474992096424, irr5:-0.26474955677986145, ndcg5:0.8528693320150317, pnl5:0.9628561735153198 
train 6, step: 0, loss: 0.00020643442985601723, grad_norm: 0.0002185323400128724, ic: 0.012179003951990952
train 6, step: 500, loss: 0.00011861068196594715, grad_norm: 4.784747542343617e-05, ic: -0.0189497842339242
Epoch 6: 2022-05-06 17:02:36.868326: train loss: 0.00021234986573723233
Eval step 0: eval loss: 0.00015564821660518646
Eval: 2022-05-06 17:02:52.951104: total loss: 0.00019042792357783968, mse:0.00038085584793722134, ic :0.01657144349783424, sharpe5:-1.3584338653832673, irr5:-0.29215094447135925, ndcg5:0.8618710657977038, pnl5:0.9424406290054321 
train 7, step: 0, loss: 0.00020458406652323902, grad_norm: 3.3567049726653272e-06, ic: 0.04979961344835131
train 7, step: 500, loss: 0.00036126025952398777, grad_norm: 0.00013389036234104788, ic: 0.07868807989204138
Epoch 7: 2022-05-06 17:04:55.546110: train loss: 0.0002104009530263225
Eval step 0: eval loss: 0.00014312969869934022
Eval: 2022-05-06 17:05:11.671158: total loss: 0.00018869572808771846, mse:0.00037739145201149375, ic :0.016900639151338066, sharpe5:-1.2730897280573845, irr5:-0.2739175856113434, ndcg5:0.8445876622668937, pnl5:0.9238463640213013 
train 8, step: 0, loss: 0.00015116760914679617, grad_norm: 5.9223117075204325e-06, ic: 0.07275366610441475
train 8, step: 500, loss: 0.00016015933942981064, grad_norm: 4.885427110962103e-05, ic: 0.042959641965746274
Epoch 8: 2022-05-06 17:07:16.833801: train loss: 0.00020957491280452502
Eval step 0: eval loss: 0.00013168842997401953
Eval: 2022-05-06 17:07:32.841072: total loss: 0.00018958731700730302, mse:0.0003791746277493681, ic :0.017230173267797542, sharpe5:-1.1808700114488602, irr5:-0.2557390034198761, ndcg5:0.8477026387500194, pnl5:0.9226230978965759 
train 9, step: 0, loss: 0.00013269805640447885, grad_norm: 2.580902062981736e-06, ic: 0.027606502076595693
train 9, step: 500, loss: 8.145398169290274e-05, grad_norm: 2.1181350976744663e-06, ic: 0.004602898331625294
Epoch 9: 2022-05-06 17:09:35.482322: train loss: 0.00020828258752796262
Eval step 0: eval loss: 0.0001262687728740275
Eval: 2022-05-06 17:09:52.369950: total loss: 0.00019163218784775367, mse:0.00038326437213064273, ic :0.01570043118250149, sharpe5:-1.1097071924060582, irr5:-0.2427668273448944, ndcg5:0.849935503148555, pnl5:0.9341845512390137 
train 10, step: 0, loss: 9.189032425638288e-05, grad_norm: 4.093224115361718e-07, ic: 0.052256887698798826
train 10, step: 500, loss: 0.0002223342307843268, grad_norm: 8.785779184626259e-05, ic: 0.07489139354662219
Epoch 10: 2022-05-06 17:11:53.939505: train loss: 0.0002086354648042439
Eval step 0: eval loss: 0.00017268816009163857
Eval: 2022-05-06 17:12:10.238509: total loss: 0.00019526456191161785, mse:0.00039052911859850675, ic :0.016587353066129903, sharpe5:-1.0388431676477192, irr5:-0.22590863704681396, ndcg5:0.8443999003788306, pnl5:0.9294589757919312 
train 11, step: 0, loss: 0.00023557893291581422, grad_norm: 5.088731502045529e-06, ic: -0.043372440187738816
train 11, step: 500, loss: 0.0002233635023003444, grad_norm: 5.700062055129369e-06, ic: 0.030415481797667406
Epoch 11: 2022-05-06 17:14:09.968105: train loss: 0.00020903563808604954
Eval step 0: eval loss: 0.00013575280900113285
Eval: 2022-05-06 17:14:26.069452: total loss: 0.00018898283388017265, mse:0.0003779656658033797, ic :0.006948826392164387, sharpe5:-0.8679126768931746, irr5:-0.18912461400032043, ndcg5:0.8510299098572806, pnl5:0.924813449382782 
train 12, step: 0, loss: 0.00016302996664308012, grad_norm: 6.445831524845122e-05, ic: -0.01444151595618577
train 12, step: 500, loss: 0.00013522776134777814, grad_norm: 4.160040552302942e-06, ic: 0.03199028347138355
Epoch 12: 2022-05-06 17:16:29.179875: train loss: 0.00020841993909196264
Eval step 0: eval loss: 0.00014755307347513735
Eval: 2022-05-06 17:16:45.538060: total loss: 0.0001890873742672639, mse:0.00037817474491986245, ic :0.014116820573074475, sharpe5:-1.1317229039222, irr5:-0.24722424149513245, ndcg5:0.8458620211565119, pnl5:0.9307048320770264 
train 13, step: 0, loss: 0.00016970066644717008, grad_norm: 1.502148553866659e-05, ic: 0.07740600813656687
train 13, step: 500, loss: 0.00012352071644272655, grad_norm: 3.7598736272286086e-08, ic: 0.0016347805819137747
Epoch 13: 2022-05-06 17:18:48.034933: train loss: 0.00020886257617557883
Eval step 0: eval loss: 0.0001629297767067328
Eval: 2022-05-06 17:19:04.342135: total loss: 0.00019219233611863978, mse:0.0003843846682427137, ic :0.01162830292325318, sharpe5:-1.2177897284924983, irr5:-0.25977084040641785, ndcg5:0.8641468535048071, pnl5:0.915327250957489 
train 14, step: 0, loss: 0.00020378627232275903, grad_norm: 8.261416233466135e-07, ic: 0.07266674725134034
train 14, step: 500, loss: 0.00017343884974252433, grad_norm: 3.8557105136674845e-06, ic: -0.07549014915647739
Epoch 14: 2022-05-06 17:21:05.352929: train loss: 0.00020896827147790027
Eval step 0: eval loss: 0.00013370979286264628
Eval: 2022-05-06 17:21:20.914981: total loss: 0.00018930814315246694, mse:0.0003786162865230056, ic :-0.008327552072145635, sharpe5:-8.243674478530883, irr5:-0.629602313041687, ndcg5:0.852947713706732, pnl5:0.20310695469379425 
train 15, step: 0, loss: 0.00013845103967469186, grad_norm: 3.1319258588046225e-06, ic: -0.03923070030764479
train 15, step: 500, loss: 0.00010324992763344198, grad_norm: 1.0455460077176751e-07, ic: -0.006871847868928367
Epoch 15: 2022-05-06 17:23:22.039240: train loss: 0.00020809804066430614
Eval step 0: eval loss: 0.00011836239718832076
Eval: 2022-05-06 17:23:37.707060: total loss: 0.0002009309131822927, mse:0.00040186181978540524, ic :0.0064959007593622005, sharpe5:-1.1637474554032088, irr5:-0.2490694224834442, ndcg5:0.8558095830451166, pnl5:0.9060031175613403 
train 16, step: 0, loss: 0.00020556867821142077, grad_norm: 5.9405032228000135e-06, ic: -0.011396674652044088
train 16, step: 500, loss: 0.0001202773637487553, grad_norm: 2.6510049080162594e-06, ic: 0.01685376118328262
Epoch 16: 2022-05-06 17:25:37.715437: train loss: 0.0002098820492528587
Eval step 0: eval loss: 0.0001824850041884929
Eval: 2022-05-06 17:25:53.707020: total loss: 0.0001987803169903874, mse:0.0003975606274430437, ic :0.001198301459248173, sharpe5:-1.2796512600034475, irr5:-0.27378711104393005, ndcg5:0.855846188711243, pnl5:0.9182106852531433 
train 17, step: 0, loss: 0.00014473388728220016, grad_norm: 4.877817965170324e-06, ic: 0.02357732084616021
train 17, step: 500, loss: 8.052114571910352e-05, grad_norm: 2.1930786000294594e-07, ic: -0.04608903194142279
Epoch 17: 2022-05-06 17:27:54.035623: train loss: 0.00020930796094482485
Eval step 0: eval loss: 0.0001575490168761462
Eval: 2022-05-06 17:28:10.255136: total loss: 0.00019083843062815814, mse:0.00038167685927483803, ic :0.006508948677996784, sharpe5:-1.1355265894532203, irr5:-0.2417500615119934, ndcg5:0.8519671734238006, pnl5:0.944484531879425 
train 18, step: 0, loss: 0.0003835975076071918, grad_norm: 0.0002966247282574594, ic: -0.005833735728232406
train 18, step: 500, loss: 0.00028739366098307073, grad_norm: 0.00023666158148501077, ic: 0.02106635805448073
Epoch 18: 2022-05-06 17:30:14.077512: train loss: 0.0002098847502381242
Eval step 0: eval loss: 0.0001382923946948722
Eval: 2022-05-06 17:30:30.207581: total loss: 0.0001887642870215886, mse:0.0003775285717193919, ic :0.004906988631215373, sharpe5:-1.4171207519620657, irr5:-0.30997928977012634, ndcg5:0.8655834519204313, pnl5:0.8816056847572327 
train 19, step: 0, loss: 0.0002342318039154634, grad_norm: 0.0002002792626238992, ic: 0.008969499608118749
train 19, step: 500, loss: 0.00020681681053247303, grad_norm: 1.0445497146285086e-07, ic: -0.06873609595122013
Epoch 19: 2022-05-06 17:32:31.621761: train loss: 0.00020845881709175305
Eval step 0: eval loss: 0.00013482605572789907
Eval: 2022-05-06 17:32:47.779049: total loss: 0.00018911671470932045, mse:0.0003782334245338142, ic :0.0019481202811517772, sharpe5:-1.1952091810852288, irr5:-0.2566153109073639, ndcg5:0.8631164338635972, pnl5:0.9165924191474915 
train 20, step: 0, loss: 0.0002265961520606652, grad_norm: 1.1172400043522356e-06, ic: -0.018149975904920148
train 20, step: 500, loss: 0.0001032520376611501, grad_norm: 1.001690942689288e-06, ic: 0.006736556216124633
Epoch 20: 2022-05-06 17:34:48.243008: train loss: 0.00020848524566056715
Eval step 0: eval loss: 0.00014178981655277312
Eval: 2022-05-06 17:35:04.119275: total loss: 0.00018870218685044252, mse:0.0003774043681970529, ic :0.01168478863851728, sharpe5:0.3367224469967186, irr5:0.10135471820831299, ndcg5:0.8402263862614636, pnl5:1.126485824584961 
train 21, step: 0, loss: 0.00038549138116650283, grad_norm: 0.00038994503581955614, ic: 0.02507667690984603
train 21, step: 500, loss: 0.00017852330347523093, grad_norm: 2.434384663783776e-05, ic: 0.05812168248488363
Epoch 21: 2022-05-06 17:37:06.038069: train loss: 0.00020882013398764238
Eval step 0: eval loss: 0.00017590218340046704
Eval: 2022-05-06 17:37:22.149370: total loss: 0.00019631738710043317, mse:0.00039263476937377036, ic :0.030730710211128838, sharpe5:1.1690811757743358, irr5:0.21638548374176025, ndcg5:0.8569035196595471, pnl5:0.9701276421546936 
train 22, step: 0, loss: 0.00013704199227504432, grad_norm: 2.769488936780543e-05, ic: 0.012771614927448799
train 22, step: 500, loss: 0.00012364995200186968, grad_norm: 4.337964892037723e-05, ic: 0.006373863454499272
Epoch 22: 2022-05-06 17:39:23.731516: train loss: 0.00020855998696243724
Eval step 0: eval loss: 0.00012660116772167385
Eval: 2022-05-06 17:39:39.906063: total loss: 0.0001917269982778321, mse:0.00038345399188761557, ic :-0.002163243592204475, sharpe5:-0.5548801412433385, irr5:-0.09706180542707443, ndcg5:0.8458100585018454, pnl5:0.9215505123138428 
train 23, step: 0, loss: 0.00020639266585931182, grad_norm: 7.673157664497567e-05, ic: -0.07681780224798303
train 23, step: 500, loss: 0.00010323018068447709, grad_norm: 2.7876652770363657e-05, ic: 0.045655054813467925
Epoch 23: 2022-05-06 17:41:41.748093: train loss: 0.00020933254644451202
Eval step 0: eval loss: 0.00013797175779473037
Eval: 2022-05-06 17:41:58.048295: total loss: 0.00018878369482831957, mse:0.00037756738562128234, ic :-0.004119845614856298, sharpe5:-0.9666566205024719, irr5:-0.16167119145393372, ndcg5:0.845346498810991, pnl5:0.9668254256248474 
train 24, step: 0, loss: 0.00016254614456556737, grad_norm: 1.8045511672560424e-06, ic: -0.028037197050804003
train 24, step: 500, loss: 0.0002379985380684957, grad_norm: 8.544491329785664e-05, ic: 0.01207175743782631
Epoch 24: 2022-05-06 17:44:00.457989: train loss: 0.00020877211933053176
Eval step 0: eval loss: 0.00015855296805966645
Eval: 2022-05-06 17:44:16.761926: total loss: 0.00019107185186351564, mse:0.0003821437015761469, ic :-0.003847983912077644, sharpe5:0.21480596906505525, irr5:0.034619055688381195, ndcg5:0.8594579517223158, pnl5:1.1018272638320923 
train 25, step: 0, loss: 0.00015278244973160326, grad_norm: 0.00011109263329871169, ic: -0.020892591749945857
train 25, step: 500, loss: 0.00018906909099314362, grad_norm: 0.00014191652539779427, ic: -0.0162380113219647
Epoch 25: 2022-05-06 17:46:18.400833: train loss: 0.0002094420909764554
Eval step 0: eval loss: 0.00013212025805842131
Eval: 2022-05-06 17:46:34.304760: total loss: 0.0001896469106269374, mse:0.0003792938190560532, ic :-0.003092133499070639, sharpe5:0.006763932335888966, irr5:0.0011223312467336655, ndcg5:0.8690132055792555, pnl5:0.9417293071746826 
train 26, step: 0, loss: 0.0001414940634276718, grad_norm: 1.7751805373897465e-05, ic: 0.003364508579935678
train 26, step: 500, loss: 6.545303767779842e-05, grad_norm: 3.939136223779628e-06, ic: 0.006580184955812033
Epoch 26: 2022-05-06 17:48:35.421778: train loss: 0.00020908486348487977
Eval step 0: eval loss: 0.00014919006207492203
Eval: 2022-05-06 17:48:51.825534: total loss: 0.00018929859048734708, mse:0.00037859717961982443, ic :0.0004551764449065285, sharpe5:-1.176667145267129, irr5:-0.2523849308490753, ndcg5:0.8497757881385414, pnl5:0.9224714040756226 
train 27, step: 0, loss: 0.00020125499577261508, grad_norm: 7.45317025615548e-05, ic: 0.024852827719175113
train 27, step: 500, loss: 0.00017263104382436723, grad_norm: 2.744526688589132e-05, ic: 0.022117539619582835
Epoch 27: 2022-05-06 17:50:54.114385: train loss: 0.00020965299511329583
Eval step 0: eval loss: 0.00012823374709114432
Eval: 2022-05-06 17:51:10.148724: total loss: 0.0001909364967474279, mse:0.0003818729902591014, ic :0.005689894143596288, sharpe5:-1.2510154873877763, irr5:-0.26811906695365906, ndcg5:0.8528269649302548, pnl5:0.9261277914047241 
train 28, step: 0, loss: 0.000312121061142534, grad_norm: 4.8722369543007596e-08, ic: -0.04889784001504166
train 28, step: 500, loss: 0.00019556123879738152, grad_norm: 6.938810596520357e-05, ic: 0.0012273541882783703
Epoch 28: 2022-05-06 17:53:13.532714: train loss: 0.00020865933217761453
Eval step 0: eval loss: 0.00014676983118988574
Eval: 2022-05-06 17:53:28.786400: total loss: 0.00018901064795976723, mse:0.0003780212933873126, ic :0.0011204575916045558, sharpe5:-0.9686099570989608, irr5:-0.21118482947349548, ndcg5:0.8554314053456918, pnl5:0.9595474004745483 
train 29, step: 0, loss: 0.00018084202019963413, grad_norm: 1.7726749738530743e-06, ic: 0.05746718635762722
train 29, step: 500, loss: 0.00012326746946200728, grad_norm: 9.868300975114437e-06, ic: -0.03179868149369802
Epoch 29: 2022-05-06 17:55:29.174273: train loss: 0.00020875290163452917
Eval step 0: eval loss: 0.00017469779413659126
Eval: 2022-05-06 17:55:45.400492: total loss: 0.00019589083202007352, mse:0.0003917816618171277, ic :0.003030334373074037, sharpe5:0.9645512854680418, irr5:0.1634628176689148, ndcg5:0.8426488816961861, pnl5:1.2628000974655151 
train 30, step: 0, loss: 0.00017077915254049003, grad_norm: 7.331909604487891e-05, ic: -0.010826719245502743
train 30, step: 500, loss: 0.0002172925742343068, grad_norm: 4.982161395535445e-07, ic: 0.004727230540729797
Epoch 30: 2022-05-06 17:57:47.300963: train loss: 0.0002098805129460811
Eval step 0: eval loss: 0.00019684220023918897
Eval: 2022-05-06 17:58:03.152264: total loss: 0.00020481061315424253, mse:0.0004096212255476356, ic :0.004580092710731134, sharpe5:-0.5881514228135347, irr5:-0.12893792986869812, ndcg5:0.8479995487079389, pnl5:0.9573031663894653 
train 31, step: 0, loss: 0.00016098965716082603, grad_norm: 0.0001127872923118422, ic: -0.03126152505338712
train 31, step: 500, loss: 0.00013152699102647603, grad_norm: 2.799255111518008e-05, ic: -0.07789296140977861
Epoch 31: 2022-05-06 18:00:04.200743: train loss: 0.00020891324784121112
Eval step 0: eval loss: 0.0001222363207489252
Eval: 2022-05-06 18:00:20.417497: total loss: 0.00019499600202675836, mse:0.0003899920000978526, ic :-0.0037470227123102356, sharpe5:-0.9242705170065164, irr5:-0.14556187391281128, ndcg5:0.8581596316786237, pnl5:0.850218653678894 
train 32, step: 0, loss: 0.0001761420862749219, grad_norm: 2.4460738955147018e-05, ic: -0.05368732715537438
train 32, step: 500, loss: 0.00017805563402362168, grad_norm: 4.732814223426746e-06, ic: -0.055575473979916606
Epoch 32: 2022-05-06 18:02:22.748938: train loss: 0.00020905678623076092
Eval step 0: eval loss: 0.00012814352521672845
Eval: 2022-05-06 18:02:38.852461: total loss: 0.00019097574087984323, mse:0.00038195148105572396, ic :-0.002010837994504687, sharpe5:-0.1207062398828566, irr5:-0.02003876119852066, ndcg5:0.8617278923476068, pnl5:0.9061371684074402 
train 33, step: 0, loss: 0.00017933431081473827, grad_norm: 9.322066375823862e-06, ic: -0.0448177465678936
train 33, step: 500, loss: 8.352160512004048e-05, grad_norm: 4.446864560468725e-06, ic: 0.026640224756700432
Epoch 33: 2022-05-06 18:04:41.018251: train loss: 0.00020915859001925224
Eval step 0: eval loss: 0.00016108887211885303
Eval: 2022-05-06 18:04:56.932214: total loss: 0.00019170098228117767, mse:0.00038340196221478155, ic :0.0018982456173335465, sharpe5:-1.0778958289325238, irr5:-0.23272091150283813, ndcg5:0.8543320539844639, pnl5:0.9184226393699646 
train 34, step: 0, loss: 0.00017260546155739576, grad_norm: 7.182125392816257e-08, ic: 0.06348346306306848
train 34, step: 500, loss: 0.00012531642278190702, grad_norm: 1.2201614845859471e-05, ic: -0.038456467389072976
Epoch 34: 2022-05-06 18:06:58.161242: train loss: 0.00020834861607972488
Eval step 0: eval loss: 0.00012424818123690784
Eval: 2022-05-06 18:07:14.095326: total loss: 0.00019323083961750564, mse:0.00038646167864823234, ic :-0.007496004397591861, sharpe5:-5.916624389290809, irr5:-0.4901588559150696, ndcg5:0.8567154631021913, pnl5:0.49056971073150635 
train 35, step: 0, loss: 0.00033281109062954783, grad_norm: 0.0003427122157422178, ic: -0.0517711381318428
train 35, step: 500, loss: 0.00033287968835793436, grad_norm: 0.00018586470065589154, ic: 0.0007779847287610383
Epoch 35: 2022-05-06 18:09:16.502821: train loss: 0.00020916477461240595
Eval step 0: eval loss: 0.00014056861982680857
Eval: 2022-05-06 18:09:32.846266: total loss: 0.00018869449158796968, mse:0.00037738897931117695, ic :0.0016434761593799101, sharpe5:1.2259140479564665, irr5:0.2090030163526535, ndcg5:0.8568773549051127, pnl5:1.1212042570114136 
train 36, step: 0, loss: 0.0002411748719168827, grad_norm: 0.0001468778862359743, ic: -0.0023291904527126903
train 36, step: 500, loss: 0.0004871961136814207, grad_norm: 0.00018887932235545478, ic: 0.0006192346414021135
Epoch 36: 2022-05-06 18:11:34.588120: train loss: 0.0002083519013107687
Eval step 0: eval loss: 0.00018178850586991757
Eval: 2022-05-06 18:11:50.723688: total loss: 0.00019850989401556032, mse:0.0003970197806695616, ic :0.0026837255805443366, sharpe5:-0.8168120554089546, irr5:-0.17778000235557556, ndcg5:0.8524020394162622, pnl5:1.0012027025222778 
train 37, step: 0, loss: 0.00034221296664327383, grad_norm: 0.00038524186336243355, ic: -0.06441817686026086
train 37, step: 500, loss: 0.00016584977856837213, grad_norm: 1.8700281472274762e-05, ic: 0.0026627291386251434
Epoch 37: 2022-05-06 18:13:51.853860: train loss: 0.0002094341762617441
Eval step 0: eval loss: 0.00014835073670838028
Eval: 2022-05-06 18:14:08.154817: total loss: 0.0001891895895251927, mse:0.00037837917384173504, ic :-0.003371325167413353, sharpe5:0.031146872830577193, irr5:0.005099916364997625, ndcg5:0.8547525304060493, pnl5:0.9792681336402893 
train 38, step: 0, loss: 0.00015799827815499157, grad_norm: 1.650361198388797e-08, ic: 0.019526204129573076
train 38, step: 500, loss: 0.00031238715746439993, grad_norm: 2.2485329434867714e-05, ic: 0.011207105208046172
Epoch 38: 2022-05-06 18:16:10.781740: train loss: 0.0002080275755098437
Eval step 0: eval loss: 0.00012742029502987862
Eval: 2022-05-06 18:16:27.114929: total loss: 0.00019130830221665072, mse:0.00038261660122880184, ic :0.0030738374120944786, sharpe5:-1.1218123219907283, irr5:-0.2435797154903412, ndcg5:0.8553140702473643, pnl5:0.947903573513031 
train 39, step: 0, loss: 0.00031803862657397985, grad_norm: 0.00016549567462889237, ic: -0.007986015269416833
train 39, step: 500, loss: 0.00018185688531957567, grad_norm: 1.617781369751738e-05, ic: 0.005272247719451161
Epoch 39: 2022-05-06 18:18:29.216671: train loss: 0.0002087379578340837
Eval step 0: eval loss: 0.00016450553084723651
Eval: 2022-05-06 18:18:44.877926: total loss: 0.00019263189692557566, mse:0.00038526378562853586, ic :0.0010571376519181548, sharpe5:-1.2661281877756119, irr5:-0.27138552069664, ndcg5:0.8531469911451606, pnl5:0.9402636289596558 
train 40, step: 0, loss: 0.00019329320639371872, grad_norm: 4.1183455726750454e-05, ic: -0.01214166428625474
train 40, step: 500, loss: 0.00032307265792042017, grad_norm: 5.574749980564566e-05, ic: 0.03791796581400773
Epoch 40: 2022-05-06 18:20:45.668804: train loss: 0.00020900688914820723
Eval step 0: eval loss: 0.00011835330951726064
Eval: 2022-05-06 18:21:01.884976: total loss: 0.00020095516642729456, mse:0.0004019103288755984, ic :-0.005689118028601279, sharpe5:-0.6919046342745423, irr5:-0.10459310561418533, ndcg5:0.8631223296029022, pnl5:1.0520148277282715 
train 41, step: 0, loss: 0.0001787941437214613, grad_norm: 3.0819475974885364e-05, ic: 0.01026324624195624
train 41, step: 500, loss: 0.0001474498276365921, grad_norm: 6.770615266771628e-05, ic: -0.023913096042232733
Epoch 41: 2022-05-06 18:23:02.787811: train loss: 0.00020841000152485356
Eval step 0: eval loss: 0.00016769008652772754
Eval: 2022-05-06 18:23:19.067898: total loss: 0.0001935776380652269, mse:0.00038715527657201657, ic :0.007624273720108846, sharpe5:-0.8146840181574225, irr5:-0.1792062222957611, ndcg5:0.8597838673167083, pnl5:0.9500417709350586 
train 42, step: 0, loss: 0.000117414616397582, grad_norm: 3.5966276043010486e-05, ic: -0.004241237135094
train 42, step: 500, loss: 0.00030201897607184947, grad_norm: 1.6386242659551746e-06, ic: -0.018367767548385282
Epoch 42: 2022-05-06 18:25:20.018425: train loss: 0.00020841270227666588
Eval step 0: eval loss: 0.000133414170704782
Eval: 2022-05-06 18:25:36.030785: total loss: 0.000189361629797162, mse:0.0003787232545948832, ic :-0.0066261973256199385, sharpe5:-3.999582016468048, irr5:-0.6565903425216675, ndcg5:0.8551637510908833, pnl5:0.698482871055603 
train 43, step: 0, loss: 0.00017232669051736593, grad_norm: 8.087958355317373e-05, ic: 0.001394510196379175
train 43, step: 500, loss: 0.00019769350183196366, grad_norm: 8.296156592185664e-05, ic: -0.0668116434253842
Epoch 43: 2022-05-06 18:27:36.678030: train loss: 0.00020909044300628556
Eval step 0: eval loss: 0.00014863691467326134
Eval: 2022-05-06 18:27:52.578381: total loss: 0.00018922570969819957, mse:0.0003784514159888474, ic :-0.009904487988809468, sharpe5:-6.434423178434372, irr5:-1.145026445388794, ndcg5:0.8584770684437214, pnl5:0.5179399251937866 
train 44, step: 0, loss: 0.00018054709653370082, grad_norm: 1.2088106994027247e-06, ic: 0.08817539484089588
train 44, step: 500, loss: 0.0001622445706743747, grad_norm: 4.920091647366432e-05, ic: 0.011198491344555285
Epoch 44: 2022-05-06 18:29:52.946881: train loss: 0.00020876691205995744
Eval step 0: eval loss: 0.00012691241863649338
Eval: 2022-05-06 18:30:08.502308: total loss: 0.0001915623410058403, mse:0.00038312467710544966, ic :-0.005207506928259577, sharpe5:0.8572725497558713, irr5:0.11701197922229767, ndcg5:0.8467005290670753, pnl5:0.9281617403030396 
train 45, step: 0, loss: 0.0003627764235716313, grad_norm: 8.48480958332612e-06, ic: 0.019533763202688792
train 45, step: 500, loss: 0.00011300045298412442, grad_norm: 2.9409689012372857e-06, ic: -0.030050696408493414
Epoch 45: 2022-05-06 18:32:11.379176: train loss: 0.00020908267989510018
Eval step 0: eval loss: 0.00014860286319162697
Eval: 2022-05-06 18:32:27.680423: total loss: 0.00018922133989785655, mse:0.00037844267599400073, ic :0.008402223171198573, sharpe5:-0.9364130697771906, irr5:-0.20418286323547363, ndcg5:0.8546414480068636, pnl5:0.9650478959083557 
train 46, step: 0, loss: 0.00024664049851708114, grad_norm: 9.032924423186261e-05, ic: 0.007315235007449476
train 46, step: 500, loss: 0.00010030577686848119, grad_norm: 9.82857765618602e-10, ic: -0.005161395106849724
Epoch 46: 2022-05-06 18:34:28.281388: train loss: 0.0002089328383570873
Eval step 0: eval loss: 0.00014318815374281257
Eval: 2022-05-06 18:34:44.352355: total loss: 0.00018874605363067116, mse:0.0003774921043028665, ic :0.003452494875050945, sharpe5:-0.860867008343339, irr5:-0.18784847855567932, ndcg5:0.8662638188262266, pnl5:0.9431069493293762 
train 47, step: 0, loss: 0.00020509403839241713, grad_norm: 0.00013348358454444884, ic: -0.023059976531722155
train 47, step: 500, loss: 0.00013601922546513379, grad_norm: 1.5529028281108423e-07, ic: 0.007808748124265831
Epoch 47: 2022-05-06 18:36:47.680013: train loss: 0.00020895564828966347
Eval step 0: eval loss: 0.00014645623741671443
Eval: 2022-05-06 18:37:03.713746: total loss: 0.00018897943775546757, mse:0.00037795887019404824, ic :-0.0043802279585778295, sharpe5:-1.196018893495202, irr5:-0.25474685430526733, ndcg5:0.8587275174229234, pnl5:0.934729278087616 
train 48, step: 0, loss: 0.0002142584417015314, grad_norm: 6.776809532921843e-05, ic: -0.0028422289728833143
train 48, step: 500, loss: 0.00015708756109233946, grad_norm: 1.272969771241622e-05, ic: 0.06757092904946269
Epoch 48: 2022-05-06 18:39:05.862717: train loss: 0.0002089511680409448
Eval step 0: eval loss: 0.00012508832151070237
Eval: 2022-05-06 18:39:22.029903: total loss: 0.00019263610805285176, mse:0.0003852722118673595, ic :-0.0023119789713802884, sharpe5:-1.0901318509876727, irr5:-0.23573100566864014, ndcg5:0.8477760710381554, pnl5:0.9865821599960327 
train 49, step: 0, loss: 0.00018305834964849055, grad_norm: 1.1068004301169778e-05, ic: 0.034969265002857644
train 49, step: 500, loss: 7.173140329541638e-05, grad_norm: 2.104690263026064e-06, ic: -0.013759116318152236
Epoch 49: 2022-05-06 18:41:23.049510: train loss: 0.00020800522998374397
Eval step 0: eval loss: 0.0001476985344197601
Eval: 2022-05-06 18:41:39.338045: total loss: 0.00018911149482930072, mse:0.00037822298684300515, ic :0.003026296187425523, sharpe5:1.8920711164176462, irr5:0.3458399176597595, ndcg5:0.8591584810593633, pnl5:1.2367703914642334 
train 50, step: 0, loss: 0.00038987831794656813, grad_norm: 0.00015936180920767513, ic: -0.0077264121365143495
train 50, step: 500, loss: 0.00017446665151510388, grad_norm: 6.032956673994655e-05, ic: 0.023401643766560766
Epoch 50: 2022-05-06 18:43:41.557891: train loss: 0.00020842446812266985
Eval step 0: eval loss: 0.00013624699204228818
Eval: 2022-05-06 18:43:57.971452: total loss: 0.0001889325539311028, mse:0.00037786510784810904, ic :-0.007368320676694735, sharpe5:-6.991555923521519, irr5:-0.9544070363044739, ndcg5:0.8624974103443276, pnl5:0.672455906867981 
train 51, step: 0, loss: 0.00013028024113737047, grad_norm: 2.8861104938665878e-05, ic: 0.021709836443165438
train 51, step: 500, loss: 0.00010280578135279939, grad_norm: 3.4422765524789405e-06, ic: 0.03289799815653737
Epoch 51: 2022-05-06 18:46:00.997193: train loss: 0.00020877272056975653
Eval step 0: eval loss: 0.00015827277093194425
Eval: 2022-05-06 18:46:17.589677: total loss: 0.00019100578680383368, mse:0.0003820115698129004, ic :-0.0058077124982521475, sharpe5:-1.14434793792665, irr5:-0.24396595358848572, ndcg5:0.8595499969439245, pnl5:0.910260796546936 
train 52, step: 0, loss: 0.0002211602550232783, grad_norm: 5.092910078966126e-07, ic: 0.0014828009587040114
train 52, step: 500, loss: 0.00043251452734693885, grad_norm: 0.0002611505531404593, ic: -0.005149177848715717
Epoch 52: 2022-05-06 18:48:13.296317: train loss: 0.00020870190033786258
Eval step 0: eval loss: 0.00014966691378504038
Eval: 2022-05-06 18:48:29.361261: total loss: 0.00018936466186980443, mse:0.00037872931649976825, ic :0.004682275054579071, sharpe5:1.796739540696144, irr5:0.30801326036453247, ndcg5:0.8561852511741604, pnl5:1.0379862785339355 
train 53, step: 0, loss: 0.00022320546850096434, grad_norm: 0.00011600665584860089, ic: -0.003959412098856155
train 53, step: 500, loss: 0.00019410194363445044, grad_norm: 6.0230094338665044e-05, ic: -0.007078203967210316
Epoch 53: 2022-05-06 18:50:32.854837: train loss: 0.00020847391683406278
Eval step 0: eval loss: 0.00015034918033052236
Eval: 2022-05-06 18:50:49.086686: total loss: 0.0001894642407528031, mse:0.0003789284816106743, ic :0.0007830211899876719, sharpe5:-1.2965981103479862, irr5:-0.2787458002567291, ndcg5:0.8594662490873224, pnl5:0.919662356376648 
train 54, step: 0, loss: 0.00019766860350500792, grad_norm: 7.688068566151396e-05, ic: 0.027078661953738772
train 54, step: 500, loss: 0.00014270603423938155, grad_norm: 1.8541817747413967e-05, ic: -0.06491211860640579
Epoch 54: 2022-05-06 18:52:50.730818: train loss: 0.00020926209398406653
Eval step 0: eval loss: 0.00012531550601124763
Eval: 2022-05-06 18:53:06.439490: total loss: 0.00019248708859304634, mse:0.00038497417294557556, ic :-0.0011512250270749014, sharpe5:-0.5983191191777587, irr5:-0.12958663702011108, ndcg5:0.8541110614355653, pnl5:0.9880355000495911 
train 55, step: 0, loss: 8.462488767690957e-05, grad_norm: 3.1057610277458546e-06, ic: -0.023363564020491525
train 55, step: 500, loss: 0.00029997577075846493, grad_norm: 2.411417429983823e-05, ic: -0.022962729974636074
Epoch 55: 2022-05-06 18:55:07.464603: train loss: 0.00020863497796194363
Eval step 0: eval loss: 0.00014422234380617738
Eval: 2022-05-06 18:55:23.204882: total loss: 0.00018880095257368915, mse:0.0003776019012244378, ic :0.0035177138838905202, sharpe5:-1.1952227787673473, irr5:-0.2589965760707855, ndcg5:0.858703885643065, pnl5:0.9522016644477844 
train 56, step: 0, loss: 0.00022586906561627984, grad_norm: 0.00011252923842905466, ic: -0.007637613316646763
train 56, step: 500, loss: 0.00021447669132612646, grad_norm: 8.19381828048587e-05, ic: -0.011867878934547505
Epoch 56: 2022-05-06 18:57:26.921873: train loss: 0.00020933253987377758
Eval step 0: eval loss: 0.00014706567162647843
Eval: 2022-05-06 18:57:43.417510: total loss: 0.0001890414279611582, mse:0.00037808285287392135, ic :0.0026786752602394573, sharpe5:0.7477982613444328, irr5:0.12324236333370209, ndcg5:0.8493260703444296, pnl5:1.1399672031402588 
train 57, step: 0, loss: 0.00012796874216292053, grad_norm: 3.3552595300004766e-05, ic: -0.005891695489697955
train 57, step: 500, loss: 0.00037766044260933995, grad_norm: 2.4877478838382908e-05, ic: -0.045979564976360535
Epoch 57: 2022-05-06 18:59:45.179933: train loss: 0.00020837846943108803
Eval step 0: eval loss: 0.00013630365720018744
Eval: 2022-05-06 19:00:01.395978: total loss: 0.00018892640873355645, mse:0.0003778528121659024, ic :0.03217328449305674, sharpe5:1.8364193507283926, irr5:0.36005815863609314, ndcg5:0.8535205721655071, pnl5:1.2713565826416016 
train 58, step: 0, loss: 0.0001812733244150877, grad_norm: 0.0001488538748164627, ic: 0.03618745573724439
train 58, step: 500, loss: 0.00010145795386051759, grad_norm: 2.5788150988305185e-06, ic: 0.0017121031921568742
Epoch 58: 2022-05-06 19:02:02.147061: train loss: 0.0002091082730370992
Eval step 0: eval loss: 0.00016053553554229438
Eval: 2022-05-06 19:02:18.366402: total loss: 0.0001915590100152536, mse:0.0003831180156103212, ic :-0.005325563715208653, sharpe5:1.0968118601292371, irr5:0.14906607568264008, ndcg5:0.8551622504633845, pnl5:0.9354080557823181 
train 59, step: 0, loss: 0.00015329921734519303, grad_norm: 2.0193853477802298e-05, ic: -0.004273680773367926
train 59, step: 500, loss: 0.00010023540380643681, grad_norm: 1.6072275891027223e-06, ic: -0.010984604318908315
Epoch 59: 2022-05-06 19:04:20.399344: train loss: 0.00020752120809462251
Eval step 0: eval loss: 0.0001860256161307916
Eval: 2022-05-06 19:04:36.410890: total loss: 0.00020018989918880596, mse:0.00040037979219886523, ic :0.0037851757011075175, sharpe5:-1.0680829138308763, irr5:-0.22743797302246094, ndcg5:0.8458378109097743, pnl5:0.9234813451766968 

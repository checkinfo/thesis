Namespace(adj_path='./data/graphs/NASDAQ_1026_1026.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='NASDAQAdjSeqTimeDataset', dout=0.3, epochs=40, glstm_layers=1, gnn_layers=1, gpu=0, graph_attn=False, hidden_dim=128, inner_prod=False, input_dim=5, input_graph=True, label_cnt=1, lr=0.0004, lstm_layers=1, market='NASDAQ', mask_adj=True, mask_type='soft', model_type='RGCNModel', normalize_adj=True, num_days=1, num_heads=1, print_inteval=100, rank_loss=False, relation_num=1, rsr_data_path='../Temporal_Relational_Stock_Ranking/data/2013-01-01', seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_250_0.8/', stock_num=1931, test_mask_path='./data/NASDAQ/test_mask_237_1026.npy', test_path='./data/NASDAQ/test_237_1026_6.npy', top_stocks=5, train_mask_path='./data/NASDAQ/train_mask_756_1026.npy', train_path='./data/NASDAQ/train_756_1026_6.npy', use_adj=True)
#tickers selected: 1026
single EOD data shape: (1245, 6)
(1026, 1245, 5) (1026, 1245) (1026, 1245) (1026, 1245)
#tickers selected: 1026
single EOD data shape: (1245, 6)
(1026, 1245, 5) (1026, 1245) (1026, 1245) (1026, 1245)
1920
RGCNModel(
  (fc1): Linear(in_features=5, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
  (fc4): Linear(in_features=128, out_features=1, bias=True)
  (gnns): ModuleList(
    (0): RGCN(
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
      (lin_gate): Linear(in_features=128, out_features=128, bias=True)
    )
  )
  (dropout): Dropout(p=0.3, inplace=False)
  (relu): LeakyReLU(negative_slope=0.01)
)
train 0, step: 0, loss: 0.0005354418535716832, grad_norm: 0.0011547131729507808, ic: 0.012305040422869236
train 0, step: 100, loss: 0.000162688666023314, grad_norm: 0.0001297395269881414, ic: 0.04014443260368569
train 0, step: 200, loss: 0.00013382843462750316, grad_norm: 3.898422693863584e-05, ic: -0.1472797419465653
train 0, step: 300, loss: 0.00016847249935381114, grad_norm: 8.137838861652017e-06, ic: -0.018549161137548037
train 0, step: 400, loss: 0.00014709557581227273, grad_norm: 2.3882079610168473e-05, ic: 0.006670302048269086
train 0, step: 500, loss: 0.0005836472264491022, grad_norm: 2.1530187983504026e-05, ic: -0.01176789474365503
train 0, step: 600, loss: 0.00017163209849968553, grad_norm: 1.859391468022316e-07, ic: 0.0403737938802488
train 0, step: 700, loss: 0.00010523490345804021, grad_norm: 2.0607332742499626e-06, ic: -0.06631078190231895
Epoch 0: 2022-05-06 15:58:25.940974: train loss: 0.00022060084480496234
Eval step 0: eval loss: 0.00023657295969314873
Eval step 100: eval loss: 0.00016870818217284977
Eval step 200: eval loss: 0.0001044786986312829
Eval: 2022-05-06 15:58:28.865316: total loss: 0.0001932645169845427, mse:0.00038652902903298135, ic :0.027090429613209385, sharpe5:0.6754330524802208, irr5:0.21674536168575287, ndcg5:0.8544211952476747, pnl5:1.1541638374328613 
train 1, step: 0, loss: 0.00020285852951928973, grad_norm: 1.972027703465306e-06, ic: 0.07783904072169956
train 1, step: 100, loss: 0.0004364078340586275, grad_norm: 0.00046730669851950457, ic: -0.017150059243259796
train 1, step: 200, loss: 0.00022885746147949249, grad_norm: 3.0504613101544978e-05, ic: 0.03391555874572992
train 1, step: 300, loss: 0.00010327641211915761, grad_norm: 7.989162303267228e-07, ic: 0.09074841582476982
train 1, step: 400, loss: 9.849039633991197e-05, grad_norm: 2.3300599110910627e-06, ic: -0.09993356385758723
train 1, step: 500, loss: 0.0004536189080681652, grad_norm: 0.00015668104660452402, ic: -0.09358733667965927
train 1, step: 600, loss: 0.00022729311604052782, grad_norm: 0.00024266311435808735, ic: 0.15109191047852108
train 1, step: 700, loss: 0.00011816904589068145, grad_norm: 7.110173827951934e-05, ic: 0.07138141377438413
Epoch 1: 2022-05-06 15:58:35.917878: train loss: 0.00021092221329747297
Eval step 0: eval loss: 0.00013013389252591878
Eval step 100: eval loss: 0.0002581574080977589
Eval step 200: eval loss: 0.0001452854776289314
Eval: 2022-05-06 15:58:38.900434: total loss: 0.000220106633220231, mse:0.00044021326999511075, ic :0.019752117159981812, sharpe5:-0.4143195414170623, irr5:-0.09048023819923401, ndcg5:0.8564560059125387, pnl5:1.0298876762390137 
train 2, step: 0, loss: 0.0002627084031701088, grad_norm: 0.00020217206123932405, ic: 0.23757975736366027
train 2, step: 100, loss: 0.00030107537168078125, grad_norm: 0.0001467650691733827, ic: 0.0002949579937902517
train 2, step: 200, loss: 0.00023080497339833528, grad_norm: 0.00014675902805926723, ic: 0.06939210213177106
train 2, step: 300, loss: 0.00015469559002667665, grad_norm: 6.806744570287699e-05, ic: 0.061715414440324065
train 2, step: 400, loss: 0.0001903945521917194, grad_norm: 4.422565865514526e-05, ic: 0.05957281780895638
train 2, step: 500, loss: 0.0001543244579806924, grad_norm: 5.06499702760847e-05, ic: 0.07550826001310953
train 2, step: 600, loss: 0.00032595015363767743, grad_norm: 0.00029923098988568047, ic: 0.017947343994809913
train 2, step: 700, loss: 0.00021879283303860575, grad_norm: 9.273181351588704e-05, ic: 0.09664048086136057
Epoch 2: 2022-05-06 15:58:46.043339: train loss: 0.00021084437101681576
Eval step 0: eval loss: 0.0001994441990973428
Eval step 100: eval loss: 0.0001791559043340385
Eval step 200: eval loss: 0.00010291440412402153
Eval: 2022-05-06 15:58:49.044004: total loss: 0.0001885838896900384, mse:0.00037716777459052077, ic :0.023520839135668214, sharpe5:-0.9573539732024073, irr5:-0.2451896071434021, ndcg5:0.8500601959268437, pnl5:0.9255438446998596 
train 3, step: 0, loss: 0.00012509214866440743, grad_norm: 1.2428811339496549e-06, ic: -0.0341186151310544
train 3, step: 100, loss: 0.00012112849071854725, grad_norm: 2.4841067760563875e-05, ic: 0.04420665807229796
train 3, step: 200, loss: 0.00021095860574860126, grad_norm: 6.904832960903754e-05, ic: -0.12731275993284483
train 3, step: 300, loss: 0.0001666463795118034, grad_norm: 1.7453085859754975e-05, ic: -0.001415089672469348
train 3, step: 400, loss: 0.0003939830930903554, grad_norm: 0.00042965866517749053, ic: 0.11626819761555765
train 3, step: 500, loss: 0.0001182864434667863, grad_norm: 7.921237458321406e-05, ic: 0.005700043040916069
train 3, step: 600, loss: 0.0001717199629638344, grad_norm: 8.938447763762606e-05, ic: 0.015445286320072265
train 3, step: 700, loss: 0.00013875197328161448, grad_norm: 7.579336526032683e-06, ic: 0.051575611823623926
Epoch 3: 2022-05-06 15:58:56.378466: train loss: 0.00021067350107902008
Eval step 0: eval loss: 0.00026688704383559525
Eval step 100: eval loss: 0.00016352359671145678
Eval step 200: eval loss: 0.00010739378922153264
Eval: 2022-05-06 15:58:59.350593: total loss: 0.00019925554735922467, mse:0.000398511093714782, ic :0.022885397563857043, sharpe5:0.24042885004542766, irr5:0.07157491147518158, ndcg5:0.853201505281098, pnl5:1.25359308719635 
train 4, step: 0, loss: 0.0003709314332809299, grad_norm: 0.00037157169909273776, ic: 0.1172903285419275
train 4, step: 100, loss: 0.00030541676096618176, grad_norm: 0.00030789862262921167, ic: -0.15827912067419175
train 4, step: 200, loss: 0.0001627686433494091, grad_norm: 1.4947531691012377e-06, ic: 0.061176415478335855
train 4, step: 300, loss: 0.00026886220439337194, grad_norm: 0.00022979520824493524, ic: 0.09022144337381843
train 4, step: 400, loss: 0.0001389826211379841, grad_norm: 2.4565994766693406e-05, ic: 0.07516192560291617
train 4, step: 500, loss: 0.0004725503968074918, grad_norm: 0.00048427650297098, ic: 0.03860298038258938
train 4, step: 600, loss: 0.00014389933494385332, grad_norm: 0.00010038487857389816, ic: -0.11572193511472513
train 4, step: 700, loss: 0.00011586406617425382, grad_norm: 1.0918109506568304e-06, ic: 0.031903765205331454
Epoch 4: 2022-05-06 15:59:06.602231: train loss: 0.00020983921242426827
Eval step 0: eval loss: 0.00023396399046760052
Eval step 100: eval loss: 0.00016821463941596448
Eval step 200: eval loss: 0.00010285516327712685
Eval: 2022-05-06 15:59:09.667092: total loss: 0.00019195725218520176, mse:0.0003839145018609731, ic :0.021998569849882348, sharpe5:1.1050068875402212, irr5:0.37215012311935425, ndcg5:0.8547779580973982, pnl5:1.2164798974990845 
train 5, step: 0, loss: 0.00012651272118091583, grad_norm: 7.022264525314918e-05, ic: 0.08644331168688116
train 5, step: 100, loss: 0.00040433398680761456, grad_norm: 0.00015201990731122952, ic: 0.09520244606521622
train 5, step: 200, loss: 0.0001649781479500234, grad_norm: 5.2207518395255796e-05, ic: 0.02796760518756242
train 5, step: 300, loss: 0.00013779815344605595, grad_norm: 1.0431072124959444e-05, ic: 0.03575921372023992
train 5, step: 400, loss: 0.0002093689690809697, grad_norm: 1.5836312064446033e-05, ic: 0.06821365093984506
train 5, step: 500, loss: 0.00010841729817911983, grad_norm: 1.250158479090714e-06, ic: 0.1354431242330421
train 5, step: 600, loss: 0.0003293100162409246, grad_norm: 0.0003791338423767464, ic: 0.053041707043481816
train 5, step: 700, loss: 0.0001672918297117576, grad_norm: 0.000129577987339946, ic: -0.02585818845096987
Epoch 5: 2022-05-06 15:59:16.662076: train loss: 0.0002092984769341462
Eval step 0: eval loss: 0.00021574393031187356
Eval step 100: eval loss: 0.0001731599768390879
Eval step 200: eval loss: 0.0001020454874378629
Eval: 2022-05-06 15:59:19.741362: total loss: 0.0001894515225704724, mse:0.0003789030459499153, ic :0.022439387572795327, sharpe5:0.7147744575887918, irr5:0.19560806453227997, ndcg5:0.845917061757385, pnl5:1.1668084859848022 
train 6, step: 0, loss: 0.00019378375145606697, grad_norm: 1.873258364896538e-05, ic: 0.10008855923986856
train 6, step: 100, loss: 0.00016639340901747346, grad_norm: 2.763117352199349e-08, ic: 0.06452262283395566
train 6, step: 200, loss: 0.00020908658916596323, grad_norm: 0.00012606371370784832, ic: 0.030956666522509668
train 6, step: 300, loss: 0.00017244814080186188, grad_norm: 4.43328119449774e-05, ic: 0.18624426382798603
train 6, step: 400, loss: 0.00026978470850735903, grad_norm: 0.00022880158961686604, ic: 0.016618169507483634
train 6, step: 500, loss: 0.0002206104400102049, grad_norm: 5.8232457149150336e-05, ic: -0.030051070660456772
train 6, step: 600, loss: 0.00027384355780668557, grad_norm: 0.00022747870451751673, ic: 0.02297734226352078
train 6, step: 700, loss: 0.00015837991668377072, grad_norm: 0.00012982282563778175, ic: 0.02210834200140168
Epoch 6: 2022-05-06 15:59:26.869058: train loss: 0.00020951441444733352
Eval step 0: eval loss: 0.0001959003711817786
Eval step 100: eval loss: 0.0001811487745726481
Eval step 200: eval loss: 0.00010327262862119824
Eval: 2022-05-06 15:59:29.940230: total loss: 0.0001885582444983657, mse:0.0003771164860426585, ic :0.02799886963459808, sharpe5:-0.6289243091270327, irr5:-0.14337080717086792, ndcg5:0.848651597193944, pnl5:0.9910228252410889 
train 7, step: 0, loss: 0.0004250408383086324, grad_norm: 0.0005035609510730044, ic: -0.048889583128371564
train 7, step: 100, loss: 0.0001327444624621421, grad_norm: 2.160847538284928e-06, ic: 0.01003080931988505
train 7, step: 200, loss: 0.0001857867173384875, grad_norm: 5.4750478879414715e-05, ic: 0.05654857665702697
train 7, step: 300, loss: 0.00028054587892256677, grad_norm: 4.081597668902005e-05, ic: 0.0793396023675372
train 7, step: 400, loss: 0.0001971522142412141, grad_norm: 0.00012045076443434226, ic: 0.08568934197276801
train 7, step: 500, loss: 0.00015873336815275252, grad_norm: 0.0001188386296366363, ic: 0.11687901986261956
train 7, step: 600, loss: 0.00023866559786256403, grad_norm: 0.00011597889974946574, ic: 0.05972622759659784
train 7, step: 700, loss: 0.0001715725229587406, grad_norm: 3.757884806676556e-05, ic: 0.12665324078664913
Epoch 7: 2022-05-06 15:59:37.178406: train loss: 0.00020947874277376798
Eval step 0: eval loss: 0.00018830136104952544
Eval step 100: eval loss: 0.00018538328004069626
Eval step 200: eval loss: 0.00010456005111336708
Eval: 2022-05-06 15:59:40.201182: total loss: 0.00018894984156250466, mse:0.00037789967732850633, ic :0.019126397880713793, sharpe5:-0.9815266318246721, irr5:-0.22012054920196533, ndcg5:0.846593656456005, pnl5:0.9144942164421082 
train 8, step: 0, loss: 0.00035879152710549533, grad_norm: 0.0003649927035382314, ic: 0.02882159201779507
train 8, step: 100, loss: 0.0002130200737155974, grad_norm: 6.307962075396541e-05, ic: -0.07088748853765059
train 8, step: 200, loss: 0.0005546711618080735, grad_norm: 0.0007158043839870753, ic: -0.010463965883947102
train 8, step: 300, loss: 0.00023311760742217302, grad_norm: 6.43610012831828e-06, ic: 0.03219235821362972
train 8, step: 400, loss: 0.00012746297579724342, grad_norm: 3.947543892738688e-06, ic: 0.05636434437051392
train 8, step: 500, loss: 0.0001245226158061996, grad_norm: 2.0030302962396624e-06, ic: -0.03196300203965926
train 8, step: 600, loss: 0.0006112385890446603, grad_norm: 0.00010618758301136329, ic: 0.09398672415322373
train 8, step: 700, loss: 0.00012793608766514808, grad_norm: 7.433465042277663e-05, ic: -0.0674411204274426
Epoch 8: 2022-05-06 15:59:47.182032: train loss: 0.000209514653330032
Eval step 0: eval loss: 0.00018179765902459621
Eval step 100: eval loss: 0.00018922628078144044
Eval step 200: eval loss: 0.00010586463031359017
Eval: 2022-05-06 15:59:50.083675: total loss: 0.00018951135902849057, mse:0.00037902271316817086, ic :0.020499871551624606, sharpe5:-1.1424433165043593, irr5:-0.24286440014839172, ndcg5:0.857601334866314, pnl5:0.9011452198028564 
train 9, step: 0, loss: 0.0002440731186652556, grad_norm: 3.1347945063569635e-05, ic: 0.05610704153579066
train 9, step: 100, loss: 0.00011701495532179251, grad_norm: 1.831001288689138e-08, ic: -0.0648594356363025
train 9, step: 200, loss: 0.00012780047836713493, grad_norm: 4.127121583644057e-07, ic: 0.034458549393852525
train 9, step: 300, loss: 0.0005060387193225324, grad_norm: 0.0006440464856392661, ic: -0.06917913954506151
train 9, step: 400, loss: 0.0008732418064028025, grad_norm: 0.0010501878634546738, ic: -0.0880486186198495
train 9, step: 500, loss: 0.00012727113789878786, grad_norm: 7.524545522735164e-06, ic: -0.055503825420757935
train 9, step: 600, loss: 0.00019956626056227833, grad_norm: 2.0136641010052736e-06, ic: -0.019238476468267082
train 9, step: 700, loss: 0.0001746665220707655, grad_norm: 2.06646313052916e-05, ic: 0.01906434567161727
Epoch 9: 2022-05-06 15:59:57.466736: train loss: 0.00020869522551514072
Eval step 0: eval loss: 0.00018934396211989224
Eval step 100: eval loss: 0.00018455478129908442
Eval step 200: eval loss: 0.00010419909813208506
Eval: 2022-05-06 16:00:00.512567: total loss: 0.00018874783912043174, mse:0.00037749567707959117, ic :0.024494240418259688, sharpe5:-0.7942533825337886, irr5:-0.18210208415985107, ndcg5:0.8458620121634595, pnl5:0.9454917311668396 
train 10, step: 0, loss: 0.00020434211182873696, grad_norm: 1.2763819904996106e-05, ic: 0.08920732584890928
train 10, step: 100, loss: 0.00016351087833754718, grad_norm: 5.146866894318398e-05, ic: 0.08250809201697668
train 10, step: 200, loss: 0.00019028925453312695, grad_norm: 0.00012960574345398916, ic: 0.09818141405880809
train 10, step: 300, loss: 0.00012767926091328263, grad_norm: 3.0257716290993812e-05, ic: -0.1146481547315156
train 10, step: 400, loss: 0.0002008652954827994, grad_norm: 2.6116951046523254e-05, ic: 0.10300336123488493
train 10, step: 500, loss: 0.00014337585889734328, grad_norm: 2.395959694241083e-09, ic: -0.04680672231180316
train 10, step: 600, loss: 0.00020514483912847936, grad_norm: 4.310159461491848e-06, ic: 0.04303490306385154
train 10, step: 700, loss: 0.00018632531282491982, grad_norm: 1.2318859505267477e-05, ic: -0.0016050376612217233
Epoch 10: 2022-05-06 16:00:07.594279: train loss: 0.0002092928367563591
Eval step 0: eval loss: 0.0001906112884171307
Eval step 100: eval loss: 0.0001836555456975475
Eval step 200: eval loss: 0.00010386641224613413
Eval: 2022-05-06 16:00:10.660865: total loss: 0.0001886134752752141, mse:0.0003772269459130184, ic :0.034289729419099295, sharpe5:1.4051627138257026, irr5:0.4828113317489624, ndcg5:0.8583681077503215, pnl5:1.2641232013702393 
train 11, step: 0, loss: 0.00039314047899097204, grad_norm: 1.6231426857492608e-05, ic: 0.08542461801566316
train 11, step: 100, loss: 0.00016002023767214268, grad_norm: 0.00011133483859924894, ic: 0.01429116969554366
train 11, step: 200, loss: 0.00012709457951132208, grad_norm: 1.1487090388876766e-05, ic: 0.13975285090469303
train 11, step: 300, loss: 0.0001058411507983692, grad_norm: 1.225174294534726e-07, ic: 0.0640702542658196
train 11, step: 400, loss: 0.00016542237426619977, grad_norm: 1.4123295176927983e-05, ic: -0.06606537369764527
train 11, step: 500, loss: 8.347365655936301e-05, grad_norm: 3.4164973932192036e-05, ic: 0.034957876467769995
train 11, step: 600, loss: 0.00027710621361620724, grad_norm: 8.038504242794502e-05, ic: 0.01006644378424931
train 11, step: 700, loss: 0.00025084326625801623, grad_norm: 8.516420016287881e-06, ic: 0.010783957182876397
Epoch 11: 2022-05-06 16:00:17.514199: train loss: 0.0002081702299499329
Eval step 0: eval loss: 0.00019059803162235767
Eval step 100: eval loss: 0.0001839323522290215
Eval step 200: eval loss: 0.0001039891576510854
Eval: 2022-05-06 16:00:20.402873: total loss: 0.00018867581675911392, mse:0.00037735162864657257, ic :0.030549658299641853, sharpe5:0.6821145987510681, irr5:0.2205662727355957, ndcg5:0.8442370823255066, pnl5:1.1482279300689697 
train 12, step: 0, loss: 0.0004411067347973585, grad_norm: 0.0005537952516744751, ic: 0.03567217397117969
train 12, step: 100, loss: 0.00015424672164954245, grad_norm: 1.1068909838617993e-07, ic: 0.163367165489316
train 12, step: 200, loss: 0.00025743833975866437, grad_norm: 2.6938254961637854e-06, ic: 0.07926308758840406
train 12, step: 300, loss: 0.00017124111764132977, grad_norm: 2.576340971515819e-06, ic: 0.050636111465750505
train 12, step: 400, loss: 0.00048107601469382644, grad_norm: 0.0006675020569932743, ic: -0.10375742985790316
train 12, step: 500, loss: 0.00020423339447006583, grad_norm: 3.4296412293581334e-05, ic: 0.09391337445989999
train 12, step: 600, loss: 0.00024125482013914734, grad_norm: 1.613026728479492e-05, ic: 0.054164321580076294
train 12, step: 700, loss: 0.00012751435860991478, grad_norm: 2.2676012355390705e-05, ic: -0.04313227709602181
Epoch 12: 2022-05-06 16:00:27.424817: train loss: 0.00020849781036870368
Eval step 0: eval loss: 0.00021182709315326065
Eval step 100: eval loss: 0.0001743136963341385
Eval step 200: eval loss: 0.00010210726031800732
Eval: 2022-05-06 16:00:30.307135: total loss: 0.00018909182333534433, mse:0.0003781836449335664, ic :0.022289738324806827, sharpe5:0.3620988552086055, irr5:0.11101385951042175, ndcg5:0.8460126883920016, pnl5:1.1449451446533203 
train 13, step: 0, loss: 0.0002454219793435186, grad_norm: 5.5523008693161984e-08, ic: 0.09513708326468624
train 13, step: 100, loss: 8.10605997685343e-05, grad_norm: 2.1351868816844683e-05, ic: -0.07662750658300477
train 13, step: 200, loss: 0.00021105205814819783, grad_norm: 1.7478176333119406e-05, ic: 0.08608738936610452
train 13, step: 300, loss: 0.0003681380476336926, grad_norm: 0.00016632586527591832, ic: 0.1703648536967277
train 13, step: 400, loss: 0.00012322138354647905, grad_norm: 6.055192336034388e-06, ic: 0.04404258569222594
train 13, step: 500, loss: 7.690343772992492e-05, grad_norm: 1.0165895890497306e-05, ic: -0.1647860980918987
train 13, step: 600, loss: 0.00041032477747648954, grad_norm: 0.00043491513375221104, ic: 0.14143049389073364
train 13, step: 700, loss: 0.00042127881897613406, grad_norm: 4.805725593274254e-05, ic: -0.0412594529846845
Epoch 13: 2022-05-06 16:00:37.538050: train loss: 0.0002076587501072189
Eval step 0: eval loss: 0.00022599479416385293
Eval step 100: eval loss: 0.00017000830848701298
Eval step 200: eval loss: 0.00010249995830236003
Eval: 2022-05-06 16:00:40.606613: total loss: 0.00019074620717743774, mse:0.00038149240890602204, ic :0.029631179855360845, sharpe5:-0.4673328542523086, irr5:-0.10993751138448715, ndcg5:0.8502917542093102, pnl5:0.984528660774231 
train 14, step: 0, loss: 8.061966946115717e-05, grad_norm: 1.4320592314919399e-05, ic: 0.050726857673683526
train 14, step: 100, loss: 0.0001514124305685982, grad_norm: 5.1305760435147655e-05, ic: 0.10533702123995643
train 14, step: 200, loss: 0.0001412147394148633, grad_norm: 6.735517255587133e-07, ic: 0.045023827054026695
train 14, step: 300, loss: 0.00017359953199047595, grad_norm: 1.9308745006042716e-05, ic: -0.009804583241342172
train 14, step: 400, loss: 0.00043271557660773396, grad_norm: 0.0005549799592846242, ic: -0.08447028924873241
train 14, step: 500, loss: 0.00013200551620684564, grad_norm: 3.874488523446349e-05, ic: -0.05064972643134193
train 14, step: 600, loss: 0.00015257130144163966, grad_norm: 1.1217833558677228e-05, ic: 0.14668469945176787
train 14, step: 700, loss: 0.0002655956777743995, grad_norm: 0.0001814042074565841, ic: -0.09671133695015419
Epoch 14: 2022-05-06 16:00:47.732028: train loss: 0.00020737507781349215
Eval step 0: eval loss: 0.00017663792823441327
Eval step 100: eval loss: 0.0001926209806697443
Eval step 200: eval loss: 0.00010705784370657057
Eval: 2022-05-06 16:00:50.738557: total loss: 0.00019014181156832156, mse:0.00038028362048158536, ic :0.028470699543601683, sharpe5:0.6710024546831846, irr5:0.22087416052818298, ndcg5:0.8467136208375647, pnl5:1.1684924364089966 
train 15, step: 0, loss: 0.0002710713888518512, grad_norm: 0.00010957037715845073, ic: -0.0012667664062036392
train 15, step: 100, loss: 0.00022981266374699771, grad_norm: 9.48453866299208e-05, ic: 0.09780208657573969
train 15, step: 200, loss: 0.0003132699057459831, grad_norm: 8.264097226125255e-05, ic: 0.11253352849721479
train 15, step: 300, loss: 8.65784750203602e-05, grad_norm: 1.9263091794217618e-05, ic: 0.01952141830501858
train 15, step: 400, loss: 0.0002605887711979449, grad_norm: 7.93206857058513e-05, ic: 0.09233070721271747
train 15, step: 500, loss: 0.00012873178638983518, grad_norm: 1.3587295040876856e-07, ic: 0.17916517069054466
train 15, step: 600, loss: 8.860691013978794e-05, grad_norm: 2.4547757115814136e-09, ic: 0.027799743588878444
train 15, step: 700, loss: 0.0001422992063453421, grad_norm: 2.84867503500733e-05, ic: -0.017286950999896796
Epoch 15: 2022-05-06 16:00:57.993407: train loss: 0.00020840593922743727
Eval step 0: eval loss: 0.0002383104438195005
Eval step 100: eval loss: 0.00016791732923593372
Eval step 200: eval loss: 0.0001040825663949363
Eval: 2022-05-06 16:01:01.068107: total loss: 0.0001929912049166949, mse:0.00038598240595465064, ic :0.039280856587646386, sharpe5:0.5430445413663983, irr5:0.15392303466796875, ndcg5:0.8587528197183529, pnl5:1.2134428024291992 
train 16, step: 0, loss: 0.00015205978706944734, grad_norm: 2.327652401379159e-06, ic: 0.0566659251238699
train 16, step: 100, loss: 0.00020332470012363046, grad_norm: 0.00021807471072196155, ic: 0.005997085330127112
train 16, step: 200, loss: 0.0001373289996990934, grad_norm: 8.285817324010525e-06, ic: -0.023668646353110695
train 16, step: 300, loss: 0.00017640466103330255, grad_norm: 2.5429995635967257e-05, ic: 0.0005808492123369532
train 16, step: 400, loss: 0.0004456432652659714, grad_norm: 0.0004814126533136631, ic: -0.08277795625429293
train 16, step: 500, loss: 0.00017497048247605562, grad_norm: 1.6774111039204713e-05, ic: 0.08319734305394309
train 16, step: 600, loss: 0.00024228249094448984, grad_norm: 0.00013265250942863467, ic: 0.1248092988940491
train 16, step: 700, loss: 0.00010136168566532433, grad_norm: 3.3718747968827923e-09, ic: -0.021629633696992296
Epoch 16: 2022-05-06 16:01:08.249168: train loss: 0.00020751951234214723
Eval step 0: eval loss: 0.00015138126036617905
Eval step 100: eval loss: 0.00021767494035884738
Eval step 200: eval loss: 0.00012013455852866173
Eval: 2022-05-06 16:01:11.296440: total loss: 0.00019921241381765003, mse:0.0003984248266136797, ic :0.018959706739827144, sharpe5:-0.35048962717875837, irr5:-0.07908463478088379, ndcg5:0.8626285072178458, pnl5:1.0227022171020508 
train 17, step: 0, loss: 0.00022988376440480351, grad_norm: 0.00013575288442481916, ic: 0.08907506082969172
train 17, step: 100, loss: 8.66253103595227e-05, grad_norm: 1.1900164691819857e-07, ic: 0.043046011398074666
train 17, step: 200, loss: 0.0001957233325811103, grad_norm: 7.730463510189176e-05, ic: 0.06828833489803529
train 17, step: 300, loss: 0.00010247355385217816, grad_norm: 2.3605747710161525e-06, ic: 0.04223864297278627
train 17, step: 400, loss: 0.0002809102297760546, grad_norm: 0.00028251039731124063, ic: -0.09964854907781777
train 17, step: 500, loss: 0.00022826905478723347, grad_norm: 5.309948738869726e-05, ic: 0.054901286600838026
train 17, step: 600, loss: 0.0001341179304290563, grad_norm: 6.644444913013823e-06, ic: 0.08608963976709558
train 17, step: 700, loss: 0.00017722320626489818, grad_norm: 0.0001061920261262068, ic: 0.12117686006716043
Epoch 17: 2022-05-06 16:01:18.469003: train loss: 0.00020793928118212153
Eval step 0: eval loss: 0.0001807239168556407
Eval step 100: eval loss: 0.00018999098392669111
Eval step 200: eval loss: 0.00010631444456521422
Eval: 2022-05-06 16:01:21.643840: total loss: 0.0001896935554815188, mse:0.0003793871067944327, ic :0.024495750041358382, sharpe5:0.04255338824121281, irr5:0.01050661876797676, ndcg5:0.8575787888212223, pnl5:1.060187816619873 
train 18, step: 0, loss: 0.0001544613332953304, grad_norm: 7.469323106612867e-06, ic: 0.07109842159348227
train 18, step: 100, loss: 0.00014176666445564479, grad_norm: 3.359770427743353e-05, ic: -0.045819949990050735
train 18, step: 200, loss: 0.00017212318198289722, grad_norm: 5.041174544189141e-05, ic: -0.06585844313835226
train 18, step: 300, loss: 0.00017643268802203238, grad_norm: 9.992380825863737e-05, ic: 0.11074876699215563
train 18, step: 400, loss: 0.00024272360315080732, grad_norm: 0.0001297647875846518, ic: -0.02935667534974705
train 18, step: 500, loss: 0.00016025903460104018, grad_norm: 0.00011912974453466789, ic: 0.09994851156938594
train 18, step: 600, loss: 0.00015185063239187002, grad_norm: 2.409574512432612e-05, ic: 0.09536153804234608
train 18, step: 700, loss: 0.0002236813015770167, grad_norm: 0.0001957866336654836, ic: 0.12466380374838495
Epoch 18: 2022-05-06 16:01:28.798319: train loss: 0.00020736776626150783
Eval step 0: eval loss: 0.00016593688633292913
Eval step 100: eval loss: 0.00020132868667133152
Eval step 200: eval loss: 0.00011105406883871183
Eval: 2022-05-06 16:01:31.856270: total loss: 0.00019261773463690818, mse:0.0003852354662536614, ic :0.021200115453956534, sharpe5:-0.025386137205641715, irr5:-0.006310590542852879, ndcg5:0.850216728338005, pnl5:0.962329626083374 
train 19, step: 0, loss: 0.00018602656200528145, grad_norm: 0.00019511720557096162, ic: 0.01025828276097367
train 19, step: 100, loss: 0.0001656146632740274, grad_norm: 3.469975667305186e-05, ic: 0.04628256744172321
train 19, step: 200, loss: 0.00018721329979598522, grad_norm: 0.00017573973561128652, ic: -0.021708339047998425
train 19, step: 300, loss: 0.00014741066843271255, grad_norm: 6.254780290287329e-05, ic: 0.03599687251393105
train 19, step: 400, loss: 0.00023079419042915106, grad_norm: 0.00019996872479189368, ic: 0.15801372448098824
train 19, step: 500, loss: 0.00012134558346588165, grad_norm: 3.750917161708404e-06, ic: -0.006276771298686396
train 19, step: 600, loss: 0.00010391082469141111, grad_norm: 1.735526522473214e-06, ic: 0.06173543676162057
train 19, step: 700, loss: 0.0002708848915062845, grad_norm: 3.3279934869004595e-05, ic: -0.08300445334149088
Epoch 19: 2022-05-06 16:01:39.167342: train loss: 0.00020851986964590946
Eval step 0: eval loss: 0.00019744783639907837
Eval step 100: eval loss: 0.00018040179566014558
Eval step 200: eval loss: 0.0001030278654070571
Eval: 2022-05-06 16:01:42.167156: total loss: 0.00018850948411346831, mse:0.0003770189653844375, ic :0.029627984948193412, sharpe5:1.6036949030309915, irr5:0.5582374930381775, ndcg5:0.8459600220747543, pnl5:1.1982232332229614 
train 20, step: 0, loss: 0.0001642435963731259, grad_norm: 8.620320682320334e-07, ic: 0.025832010744845764
train 20, step: 100, loss: 0.00016766511544119567, grad_norm: 5.518336420971048e-05, ic: 0.03637229901891452
train 20, step: 200, loss: 0.0002604537585284561, grad_norm: 2.7740852362428738e-05, ic: 0.07621637874214773
train 20, step: 300, loss: 0.0002253151178592816, grad_norm: 9.456264622928356e-06, ic: 0.0121896329900478
train 20, step: 400, loss: 0.00010969851427944377, grad_norm: 2.9922090222325988e-05, ic: 0.027306145948161564
train 20, step: 500, loss: 0.0001798707526177168, grad_norm: 6.440692841997883e-08, ic: 0.07677517423244813
train 20, step: 600, loss: 0.00043653041939251125, grad_norm: 0.00044289710279559234, ic: 0.08138951010764284
train 20, step: 700, loss: 0.00017511763144284487, grad_norm: 1.7059618486625596e-05, ic: 0.0062108975094939955
Epoch 20: 2022-05-06 16:01:49.102242: train loss: 0.0002078510186411764
Eval step 0: eval loss: 0.00019592299940995872
Eval step 100: eval loss: 0.0001811554975574836
Eval step 200: eval loss: 0.00010323966125724837
Eval: 2022-05-06 16:01:52.126201: total loss: 0.00018850419091596466, mse:0.00037700837618737776, ic :0.02937489362336728, sharpe5:-0.4805310896784067, irr5:-0.11546573787927628, ndcg5:0.8507705582697836, pnl5:0.9992778301239014 
train 21, step: 0, loss: 0.0001662755385041237, grad_norm: 0.00010217224729867952, ic: 0.04930412593311462
train 21, step: 100, loss: 0.00020234132534824312, grad_norm: 4.900635394749796e-06, ic: 0.019752571994526874
train 21, step: 200, loss: 0.000358509918441996, grad_norm: 5.503325976896538e-05, ic: -0.04137586394538027
train 21, step: 300, loss: 0.0001473164011258632, grad_norm: 8.527880152236057e-05, ic: 0.009714823720174359
train 21, step: 400, loss: 0.00015132276166696101, grad_norm: 7.295570358888474e-05, ic: 0.1132361982466229
train 21, step: 500, loss: 0.0001563840196467936, grad_norm: 3.43699585228095e-05, ic: 0.19980822397823939
train 21, step: 600, loss: 0.0004568852309603244, grad_norm: 0.0003909680673523472, ic: -0.03663430697405911
train 21, step: 700, loss: 0.0008602167945355177, grad_norm: 0.0009442131212124427, ic: -0.10041751470577592
Epoch 21: 2022-05-06 16:01:59.146432: train loss: 0.0002081530760510729
Eval step 0: eval loss: 0.00020355138985905796
Eval step 100: eval loss: 0.00017773875151760876
Eval step 200: eval loss: 0.0001024448501993902
Eval: 2022-05-06 16:02:02.355198: total loss: 0.00018858883616966354, mse:0.0003771776652739007, ic :0.03178111747855012, sharpe5:0.9058701926842332, irr5:0.3104248642921448, ndcg5:0.8490622985859175, pnl5:1.1940264701843262 
train 22, step: 0, loss: 0.0002673408598639071, grad_norm: 0.00019038880534471856, ic: -0.14852784486332055
train 22, step: 100, loss: 0.00014170217036735266, grad_norm: 2.8837345166988543e-05, ic: -0.06250955453328254
train 22, step: 200, loss: 0.00019001115288119763, grad_norm: 1.8182746300608436e-05, ic: 0.10992859319878287
train 22, step: 300, loss: 0.000208813144126907, grad_norm: 1.1106086983211427e-05, ic: 0.05661879279162067
train 22, step: 400, loss: 0.0001671049976721406, grad_norm: 4.1035354635761135e-05, ic: 0.03827524110302541
train 22, step: 500, loss: 0.00013882643543183804, grad_norm: 9.085457895689918e-05, ic: 0.05957576507605198
train 22, step: 600, loss: 0.00012364804570097476, grad_norm: 2.5447413393701163e-05, ic: 0.053207703858498975
train 22, step: 700, loss: 9.988188685383648e-05, grad_norm: 2.907776155839351e-05, ic: -0.03575101028593519
Epoch 22: 2022-05-06 16:02:09.678321: train loss: 0.0002074505217987828
Eval step 0: eval loss: 0.00020030303858220577
Eval step 100: eval loss: 0.00017918815137818456
Eval step 200: eval loss: 0.00010267952166032046
Eval: 2022-05-06 16:02:12.769379: total loss: 0.00018848299734630834, mse:0.00037696599095514194, ic :0.03321861688814378, sharpe5:0.6603967355936765, irr5:0.21256615221500397, ndcg5:0.8531824567656665, pnl5:1.2068549394607544 
train 23, step: 0, loss: 0.00013321975711733103, grad_norm: 3.052999102401623e-05, ic: 0.0480325218691237
train 23, step: 100, loss: 0.00012296422210056335, grad_norm: 5.651884170179522e-05, ic: -0.08082727210488819
train 23, step: 200, loss: 0.0002807551936712116, grad_norm: 0.00016184943512758573, ic: 0.14160161209965677
train 23, step: 300, loss: 0.0005218480946496129, grad_norm: 0.0006948820026728739, ic: -0.03273992694143686
train 23, step: 400, loss: 0.0001285939069930464, grad_norm: 1.4697016654939472e-05, ic: 0.1406636973887982
train 23, step: 500, loss: 0.00012649610289372504, grad_norm: 2.665476373701378e-06, ic: -0.20146802839931727
train 23, step: 600, loss: 0.00022387297940440476, grad_norm: 8.69240198454846e-06, ic: 0.06274435329391936
train 23, step: 700, loss: 0.0002040655817836523, grad_norm: 0.0001644832790166451, ic: -0.0552375513325565
Epoch 23: 2022-05-06 16:02:19.845899: train loss: 0.00020759014809517258
Eval step 0: eval loss: 0.0002485799486748874
Eval step 100: eval loss: 0.00016595363558735698
Eval step 200: eval loss: 0.00010464755905559286
Eval: 2022-05-06 16:02:22.942143: total loss: 0.00019487528340304981, mse:0.0003897505667470483, ic :0.03399837439735821, sharpe5:1.547093309685588, irr5:0.5333579182624817, ndcg5:0.8502924983046111, pnl5:1.2699450254440308 
train 24, step: 0, loss: 0.00014342677604872733, grad_norm: 4.622284537912606e-06, ic: 0.03766924793535647
train 24, step: 100, loss: 0.00012123934720875695, grad_norm: 2.0255009371877133e-05, ic: 0.053546932718343786
train 24, step: 200, loss: 0.00012697078636847436, grad_norm: 6.1444291208209746e-06, ic: 0.07973005661761523
train 24, step: 300, loss: 0.00016307631449308246, grad_norm: 6.724194078524149e-05, ic: 0.033120271883635796
train 24, step: 400, loss: 0.000166079422342591, grad_norm: 5.515596507802723e-05, ic: 0.04428300667628522
train 24, step: 500, loss: 0.0001380958710797131, grad_norm: 1.0752744790849507e-07, ic: 0.1411091915538624
train 24, step: 600, loss: 0.00023568305186927319, grad_norm: 5.916889081667994e-06, ic: -0.0350005001810792
train 24, step: 700, loss: 0.00016635458450764418, grad_norm: 3.8067889712748233e-06, ic: 0.01130886722337305
Epoch 24: 2022-05-06 16:02:30.052801: train loss: 0.0002081162649095413
Eval step 0: eval loss: 0.0002183428587159142
Eval step 100: eval loss: 0.0001724396279314533
Eval step 200: eval loss: 0.00010205632861470804
Eval: 2022-05-06 16:02:33.127374: total loss: 0.00018970696655125753, mse:0.00037941392830123985, ic :0.029347772468587097, sharpe5:-0.676052219979465, irr5:-0.16217583417892456, ndcg5:0.8459185518185701, pnl5:1.0130233764648438 
train 25, step: 0, loss: 0.00010786446364363655, grad_norm: 9.721269254078617e-06, ic: 0.05486354709825848
train 25, step: 100, loss: 0.0001700162683846429, grad_norm: 1.3848381897731504e-05, ic: -0.05774819212176245
train 25, step: 200, loss: 0.00014406070113182068, grad_norm: 4.219851806193649e-05, ic: -0.06701188841328704
train 25, step: 300, loss: 0.00016252270143013448, grad_norm: 1.085647844064278e-05, ic: 0.01797731108836887
train 25, step: 400, loss: 0.00010475656017661095, grad_norm: 6.681472126161946e-09, ic: 0.033468511544777736
train 25, step: 500, loss: 0.00010407284571556374, grad_norm: 7.921826663195788e-06, ic: -0.040036916348258636
train 25, step: 600, loss: 0.0001357792061753571, grad_norm: 4.298512723291517e-08, ic: 0.0770754098615874
train 25, step: 700, loss: 9.179376502288505e-05, grad_norm: 7.592290215258589e-07, ic: 0.055028264235611794
Epoch 25: 2022-05-06 16:02:40.318552: train loss: 0.00020700465029703811
Eval step 0: eval loss: 0.00018710958829615265
Eval step 100: eval loss: 0.0001860314077930525
Eval step 200: eval loss: 0.00010446507076267153
Eval: 2022-05-06 16:02:43.405294: total loss: 0.0001888190082832283, mse:0.00037763801449084165, ic :0.029126877084468997, sharpe5:-0.4940433428809046, irr5:-0.11953016370534897, ndcg5:0.8485844496880848, pnl5:1.0300343036651611 
train 26, step: 0, loss: 0.0002335963654331863, grad_norm: 0.00022457236336734528, ic: -0.05306004246993582
train 26, step: 100, loss: 0.00020887509163003415, grad_norm: 9.347790752362241e-05, ic: 0.22562608764345543
train 26, step: 200, loss: 0.00034843728644773364, grad_norm: 0.0003496496294503146, ic: 0.011817440200069083
train 26, step: 300, loss: 0.00023654363758396357, grad_norm: 2.1788406458797212e-07, ic: 0.02832062582564621
train 26, step: 400, loss: 0.0003394410596229136, grad_norm: 9.985502584203604e-05, ic: -0.0005572012576340064
train 26, step: 500, loss: 0.00012823367433156818, grad_norm: 1.079448794681619e-05, ic: 0.001816552825813833
train 26, step: 600, loss: 0.0002191722596762702, grad_norm: 0.0001611680480746528, ic: -0.017378077491975757
train 26, step: 700, loss: 0.00023580892593599856, grad_norm: 0.00014116532058139596, ic: 0.06485810604743726
Epoch 26: 2022-05-06 16:02:50.394624: train loss: 0.000207223111093052
Eval step 0: eval loss: 0.0001880331983556971
Eval step 100: eval loss: 0.00018527313659433275
Eval step 200: eval loss: 0.00010423208732390776
Eval: 2022-05-06 16:02:53.394458: total loss: 0.00018872166870327636, mse:0.00037744333625867475, ic :0.03214479931138458, sharpe5:0.3629582878388464, irr5:0.10965996980667114, ndcg5:0.8566496867135248, pnl5:1.2062933444976807 
train 27, step: 0, loss: 0.0003820500860456377, grad_norm: 0.00010398472951801215, ic: 0.005234530593551872
train 27, step: 100, loss: 0.0004486863035708666, grad_norm: 0.000488535276623931, ic: 0.13465946480332092
train 27, step: 200, loss: 0.00013153588224668056, grad_norm: 6.564531366825203e-06, ic: -0.01659276644208467
train 27, step: 300, loss: 0.00011858375364681706, grad_norm: 5.975692312495733e-05, ic: 0.1257965068184695
train 27, step: 400, loss: 0.00020671263337135315, grad_norm: 0.00018318113657787082, ic: 0.065393464990576
train 27, step: 500, loss: 0.0001812005793908611, grad_norm: 2.434149951381029e-08, ic: -0.0031337110664151693
train 27, step: 600, loss: 0.00044613226782530546, grad_norm: 0.0005887386683123795, ic: -0.08207437851876967
train 27, step: 700, loss: 0.0003782559942919761, grad_norm: 7.694624904483237e-05, ic: -0.00203535052311969
Epoch 27: 2022-05-06 16:03:00.478035: train loss: 0.00020767581096055472
Eval step 0: eval loss: 0.0002397097268840298
Eval step 100: eval loss: 0.00016731098003219813
Eval step 200: eval loss: 0.00010348302021156996
Eval: 2022-05-06 16:03:03.649218: total loss: 0.000193103385970324, mse:0.00038620676845654205, ic :0.027532644275196003, sharpe5:-0.1512563887797296, irr5:-0.03739473223686218, ndcg5:0.843985764051045, pnl5:1.0595307350158691 
train 28, step: 0, loss: 9.470730583416298e-05, grad_norm: 3.4350628891660124e-05, ic: 0.033022769630918485
train 28, step: 100, loss: 0.00019090362184215337, grad_norm: 7.913555717276559e-05, ic: 0.15929827615372233
train 28, step: 200, loss: 0.00032747676596045494, grad_norm: 0.0001456018018650947, ic: 0.12284246856941491
train 28, step: 300, loss: 0.00019044072541873902, grad_norm: 6.179233086996544e-06, ic: 0.04392093617076441
train 28, step: 400, loss: 0.00022799345606472343, grad_norm: 1.4870537577328952e-06, ic: -0.090492956721575
train 28, step: 500, loss: 0.00013087129627820104, grad_norm: 6.750101520389153e-06, ic: 0.12836366177820813
train 28, step: 600, loss: 0.00011466519208624959, grad_norm: 2.9999547597022935e-05, ic: -0.01729172878757774
train 28, step: 700, loss: 0.00013369129737839103, grad_norm: 1.1394508331413428e-06, ic: 0.057353741036141645
Epoch 28: 2022-05-06 16:03:10.884523: train loss: 0.00020749320898922808
Eval step 0: eval loss: 0.0002502780989743769
Eval step 100: eval loss: 0.0001655030355323106
Eval step 200: eval loss: 0.00010476409806869924
Eval: 2022-05-06 16:03:13.819706: total loss: 0.00019525790911895948, mse:0.00039051581121801737, ic :0.031918372600043037, sharpe5:1.3393716886639595, irr5:0.46277379989624023, ndcg5:0.8567668770879816, pnl5:1.2415030002593994 
train 29, step: 0, loss: 0.00022276303207036108, grad_norm: 4.471428213682106e-05, ic: 0.0752840182928968
train 29, step: 100, loss: 0.0004249417397659272, grad_norm: 0.00032297612042652275, ic: 0.057688361408361484
train 29, step: 200, loss: 0.00012334492930676788, grad_norm: 4.091761018473819e-05, ic: -0.03655185264111214
train 29, step: 300, loss: 0.00021614108118228614, grad_norm: 2.697277791978542e-05, ic: 0.16760502273943306
train 29, step: 400, loss: 0.0001695171813480556, grad_norm: 1.103015692905691e-05, ic: 0.16683546482475414
train 29, step: 500, loss: 0.00012412328214850277, grad_norm: 1.1480681498240126e-05, ic: 0.06068874422367215
train 29, step: 600, loss: 8.743600483285263e-05, grad_norm: 4.7851153797200975e-08, ic: 0.05483280413088046
train 29, step: 700, loss: 0.0001180048129754141, grad_norm: 4.547845951303284e-05, ic: 0.12652582756557115
Epoch 29: 2022-05-06 16:03:21.051382: train loss: 0.00020742143451992504
Eval step 0: eval loss: 0.00024038829724304378
Eval step 100: eval loss: 0.0001670749916229397
Eval step 200: eval loss: 0.00010355743143009022
Eval: 2022-05-06 16:03:24.098491: total loss: 0.00019324273474058688, mse:0.0003864854682198436, ic :0.029578995009809463, sharpe5:0.5902069193869829, irr5:0.18651150166988373, ndcg5:0.8544224576899025, pnl5:1.4129992723464966 
train 30, step: 0, loss: 0.0002780717040877789, grad_norm: 7.768362075390367e-06, ic: 0.1323867621948849
train 30, step: 100, loss: 0.00018522173922974616, grad_norm: 9.786909888833204e-06, ic: 0.15014823153827972
train 30, step: 200, loss: 0.00011303495557513088, grad_norm: 3.399412256765534e-05, ic: 0.09916131461873143
train 30, step: 300, loss: 0.00027519374270923436, grad_norm: 4.637169156626991e-06, ic: 0.1035492844853158
train 30, step: 400, loss: 9.787359886104241e-05, grad_norm: 1.867118877957539e-06, ic: -0.03531528089278937
train 30, step: 500, loss: 0.0003583779907785356, grad_norm: 0.00011258768032946285, ic: -0.0690239583165764
train 30, step: 600, loss: 0.0005106693715788424, grad_norm: 0.0005498619471313664, ic: 0.05625606683832507
train 30, step: 700, loss: 0.0001675898238318041, grad_norm: 0.00011475797224384572, ic: 0.09276089040616622
Epoch 30: 2022-05-06 16:03:31.379790: train loss: 0.00020732886597089352
Eval step 0: eval loss: 0.00021041423315182328
Eval step 100: eval loss: 0.00017494063649792224
Eval step 200: eval loss: 0.00010215774091193452
Eval: 2022-05-06 16:03:34.520512: total loss: 0.0001890294586670372, mse:0.0003780589118491203, ic :0.02977978560638964, sharpe5:0.5190984910726547, irr5:0.1752403825521469, ndcg5:0.8504052483387825, pnl5:1.233157992362976 
train 31, step: 0, loss: 0.000308316812152043, grad_norm: 1.7109253064407158e-06, ic: 0.11329234548338311
train 31, step: 100, loss: 0.0001738629216561094, grad_norm: 1.0359201225769186e-06, ic: 0.08385171925022727
train 31, step: 200, loss: 0.00012199224875075743, grad_norm: 2.194001636957829e-05, ic: -0.03756180704995729
train 31, step: 300, loss: 0.00013460555055644363, grad_norm: 2.8316242099454123e-05, ic: 0.1521597458449937
train 31, step: 400, loss: 0.00017013447359204292, grad_norm: 8.881813585204237e-05, ic: 0.15777797681892086
train 31, step: 500, loss: 0.0007048363331705332, grad_norm: 0.0008061565554115741, ic: -0.11537082356261343
train 31, step: 600, loss: 0.00026880408404394984, grad_norm: 0.00014780329190344237, ic: 0.23805278367421934
train 31, step: 700, loss: 0.00014508134336210787, grad_norm: 3.513266702077183e-05, ic: 0.01457889093407605
Epoch 31: 2022-05-06 16:03:41.631668: train loss: 0.00020733937543634918
Eval step 0: eval loss: 0.0002447679580654949
Eval step 100: eval loss: 0.000166545229149051
Eval step 200: eval loss: 0.00010409752576379105
Eval: 2022-05-06 16:03:44.863858: total loss: 0.00019417680537656652, mse:0.0003883536122559226, ic :0.03190346101208998, sharpe5:0.6483242404460907, irr5:0.2168523520231247, ndcg5:0.8479676385864877, pnl5:1.2847542762756348 
train 32, step: 0, loss: 0.00016022392082959414, grad_norm: 0.00012035067757541004, ic: 0.09628868535504564
train 32, step: 100, loss: 0.0001839903270592913, grad_norm: 0.00016131604222329018, ic: 0.007663611010445468
train 32, step: 200, loss: 0.00021375881624408066, grad_norm: 0.00021591647223517474, ic: -0.00780491508576615
train 32, step: 300, loss: 9.956408030120656e-05, grad_norm: 1.0589078042383202e-06, ic: 0.08310684321827597
train 32, step: 400, loss: 0.00039648241363465786, grad_norm: 2.20080571548596e-05, ic: 0.06707106007517485
train 32, step: 500, loss: 0.0001985079434234649, grad_norm: 7.26801915709716e-05, ic: 0.09798182242507425
train 32, step: 600, loss: 0.00022101521608419716, grad_norm: 0.00010282106837286864, ic: 0.0668645268339453
train 32, step: 700, loss: 0.0003034014371223748, grad_norm: 4.675853344335699e-07, ic: 0.040242823340190886
Epoch 32: 2022-05-06 16:03:52.056570: train loss: 0.0002072153948580874
Eval step 0: eval loss: 0.00019942918152082711
Eval step 100: eval loss: 0.00017952756024897099
Eval step 200: eval loss: 0.00010273807856719941
Eval: 2022-05-06 16:03:55.052117: total loss: 0.00018854640861178977, mse:0.0003770928142342739, ic :0.02991283829230776, sharpe5:0.470546429939568, irr5:0.14137089252471924, ndcg5:0.8484448023954217, pnl5:1.1732574701309204 
train 33, step: 0, loss: 0.00018047452613245696, grad_norm: 8.915986589478023e-05, ic: 0.08252956573508025
train 33, step: 100, loss: 0.00018072855891659856, grad_norm: 2.0840867730615853e-05, ic: 0.07275246511651882
train 33, step: 200, loss: 0.00013417897571343929, grad_norm: 1.8279219511059092e-05, ic: -0.1895753205998994
train 33, step: 300, loss: 0.00016547177801840007, grad_norm: 7.294377916751785e-06, ic: 0.10420390072337335
train 33, step: 400, loss: 8.139657438732684e-05, grad_norm: 2.383816810447608e-07, ic: 0.011669301205181259
train 33, step: 500, loss: 0.000251634482992813, grad_norm: 2.5981846194582454e-06, ic: 0.05318941736453886
train 33, step: 600, loss: 0.00018977645959239453, grad_norm: 0.00010542397512650611, ic: 0.0919542982291159
train 33, step: 700, loss: 0.0002890285395551473, grad_norm: 5.4670369503277954e-05, ic: 0.09062745179583943
Epoch 33: 2022-05-06 16:04:01.927801: train loss: 0.00020691047764509693
Eval step 0: eval loss: 0.00021838735847268254
Eval step 100: eval loss: 0.0001723872119328007
Eval step 200: eval loss: 0.00010215127986157313
Eval: 2022-05-06 16:04:05.064086: total loss: 0.00018986831618333827, mse:0.00037973663064704954, ic :0.023328852574230383, sharpe5:1.149421292245388, irr5:0.39256739616394043, ndcg5:0.8499358494123357, pnl5:1.3138022422790527 
train 34, step: 0, loss: 0.0001099801593227312, grad_norm: 5.97907378054884e-08, ic: 0.04158763479028785
train 34, step: 100, loss: 0.00014829091378487647, grad_norm: 3.1761443685880183e-07, ic: 0.09209602560798559
train 34, step: 200, loss: 0.00023025833070278168, grad_norm: 6.645564510516646e-05, ic: 0.1423976526114432
train 34, step: 300, loss: 0.00017870635201688856, grad_norm: 6.574347386527988e-07, ic: -0.07117229648606731
train 34, step: 400, loss: 0.00019685699953697622, grad_norm: 2.562809237605431e-06, ic: 0.20228993521211103
train 34, step: 500, loss: 0.0002749103296082467, grad_norm: 7.68700585397766e-05, ic: 0.08744312535971016
train 34, step: 600, loss: 8.766122482484207e-05, grad_norm: 2.2647634805736946e-09, ic: 0.0190304282553204
train 34, step: 700, loss: 0.00011504851863719523, grad_norm: 3.875663963157699e-05, ic: -0.06833805507659244
Epoch 34: 2022-05-06 16:04:12.228335: train loss: 0.0002071461945117624
Eval step 0: eval loss: 0.00021221798670012504
Eval step 100: eval loss: 0.00017425496480427682
Eval step 200: eval loss: 0.0001020453855744563
Eval: 2022-05-06 16:04:15.399245: total loss: 0.00018915454649871564, mse:0.00037830908823615093, ic :0.024738605120301, sharpe5:1.5694335919618605, irr5:0.5304327607154846, ndcg5:0.854781805091715, pnl5:1.2129650115966797 
train 35, step: 0, loss: 0.00020588563347700983, grad_norm: 8.517139934432027e-05, ic: 0.04705159398030669
train 35, step: 100, loss: 0.0002976431860588491, grad_norm: 0.00016815340635476726, ic: 0.09704609123240276
train 35, step: 200, loss: 0.00016510218847543, grad_norm: 7.750998899192127e-06, ic: 0.05588671658963185
train 35, step: 300, loss: 0.0007367075304500759, grad_norm: 0.00045068391925585016, ic: 0.1243457902006432
train 35, step: 400, loss: 0.00017854930774774402, grad_norm: 8.216650070076932e-05, ic: 0.029265670177478425
train 35, step: 500, loss: 0.00023952353512868285, grad_norm: 7.294450396939544e-05, ic: 0.17469674889124315
train 35, step: 600, loss: 8.583346789237112e-05, grad_norm: 4.4414482303390014e-05, ic: -0.004791438430980441
train 35, step: 700, loss: 0.0001535618066554889, grad_norm: 6.761862285441335e-07, ic: 0.00969278624309802
Epoch 35: 2022-05-06 16:04:22.347865: train loss: 0.00020674963597657733
Eval step 0: eval loss: 0.00020986808522138745
Eval step 100: eval loss: 0.00017522639245726168
Eval step 200: eval loss: 0.00010208547610091045
Eval: 2022-05-06 16:04:25.387111: total loss: 0.00018896550876488, mse:0.0003779310137925267, ic :0.027015227924911716, sharpe5:1.6208199421316385, irr5:0.5476041436195374, ndcg5:0.8570487851302594, pnl5:1.2857943773269653 
train 36, step: 0, loss: 0.00017841887893155217, grad_norm: 0.00012440500847514207, ic: -0.12137424283610335
train 36, step: 100, loss: 0.00011042334517696872, grad_norm: 3.909947666888605e-06, ic: 0.03401219622264668
train 36, step: 200, loss: 0.00011573455412872136, grad_norm: 2.1027333177943558e-05, ic: 0.07704230338510212
train 36, step: 300, loss: 0.000390421919291839, grad_norm: 0.0001051663970400011, ic: 0.12193037229945966
train 36, step: 400, loss: 0.00015283707762137055, grad_norm: 4.649319087770566e-06, ic: 0.11785860013604485
train 36, step: 500, loss: 0.00017375343304593116, grad_norm: 5.4717103744952995e-05, ic: 0.0634481374840505
train 36, step: 600, loss: 0.0009013585513457656, grad_norm: 0.0009912536778101371, ic: -0.08622131911798331
train 36, step: 700, loss: 0.0001621241244720295, grad_norm: 1.3944277486670491e-05, ic: 0.025993640737700354
Epoch 36: 2022-05-06 16:04:32.281566: train loss: 0.0002068793448391725
Eval step 0: eval loss: 0.00024118270084727556
Eval step 100: eval loss: 0.0001670755009399727
Eval step 200: eval loss: 0.00010323790775146335
Eval: 2022-05-06 16:04:35.258435: total loss: 0.00019314865463549444, mse:0.0003862973111868817, ic :0.031278537258881675, sharpe5:1.0819284284859896, irr5:0.3651752471923828, ndcg5:0.8509428211390174, pnl5:1.315889596939087 
train 37, step: 0, loss: 0.0002928206231445074, grad_norm: 4.6885635632156246e-05, ic: 0.13483409504002894
train 37, step: 100, loss: 7.14766065357253e-05, grad_norm: 9.96827219040508e-09, ic: 0.024790379598969722
train 37, step: 200, loss: 0.00010886105883400887, grad_norm: 2.4451473399572015e-05, ic: 0.08534387655165163
train 37, step: 300, loss: 0.00018137767619919032, grad_norm: 0.000104764724241118, ic: 0.18771424254295954
train 37, step: 400, loss: 0.0001280242868233472, grad_norm: 1.7430681234635879e-06, ic: 0.03944111521214911
train 37, step: 500, loss: 0.00013889759429730475, grad_norm: 2.6056424740631255e-07, ic: 0.05094783794713751
train 37, step: 600, loss: 0.00023584000882692635, grad_norm: 1.7769149786215897e-05, ic: 0.0496346215437314
train 37, step: 700, loss: 0.00012633395090233535, grad_norm: 1.2541609326987987e-06, ic: 0.05402832403867784
Epoch 37: 2022-05-06 16:04:42.089031: train loss: 0.00020656912967860266
Eval step 0: eval loss: 0.0002039583632722497
Eval step 100: eval loss: 0.00017781826318241656
Eval step 200: eval loss: 0.00010233440843876451
Eval: 2022-05-06 16:04:45.209494: total loss: 0.0001886103402007316, mse:0.00037722067979922814, ic :0.027918175684121034, sharpe5:0.5486177583038807, irr5:0.16860024631023407, ndcg5:0.8580854940346688, pnl5:1.2541927099227905 
train 38, step: 0, loss: 0.00021254876628518105, grad_norm: 0.00011309328155885426, ic: 0.044761912304744036
train 38, step: 100, loss: 0.00010997496428899467, grad_norm: 1.3744526487228806e-05, ic: -0.022348716486306326
train 38, step: 200, loss: 0.00018562843615654856, grad_norm: 1.599291531547809e-07, ic: 0.10398590631971202
train 38, step: 300, loss: 0.00017782043141778558, grad_norm: 3.7481223871927798e-06, ic: 0.03913289716598359
train 38, step: 400, loss: 0.0002038931561401114, grad_norm: 1.8012245193783704e-06, ic: -0.011963903710376533
train 38, step: 500, loss: 0.00025741467834450305, grad_norm: 2.779732648076327e-05, ic: 0.020463624028465847
train 38, step: 600, loss: 0.000331090617692098, grad_norm: 7.561550869506811e-05, ic: 0.157984847671868
train 38, step: 700, loss: 0.00014992164506111294, grad_norm: 9.717318857528699e-05, ic: -0.006372406009265553
Epoch 38: 2022-05-06 16:04:52.135088: train loss: 0.00020657363074017527
Eval step 0: eval loss: 0.00024912034859880805
Eval step 100: eval loss: 0.0001658277615206316
Eval step 200: eval loss: 0.0001041928117047064
Eval: 2022-05-06 16:04:55.206204: total loss: 0.00019476542464394312, mse:0.0003895308493972828, ic :0.03417548023110252, sharpe5:0.5102895578742027, irr5:0.13709107041358948, ndcg5:0.8532024589985894, pnl5:1.1294463872909546 
train 39, step: 0, loss: 0.00017391696746926755, grad_norm: 0.0001305524257885601, ic: 0.01595624546953833
train 39, step: 100, loss: 0.00014371245924849063, grad_norm: 5.019432211650377e-05, ic: 0.03491373963990942
train 39, step: 200, loss: 0.00013876789307687432, grad_norm: 4.4303310541429e-05, ic: 0.02257310177547585
train 39, step: 300, loss: 0.00015941797755658627, grad_norm: 0.00011393133220582172, ic: -0.0036476724602432856
train 39, step: 400, loss: 0.00022915667796041816, grad_norm: 2.593205706043604e-05, ic: 0.05810794459880362
train 39, step: 500, loss: 0.00017924421990755945, grad_norm: 5.2654017607337335e-05, ic: 0.19838961973770042
train 39, step: 600, loss: 0.00017338221368845552, grad_norm: 8.584881295757366e-05, ic: 0.004592746506134815
train 39, step: 700, loss: 0.00022874836577102542, grad_norm: 2.058597829806705e-06, ic: -0.0894384130373231
Epoch 39: 2022-05-06 16:05:01.383262: train loss: 0.00020702807092518754
Eval step 0: eval loss: 0.00020224822219461203
Eval step 100: eval loss: 0.00017878397193271667
Eval step 200: eval loss: 0.00010271326027577743
Eval: 2022-05-06 16:05:04.404423: total loss: 0.00018869679507141403, mse:0.00037739359215530153, ic :0.007786998219928628, sharpe5:0.49292200706899164, irr5:0.11862237751483917, ndcg5:0.8638269182155266, pnl5:1.1313070058822632 

Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='SparseAdjSeqTimeDataset', dout=0.3, epochs=40, gnn_layers=2, gpu=0, hidden_dim=128, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=3, mask_adj=True, mask_type='soft', model_type='GNNModel', normalize_adj=False, num_days=1, num_heads=1, print_inteval=500, relation_num=1, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_250_0.6/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=False)
load 2305 train graphs successful!
load 126 test graphs successful!
44933
GNNModel(
  (fc1): Linear(in_features=9, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
  (fc4): Linear(in_features=128, out_features=1, bias=True)
  (gnns): ModuleList(
    (0): GraphConv(128, 128)
    (1): GraphConv(128, 128)
  )
  (dropout): Dropout(p=0.3, inplace=False)
  (relu): LeakyReLU(negative_slope=0.01)
)
train 0, step: 0, loss: 2.073249521368577, grad_norm: 0.47052302164852433, ic: 0.0025492787917604023
train 0, step: 500, loss: 1.3638655956809136, grad_norm: 0.8588216715284761, ic: -0.02395417624836364
train 0, step: 1000, loss: 1.506350153596819, grad_norm: 0.03256825160064725, ic: 0.11223123156513615
train 0, step: 1500, loss: 1.2019164945234435, grad_norm: 0.14376679545501994, ic: 0.06376884361505568
train 0, step: 2000, loss: 1.5583254186118523, grad_norm: 0.04410743531477486, ic: -0.034345839312868096
Epoch 0: 2022-04-04 00:48:43.309243: train loss: 1.647494009301044
Eval step 0: eval loss: 1.0109837568703923
Eval: 2022-04-04 00:48:48.467360: total loss: 1.092264682810372, mse:4.887717814978042, ic :0.02510528734690897, sharpe5:6.829163653850555, irr5:205.59107971191406, ndcg5:0.8451173980048018, pnl5:2.2813189029693604 
train 1, step: 0, loss: 0.6403424857866646, grad_norm: 0.05735818744190367, ic: 0.05356602260579689
train 1, step: 500, loss: 1.2630390729725203, grad_norm: 0.28091275009491307, ic: 0.2069250460782655
train 1, step: 1000, loss: 0.8846260581678888, grad_norm: 0.06709643738625126, ic: 0.01726703612875304
train 1, step: 1500, loss: 1.863329259360709, grad_norm: 0.5228614320521453, ic: 0.05674865071045884
train 1, step: 2000, loss: 1.3733177477148737, grad_norm: 0.22431830443704914, ic: 0.0247252054147097
Epoch 1: 2022-04-04 00:49:42.779997: train loss: 1.6456733009085291
Eval step 0: eval loss: 1.00579586501119
Eval: 2022-04-04 00:49:48.316939: total loss: 1.086554407280622, mse:4.71742321444787, ic :0.12150531574144642, sharpe5:7.070401196479797, irr5:205.25430297851562, ndcg5:0.8537634181504564, pnl5:3.2849183082580566 
train 2, step: 0, loss: 1.317464734040096, grad_norm: 0.4987139166147415, ic: 0.06315015736666092
train 2, step: 500, loss: 0.9551519414181051, grad_norm: 0.34269593151546857, ic: 0.07096058121464843
train 2, step: 1000, loss: 3.0643893668389555, grad_norm: 1.1635468509419338, ic: 0.1883895486433818
train 2, step: 1500, loss: 2.27129967225912, grad_norm: 0.849969096907748, ic: 0.09116529965096559
train 2, step: 2000, loss: 1.4688991194169052, grad_norm: 0.28763977829192655, ic: -0.10435809513973579
Epoch 2: 2022-04-04 00:50:43.391708: train loss: 1.6386846708750302
Eval step 0: eval loss: 1.000142897474822
Eval: 2022-04-04 00:50:48.956129: total loss: 1.0863501295327926, mse:4.71901099763325, ic :0.11799343449599389, sharpe5:8.718926475048065, irr5:240.93283081054688, ndcg5:0.8410872456804537, pnl5:3.4245691299438477 
train 3, step: 0, loss: 1.832139777699407, grad_norm: 0.07035847578432088, ic: -0.14177265072701292
train 3, step: 500, loss: 0.7624633315309671, grad_norm: 0.03215451843071773, ic: 0.5351407771300409
train 3, step: 1000, loss: 1.3803846571180556, grad_norm: 0.42946567412093994, ic: 0.21814177795396486
train 3, step: 1500, loss: 2.618805474490043, grad_norm: 0.4510176288954361, ic: -0.0588930449997698
train 3, step: 2000, loss: 1.3491874926017993, grad_norm: 0.18346989760066018, ic: 0.08909791524543478
Epoch 3: 2022-04-04 00:51:43.561840: train loss: 1.6390570301250553
Eval step 0: eval loss: 1.0027759264744602
Eval: 2022-04-04 00:51:48.866121: total loss: 1.0873301773171453, mse:4.718836450591878, ic :0.11850003132403512, sharpe5:7.983689634203911, irr5:228.912109375, ndcg5:0.8403846157778863, pnl5:3.4145851135253906 
train 4, step: 0, loss: 1.157129760927987, grad_norm: 0.18020038322245532, ic: 0.07299197277012767
train 4, step: 500, loss: 0.9933502253884509, grad_norm: 0.0036182187642901293, ic: 0.1114384712158574
train 4, step: 1000, loss: 1.3336195607479977, grad_norm: 0.06525756082850474, ic: 0.025930490655865272
train 4, step: 1500, loss: 1.0499131422776442, grad_norm: 0.14762204733339462, ic: 0.608779358271939
train 4, step: 2000, loss: 4.149835113837529, grad_norm: 1.0741910543861504, ic: -0.009301726745125666
Epoch 4: 2022-04-04 00:52:43.767196: train loss: 1.6382725206485556
Eval step 0: eval loss: 1.0082908176383951
Eval: 2022-04-04 00:52:49.140722: total loss: 1.0917781425379556, mse:4.72942997190144, ic :0.11723684475869894, sharpe5:8.230324628949164, irr5:237.9950714111328, ndcg5:0.8287218590261174, pnl5:3.0750067234039307 
train 5, step: 0, loss: 0.9928327155131379, grad_norm: 0.1572590635556513, ic: -0.12002875814954261
train 5, step: 500, loss: 0.789290682776091, grad_norm: 0.021324660123400358, ic: 0.14223410444601015
train 5, step: 1000, loss: 1.0932467208775332, grad_norm: 0.05214430741811103, ic: 0.3950916479166109
train 5, step: 1500, loss: 1.7586687785823172, grad_norm: 0.34072044987631106, ic: -0.08006094488510518
train 5, step: 2000, loss: 2.1102405777018056, grad_norm: 1.168577503882614, ic: 0.03403970290605599
Epoch 5: 2022-04-04 00:53:44.087051: train loss: 1.6386896105301159
Eval step 0: eval loss: 1.0041227496379672
Eval: 2022-04-04 00:53:49.620703: total loss: 1.087146282463471, mse:4.715379270426087, ic :0.12131855862273572, sharpe5:8.118168109059333, irr5:232.5181884765625, ndcg5:0.8635193402860539, pnl5:2.7082226276397705 
train 6, step: 0, loss: 0.7790782179104637, grad_norm: 0.009738331910609587, ic: -0.06291735165987103
train 6, step: 500, loss: 1.4168323717619242, grad_norm: 0.26972480060965254, ic: 0.05176399259328439
train 6, step: 1000, loss: 1.2232729269383218, grad_norm: 0.214501059821067, ic: 0.23059194783886897
train 6, step: 1500, loss: 1.0613527233195754, grad_norm: 0.34099427624594714, ic: 0.07766244941291814
train 6, step: 2000, loss: 2.294904293678396, grad_norm: 1.2425659613643112, ic: 0.06762842443523444
Epoch 6: 2022-04-04 00:54:43.743023: train loss: 1.6381791716863314
Eval step 0: eval loss: 1.0014374598884281
Eval: 2022-04-04 00:54:49.011472: total loss: 1.0856553505109914, mse:4.714387464662233, ic :0.12339864466534055, sharpe5:8.100122684240342, irr5:232.35963439941406, ndcg5:0.8461168107972671, pnl5:3.064723253250122 
train 7, step: 0, loss: 1.4565391477682248, grad_norm: 0.5336899328310752, ic: 0.19830345738139554
train 7, step: 500, loss: 1.339934827849867, grad_norm: 0.07561803268981926, ic: 0.18415371750350396
train 7, step: 1000, loss: 0.640555221281728, grad_norm: 0.0281387265339823, ic: 0.29533357788457953
train 7, step: 1500, loss: 1.00351614963066, grad_norm: 0.12969534299806995, ic: 0.10084792550212848
train 7, step: 2000, loss: 1.582906312937467, grad_norm: 0.6346313181535995, ic: 0.41968791728467564
Epoch 7: 2022-04-04 00:55:43.271985: train loss: 1.6376589639957815
Eval step 0: eval loss: 0.9910724754393759
Eval: 2022-04-04 00:55:48.767765: total loss: 1.083838644632537, mse:4.722998762628152, ic :0.12232821675695621, sharpe5:8.128156138658523, irr5:233.37908935546875, ndcg5:0.8507219284931601, pnl5:3.1938371658325195 
train 8, step: 0, loss: 1.2100563953273105, grad_norm: 0.08695857821397784, ic: 0.04295862458582086
train 8, step: 500, loss: 5.529121614175157, grad_norm: 1.393707830998679, ic: 0.1531109562379046
train 8, step: 1000, loss: 1.8813961775211117, grad_norm: 0.5843222402669246, ic: 0.06115450239832164
train 8, step: 1500, loss: 1.0775045011534585, grad_norm: 0.3754111939103484, ic: 0.6404942834948704
train 8, step: 2000, loss: 1.1250523298214643, grad_norm: 0.5304297871333832, ic: 0.020542289501133116
Epoch 8: 2022-04-04 00:56:42.782690: train loss: 1.6372409110198825
Eval step 0: eval loss: 0.9997343893990257
Eval: 2022-04-04 00:56:48.134145: total loss: 1.0872026024772012, mse:4.713958421522179, ic :0.12520994304715297, sharpe5:8.318460311293602, irr5:239.9420623779297, ndcg5:0.8381594912213282, pnl5:3.2605020999908447 
train 9, step: 0, loss: 1.1221647147017553, grad_norm: 0.02625084780597486, ic: 0.4375054985194142
train 9, step: 500, loss: 3.0797879060835234, grad_norm: 3.2193893689988364, ic: 0.09515371464732285
train 9, step: 1000, loss: 0.8691486546838293, grad_norm: 0.105149545798981, ic: 0.22154856852402227
train 9, step: 1500, loss: 2.1535715755419367, grad_norm: 0.9903127632752049, ic: -0.04248420747366894
train 9, step: 2000, loss: 0.6058271814761998, grad_norm: 0.008451752064741348, ic: 0.03933512182259016
Epoch 9: 2022-04-04 00:57:42.501511: train loss: 1.6366200948956653
Eval step 0: eval loss: 0.9982781593519615
Eval: 2022-04-04 00:57:47.838415: total loss: 1.0853243028931148, mse:4.739348248690099, ic :0.1387489695282184, sharpe5:15.569433050751686, irr5:487.58441162109375, ndcg5:0.8406224755206086, pnl5:5.818945407867432 
train 10, step: 0, loss: 1.3210792032334489, grad_norm: 0.08269775589127493, ic: 0.36874649955458094
train 10, step: 500, loss: 0.8991369749218158, grad_norm: 0.013582940656631367, ic: 0.09188508093716558
train 10, step: 1000, loss: 1.5226417560561512, grad_norm: 0.5028433464608779, ic: 0.043858090474323916
train 10, step: 1500, loss: 2.8336595584800355, grad_norm: 4.996197162895044, ic: 0.062005070923746464
train 10, step: 2000, loss: 1.375328179913089, grad_norm: 0.15993169889516662, ic: 0.13398899355473645
Epoch 10: 2022-04-04 00:58:41.781972: train loss: 1.6348078143699167
Eval step 0: eval loss: 1.005336381812796
Eval: 2022-04-04 00:58:47.086328: total loss: 1.0830397550358826, mse:4.686577896031876, ic :0.15570395429990092, sharpe5:13.658116366267203, irr5:453.64495849609375, ndcg5:0.8407125497040648, pnl5:4.490474224090576 
train 11, step: 0, loss: 4.761196491399531, grad_norm: 1.3425929033151665, ic: 0.36037463141134707
train 11, step: 500, loss: 0.988940917218702, grad_norm: 0.08427077358516492, ic: 0.04045981846955335
train 11, step: 1000, loss: 1.0300587203828184, grad_norm: 0.33117893146022837, ic: 0.07074615004849366
train 11, step: 1500, loss: 0.6978671821468775, grad_norm: 0.08971422061389324, ic: 0.0036277665897151493
train 11, step: 2000, loss: 1.1339676560278735, grad_norm: 0.07130877842553177, ic: -0.176298146337447
Epoch 11: 2022-04-04 00:59:40.844423: train loss: 1.6298188872132218
Eval step 0: eval loss: 0.9951399431032779
Eval: 2022-04-04 00:59:46.160422: total loss: 1.0820746683179903, mse:4.700141438014327, ic :0.14787552762684394, sharpe5:13.241596897244452, irr5:406.51751708984375, ndcg5:0.8443799670626762, pnl5:5.055165767669678 
train 12, step: 0, loss: 1.3857631668845056, grad_norm: 0.3115505659943746, ic: 0.15887414218155385
train 12, step: 500, loss: 0.8218936333057912, grad_norm: 0.41815421686980425, ic: 0.017199296998769972
train 12, step: 1000, loss: 1.193178604649365, grad_norm: 0.41810110477721363, ic: 0.60403214387051
train 12, step: 1500, loss: 1.0865588640218846, grad_norm: 0.21040732645490678, ic: 0.10222945641300223
train 12, step: 2000, loss: 1.1155086305041595, grad_norm: 0.07423930535023623, ic: 0.14243806667757689
Epoch 12: 2022-04-04 01:00:40.247949: train loss: 1.6296867618128286
Eval step 0: eval loss: 1.0042776677280805
Eval: 2022-04-04 01:00:45.608498: total loss: 1.082987952266023, mse:4.685945606011931, ic :0.16092439999743985, sharpe5:14.603188853859901, irr5:494.0492858886719, ndcg5:0.8465996012341372, pnl5:5.335002899169922 
train 13, step: 0, loss: 1.0724822088518549, grad_norm: 0.05839971226444811, ic: 0.4469137136997729
train 13, step: 500, loss: 1.1420264790076335, grad_norm: 0.08928079099723855, ic: -0.035243666098354075
train 13, step: 1000, loss: 1.3814456198367426, grad_norm: 0.4870518811980578, ic: 0.10065338781366863
train 13, step: 1500, loss: 0.7774375787790144, grad_norm: 0.09437030888986574, ic: -0.019020537753772923
train 13, step: 2000, loss: 1.0335905247935868, grad_norm: 0.023715236161962375, ic: 0.06711976962820798
Epoch 13: 2022-04-04 01:01:39.913834: train loss: 1.6287231521066712
Eval step 0: eval loss: 0.996523535207675
Eval: 2022-04-04 01:01:45.244277: total loss: 1.0820872696815746, mse:4.707244921924858, ic :0.15091756976174311, sharpe5:14.07987720966339, irr5:462.38397216796875, ndcg5:0.8367959102810825, pnl5:4.963149070739746 
train 14, step: 0, loss: 1.750670481536348, grad_norm: 0.5544288346430452, ic: 0.18950817752154142
train 14, step: 500, loss: 1.2632816267048586, grad_norm: 0.16033063645961845, ic: 0.2303548909959582
train 14, step: 1000, loss: 1.0702822346332643, grad_norm: 0.22811008769739335, ic: 0.1501730482662972
train 14, step: 1500, loss: 0.9653125789369226, grad_norm: 0.1310780430383869, ic: 0.19688554443243678
train 14, step: 2000, loss: 2.2884881920371125, grad_norm: 0.60405604469835, ic: -0.06574671161574497
Epoch 14: 2022-04-04 01:02:39.292876: train loss: 1.62774601545235
Eval step 0: eval loss: 1.0085217805835307
Eval: 2022-04-04 01:02:44.805246: total loss: 1.0858496488254106, mse:4.68956476794859, ic :0.1655010981612975, sharpe5:15.576172771453857, irr5:526.4935302734375, ndcg5:0.8407122560064142, pnl5:4.885477542877197 
train 15, step: 0, loss: 0.9579363044318636, grad_norm: 0.15304031599116433, ic: 0.13844150151386037
train 15, step: 500, loss: 1.2251458688944328, grad_norm: 0.045859365286305506, ic: 0.08186894533921642
train 15, step: 1000, loss: 1.7541221354166667, grad_norm: 0.08510621609967194, ic: -0.025155165633474936
train 15, step: 1500, loss: 5.397578759425754, grad_norm: 0.9040925810244314, ic: -0.009093633425988668
train 15, step: 2000, loss: 0.923879089017511, grad_norm: 0.08101719353493338, ic: 0.07453144495947947
Epoch 15: 2022-04-04 01:03:38.881761: train loss: 1.6286686369548553
Eval step 0: eval loss: 1.0083521420607884
Eval: 2022-04-04 01:03:44.548187: total loss: 1.0834081605944126, mse:4.682965014660967, ic :0.16144312121579613, sharpe5:14.427935305237769, irr5:471.92315673828125, ndcg5:0.8416460009140819, pnl5:5.484477519989014 
train 16, step: 0, loss: 6.358088481553999, grad_norm: 1.1400414729066737, ic: 0.15557724555914443
train 16, step: 500, loss: 1.3632829938616071, grad_norm: 0.8207001639253991, ic: -0.01816282574483953
train 16, step: 1000, loss: 0.8608555820658743, grad_norm: 0.8308098392015268, ic: -0.0741503422068997
train 16, step: 1500, loss: 1.2447925383750955, grad_norm: 0.46049630332507535, ic: 0.14354863356531922
train 16, step: 2000, loss: 0.9498927742696287, grad_norm: 0.4487697073143545, ic: 0.5508005004615156
Epoch 16: 2022-04-04 01:04:39.000017: train loss: 1.6260938207659692
Eval step 0: eval loss: 0.9974444943267837
Eval: 2022-04-04 01:04:44.350580: total loss: 1.07892557565992, mse:4.68735324319729, ic :0.1666189968564421, sharpe5:15.210131682157515, irr5:532.5899658203125, ndcg5:0.8426088878642007, pnl5:4.903597354888916 
train 17, step: 0, loss: 1.1831210083756711, grad_norm: 0.05584540102331981, ic: 0.12676369182513095
train 17, step: 500, loss: 1.0444715291407525, grad_norm: 0.05540555150753815, ic: -0.022995933488840287
train 17, step: 1000, loss: 3.361498539990718, grad_norm: 0.8249027842472596, ic: -0.020396608137336777
train 17, step: 1500, loss: 0.8827451440508698, grad_norm: 0.012725417862007177, ic: 0.08566522663773599
train 17, step: 2000, loss: 1.0140203898385067, grad_norm: 0.7256909510275306, ic: 0.5725340826299166
Epoch 17: 2022-04-04 01:05:38.894680: train loss: 1.6283533069613272
Eval step 0: eval loss: 1.002986255101369
Eval: 2022-04-04 01:05:44.619021: total loss: 1.0834502693624206, mse:4.709097647415601, ic :0.15732632592795054, sharpe5:14.712645701766013, irr5:502.0828857421875, ndcg5:0.8499190177700694, pnl5:4.4437174797058105 
train 18, step: 0, loss: 0.8508383009848637, grad_norm: 0.08878685130133147, ic: 0.015454334472469852
train 18, step: 500, loss: 2.5421927960661463, grad_norm: 1.5507287718024818, ic: 0.09723445606189816
train 18, step: 1000, loss: 1.3590294268491456, grad_norm: 0.48796306526989636, ic: 0.5345302713877522
train 18, step: 1500, loss: 1.7485813695072245, grad_norm: 0.8189654257695842, ic: 0.32909751621009203
train 18, step: 2000, loss: 1.2499781387655255, grad_norm: 0.3544915065823861, ic: 0.2196263002712886
Epoch 18: 2022-04-04 01:06:39.515964: train loss: 1.62744413214584
Eval step 0: eval loss: 1.0017204264580042
Eval: 2022-04-04 01:06:44.870431: total loss: 1.0813919244635481, mse:4.683190780674745, ic :0.16821717008136905, sharpe5:15.360601031184196, irr5:527.5882568359375, ndcg5:0.8517933150045757, pnl5:3.696995258331299 
train 19, step: 0, loss: 2.234734766521614, grad_norm: 0.9973729246820182, ic: 0.24644418193880935
train 19, step: 500, loss: 1.0226286422374637, grad_norm: 0.05705201585017611, ic: 0.040361735353613204
train 19, step: 1000, loss: 1.0091978411338167, grad_norm: 0.07918880425916214, ic: 0.5064112168324835
train 19, step: 1500, loss: 1.5825315875771604, grad_norm: 0.1826775010186461, ic: 0.11627246700552538
train 19, step: 2000, loss: 1.727037186412413, grad_norm: 1.6743784605531866, ic: 0.6244236614448746
Epoch 19: 2022-04-04 01:07:39.934237: train loss: 1.6261645879525335
Eval step 0: eval loss: 1.0027558706885202
Eval: 2022-04-04 01:07:45.411887: total loss: 1.0807680586761301, mse:4.690020258735589, ic :0.15423807405533316, sharpe5:12.373290064930915, irr5:390.4350280761719, ndcg5:0.8440965009475129, pnl5:4.441039562225342 
train 20, step: 0, loss: 1.251605787776652, grad_norm: 0.391170097087976, ic: 0.4560882290051587
train 20, step: 500, loss: 1.2502999778220407, grad_norm: 0.5985357578731324, ic: 0.010391151092221801
train 20, step: 1000, loss: 1.5713717782226047, grad_norm: 0.4937607098800901, ic: 0.171969875114698
train 20, step: 1500, loss: 0.8736632015034465, grad_norm: 0.7982842748013275, ic: 0.5943111232255642
train 20, step: 2000, loss: 1.360372088470089, grad_norm: 0.11117434499477603, ic: -0.04646805496587235
Epoch 20: 2022-04-04 01:08:40.004521: train loss: 1.6255181875047044
Eval step 0: eval loss: 0.9983345983906002
Eval: 2022-04-04 01:08:45.641736: total loss: 1.0811323267188417, mse:4.686919446497514, ic :0.1627184690929206, sharpe5:14.900066692829132, irr5:515.4661254882812, ndcg5:0.8474990002783174, pnl5:5.151698589324951 
train 21, step: 0, loss: 1.3879296305575801, grad_norm: 0.43297031063622304, ic: 0.35142834152436764
train 21, step: 500, loss: 1.1109156823833206, grad_norm: 0.18053350286868453, ic: 0.06334959045895636
train 21, step: 1000, loss: 0.9015344950441659, grad_norm: 0.3159631186769881, ic: 0.10037848442249711
train 21, step: 1500, loss: 0.7392550100755402, grad_norm: 0.1988577186002451, ic: 0.628728595920494
train 21, step: 2000, loss: 1.145229614078561, grad_norm: 0.08139582452788775, ic: 0.25785382741747354
Epoch 21: 2022-04-04 01:09:41.992567: train loss: 1.6257463053063905
Eval step 0: eval loss: 1.0061528837134674
Eval: 2022-04-04 01:09:47.293701: total loss: 1.0836307951139852, mse:4.696550333986303, ic :0.1496827993189507, sharpe5:11.908911484479903, irr5:377.2113952636719, ndcg5:0.845192647678327, pnl5:3.9385972023010254 
train 22, step: 0, loss: 1.0404307865253215, grad_norm: 0.3137048354508319, ic: 0.09883796117181366
train 22, step: 500, loss: 1.0270974947711613, grad_norm: 0.002481448664237029, ic: 0.02109997576323392
train 22, step: 1000, loss: 0.9097509055805278, grad_norm: 0.06223380237673165, ic: 0.12519114605262271
train 22, step: 1500, loss: 1.0129316573573792, grad_norm: 0.02960577089764491, ic: 0.21878958104028476
train 22, step: 2000, loss: 1.0568091813908067, grad_norm: 0.10403988978090775, ic: 0.014646114115742383
Epoch 22: 2022-04-04 01:10:41.334313: train loss: 1.6271076535144542
Eval step 0: eval loss: 1.0030074679518826
Eval: 2022-04-04 01:10:46.677419: total loss: 1.080517097392717, mse:4.673415873808863, ic :0.17042069898517095, sharpe5:16.392625848054884, irr5:545.1643676757812, ndcg5:0.8405521732642073, pnl5:6.316384315490723 
train 23, step: 0, loss: 1.3102870204572215, grad_norm: 0.8441344874899455, ic: -0.011577412325541568
train 23, step: 500, loss: 0.8948201609181834, grad_norm: 0.2267711688778079, ic: 0.5923694678833761
train 23, step: 1000, loss: 2.2822161159122425, grad_norm: 0.9719789850845619, ic: 0.10349279401880927
train 23, step: 1500, loss: 0.7891227383526436, grad_norm: 0.3616939385327253, ic: 0.7084162336804206
train 23, step: 2000, loss: 1.4509943055998442, grad_norm: 0.47850407855390115, ic: 0.4220693407125474
Epoch 23: 2022-04-04 01:11:41.181421: train loss: 1.6246034581474889
Eval step 0: eval loss: 1.0077806164428647
Eval: 2022-04-04 01:11:46.511392: total loss: 1.0851503648715448, mse:4.687465087873457, ic :0.16224995553948054, sharpe5:13.374373651742934, irr5:429.7168273925781, ndcg5:0.8458543155406548, pnl5:4.019885063171387 
train 24, step: 0, loss: 1.1818973442988876, grad_norm: 0.3473925820855133, ic: 0.28118198983188586
train 24, step: 500, loss: 1.2496021308578853, grad_norm: 1.9310463575207837, ic: -0.008179876244159393
train 24, step: 1000, loss: 1.0343568383193598, grad_norm: 0.8237509270680552, ic: 0.1505464467409229
train 24, step: 1500, loss: 1.2014469657357283, grad_norm: 0.14092430981263432, ic: 0.06759893294135819
train 24, step: 2000, loss: 1.3458675567321616, grad_norm: 0.41927363860178074, ic: 0.45923430070601273
Epoch 24: 2022-04-04 01:12:40.628725: train loss: 1.6242896798958333
Eval step 0: eval loss: 1.0048500290037519
Eval: 2022-04-04 01:12:45.963634: total loss: 1.0804347384934532, mse:4.676829498487499, ic :0.17065443058819108, sharpe5:14.932136412262915, irr5:524.415771484375, ndcg5:0.8482158896867444, pnl5:4.625842571258545 
train 25, step: 0, loss: 1.326950786594926, grad_norm: 0.4729721718941981, ic: 0.21705507916401662
train 25, step: 500, loss: 1.4879405034052862, grad_norm: 1.317148563864767, ic: 0.11514774777069635
train 25, step: 1000, loss: 1.3574102225147355, grad_norm: 0.21800580975836772, ic: 0.269644615062236
train 25, step: 1500, loss: 2.8768972758374183, grad_norm: 1.1198576656761963, ic: 0.1816260067183183
train 25, step: 2000, loss: 1.2078953996489319, grad_norm: 0.2772718817672609, ic: 0.17640790460789105
Epoch 25: 2022-04-04 01:13:39.886211: train loss: 1.6261649347809188
Eval step 0: eval loss: 1.0007439925207344
Eval: 2022-04-04 01:13:45.464771: total loss: 1.0798367770522108, mse:4.675706241853165, ic :0.16539175286297675, sharpe5:13.979005583524703, irr5:475.2672424316406, ndcg5:0.8482162174285386, pnl5:3.869497537612915 
train 26, step: 0, loss: 1.6127448508522726, grad_norm: 0.6621202501707165, ic: 0.1825621598295324
train 26, step: 500, loss: 1.007368352634552, grad_norm: 0.18439916058556471, ic: -0.055123715670179776
train 26, step: 1000, loss: 1.8025888257181515, grad_norm: 0.789659629811281, ic: 0.19501536070181125
train 26, step: 1500, loss: 0.9264137961647728, grad_norm: 0.009305478206596792, ic: -0.05611639183848866
train 26, step: 2000, loss: 0.9917753444881889, grad_norm: 0.16350592473713743, ic: 0.15743021158975065
Epoch 26: 2022-04-04 01:14:40.074862: train loss: 1.6249541105527991
Eval step 0: eval loss: 1.0016201475283042
Eval: 2022-04-04 01:14:45.494384: total loss: 1.080277787738682, mse:4.669799525309617, ic :0.17435037680435464, sharpe5:15.708114273548125, irr5:547.267822265625, ndcg5:0.8496897622982191, pnl5:4.866191387176514 
train 27, step: 0, loss: 1.6310275893613517, grad_norm: 0.9258960418002314, ic: 0.6502292870521575
train 27, step: 500, loss: 1.528232129513754, grad_norm: 0.26411541531890775, ic: -0.14514657051075364
train 27, step: 1000, loss: 2.5747726665695416, grad_norm: 0.8005582194215244, ic: 0.4017997453417117
train 27, step: 1500, loss: 0.8765675996757893, grad_norm: 0.6278157287345904, ic: 0.5397784187735997
train 27, step: 2000, loss: 1.3616238314252112, grad_norm: 0.7744108407863746, ic: -0.022221398765535263
Epoch 27: 2022-04-04 01:15:40.393023: train loss: 1.6230171513167575
Eval step 0: eval loss: 1.0019731807859398
Eval: 2022-04-04 01:15:46.085789: total loss: 1.0789410937040738, mse:4.6718087510230175, ic :0.17387716789438215, sharpe5:15.380913839936255, irr5:536.3411254882812, ndcg5:0.8419949879948918, pnl5:5.60719108581543 
train 28, step: 0, loss: 1.1643561876398312, grad_norm: 0.1279866675209143, ic: 0.14710312243454435
train 28, step: 500, loss: 2.9277229120546746, grad_norm: 0.46707604614608206, ic: 0.11838170817021784
train 28, step: 1000, loss: 2.7399443374802526, grad_norm: 2.2797505178299255, ic: -0.04509285041456762
train 28, step: 1500, loss: 1.0263277923907734, grad_norm: 0.004143698001776538, ic: 0.19396483465828387
train 28, step: 2000, loss: 1.745187803756359, grad_norm: 0.5056047517805499, ic: 0.09107739458805558
Epoch 28: 2022-04-04 01:16:42.288582: train loss: 1.6232333847143061
Eval step 0: eval loss: 1.0040463833761188
Eval: 2022-04-04 01:16:48.009286: total loss: 1.0794999878313647, mse:4.677412722207861, ic :0.16751111198391552, sharpe5:14.51316415786743, irr5:490.8874816894531, ndcg5:0.8392770915380953, pnl5:3.8723387718200684 
train 29, step: 0, loss: 1.5189679126291225, grad_norm: 0.1294218019019837, ic: 0.06732013621131212
train 29, step: 500, loss: 2.5392670230771213, grad_norm: 2.240193322625868, ic: -0.023291262402059927
train 29, step: 1000, loss: 1.703173828125, grad_norm: 1.0195171893328026, ic: 0.4821337784319476
train 29, step: 1500, loss: 3.981198944075416, grad_norm: 1.3756901421016925, ic: 0.13071224566842135
train 29, step: 2000, loss: 0.9198909184370004, grad_norm: 0.2710194495459662, ic: 0.47230343105908473
Epoch 29: 2022-04-04 01:17:45.416910: train loss: 1.6253787307485446
Eval step 0: eval loss: 1.0019841086180226
Eval: 2022-04-04 01:17:51.164403: total loss: 1.0806095813847618, mse:4.682542604575253, ic :0.1669635061696421, sharpe5:13.922688004374503, irr5:464.6121826171875, ndcg5:0.8473708445139247, pnl5:3.395308256149292 
train 30, step: 0, loss: 1.2488135800589042, grad_norm: 0.14431776711978994, ic: 0.9825577821604085
train 30, step: 500, loss: 1.9419744950306566, grad_norm: 0.7929414127813011, ic: 0.174133696473598
train 30, step: 1000, loss: 3.423125877808989, grad_norm: 0.784286787084248, ic: 0.3914110700835708
train 30, step: 1500, loss: 1.0848306448348446, grad_norm: 0.2858097863722437, ic: 0.15364678072584823
train 30, step: 2000, loss: 1.0962033711347723, grad_norm: 1.7160716017077626, ic: 0.44047817139100875
Epoch 30: 2022-04-04 01:18:48.518498: train loss: 1.625141950602703
Eval step 0: eval loss: 1.017687789009018
Eval: 2022-04-04 01:18:54.595612: total loss: 1.0854151575495403, mse:4.695809946433064, ic :0.15701385798044515, sharpe5:13.418702568411826, irr5:449.6328125, ndcg5:0.841484637985347, pnl5:3.6922707557678223 
train 31, step: 0, loss: 1.1616228628849639, grad_norm: 0.41605052218937344, ic: 0.216723321857909
train 31, step: 500, loss: 0.8206688650156617, grad_norm: 0.09916355378331672, ic: 0.21038038442215473
train 31, step: 1000, loss: 5.297458657587549, grad_norm: 4.185972273410052, ic: -0.06853220502187422
train 31, step: 1500, loss: 1.664866805629347, grad_norm: 0.3615171380058672, ic: 0.28943973126934264
train 31, step: 2000, loss: 0.9377056954920977, grad_norm: 0.868333534037943, ic: 0.26671720976349
Epoch 31: 2022-04-04 01:19:52.065857: train loss: 1.6251743389255673
Eval step 0: eval loss: 1.0113902722238677
Eval: 2022-04-04 01:19:57.629204: total loss: 1.0832498783304403, mse:4.678355936422192, ic :0.16470626365132482, sharpe5:13.477466311454773, irr5:450.46966552734375, ndcg5:0.850689926749922, pnl5:3.4820361137390137 
train 32, step: 0, loss: 0.8845648892093916, grad_norm: 0.7086780022681185, ic: 0.11227346119086262
train 32, step: 500, loss: 1.102432809224943, grad_norm: 0.44423921563427193, ic: 0.16783919797287153
train 32, step: 1000, loss: 1.3813406174919913, grad_norm: 0.07285302123500775, ic: 0.07142645487753092
train 32, step: 1500, loss: 2.081694517342299, grad_norm: 0.4717297554847775, ic: 0.43360083892054035
train 32, step: 2000, loss: 1.064665085402021, grad_norm: 0.4359837896979343, ic: 0.4652497922059887
Epoch 32: 2022-04-04 01:20:55.158593: train loss: 1.6204972078693702
Eval step 0: eval loss: 1.0047825335703
Eval: 2022-04-04 01:21:00.933387: total loss: 1.0786023957745279, mse:4.664417962172657, ic :0.17817750873072782, sharpe5:16.24586547374725, irr5:562.214599609375, ndcg5:0.8427841875267831, pnl5:4.088550567626953 
train 33, step: 0, loss: 1.1633508739078018, grad_norm: 0.019671854869491683, ic: 0.039489816393343785
train 33, step: 500, loss: 3.1473930059809763, grad_norm: 0.4391216256348948, ic: 0.5220536710520688
train 33, step: 1000, loss: 5.178360641046067, grad_norm: 4.017264190563596, ic: 0.06961273254326054
train 33, step: 1500, loss: 1.3667514707983994, grad_norm: 2.090977211557168, ic: 0.0036415998850860484
train 33, step: 2000, loss: 1.8607028221899224, grad_norm: 0.3442592377491115, ic: 0.08306287742712735
Epoch 33: 2022-04-04 01:21:59.563225: train loss: 1.6247192650657631
Eval step 0: eval loss: 1.0181896336270733
Eval: 2022-04-04 01:22:05.307394: total loss: 1.0921942214133762, mse:4.706834359656931, ic :0.16214138155083396, sharpe5:13.09141227185726, irr5:444.43597412109375, ndcg5:0.8362884761886233, pnl5:3.8893537521362305 
train 34, step: 0, loss: 0.7048786725559628, grad_norm: 0.5552265026620424, ic: 0.1503447417190319
train 34, step: 500, loss: 1.7991600978169409, grad_norm: 0.9845994596260754, ic: 0.8819592875369539
train 34, step: 1000, loss: 0.6997780004040948, grad_norm: 0.01283933059975698, ic: 0.4393926788249017
train 34, step: 1500, loss: 1.6249164287860578, grad_norm: 1.3943196450023243, ic: 0.6512039024519587
train 34, step: 2000, loss: 2.9818664249124796, grad_norm: 0.6422335822599613, ic: 0.10290037725836453
Epoch 34: 2022-04-04 01:23:02.428625: train loss: 1.6217016556244244
Eval step 0: eval loss: 1.010743151720478
Eval: 2022-04-04 01:23:08.126738: total loss: 1.0823707126754387, mse:4.683989001456507, ic :0.15981814083760115, sharpe5:13.251106288433075, irr5:436.7921447753906, ndcg5:0.8523795538305075, pnl5:3.6825530529022217 
train 35, step: 0, loss: 1.0642483868176424, grad_norm: 0.7960263479110803, ic: -0.005245077136804107
train 35, step: 500, loss: 3.280968868371212, grad_norm: 1.2519864082683716, ic: -0.06465636157967758
train 35, step: 1000, loss: 1.3621120153923394, grad_norm: 0.10106151207872388, ic: 0.49097659250681613
train 35, step: 1500, loss: 1.6288324679437962, grad_norm: 0.3898087622615547, ic: 0.0437899914964038
train 35, step: 2000, loss: 1.2875287743877502, grad_norm: 0.06043218353976358, ic: -0.12239127475581668
Epoch 35: 2022-04-04 01:24:04.534255: train loss: 1.6259816351512602
Eval step 0: eval loss: 1.0062034088665086
Eval: 2022-04-04 01:24:10.031263: total loss: 1.0821340578161935, mse:4.6852162204978605, ic :0.16168838270962327, sharpe5:13.574439777731895, irr5:441.5694580078125, ndcg5:0.854008126791933, pnl5:4.8210129737854 
train 36, step: 0, loss: 8.95635759915154, grad_norm: 1.2057890608074653, ic: -0.17154476233285665
train 36, step: 500, loss: 0.8564396756422691, grad_norm: 0.009091952106137717, ic: 0.10494796933914749
train 36, step: 1000, loss: 1.9913964546922491, grad_norm: 2.0632444821093427, ic: 0.11411441534812022
train 36, step: 1500, loss: 1.0519278339549536, grad_norm: 0.18952473216233862, ic: 0.10901012944414509
train 36, step: 2000, loss: 2.101424407509932, grad_norm: 1.53100896750313, ic: 0.400248966911545
Epoch 36: 2022-04-04 01:25:04.730051: train loss: 1.6229211779574928
Eval step 0: eval loss: 1.020315868343536
Eval: 2022-04-04 01:25:10.244139: total loss: 1.0870118609932886, mse:4.6893777430545684, ic :0.1622206010693696, sharpe5:12.759946659207344, irr5:432.8515319824219, ndcg5:0.8422544950756421, pnl5:3.527916431427002 
train 37, step: 0, loss: 1.177811840009307, grad_norm: 0.19066738870370997, ic: 0.1645578049337029
train 37, step: 500, loss: 2.3324478086099583, grad_norm: 0.039792057144870926, ic: 0.18206616823533447
train 37, step: 1000, loss: 0.7658249360823594, grad_norm: 0.5887422455369351, ic: 0.1528256870437923
train 37, step: 1500, loss: 3.097625887333439, grad_norm: 1.5001323444292123, ic: 0.20558738025662732
train 37, step: 2000, loss: 3.1177054865731937, grad_norm: 3.270932722395667, ic: 0.012714421790173826
Epoch 37: 2022-04-04 01:26:05.558095: train loss: 1.6217918325275422
Eval step 0: eval loss: 1.0056754017328198
Eval: 2022-04-04 01:26:11.044847: total loss: 1.0792673318180503, mse:4.670386889688879, ic :0.1725828604566199, sharpe5:16.030313597917555, irr5:550.48291015625, ndcg5:0.8457472436967847, pnl5:5.004687309265137 
train 38, step: 0, loss: 1.3559494480942236, grad_norm: 1.5437012643215657, ic: -0.15591697531171506
train 38, step: 500, loss: 1.7118254905523256, grad_norm: 1.0463018972241465, ic: 0.2112741323833008
train 38, step: 1000, loss: 1.823273256456206, grad_norm: 0.7771302229766093, ic: 0.1654085920125477
train 38, step: 1500, loss: 1.081977231246137, grad_norm: 0.15119098170947243, ic: 0.4779966304136611
train 38, step: 2000, loss: 0.7586982214238254, grad_norm: 0.16658746184474854, ic: 0.5666622063556165
Epoch 38: 2022-04-04 01:27:06.220402: train loss: 1.6219147558673286
Eval step 0: eval loss: 0.9965720676383951
Eval: 2022-04-04 01:27:11.727059: total loss: 1.078374200683621, mse:4.681561262282745, ic :0.17062054116585343, sharpe5:14.955635098814964, irr5:526.0032958984375, ndcg5:0.8473747089846763, pnl5:3.7288858890533447 
train 39, step: 0, loss: 0.8635115058501185, grad_norm: 0.03361935036405615, ic: 0.542379376054034
train 39, step: 500, loss: 1.2450649136051524, grad_norm: 0.5223538457927086, ic: 0.038746736323802454
train 39, step: 1000, loss: 1.398654822147254, grad_norm: 0.3251225211823678, ic: 0.06199177257010258
train 39, step: 1500, loss: 2.4408094843360675, grad_norm: 0.6256704016434002, ic: -0.07291535102545649
train 39, step: 2000, loss: 2.9529543738382897, grad_norm: 1.8837167887973447, ic: 0.19909462709578318
Epoch 39: 2022-04-04 01:28:07.140504: train loss: 1.6205155718282267
Eval step 0: eval loss: 0.9985140719622169
Eval: 2022-04-04 01:28:12.886265: total loss: 1.0780102689373814, mse:4.675969992507463, ic :0.17177501910432239, sharpe5:15.682294285297393, irr5:547.9292602539062, ndcg5:0.8417936346809404, pnl5:5.4502692222595215 

Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='RGCNSeqTimeDataset', dout=0.3, epochs=40, glstm_layers=1, gnn_layers=1, gpu=0, graph_attn=False, hidden_dim=128, inner_prod=False, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=1, market=None, mask_adj=True, mask_type='soft', model_type='BiGLSTM', normalize_adj=True, num_days=8, num_heads=1, print_inteval=500, rank_loss=False, relation_num=2, rsr_data_path=None, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_250_0.8/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
load 2305 train graphs successful!
load 126 test graphs successful!
97148
BiGLSTM(
  (input_to_hidden): Linear(in_features=9, out_features=128, bias=True)
  (forward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
            (1): Linear(in_features=128, out_features=128, bias=False)
          )
          (lin_out): Linear(in_features=256, out_features=128, bias=True)
        )
      )
    )
  )
  (backward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
            (1): Linear(in_features=128, out_features=128, bias=False)
          )
          (lin_out): Linear(in_features=256, out_features=128, bias=True)
        )
      )
    )
  )
  (fc0): ModuleList(
    (0): Linear(in_features=256, out_features=128, bias=True)
  )
  (w_out): Linear(in_features=128, out_features=1, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
)
train 0, step: 0, loss: 4.896541258429437, grad_norm: 4.674170520939608, ic: 0.0028186852262038816
train 0, step: 500, loss: 0.865882902281933, grad_norm: 0.024421208095099144, ic: 0.016459876806600698
train 0, step: 1000, loss: 1.940121609535022, grad_norm: 0.43260947710190195, ic: -0.04357298307268982
train 0, step: 1500, loss: 0.9530329406497036, grad_norm: 0.05140367096086218, ic: 0.05209507057612938
train 0, step: 2000, loss: 0.9986689150805436, grad_norm: 0.12961996577428592, ic: 0.037029123125342685
Epoch 0: 2022-04-27 19:30:09.021263: train loss: 1.6493203691110576
Eval step 0: eval loss: 0.8358154296874999
Eval: 2022-04-27 19:30:39.648811: total loss: 1.0791677544931804, mse:4.823428421368321, ic :0.00799710097867277, sharpe5:8.00696224451065, irr5:227.38819885253906, ndcg5:0.8662703604682241, pnl5:3.257512092590332 
train 1, step: 0, loss: 2.762096183530746, grad_norm: 0.7413103806781751, ic: 0.025281141445914774
train 1, step: 500, loss: 1.7504232897557428, grad_norm: 0.6571583362531103, ic: 0.1467321912049333
train 1, step: 1000, loss: 0.8746097226263007, grad_norm: 0.1516340500922972, ic: 0.03283399447804761
train 1, step: 1500, loss: 1.7072400323275863, grad_norm: 0.18153639713786704, ic: -0.006411919746818198
train 1, step: 2000, loss: 2.1746982421875, grad_norm: 0.8084827535794473, ic: 0.008659026784796266
Epoch 1: 2022-04-27 19:38:46.906399: train loss: 1.6467389603333924
Eval step 0: eval loss: 0.8353997603357152
Eval: 2022-04-27 19:39:18.071019: total loss: 1.0790541171028503, mse:4.823483069702596, ic :0.010909549752590687, sharpe5:7.76139188915491, irr5:218.02052307128906, ndcg5:0.8420960017367056, pnl5:2.9005343914031982 
train 2, step: 0, loss: 2.141441761363636, grad_norm: 0.007093502499530634, ic: 0.08768727614484265
train 2, step: 500, loss: 3.293423027313185, grad_norm: 0.25441027498299074, ic: 0.025240200805691664
train 2, step: 1000, loss: 2.07403634608477, grad_norm: 1.776508919236855e-05, ic: 0.19660425105151252
train 2, step: 1500, loss: 1.480244457448712, grad_norm: 0.051613721019339455, ic: -0.02423125292004729
train 2, step: 2000, loss: 3.218845402644231, grad_norm: 0.7288382894886493, ic: 0.11392393461527245
Epoch 2: 2022-04-27 19:47:15.564719: train loss: 1.6466655781823376
Eval step 0: eval loss: 0.8364939553971285
Eval: 2022-04-27 19:47:46.622646: total loss: 1.079366402375687, mse:4.822700499224004, ic :0.020852533081639958, sharpe5:11.297869960069656, irr5:330.4847106933594, ndcg5:0.8357194075363695, pnl5:2.386320114135742 
train 3, step: 0, loss: 1.5218940548780489, grad_norm: 0.49475042250928153, ic: -0.008215511698930537
train 3, step: 500, loss: 1.494998654072044, grad_norm: 0.32411627282228306, ic: -0.007299248888679225
train 3, step: 1000, loss: 3.6850422895977264, grad_norm: 0.6803427340288127, ic: -0.07708780587357346
train 3, step: 1500, loss: 1.9385824500051148, grad_norm: 0.8924433064670768, ic: -0.0103590410787111
train 3, step: 2000, loss: 0.9012608213682433, grad_norm: 0.004156284043986004, ic: -0.021100911990253983
Epoch 3: 2022-04-27 19:55:51.071083: train loss: 1.6469572009384759
Eval step 0: eval loss: 0.8360161575301304
Eval: 2022-04-27 19:56:22.569946: total loss: 1.079222006472178, mse:4.823302573325398, ic :0.03100847160547616, sharpe5:11.588248343467711, irr5:401.44049072265625, ndcg5:0.8655572947771291, pnl5:3.5043907165527344 
train 4, step: 0, loss: 1.438660514987245, grad_norm: 0.041589316118737514, ic: 0.07732555005369957
train 4, step: 500, loss: 1.6405721349040354, grad_norm: 0.5385357963315464, ic: -0.0453642675768791
train 4, step: 1000, loss: 2.9301229337366617, grad_norm: 0.7804327778088529, ic: 0.02956526738258075
train 4, step: 1500, loss: 2.157993802742616, grad_norm: 0.4620609565858107, ic: -0.0491895069159413
train 4, step: 2000, loss: 1.0856062205360615, grad_norm: 0.38801057725822424, ic: 0.19478192880285833
Epoch 4: 2022-04-27 20:04:28.061227: train loss: 1.6432047692052156
Eval step 0: eval loss: 0.841309494163264
Eval: 2022-04-27 20:04:58.736564: total loss: 1.083561272399691, mse:4.765640247336744, ic :0.11835067957969457, sharpe5:11.628443564772605, irr5:397.24853515625, ndcg5:0.8486818760683384, pnl5:3.5684194564819336 
train 5, step: 0, loss: 1.3103057656512165, grad_norm: 0.11083428231561002, ic: 0.37875135328522347
train 5, step: 500, loss: 0.9983632316861618, grad_norm: 1.4605808727170195, ic: 0.8264459391167452
train 5, step: 1000, loss: 0.9949546141642721, grad_norm: 0.1933729893404212, ic: 0.044412031021246565
train 5, step: 1500, loss: 1.53302852519621, grad_norm: 0.17516042645904517, ic: 0.016966265997476197
train 5, step: 2000, loss: 1.1106541184427565, grad_norm: 0.03754306007454626, ic: 0.15141277312562243
Epoch 5: 2022-04-27 20:12:59.059108: train loss: 1.6421875902092384
Eval step 0: eval loss: 0.8361036262472009
Eval: 2022-04-27 20:13:30.803641: total loss: 1.0758874815471926, mse:4.642143532714702, ic :0.1373064524133233, sharpe5:11.432946259975433, irr5:400.4518127441406, ndcg5:0.8585511185302679, pnl5:3.3295693397521973 
train 6, step: 0, loss: 1.3432510108278508, grad_norm: 0.5018500351868025, ic: 0.03735322669396326
train 6, step: 500, loss: 1.0096674827120022, grad_norm: 0.053396686875718635, ic: 0.00939285108395422
train 6, step: 1000, loss: 1.08837890625, grad_norm: 0.11752840986557488, ic: 0.8017446852437801
train 6, step: 1500, loss: 1.5746771694214876, grad_norm: 0.768796943531863, ic: -0.00015697008971521376
train 6, step: 2000, loss: 0.8149279188976181, grad_norm: 0.19654640170817989, ic: 0.3356284696436446
Epoch 6: 2022-04-27 20:21:41.974392: train loss: 1.63819119816516
Eval step 0: eval loss: 0.830507236235511
Eval: 2022-04-27 20:22:13.850400: total loss: 1.0732544309419711, mse:4.630676122472235, ic :0.13978754614039812, sharpe5:11.51112323641777, irr5:410.28961181640625, ndcg5:0.8440535520090797, pnl5:3.1602602005004883 
train 7, step: 0, loss: 0.9975082397460938, grad_norm: 0.05237791753651012, ic: 0.03745423051294656
train 7, step: 500, loss: 0.6566000709417743, grad_norm: 0.003293144635326764, ic: -0.015950533573675024
train 7, step: 1000, loss: 1.025184509323829, grad_norm: 0.23742282889761315, ic: -0.013221701753600082
train 7, step: 1500, loss: 2.2492777833601285, grad_norm: 0.7811584286216549, ic: 0.42425736331289526
train 7, step: 2000, loss: 0.9192150898626819, grad_norm: 0.05658331141725089, ic: -0.007953073969176806
Epoch 7: 2022-04-27 20:30:04.572940: train loss: 1.6376953299265191
Eval step 0: eval loss: 0.8347968050250263
Eval: 2022-04-27 20:30:36.395912: total loss: 1.0753111918603422, mse:4.637841495301411, ic :0.1371612224559348, sharpe5:11.381462361216544, irr5:402.6759948730469, ndcg5:0.8310034442767409, pnl5:3.31695556640625 
train 8, step: 0, loss: 3.617576709692029, grad_norm: 1.0810603869951558, ic: -0.05024190365728948
train 8, step: 500, loss: 2.7469152201272795, grad_norm: 1.6101884694909874, ic: -0.08250235067496559
train 8, step: 1000, loss: 3.067065075860507, grad_norm: 0.8900619820956025, ic: 0.07163400037813968
train 8, step: 1500, loss: 0.7109027302809032, grad_norm: 0.06767663809806779, ic: 0.5593107197817732
train 8, step: 2000, loss: 1.061182367594603, grad_norm: 0.510821265282047, ic: 0.660602328181787
Epoch 8: 2022-04-27 20:38:47.032516: train loss: 1.6368038978882635
Eval step 0: eval loss: 0.827714282921167
Eval: 2022-04-27 20:39:18.376821: total loss: 1.0729743304889954, mse:4.64863247825284, ic :0.13984046152226054, sharpe5:11.510123392939567, irr5:402.59869384765625, ndcg5:0.8327470201501957, pnl5:3.0598719120025635 
train 9, step: 0, loss: 5.4476768092105265, grad_norm: 1.0295177337988304, ic: -0.013645182330097245
train 9, step: 500, loss: 1.3334478663811518, grad_norm: 1.0628995251277353, ic: 0.3062441799962912
train 9, step: 1000, loss: 0.9323922894858374, grad_norm: 0.007009681352943691, ic: -0.01474121351923939
train 9, step: 1500, loss: 1.0861397519905192, grad_norm: 0.059170071762335755, ic: 0.4818602023393576
train 9, step: 2000, loss: 1.0815962868175286, grad_norm: 0.1969689034678278, ic: 0.24970338492474703
Epoch 9: 2022-04-27 20:47:18.891526: train loss: 1.6366279864805173
Eval step 0: eval loss: 0.8285248478044323
Eval: 2022-04-27 20:47:49.742153: total loss: 1.071597285278165, mse:4.624565608973941, ic :0.14398884227319708, sharpe5:12.360278856754302, irr5:433.3145446777344, ndcg5:0.8644010987498911, pnl5:3.369929552078247 
train 10, step: 0, loss: 7.16532235103863, grad_norm: 1.1343740652240575, ic: 0.1853038442321256
train 10, step: 500, loss: 1.1261603386847527, grad_norm: 0.046582058725376435, ic: -0.11980085555227328
train 10, step: 1000, loss: 2.386644609135353, grad_norm: 0.7189383034002573, ic: 0.11554660032440378
train 10, step: 1500, loss: 1.0986244895241477, grad_norm: 0.23512840310628066, ic: -0.036109532657737
train 10, step: 2000, loss: 2.7950331853153494, grad_norm: 0.2579994097719804, ic: 0.4875352212378732
Epoch 10: 2022-04-27 20:55:52.378313: train loss: 1.6369557619524122
Eval step 0: eval loss: 0.8299726480176501
Eval: 2022-04-27 20:56:24.084489: total loss: 1.0720410456881668, mse:4.62628120039585, ic :0.14206985293942284, sharpe5:11.564748710989951, irr5:407.9143371582031, ndcg5:0.8450875898316234, pnl5:3.2001354694366455 
train 11, step: 0, loss: 1.2735823227837395, grad_norm: 0.06724471818795791, ic: 0.10615987717644396
train 11, step: 500, loss: 0.6766798772553781, grad_norm: 0.061034741325369124, ic: 0.5754555113733438
train 11, step: 1000, loss: 0.9678392528210017, grad_norm: 0.25332658912982825, ic: 0.05772817587768542
train 11, step: 1500, loss: 1.0554557934141995, grad_norm: 0.054106836479518444, ic: 0.18244323536173054
train 11, step: 2000, loss: 0.7960846284742792, grad_norm: 0.0007211164648066156, ic: -0.015036005809520293
Epoch 11: 2022-04-27 21:04:28.235437: train loss: 1.6362437772193774
Eval step 0: eval loss: 0.8571443547690002
Eval: 2022-04-27 21:04:59.214337: total loss: 1.097573769015162, mse:4.77835793913469, ic :0.0917662128883603, sharpe5:11.475774938464165, irr5:377.4046630859375, ndcg5:0.8374730953107853, pnl5:3.352588176727295 
train 12, step: 0, loss: 1.015217622121175, grad_norm: 8.397150667535744, ic: 0.28680598812704594
train 12, step: 500, loss: 0.9461544952267609, grad_norm: 0.0718291970574167, ic: 0.04792847951408295
train 12, step: 1000, loss: 3.000978700674264, grad_norm: 0.19517822229430012, ic: 0.124877781460219
train 12, step: 1500, loss: 0.9228262745144707, grad_norm: 0.11271886635268427, ic: -0.02657896127790729
train 12, step: 2000, loss: 0.8819408589619524, grad_norm: 0.016796529264243392, ic: 0.01341036302002783
Epoch 12: 2022-04-27 21:13:01.136408: train loss: 1.6358129812178952
Eval step 0: eval loss: 0.8324684649548867
Eval: 2022-04-27 21:13:32.597111: total loss: 1.072680521055035, mse:4.622426002086766, ic :0.1419479860182136, sharpe5:11.677848318815231, irr5:416.9583740234375, ndcg5:0.837773197869505, pnl5:2.5694267749786377 
train 13, step: 0, loss: 2.0774987934761087, grad_norm: 0.6420009695082736, ic: 0.4188068069778657
train 13, step: 500, loss: 0.8438103690153905, grad_norm: 0.12021229971078783, ic: 0.5601649825651842
train 13, step: 1000, loss: 0.9592726739460989, grad_norm: 0.43125597213226136, ic: 0.5724500459917014
train 13, step: 1500, loss: 2.3610929419154956, grad_norm: 0.16927571174001296, ic: 0.06356892765113432
train 13, step: 2000, loss: 1.4837364566794167, grad_norm: 0.03176536131842056, ic: 0.051251747570600886
Epoch 13: 2022-04-27 21:21:35.591101: train loss: 1.6359257968362317
Eval step 0: eval loss: 0.831791740071786
Eval: 2022-04-27 21:22:06.801462: total loss: 1.0761608618223963, mse:4.661289455242926, ic :0.12933958062777695, sharpe5:11.707425523996353, irr5:403.75006103515625, ndcg5:0.8471556121137203, pnl5:3.363964557647705 
train 14, step: 0, loss: 4.548900872050507, grad_norm: 1.7374899288387193, ic: 0.11648200368210976
train 14, step: 500, loss: 0.8286351195169152, grad_norm: 0.050377696894609164, ic: -0.12159844199207237
train 14, step: 1000, loss: 1.887607814872817, grad_norm: 0.23013542852100707, ic: 0.4040822475312803
train 14, step: 1500, loss: 1.124541230254121, grad_norm: 0.07194400999543595, ic: 0.011423624285148292
train 14, step: 2000, loss: 1.1278208579928581, grad_norm: 0.2956574296835128, ic: 0.14648393164202989
Epoch 14: 2022-04-27 21:30:07.553628: train loss: 1.6370396729469618
Eval step 0: eval loss: 0.8378457329672682
Eval: 2022-04-27 21:30:38.878466: total loss: 1.0752714751191352, mse:4.62406539213664, ic :0.1416298808603658, sharpe5:12.1394052028656, irr5:421.2146301269531, ndcg5:0.8513577597268458, pnl5:3.041503667831421 
train 15, step: 0, loss: 3.3643406493190664, grad_norm: 0.5891909258423562, ic: -0.01997763723541248
train 15, step: 500, loss: 1.2582654691396509, grad_norm: 0.008691764369685133, ic: -0.023605683440611765
train 15, step: 1000, loss: 1.3135202299288617, grad_norm: 0.15198099561331235, ic: -0.028189547647065057
train 15, step: 1500, loss: 0.857082000492126, grad_norm: 0.20841928854672398, ic: 0.001047100481143072
train 15, step: 2000, loss: 1.4580712065028683, grad_norm: 0.5704797169927596, ic: -0.0018188516550770688
Epoch 15: 2022-04-27 21:38:43.010705: train loss: 1.6353577453696666
Eval step 0: eval loss: 0.8416749333179662
Eval: 2022-04-27 21:39:14.406174: total loss: 1.0769216102328218, mse:4.631288407979809, ic :0.14147692076066193, sharpe5:11.666585181355476, irr5:405.4473876953125, ndcg5:0.8435010706429173, pnl5:3.265495538711548 
train 16, step: 0, loss: 0.6935308823392963, grad_norm: 0.2145841326692146, ic: -0.19903379123627749
train 16, step: 500, loss: 1.5654588964895448, grad_norm: 0.6306012247435686, ic: 0.12107100102017959
train 16, step: 1000, loss: 0.8875828598484848, grad_norm: 7.129213305825662, ic: -0.1170676669488571
train 16, step: 1500, loss: 0.8393303620899824, grad_norm: 0.9683913144127112, ic: 0.06296031217374383
train 16, step: 2000, loss: 3.345092471033753, grad_norm: 1.9939769405671803, ic: 0.046840534627023436
Epoch 16: 2022-04-27 21:47:23.190550: train loss: 1.6361513261792568
Eval step 0: eval loss: 0.8309151234440858
Eval: 2022-04-27 21:47:54.703290: total loss: 1.0727564775879517, mse:4.624333073208451, ic :0.14273628758810333, sharpe5:11.561606345772743, irr5:400.2080383300781, ndcg5:0.8521862154692403, pnl5:3.0584988594055176 
train 17, step: 0, loss: 1.267943105520557, grad_norm: 0.2513406100396485, ic: -0.06420021292401679
train 17, step: 500, loss: 1.8411564193766938, grad_norm: 1.3137973328829775, ic: 0.16709344755320066
train 17, step: 1000, loss: 1.2742223486794142, grad_norm: 0.1311882121551865, ic: 0.128036513503439
train 17, step: 1500, loss: 4.525900073475386, grad_norm: 12.200128261370297, ic: 0.1610789348673432
train 17, step: 2000, loss: 1.2948291326384747, grad_norm: 0.8775698441527409, ic: 0.0029073693324975884
Epoch 17: 2022-04-27 21:55:47.072886: train loss: 1.6368377880818723
Eval step 0: eval loss: 0.8395077672220758
Eval: 2022-04-27 21:56:18.824411: total loss: 1.0777006095485688, mse:4.655283004252341, ic :0.13857738827600175, sharpe5:11.512717121243476, irr5:405.5333251953125, ndcg5:0.8455462057648474, pnl5:3.2638559341430664 
train 18, step: 0, loss: 1.4377399147447876, grad_norm: 0.5921850574659907, ic: -0.06479117430599178
train 18, step: 500, loss: 1.4393035666994551, grad_norm: 1.1116621855507707, ic: -0.00942584164014547
train 18, step: 1000, loss: 0.6780153039383561, grad_norm: 0.0257410319875173, ic: 0.5563447349414881
train 18, step: 1500, loss: 1.4486681838976763, grad_norm: 0.1412050993201926, ic: 0.006809857700532277
train 18, step: 2000, loss: 0.9092539404607882, grad_norm: 0.007619843449157445, ic: 0.008708454632863585
Epoch 18: 2022-04-27 22:13:35.719106: train loss: 1.6378160717259669
Eval step 0: eval loss: 0.8302985976192043
Eval: 2022-04-27 22:15:00.049267: total loss: 1.0737432212272313, mse:4.643502056170984, ic :0.14671172533778892, sharpe5:11.837783546447753, irr5:404.43487548828125, ndcg5:0.8410258745697344, pnl5:2.833259344100952 
train 19, step: 0, loss: 1.4601287357390873, grad_norm: 0.7833376069206481, ic: 0.07048401540021572
train 19, step: 500, loss: 0.8703073572229455, grad_norm: 0.04937455993887505, ic: 0.24042585764819746
train 19, step: 1000, loss: 0.9781543265352126, grad_norm: 0.020503944392294367, ic: 0.011311051305217402
train 19, step: 1500, loss: 3.986478418174631, grad_norm: 1.5021714654651666, ic: 0.049921226016977654
train 19, step: 2000, loss: 1.005664813701923, grad_norm: 0.6333511896279023, ic: 0.03970075552309157
Epoch 19: 2022-04-27 22:37:08.873657: train loss: 1.6375370324990377
Eval step 0: eval loss: 0.8303570601661288
Eval: 2022-04-27 22:38:36.116870: total loss: 1.0723088780753405, mse:4.626297720545451, ic :0.14680884339116235, sharpe5:11.867580206394194, irr5:414.8416748046875, ndcg5:0.8631447333367358, pnl5:3.6029107570648193 
train 20, step: 0, loss: 2.2997467885375493, grad_norm: 3.9273699506549433, ic: 0.03843316799020645
train 20, step: 500, loss: 3.2002684659090908, grad_norm: 0.836724180545198, ic: 0.11665343729404926
train 20, step: 1000, loss: 0.9795516014099122, grad_norm: 0.26310161309414776, ic: 0.044140585971024854
train 20, step: 1500, loss: 1.9643208852770866, grad_norm: 0.3708047062104066, ic: 0.1401717624890581
train 20, step: 2000, loss: 1.0591649713562907, grad_norm: 0.11448971906568803, ic: -0.03834879425867959
Epoch 20: 2022-04-27 23:01:02.334507: train loss: 1.6372355153186173
Eval step 0: eval loss: 0.8404054149310128
Eval: 2022-04-27 23:02:20.811047: total loss: 1.0817348113906333, mse:4.686615555563258, ic :0.12076423970301053, sharpe5:11.079425443410873, irr5:385.657470703125, ndcg5:0.8495668656255243, pnl5:2.78109073638916 
train 21, step: 0, loss: 1.0017302139945652, grad_norm: 189.6684421566453, ic: 0.05713437918138526
train 21, step: 500, loss: 0.8059267027188192, grad_norm: 22.843786733985993, ic: 0.059200043220105435
train 21, step: 1000, loss: 0.9442404362193325, grad_norm: 2.820036918311701, ic: 0.15140379598770465
train 21, step: 1500, loss: 1.0225428450098992, grad_norm: 0.36313480051763625, ic: 0.1448299101402643
train 21, step: 2000, loss: 0.9421694260234981, grad_norm: 0.9675206376315846, ic: 0.09269973747183946
Epoch 21: 2022-04-27 23:24:29.560145: train loss: 1.6422644504795665
Eval step 0: eval loss: 0.8368664692274762
Eval: 2022-04-27 23:25:53.165707: total loss: 1.0792454945291305, mse:4.672580033453808, ic :0.12685204391839916, sharpe5:11.556491725444793, irr5:397.73236083984375, ndcg5:0.868075207190596, pnl5:3.278286933898926 
train 22, step: 0, loss: 1.0720426915055614, grad_norm: 0.159317478842603, ic: 0.02485094414061958
train 22, step: 500, loss: 3.31445510988313, grad_norm: 5.114712843870315, ic: -0.034655978401932394
train 22, step: 1000, loss: 1.2245238552203759, grad_norm: 0.18240740358546853, ic: 0.41588546609140503
train 22, step: 1500, loss: 0.9817686230066872, grad_norm: 0.24562932932650047, ic: 0.02242493753298024
train 22, step: 2000, loss: 1.7762402731274802, grad_norm: 32.23099104623171, ic: 0.11968140294029617
Epoch 22: 2022-04-27 23:48:04.514130: train loss: 1.638866572721026
Eval step 0: eval loss: 0.8311188741026738
Eval: 2022-04-27 23:49:29.319115: total loss: 1.0725934829952235, mse:4.6226345353408185, ic :0.14158833362098736, sharpe5:10.981701858043671, irr5:385.5721740722656, ndcg5:0.8458402839715615, pnl5:2.743666887283325 
train 23, step: 0, loss: 0.9951017792011888, grad_norm: 0.529355055185083, ic: 0.1661403216327907
train 23, step: 500, loss: 1.4338819662480378, grad_norm: 0.19794127724434976, ic: 0.0041216951117490006
train 23, step: 1000, loss: 1.6358833821614585, grad_norm: 0.5440976995135767, ic: 0.25488168388020327
train 23, step: 1500, loss: 1.126447699569503, grad_norm: 0.2845290359291148, ic: 0.08040313325677934
train 23, step: 2000, loss: 1.9510872997257505, grad_norm: 3.611213495393561, ic: 0.3642023384600126
Epoch 23: 2022-04-28 00:11:43.135882: train loss: 1.6373138933857676
Eval step 0: eval loss: 0.8358568486976422
Eval: 2022-04-28 00:13:15.175382: total loss: 1.0743188378375335, mse:4.628347367194641, ic :0.14495200894066518, sharpe5:11.762439617514609, irr5:394.54315185546875, ndcg5:0.8543281782451361, pnl5:3.8552567958831787 
train 24, step: 0, loss: 2.2169582933142804, grad_norm: 0.020373348654794326, ic: 0.18145646310531055
train 24, step: 500, loss: 1.2553726136916343, grad_norm: 0.1155872152886956, ic: 0.030778772567096123
train 24, step: 1000, loss: 0.9507119476915936, grad_norm: 0.060770349302819854, ic: 0.48812123918103434
train 24, step: 1500, loss: 2.5948956293796375, grad_norm: 1.4892383040640509, ic: -0.03392255975245433
train 24, step: 2000, loss: 0.9351735010123777, grad_norm: 0.9465063853908118, ic: 0.09838343883646312
Epoch 24: 2022-04-28 00:35:42.660577: train loss: 1.6408861857475177
Eval step 0: eval loss: 0.8394412652710089
Eval: 2022-04-28 00:37:09.385917: total loss: 1.0771491768106314, mse:4.641134242532692, ic :0.14146503734107407, sharpe5:12.090987995266914, irr5:409.1782531738281, ndcg5:0.8516085935867972, pnl5:3.5148000717163086 
train 25, step: 0, loss: 0.9132830645586993, grad_norm: 0.3398455465410133, ic: 0.5346356108895174
train 25, step: 500, loss: 0.8956105212070431, grad_norm: 6.839229525170591, ic: 0.02084742202455116
train 25, step: 1000, loss: 2.1856102809048936, grad_norm: 0.4136489690210427, ic: 0.10623731050491939
train 25, step: 1500, loss: 1.1785623552996025, grad_norm: 1.6285011322561511, ic: 0.46169578265779404
train 25, step: 2000, loss: 1.0632535999306036, grad_norm: 1.1823606078463618, ic: 0.505004000344846
Epoch 25: 2022-04-28 00:59:08.366056: train loss: 1.638929007489459
Eval step 0: eval loss: 0.8357395377123946
Eval: 2022-04-28 01:00:38.599267: total loss: 1.076717235058895, mse:4.699946327798539, ic :0.13643372383645683, sharpe5:12.411596272587776, irr5:417.8885803222656, ndcg5:0.8540500891026926, pnl5:4.3317742347717285 
train 26, step: 0, loss: 6.694796918680112, grad_norm: 0.9433372180438782, ic: 0.10118482089481247
train 26, step: 500, loss: 3.9217394723661063, grad_norm: 3.3205763828612005, ic: 0.08538268809674504
train 26, step: 1000, loss: 1.2629712642268447, grad_norm: 2.2229794106008, ic: 0.1211044576966516
train 26, step: 1500, loss: 0.8504563646737165, grad_norm: 0.30669742492583363, ic: 0.15934703975795456
train 26, step: 2000, loss: 0.9727317395874312, grad_norm: 0.37287963328027607, ic: -0.02076136424951777
Epoch 26: 2022-04-28 01:23:08.414198: train loss: 1.6387483087637906
Eval step 0: eval loss: 0.8335612450811709
Eval: 2022-04-28 01:24:27.300584: total loss: 1.0738911890424738, mse:4.626654380924332, ic :0.1402905611027557, sharpe5:11.418185089230537, irr5:386.1073913574219, ndcg5:0.8591883573721115, pnl5:4.202220916748047 
train 27, step: 0, loss: 0.8298203890931373, grad_norm: 0.027786318461436338, ic: 0.0055843892186523275
train 27, step: 500, loss: 0.9203647616104631, grad_norm: 0.7655166000080937, ic: 0.260593474283302
train 27, step: 1000, loss: 0.765023994888341, grad_norm: 0.14619431884895212, ic: 0.005307163291228559
train 27, step: 1500, loss: 0.6351105832171519, grad_norm: 0.36152430358781923, ic: 0.5390085382854024
train 27, step: 2000, loss: 1.3813882536660023, grad_norm: 0.20053743395771068, ic: 0.0489449213883629
Epoch 27: 2022-04-28 01:46:35.185369: train loss: 1.6374847019470438
Eval step 0: eval loss: 0.8390768551600368
Eval: 2022-04-28 01:47:55.152928: total loss: 1.0760777354613624, mse:4.636784499261642, ic :0.14004763054220967, sharpe5:11.494556293487548, irr5:389.443359375, ndcg5:0.8544081986269689, pnl5:3.33122181892395 
train 28, step: 0, loss: 1.5652234405164092, grad_norm: 3.293806143861748, ic: 0.08111024300233251
train 28, step: 500, loss: 1.3741135061486864, grad_norm: 0.8714395021738368, ic: 0.12866275974259922
train 28, step: 1000, loss: 0.9428073293794461, grad_norm: 0.7957145132729476, ic: 0.5486995431973497
train 28, step: 1500, loss: 1.0680700863806332, grad_norm: 6.630615623533333, ic: 0.0014521400998539257
norm clip needed:  tensor(134.7133, device='cuda:0') backward_cells.0.Wn.weight torch.Size([640, 128])
train 28, step: 2000, loss: 1.0326344308677626, grad_norm: 18917.086084650506, ic: 0.03644911398786259
Epoch 28: 2022-04-28 02:10:23.352907: train loss: 1.6422617513160334
Eval step 0: eval loss: 0.8315596907106164
Eval: 2022-04-28 02:11:39.298049: total loss: 1.0791529528053063, mse:4.6897148033187515, ic :0.12426242392513699, sharpe5:11.822266581058502, irr5:405.6651611328125, ndcg5:0.8363761842924092, pnl5:4.107752323150635 
train 29, step: 0, loss: 0.9185195008943802, grad_norm: 268.45378126803166, ic: 0.02465664039958555
train 29, step: 500, loss: 1.2121738292718731, grad_norm: 13.500651256284357, ic: 0.32702130187061357
train 29, step: 1000, loss: 1.1141337748225248, grad_norm: 4.715723682198789, ic: 0.03596117503634008
train 29, step: 1500, loss: 2.379854415190769, grad_norm: 2.967546467310384, ic: 0.003769068152940645
train 29, step: 2000, loss: 4.5876186041184415, grad_norm: 13.392304831848126, ic: 0.060601748710997376
Epoch 29: 2022-04-28 02:33:51.697906: train loss: 1.649429218082608
Eval step 0: eval loss: 0.8290459941385668
Eval: 2022-04-28 02:35:16.720781: total loss: 1.0740330435096632, mse:4.692387892989723, ic :0.14794928909137464, sharpe5:12.263102016448974, irr5:430.5568542480469, ndcg5:0.8605125467255779, pnl5:3.4264416694641113 
train 30, step: 0, loss: 1.0445022535114565, grad_norm: 2.9829284808205934, ic: 0.42012992275258615
train 30, step: 500, loss: 1.4150818221582753, grad_norm: 11.84446733446506, ic: 0.0031399291690796492
train 30, step: 1000, loss: 0.9693002411813447, grad_norm: 34.968462104754785, ic: -0.06378850092372272
train 30, step: 1500, loss: 1.5415687663196305, grad_norm: 95.78392658108974, ic: 0.05140628899012974
train 30, step: 2000, loss: 1.848714254973221, grad_norm: 1.6700440654591762, ic: 0.014922088890409125
Epoch 30: 2022-04-28 02:57:25.252003: train loss: 1.6454985176837154
Eval step 0: eval loss: 0.8318654453289647
Eval: 2022-04-28 02:58:47.672473: total loss: 1.0752084326932692, mse:4.708155910592187, ic :0.14238356042294936, sharpe5:11.187288406491279, irr5:391.2762451171875, ndcg5:0.8468476423532703, pnl5:2.61210298538208 
train 31, step: 0, loss: 1.1025974836420802, grad_norm: 382.6084763413587, ic: 0.24179514039107394
train 31, step: 500, loss: 1.3383996029449587, grad_norm: 6.391580504577752, ic: 0.03949451931081335
train 31, step: 1000, loss: 4.356776169740437, grad_norm: 8.828718072240251, ic: 0.3921331999078014
train 31, step: 1500, loss: 0.9210414759487351, grad_norm: 16.562533201250375, ic: 0.4295578009604372
train 31, step: 2000, loss: 1.26386982184413, grad_norm: 2.6712831944941087, ic: -0.12233230482294292
Epoch 31: 2022-04-28 03:21:30.691858: train loss: 1.6462154955442052
Eval step 0: eval loss: 0.8361689705240714
Eval: 2022-04-28 03:22:53.001295: total loss: 1.0780414822427398, mse:4.717803565129286, ic :0.1331835444602744, sharpe5:11.09498497545719, irr5:380.4862060546875, ndcg5:0.8521080328020663, pnl5:3.315962791442871 
train 32, step: 0, loss: 1.1435970267744058, grad_norm: 1.0251836350785117, ic: 0.11733986587851428
train 32, step: 500, loss: 1.4959408256951279, grad_norm: 1.9252357083629164, ic: 0.09040350180261658
train 32, step: 1000, loss: 1.048008488488875, grad_norm: 1.0255334086132253, ic: 0.4976132329328767
train 32, step: 1500, loss: 1.0103684344608124, grad_norm: 1.8830401194121758, ic: 0.01083525371941893
train 32, step: 2000, loss: 1.0043392569690777, grad_norm: 0.3911286733196526, ic: 0.48958550600866835
Epoch 32: 2022-04-28 03:45:00.581790: train loss: 1.6453458582009495
Eval step 0: eval loss: 0.8278403407781216
Eval: 2022-04-28 03:46:22.076220: total loss: 1.0742819287369423, mse:4.686641712264282, ic :0.13879464755254306, sharpe5:11.74895450055599, irr5:389.4315490722656, ndcg5:0.8601308301451587, pnl5:3.239936113357544 
train 33, step: 0, loss: 1.2666692328676206, grad_norm: 0.5427293604045766, ic: 0.18242235518313227
train 33, step: 500, loss: 1.1017863111153552, grad_norm: 6.6934847609212085, ic: -0.02299353008326175
train 33, step: 1000, loss: 1.0804326915025455, grad_norm: 1.9208872012976546, ic: 0.10196900812764853
train 33, step: 1500, loss: 0.9375706646648874, grad_norm: 0.35203280969697137, ic: 0.4845908666039088
train 33, step: 2000, loss: 0.831822898610836, grad_norm: 0.45122518539937195, ic: 0.16021307911331514
Epoch 33: 2022-04-28 04:08:35.528648: train loss: 1.6445103280071125
Eval step 0: eval loss: 0.8339783293680848
Eval: 2022-04-28 04:09:58.333308: total loss: 1.0764979332095541, mse:4.711579880179778, ic :0.14045023517085609, sharpe5:12.072058129906655, irr5:416.1961364746094, ndcg5:0.85053151854981, pnl5:3.670093059539795 
train 34, step: 0, loss: 1.079216093424705, grad_norm: 1.1573407093100418, ic: 0.46382467764924007
train 34, step: 500, loss: 0.8323774891891246, grad_norm: 0.9149840017372683, ic: 0.037409480182173264
train 34, step: 1000, loss: 3.263410858294931, grad_norm: 35.46126150734533, ic: 0.17237161602045376
train 34, step: 1500, loss: 0.8793549566075685, grad_norm: 0.44719515644236535, ic: 0.4412844962653733
train 34, step: 2000, loss: 6.942435006777692, grad_norm: 24.656286639446982, ic: 0.2224916174074419
Epoch 34: 2022-04-28 04:32:14.210090: train loss: 1.647280926907077
Eval step 0: eval loss: 0.83447040521684
Eval: 2022-04-28 04:33:39.122287: total loss: 1.0772452315456646, mse:4.778072903685588, ic :0.14657310098967807, sharpe5:12.563887474536894, irr5:407.2910461425781, ndcg5:0.8552009186916054, pnl5:4.961032390594482 
train 35, step: 0, loss: 1.3009129423253676, grad_norm: 5.493934738911722, ic: 0.3470098338726747
train 35, step: 500, loss: 1.191861393601799, grad_norm: 2.3136568312686117, ic: 0.044176762241603315
train 35, step: 1000, loss: 2.0068634097996285, grad_norm: 4.508582446130663, ic: 0.05301383799328736
train 35, step: 1500, loss: 1.525382089256344, grad_norm: 8.57486095873823, ic: 0.025998425062739278
train 35, step: 2000, loss: 0.821873384363511, grad_norm: 0.306892564428994, ic: 0.47456573173008865
Epoch 35: 2022-04-28 04:55:58.471248: train loss: 1.6495862439527424
Eval step 0: eval loss: 0.8431399056984324
Eval: 2022-04-28 04:57:18.867667: total loss: 1.0807138578478765, mse:4.737033312809171, ic :0.1405557111327305, sharpe5:12.405907475352286, irr5:398.66668701171875, ndcg5:0.8461973788010269, pnl5:5.2333526611328125 
train 36, step: 0, loss: 1.8805922383977631, grad_norm: 5.3586771889349505, ic: -0.039821952059288866
train 36, step: 500, loss: 0.8558739195478724, grad_norm: 0.16280688630616807, ic: 0.0726769650408644
train 36, step: 1000, loss: 1.6858384232954544, grad_norm: 1.410808507356639, ic: 0.16984712273063826
train 36, step: 1500, loss: 0.8067876804641813, grad_norm: 0.11006331764735355, ic: 0.17781904907733032
train 36, step: 2000, loss: 1.164717840144708, grad_norm: 2.245539237469603, ic: 0.7199837056921382
Epoch 36: 2022-04-28 05:19:03.529645: train loss: 1.643125719861985
Eval step 0: eval loss: 0.8259655517320863
Eval: 2022-04-28 05:20:27.209732: total loss: 1.0751959944497251, mse:4.67425623598106, ic :0.1393298645302242, sharpe5:11.574413233995436, irr5:394.1772766113281, ndcg5:0.8564097879497853, pnl5:2.644707679748535 
train 37, step: 0, loss: 2.1617452203771057, grad_norm: 5.531323935445993, ic: 0.04996317913804681
train 37, step: 500, loss: 2.33867123776509, grad_norm: 2.737863441083939, ic: 0.020779595171052
train 37, step: 1000, loss: 1.0896081561548705, grad_norm: 5.901667403718322, ic: -0.05819154451959407
train 37, step: 1500, loss: 2.0418701171875, grad_norm: 17.820948022920476, ic: 0.4575165261499077
train 37, step: 2000, loss: 1.336454372469373, grad_norm: 7.374484196669396, ic: -0.03833751095596584
Epoch 37: 2022-04-28 05:42:48.083567: train loss: 1.6444660823700854
Eval step 0: eval loss: 0.8417132651969178
Eval: 2022-04-28 05:44:16.557680: total loss: 1.0822628165678905, mse:4.8197610039124985, ic :0.037251407776974804, sharpe5:7.6574890440702434, irr5:211.62289428710938, ndcg5:0.8232117573005109, pnl5:2.5470211505889893 
train 38, step: 0, loss: 1.287589282524295, grad_norm: 335.08757882947106, ic: -0.013274665379674568
train 38, step: 500, loss: 0.9283736617476852, grad_norm: 0.5352603444728465, ic: 0.05950138886007511
train 38, step: 1000, loss: 0.8804355545948617, grad_norm: 170.12395400673103, ic: 0.030014434275217987
train 38, step: 1500, loss: 0.9708945260594628, grad_norm: 20.565107807014066, ic: 0.057447879329008425
train 38, step: 2000, loss: 2.331242771667296, grad_norm: 18.112750057576086, ic: 0.014230571210156695
Epoch 38: 2022-04-28 06:06:46.585696: train loss: 1.6478482240750423
Eval step 0: eval loss: 0.8335028468494796
Eval: 2022-04-28 06:08:12.670489: total loss: 1.0766367605199687, mse:4.687263487732079, ic :0.1344006836767384, sharpe5:11.054046256542206, irr5:370.9573059082031, ndcg5:0.8481160848996793, pnl5:2.5080924034118652 
train 39, step: 0, loss: 0.9737583358717986, grad_norm: 22.97083617881556, ic: 0.08267163485454053
train 39, step: 500, loss: 0.9135117292587432, grad_norm: 2.3551601449565593, ic: 0.021206170756607367
train 39, step: 1000, loss: 0.9652496593559596, grad_norm: 0.8305192021233466, ic: 0.0798821689604404
train 39, step: 1500, loss: 2.1083345972414818, grad_norm: 0.3118672834649481, ic: -0.019630134701456407
train 39, step: 2000, loss: 0.62651040316758, grad_norm: 0.1857564864922394, ic: 0.02239843233385289
Epoch 39: 2022-04-28 06:30:53.438721: train loss: 1.646051387322782
Eval step 0: eval loss: 0.8356682764340753
Eval: 2022-04-28 06:32:21.561237: total loss: 1.076778355789397, mse:4.677166327641244, ic :0.13262517261888374, sharpe5:11.303296735882759, irr5:357.80950927734375, ndcg5:0.8438031730233024, pnl5:3.5978751182556152 

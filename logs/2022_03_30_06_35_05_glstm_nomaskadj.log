Namespace(train_path='./data/train_2305_1931_12.npy', test_path='./data/test_126_1931_12.npy', train_mask_path='./data/train_mask_2305_1931.npy', test_mask_path='./data/test_mask_126_1931.npy', label_cnt=3, batch_size=1, lr=0.001, adj_path='./data/concepts_graph_1931_233_3.npy', model_type='GLSTM', dataset_type='AdjTimeDataset', seed=10086, num_days=8, epochs=20, hidden_dim=128, input_dim=9, dout=0.3, lstm_layers=1, num_heads=1, gnn_layers=2, print_inteval=500, relation_num=1, mask_type='soft', shuffle=True, input_graph=True, use_adj=False, mask_adj=False)
834876
GLSTM(
  (input_to_hidden): Linear(in_features=9, out_features=128, bias=True)
  (glstm_cell): GLSTMCell(
    (dropout): Dropout(p=0.3, inplace=False)
    (Wh): Linear(in_features=128, out_features=640, bias=False)
    (Wn): Linear(in_features=128, out_features=640, bias=False)
    (Wt): Linear(in_features=128, out_features=640, bias=False)
    (U): Linear(in_features=128, out_features=640, bias=False)
    (V): Linear(in_features=128, out_features=640, bias=True)
    (relu): LeakyReLU(negative_slope=0.01)
    (gnn): ModuleList(
      (0): GraphConv(128, 128)
      (1): GraphConv(128, 128)
    )
  )
  (w_out): Linear(in_features=128, out_features=1, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
)
train 0, step: 0, loss: 1.3512021685959001, grad_norm: 4.048663404253795, ic: 0.07032990217181787
train 0, step: 500, loss: 2.0853846504912372, grad_norm: 2.1346579056330635, ic: 0.2016030403644023
train 0, step: 1000, loss: 2.491484404887146, grad_norm: 0.3998586731641968, ic: 0.05538371308117583
train 0, step: 1500, loss: 2.059852518061156, grad_norm: 1.923789835068599, ic: 0.019237270188707502
train 0, step: 2000, loss: 1.452789986247349, grad_norm: 0.46310270832955625, ic: 0.08492672746536166
Epoch 0: train loss: 1.6319397903518302
Eval step 0: eval loss: 0.8325174742463137
Eval: total loss: 1.0731827624397339, mse:4.631957109047174, ic :-0.0014152133387064396, sharpe5:0.8796808795630932, irr5:10.760680198669434, ndcg5:0.8476333274407399 
train 1, step: 0, loss: 1.9992769537250383, grad_norm: 0.0007439382476923359, ic: 0.08470365383446112
train 1, step: 500, loss: 1.184301493400271, grad_norm: 0.3488538808204286, ic: 0.07315499483029356
train 1, step: 1000, loss: 1.028368836162802, grad_norm: 0.0123658182794948, ic: 0.05763253446287259
train 1, step: 1500, loss: 8.8850399064429, grad_norm: 1.049961524549503, ic: 0.09598431421831738
train 1, step: 2000, loss: 1.283054138562694, grad_norm: 0.06544500121963757, ic: 0.08272038263244456
Epoch 1: train loss: 1.6281420386011234
Eval step 0: eval loss: 0.8384255745211294
Eval: total loss: 1.0749066363876643, mse:4.629555425348349, ic :0.00047496652986753587, sharpe5:0.5870426796376705, irr5:6.657674789428711, ndcg5:0.8349955596321704 
train 2, step: 0, loss: 1.4824913006922624, grad_norm: 0.9611937276358267, ic: -0.08657497172699846
train 2, step: 500, loss: 1.751188684682377, grad_norm: 0.7917778927723613, ic: 0.026251716977244672
train 2, step: 1000, loss: 1.2448928972145707, grad_norm: 0.29761003664418334, ic: 0.030613755026101995
train 2, step: 1500, loss: 1.4642051569040144, grad_norm: 0.21788028973275375, ic: 0.03889547726625359
train 2, step: 2000, loss: 0.8714710582386364, grad_norm: 0.3459932614568915, ic: -0.047246405154717355
Epoch 2: train loss: 1.627973184835808
Eval step 0: eval loss: 0.8305871048495919
Eval: total loss: 1.0739597040858089, mse:4.642405684574281, ic :0.0017561131389441894, sharpe5:0.375386598855257, irr5:3.84226131439209, ndcg5:0.8424641052291427 
train 3, step: 0, loss: 0.7373565927436807, grad_norm: 0.03734377220699722, ic: -0.009000128081791915
train 3, step: 500, loss: 0.816719442102162, grad_norm: 0.02042018027740442, ic: 0.06409819300790345
train 3, step: 1000, loss: 3.1916414586509148, grad_norm: 0.6462483692766504, ic: 0.12747476592622695
train 3, step: 1500, loss: 1.327310663838187, grad_norm: 0.0310906872806376, ic: 0.057252037166074375
train 3, step: 2000, loss: 1.1220303838867982, grad_norm: 0.007514168212217628, ic: 0.04600003168185506
Epoch 3: train loss: 1.628715513567216
Eval step 0: eval loss: 0.8349430029991113
Eval: total loss: 1.07352667690015, mse:4.628740143752104, ic :0.0019964516303600625, sharpe5:1.0171688170731068, irr5:11.571556091308594, ndcg5:0.8341270521496972 
train 4, step: 0, loss: 3.259559637220939, grad_norm: 0.6693199369826713, ic: 0.07525620640411838
train 4, step: 500, loss: 0.786662904934056, grad_norm: 1.2383440367591655e-05, ic: 0.001694678585638504
train 4, step: 1000, loss: 1.1042080995922074, grad_norm: 0.1749855530119521, ic: -0.06964523125810551
train 4, step: 1500, loss: 0.8839857415965393, grad_norm: 0.006606701077498734, ic: -0.011899073287756669
train 4, step: 2000, loss: 1.039985849961627, grad_norm: 0.03201919821257849, ic: 0.09353180990620262
Epoch 4: train loss: 1.6282894577930433
Eval step 0: eval loss: 0.8359670051466231
Eval: total loss: 1.0737849520485128, mse:4.628310127556071, ic :0.003786407401501577, sharpe5:0.9430667703598737, irr5:10.583877563476562, ndcg5:0.8325890979346281 
train 5, step: 0, loss: 1.1004684722776408, grad_norm: 0.021077105782969854, ic: 0.008997290335456605
train 5, step: 500, loss: 3.3942882449127905, grad_norm: 0.2075315722771356, ic: 0.06165117370991339
train 5, step: 1000, loss: 1.1735169107329717, grad_norm: 0.21647055291364836, ic: -0.009350074903656221
train 5, step: 1500, loss: 1.063764121429119, grad_norm: 0.08771337869191088, ic: 0.05666266854581496
train 5, step: 2000, loss: 0.9341792808813324, grad_norm: 0.05933921144322009, ic: 0.04031501133752661
Epoch 5: train loss: 1.628217088306845
Eval step 0: eval loss: 0.8368271540942601
Eval: total loss: 1.0740620943699368, mse:4.628280515104493, ic :0.004101181741813405, sharpe5:0.6082116102799773, irr5:6.5542378425598145, ndcg5:0.8343240359479419 
train 6, step: 0, loss: 1.0524295806884767, grad_norm: 0.010651130528558594, ic: 0.02071314161294935
train 6, step: 500, loss: 5.408923185324367, grad_norm: 0.6633422649383076, ic: 0.07351133041815874
train 6, step: 1000, loss: 2.9684680138677813, grad_norm: 0.6636489444854281, ic: 0.029265663137591363
train 6, step: 1500, loss: 0.8662110306834446, grad_norm: 0.028210435738660933, ic: 0.07535243104633894
train 6, step: 2000, loss: 2.8418625480860564, grad_norm: 0.7566013070999752, ic: -0.024745718310535587
Epoch 6: train loss: 1.6280138235218156
Eval step 0: eval loss: 0.8509124868351763
Eval: total loss: 1.0817101254748214, mse:4.646980957836534, ic :0.005667178914037218, sharpe5:0.24335898796096442, irr5:1.8527803421020508, ndcg5:0.8384361667980889 
train 7, step: 0, loss: 1.6438248929604093, grad_norm: 0.3571215960248137, ic: -0.10192463927130867
train 7, step: 500, loss: 1.270611798321759, grad_norm: 0.2830915678562286, ic: -0.04227034753295848
train 7, step: 1000, loss: 1.6844776582819134, grad_norm: 0.0074694227581627495, ic: 0.22974968631345094
train 7, step: 1500, loss: 1.673399435902556, grad_norm: 0.1270897655128315, ic: 0.20894598866523198
train 7, step: 2000, loss: 0.7934303947561078, grad_norm: 0.0011306754065440055, ic: 0.01992541414917274
Epoch 7: train loss: 1.6278951605510323
Eval step 0: eval loss: 0.8419382940034228
Eval: total loss: 1.076382388453039, mse:4.632079463766089, ic :0.008142874686904408, sharpe5:0.43975249825045465, irr5:4.307140350341797, ndcg5:0.8357812778485595 
train 8, step: 0, loss: 1.326975122014102, grad_norm: 0.4138134340817595, ic: 0.013688749255398355
train 8, step: 500, loss: 1.186279220676303, grad_norm: 0.48524639925616275, ic: 0.07578626232716022
train 8, step: 1000, loss: 1.175382420274078, grad_norm: 0.01065610434375109, ic: -0.05593819333249441
train 8, step: 1500, loss: 1.1842234365765367, grad_norm: 0.47166111879746614, ic: -0.0443802355327901
train 8, step: 2000, loss: 0.9724079901298868, grad_norm: 0.04313230253915651, ic: 0.053262423521412354
Epoch 8: train loss: 1.6275514083514622
Eval step 0: eval loss: 0.8510710046817404
Eval: total loss: 1.0815683016165971, mse:4.645557636447779, ic :0.01007898064740931, sharpe5:0.7009676667675375, irr5:7.461158752441406, ndcg5:0.8302704817542854 
train 9, step: 0, loss: 0.8746250164253632, grad_norm: 0.1487626663393954, ic: 0.029446241223808265
train 9, step: 500, loss: 1.2365394650524808, grad_norm: 0.10358078459927515, ic: -0.019059539914845873
train 9, step: 1000, loss: 0.8896051068339523, grad_norm: 0.23861373424799023, ic: 0.12722185848461257
train 9, step: 1500, loss: 0.9464717515044542, grad_norm: 0.08991047215463356, ic: 0.14058730179309356
train 9, step: 2000, loss: 0.8163457455842391, grad_norm: 0.012984073659984264, ic: 0.011334737124878962
Epoch 9: train loss: 1.6279492721721662
Eval step 0: eval loss: 0.8375690896113085
Eval: total loss: 1.074132907207794, mse:4.627053367940811, ic :0.01845804584634828, sharpe5:0.5018726517632603, irr5:4.897519111633301, ndcg5:0.8418416533553154 
train 10, step: 0, loss: 2.0356456792466693, grad_norm: 0.5484823767755362, ic: 0.0035039814028285363
train 10, step: 500, loss: 1.093713545871723, grad_norm: 0.3451094837994489, ic: 0.04893225183335005
train 10, step: 1000, loss: 1.8973280603469014, grad_norm: 0.22132550432955658, ic: 0.11480149310176102
train 10, step: 1500, loss: 0.8521854264768836, grad_norm: 0.2165377045250907, ic: 0.02515200168493525
train 10, step: 2000, loss: 1.1263787352316899, grad_norm: 0.3309388124647151, ic: 0.06095005178345875
Epoch 10: train loss: 1.627525311336137
Eval step 0: eval loss: 0.8372179847946287
Eval: total loss: 1.073921601455718, mse:4.626572849683806, ic :0.021368065653764, sharpe5:0.5222331115230918, irr5:5.210280895233154, ndcg5:0.8302683579766018 
train 11, step: 0, loss: 1.1010489327566964, grad_norm: 0.263068743903501, ic: 0.09913124853220051
train 11, step: 500, loss: 0.9350507112475934, grad_norm: 0.007446883667238346, ic: 0.029498621376153698
train 11, step: 1000, loss: 2.094237161338876, grad_norm: 0.007198896952256932, ic: -0.055431761671843785
train 11, step: 1500, loss: 1.8302241345472041, grad_norm: 0.6540436947814474, ic: -0.14825296395526213
train 11, step: 2000, loss: 1.3660681333764597, grad_norm: 0.03016214737955863, ic: 0.21385687323577082
Epoch 11: train loss: 1.6275172212323459
Eval step 0: eval loss: 0.8434688975900144
Eval: total loss: 1.0762519057815376, mse:4.6287481654845175, ic :0.02995896704068518, sharpe5:0.5513638397678733, irr5:5.392139434814453, ndcg5:0.8395815732557741 
train 12, step: 0, loss: 2.43369336528908, grad_norm: 0.5816337421840865, ic: -0.0022936388124486073
train 12, step: 500, loss: 1.0579841956313776, grad_norm: 0.194826034351032, ic: -0.020759700255433566
train 12, step: 1000, loss: 0.8773138745087666, grad_norm: 0.01066303597369714, ic: -0.010270843209141164
train 12, step: 1500, loss: 1.6826491215058017, grad_norm: 0.36609944429968744, ic: -0.17792823657507167
train 12, step: 2000, loss: 1.7893464710790787, grad_norm: 0.819523064858413, ic: -0.14842521083152743
Epoch 12: train loss: 1.6275384597112128
Eval step 0: eval loss: 0.8388031632602685
Eval: total loss: 1.0731736284644868, mse:4.621358702091325, ic :0.04379471731781845, sharpe5:0.15988537439145148, irr5:0.9451429843902588, ndcg5:0.8481114765450649 
train 13, step: 0, loss: 0.9045531101490495, grad_norm: 0.026353423409144486, ic: 0.054602352141834364
train 13, step: 500, loss: 1.1867380702439232, grad_norm: 0.22209234607012657, ic: -0.04317424982786569
train 13, step: 1000, loss: 1.4878083557641806, grad_norm: 0.19783081175166126, ic: -0.1312956384928849
train 13, step: 1500, loss: 2.759729981235283, grad_norm: 0.718859703467585, ic: 0.012127187520913945
train 13, step: 2000, loss: 0.8455334757395128, grad_norm: 0.0005692287032351751, ic: 0.01084001220300144
Epoch 13: train loss: 1.6275019703116997
Eval step 0: eval loss: 0.8386005483971827
Eval: total loss: 1.0729869762932513, mse:4.620271102935919, ic :0.04759047095277073, sharpe5:1.7242433211207389, irr5:18.449539184570312, ndcg5:0.8351110285535535 
train 14, step: 0, loss: 1.2130148303826045, grad_norm: 0.26084559185217093, ic: 0.07454361763397623
train 14, step: 500, loss: 1.122643098008209, grad_norm: 0.04868851739003593, ic: 0.35590841689981384
train 14, step: 1000, loss: 1.3398215553977273, grad_norm: 0.0687914819273005, ic: 0.13373891712501185
train 14, step: 1500, loss: 2.281088515135188, grad_norm: 0.07888086514602553, ic: 0.05219968553321238
train 14, step: 2000, loss: 1.2648082699195569, grad_norm: 0.4489419648272398, ic: 0.0836340128930159
Epoch 14: train loss: 1.6266748683280337
Eval step 0: eval loss: 0.8358214078544628
Eval: total loss: 1.0725776176829824, mse:4.631129552547807, ic :0.039791471499415705, sharpe5:0.9706759179756045, irr5:11.097265243530273, ndcg5:0.8366267753144221 
train 15, step: 0, loss: 1.3347632067097597, grad_norm: 0.012877066695906611, ic: 0.17499893532185157
train 15, step: 500, loss: 1.2062490989842087, grad_norm: 0.31673918787644756, ic: -0.02015371154222019
train 15, step: 1000, loss: 0.9208588203600405, grad_norm: 0.13257130930324917, ic: -0.052706989796173026
train 15, step: 1500, loss: 0.9100363088208576, grad_norm: 0.0012947311488938791, ic: -0.10970500046392839
train 15, step: 2000, loss: 8.087426928011233, grad_norm: 0.8378471941585528, ic: 0.016294287655137078
Epoch 15: train loss: 1.6269220584550204
Eval step 0: eval loss: 0.8373887803819444
Eval: total loss: 1.0727439527846885, mse:4.62141752241443, ic :0.04407431817415163, sharpe5:0.37850909963250157, irr5:3.31864070892334, ndcg5:0.852108902267115 
train 16, step: 0, loss: 1.1621130662963697, grad_norm: 0.1554058992887585, ic: 0.06987252959983638
train 16, step: 500, loss: 0.8692185401143045, grad_norm: 0.0006742652465602307, ic: 0.0026718225866575636
train 16, step: 1000, loss: 1.0211493796966642, grad_norm: 0.019795350995439734, ic: -0.06401668515507064
train 16, step: 1500, loss: 1.0973804270038168, grad_norm: 0.012029380522341484, ic: 0.10446455562741165
train 16, step: 2000, loss: 0.9906834293706962, grad_norm: 0.10899612640843086, ic: 0.07108229765718584
Epoch 16: train loss: 1.6265378992652961
Eval step 0: eval loss: 0.837396686989863
Eval: total loss: 1.0734104718589759, mse:4.6234881255462925, ic :0.0382378686002011, sharpe5:2.424148654192686, irr5:23.16950035095215, ndcg5:0.8727773532910698 
train 17, step: 0, loss: 1.1004339534579528, grad_norm: 0.13337769711285644, ic: 0.13338537668654857
train 17, step: 500, loss: 0.9914478088689179, grad_norm: 0.04083179708448563, ic: 0.24410710710830213
train 17, step: 1000, loss: 2.129199859352223, grad_norm: 0.018932955993275557, ic: -0.016065133575887052
train 17, step: 1500, loss: 0.888750804774168, grad_norm: 0.22234932940778052, ic: 0.14702305599418425
train 17, step: 2000, loss: 1.1250405962941283, grad_norm: 0.05355232996251764, ic: 0.2789685961891216
Epoch 17: train loss: 1.6264619374789184
Eval step 0: eval loss: 0.8343392081358609
Eval: total loss: 1.0728858783066606, mse:4.636712247386354, ic :0.038691789510658686, sharpe5:1.0342957480251789, irr5:9.990599632263184, ndcg5:0.8497797297077527 
train 18, step: 0, loss: 0.9303020544424254, grad_norm: 0.13644724501900532, ic: 0.1773151815963439
train 18, step: 500, loss: 1.0119729767434846, grad_norm: 0.07646849279439566, ic: 0.20444658545289388
train 18, step: 1000, loss: 0.946071091409371, grad_norm: 0.27571246183892917, ic: 0.032453786860213434
train 18, step: 1500, loss: 7.601557922363281, grad_norm: 1.1748348394705133, ic: 0.06321361461180156
train 18, step: 2000, loss: 0.7870525330987596, grad_norm: 0.07744696184053537, ic: 0.04857768564681242
Epoch 18: train loss: 1.626493159843361
Eval step 0: eval loss: 0.839102328733873
Eval: total loss: 1.0728918613675669, mse:4.622127396197427, ic :0.046338333615369466, sharpe5:1.6977803398668765, irr5:20.077438354492188, ndcg5:0.8401949385608501 
train 19, step: 0, loss: 1.28623437428666, grad_norm: 0.1196995548471978, ic: 0.1438504406494905
train 19, step: 500, loss: 1.4735257399397357, grad_norm: 0.1858239621288418, ic: 0.013106111545146676
train 19, step: 1000, loss: 1.901721928117838, grad_norm: 0.03909443494164592, ic: 0.04539828079614367
train 19, step: 1500, loss: 1.4134361766209111, grad_norm: 0.605806947127739, ic: -0.0015994128680261346
train 19, step: 2000, loss: 1.3545993553858147, grad_norm: 0.07575574154452731, ic: 0.2528382602230622
Epoch 19: train loss: 1.6289450769951146
Eval step 0: eval loss: 0.8413623329713006
Eval: total loss: 1.0740285885567509, mse:4.62336011954844, ic :0.04203201286724241, sharpe5:2.3447481228411196, irr5:22.486387252807617, ndcg5:0.8546441686490914 

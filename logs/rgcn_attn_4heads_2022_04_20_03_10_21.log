Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='AdjSeqTimeDataset', dout=0.3, epochs=40, glstm_layers=1, gnn_layers=2, gpu=0, graph_attn=True, hidden_dim=128, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=3, mask_adj=True, mask_type='soft', model_type='RGCNModel', normalize_adj=True, num_days=1, num_heads=4, print_inteval=500, relation_num=1, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_250_0.8/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
34977
RGCNModel(
  (fc1): Linear(in_features=9, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=128, bias=True)
  (fc3): Linear(in_features=2048, out_features=128, bias=True)
  (fc4): Linear(in_features=128, out_features=1, bias=True)
  (gnns): ModuleList(
    (0): RGCN(
      (attention): ModuleList(
        (0): GraphAttentionLayer (128 -> 128)
      )
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
    )
    (1): RGCN(
      (attention): ModuleList(
        (0): GraphAttentionLayer (512 -> 512)
      )
      (lin_rel): ModuleList(
        (0): Linear(in_features=512, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=512, out_features=128, bias=False)
      )
    )
  )
  (dropout): Dropout(p=0.3, inplace=False)
  (relu): LeakyReLU(negative_slope=0.01)
)
train 0, step: 0, loss: 2.046123085474308, grad_norm: 0.6696054152707522, ic: 0.08860472704682132
train 0, step: 500, loss: 1.4233115241778809, grad_norm: 0.7306900552086051, ic: -0.03289372795993867
train 0, step: 1000, loss: 1.516400176452537, grad_norm: 0.034990657004039125, ic: -0.04403457710199122
train 0, step: 1500, loss: 1.1878672430462145, grad_norm: 0.09517226429000238, ic: 0.01805845508093773
train 0, step: 2000, loss: 1.5551289814274487, grad_norm: 0.04159791392447875, ic: -0.008278033231760842
Epoch 0: 2022-04-20 15:11:35.038678: train loss: 1.648595731989992
Eval step 0: eval loss: 1.0133070782525342
Eval: 2022-04-20 15:11:39.266634: total loss: 1.091162464642096, mse:4.888559523150542, ic :0.0015302062461471657, sharpe5:0.694153336174786, irr5:8.745415687561035, ndcg5:0.8422700869645547, pnl5:0.9220432639122009 
train 1, step: 0, loss: 0.6433517909286046, grad_norm: 0.04917440755729181, ic: 0.07241527564510507
train 1, step: 500, loss: 1.3303600976038876, grad_norm: 0.5403669867475324, ic: -0.02971300789863729
train 1, step: 1000, loss: 0.8872921494535141, grad_norm: 0.06471773599173897, ic: -0.0018317675560264434
train 1, step: 1500, loss: 1.8400480689072027, grad_norm: 0.4911242106568845, ic: -0.04575456609349651
train 1, step: 2000, loss: 1.3787902551624713, grad_norm: 0.2126145674982155, ic: 0.0028364975551981014
Epoch 1: 2022-04-20 15:12:46.887605: train loss: 1.6464062598978437
Eval step 0: eval loss: 1.0131976070876119
Eval: 2022-04-20 15:12:51.077443: total loss: 1.0908926598024642, mse:4.888344819360218, ic :0.009689496985128894, sharpe5:0.9138930616155266, irr5:6.977439880371094, ndcg5:0.8327840328738463, pnl5:1.019343376159668 
train 2, step: 0, loss: 1.3189777563169809, grad_norm: 0.46647370188302717, ic: -0.02813836618674534
train 2, step: 500, loss: 0.9381608282850437, grad_norm: 0.2385369357887958, ic: 0.06182404281796577
train 2, step: 1000, loss: 2.953927290193145, grad_norm: 0.7803006068674387, ic: -0.02342728875522831
train 2, step: 1500, loss: 2.2818602547581284, grad_norm: 0.8081633458685613, ic: 0.015125989439122689
train 2, step: 2000, loss: 1.4697946344158832, grad_norm: 0.2707020716013262, ic: -0.004577842848399471
Epoch 2: 2022-04-20 15:13:58.362878: train loss: 1.6463319886675902
Eval step 0: eval loss: 1.0135467834633358
Eval: 2022-04-20 15:14:02.212704: total loss: 1.0916491038709553, mse:4.889161000836513, ic :-0.0022406866648920594, sharpe5:1.2347664937376976, irr5:11.845680236816406, ndcg5:0.8473774102391747, pnl5:1.0370665788650513 
train 3, step: 0, loss: 1.8174070958062356, grad_norm: 0.05316757459918488, ic: 0.08995270277024481
train 3, step: 500, loss: 0.7867381106989813, grad_norm: 0.023697193049392006, ic: 0.026238603898849754
train 3, step: 1000, loss: 1.4384161776422184, grad_norm: 0.3514549584180634, ic: 0.09215523048832852
train 3, step: 1500, loss: 2.654255335218484, grad_norm: 0.3492202785278031, ic: -0.0022025787366929256
train 3, step: 2000, loss: 1.3633310029000947, grad_norm: 0.15688869634144217, ic: 0.009158454673878083
Epoch 3: 2022-04-20 15:15:09.873343: train loss: 1.646385174396669
Eval step 0: eval loss: 1.0136049580988349
Eval: 2022-04-20 15:15:13.920585: total loss: 1.0917585746858538, mse:4.8893235203557746, ic :0.026233304758163142, sharpe5:1.9945680794119833, irr5:13.793682098388672, ndcg5:0.8372953788135232, pnl5:1.1157132387161255 
train 4, step: 0, loss: 1.1705953984137176, grad_norm: 0.14640327513642282, ic: 0.0075439698402736
train 4, step: 500, loss: 0.9983935335497837, grad_norm: 0.002442701190370554, ic: 0.08143284206470797
train 4, step: 1000, loss: 1.3370354810259344, grad_norm: 0.05999960211625704, ic: 0.04679545193221402
train 4, step: 1500, loss: 1.095051066080729, grad_norm: 0.07262692138453791, ic: 0.22112537455522577
train 4, step: 2000, loss: 4.16846433049764, grad_norm: 0.8732044345945382, ic: -0.06632849810861326
Epoch 4: 2022-04-20 15:16:21.140198: train loss: 1.647160480295829
Eval step 0: eval loss: 1.0189000069938126
Eval: 2022-04-20 15:16:25.218280: total loss: 1.0990073602329737, mse:4.90738988705843, ic :0.007769019942694575, sharpe5:6.22492428123951, irr5:191.4799346923828, ndcg5:0.8536892554910519, pnl5:2.124342441558838 
train 5, step: 0, loss: 1.005362912342917, grad_norm: 0.42811859903057, ic: -0.04411541400854315
train 5, step: 500, loss: 0.7973029210480845, grad_norm: 0.002354907092183181, ic: 0.04758792577666264
train 5, step: 1000, loss: 1.1136803171014091, grad_norm: 0.03110964297297598, ic: 0.014834562985840072
train 5, step: 1500, loss: 1.729467574949187, grad_norm: 0.29569346503978194, ic: -0.06901262451534677
train 5, step: 2000, loss: 2.1953934048061603, grad_norm: 0.7668730582468093, ic: -0.012380055662201942
Epoch 5: 2022-04-20 15:17:32.803581: train loss: 1.6465392505860215
Eval step 0: eval loss: 1.0135820096514612
Eval: 2022-04-20 15:17:37.201193: total loss: 1.0916974561913102, mse:4.889254996921409, ic :-0.02256399080380921, sharpe5:-2.385781434327364, irr5:-41.63643264770508, ndcg5:0.8455107198515374, pnl5:0.8081456422805786 
train 6, step: 0, loss: 0.7739220213841119, grad_norm: 0.009202482999109685, ic: -0.016144524841471976
train 6, step: 500, loss: 1.4560992146096035, grad_norm: 0.21315707599342515, ic: 0.01412128589825732
train 6, step: 1000, loss: 1.247093537014211, grad_norm: 0.1683321017266017, ic: 0.06373469259734335
train 6, step: 1500, loss: 1.0795701282429244, grad_norm: 0.2981308035675851, ic: 0.008241955381040618
train 6, step: 2000, loss: 2.2727682110525778, grad_norm: 0.8909489882655867, ic: 0.007312973738310054
Epoch 6: 2022-04-20 15:18:44.463883: train loss: 1.646364621914811
Eval step 0: eval loss: 1.0134194420788902
Eval: 2022-04-20 15:18:48.315134: total loss: 1.0914017579918134, mse:4.888825750976316, ic :0.018280320636545406, sharpe5:0.7185881935805082, irr5:8.173379898071289, ndcg5:0.8422988376345564, pnl5:1.088113784790039 
train 7, step: 0, loss: 1.4565481974619028, grad_norm: 0.47113832199337424, ic: 0.027781884965238934
train 7, step: 500, loss: 1.3321115304757885, grad_norm: 0.021205056164630705, ic: 0.02809058338498846
train 7, step: 1000, loss: 0.6639676790409857, grad_norm: 0.003514570911282008, ic: 0.18686466433228946
train 7, step: 1500, loss: 1.006823758573964, grad_norm: 0.12256196998697398, ic: 0.02851634151316257
train 7, step: 2000, loss: 1.5835781188094296, grad_norm: 0.5296587519855538, ic: 0.41118913442408245
Epoch 7: 2022-04-20 15:19:55.352645: train loss: 1.6470082983065057
Eval step 0: eval loss: 1.0136435269179502
Eval: 2022-04-20 15:19:59.500940: total loss: 1.0883499578767986, mse:4.728733671698309, ic :0.08152365611417704, sharpe5:6.214015865921974, irr5:191.96678161621094, ndcg5:0.8377485851440434, pnl5:2.371305465698242 
train 8, step: 0, loss: 1.2188886549047195, grad_norm: 0.08149690084000939, ic: 0.04446635644140468
train 8, step: 500, loss: 5.543112249583659, grad_norm: 0.9894744991859259, ic: 0.039679167544645594
train 8, step: 1000, loss: 1.8599841049685784, grad_norm: 0.5078227242975116, ic: 0.1522082991550887
train 8, step: 1500, loss: 1.0689954734026055, grad_norm: 0.7929740677172499, ic: 0.6361353153464477
train 8, step: 2000, loss: 1.1369169186323116, grad_norm: 0.4538226737263721, ic: 0.04344059630497342
Epoch 8: 2022-04-20 15:21:06.541419: train loss: 1.6410935604472825
Eval step 0: eval loss: 1.016054463800849
Eval: 2022-04-20 15:21:10.663561: total loss: 1.0923986973555406, mse:4.750525655874565, ic :0.0980483076404901, sharpe5:7.0992519307136535, irr5:203.4840087890625, ndcg5:0.8482461800715837, pnl5:2.999305248260498 
train 9, step: 0, loss: 1.1212480997750356, grad_norm: 0.12594678751645033, ic: 0.43987613299594824
train 9, step: 500, loss: 3.242600718226788, grad_norm: 5.514668759444062, ic: 0.14999999307890916
train 9, step: 1000, loss: 0.8653291061508908, grad_norm: 0.06050644364819716, ic: 0.005456710961141219
train 9, step: 1500, loss: 2.131103317780085, grad_norm: 0.7771125933730185, ic: 0.012495602163932307
train 9, step: 2000, loss: 0.6087042375590087, grad_norm: 0.011073450921332089, ic: -0.008323251470161355
Epoch 9: 2022-04-20 15:22:18.924889: train loss: 1.6412983381954764
Eval step 0: eval loss: 1.013040503431082
Eval: 2022-04-20 15:22:22.838354: total loss: 1.088201827194198, mse:4.7373634945292995, ic :0.08041174934484117, sharpe5:4.73365300387144, irr5:146.2225341796875, ndcg5:0.8415431652608435, pnl5:1.6079994440078735 
train 10, step: 0, loss: 1.3165767443606513, grad_norm: 0.1170236040129438, ic: 0.3741749460224876
train 10, step: 500, loss: 0.9058501942759666, grad_norm: 0.006585539500829439, ic: 0.02442007776930321
train 10, step: 1000, loss: 1.5335595784437448, grad_norm: 0.4680229041588158, ic: 0.03754760857098643
train 10, step: 1500, loss: 3.1118054573785403, grad_norm: 0.65657470394655, ic: -0.0297948287864008
train 10, step: 2000, loss: 1.3958335806895896, grad_norm: 0.10598019652625018, ic: -0.01658077287381004
Epoch 10: 2022-04-20 15:23:31.082862: train loss: 1.6422703113278487
Eval step 0: eval loss: 1.013271916345774
Eval: 2022-04-20 15:23:35.472839: total loss: 1.0887061947740249, mse:4.731640897357216, ic :0.08205513317616124, sharpe5:6.659313232898712, irr5:200.05189514160156, ndcg5:0.8530169425403599, pnl5:2.586958646774292 
train 11, step: 0, loss: 4.875474155834636, grad_norm: 0.46092033004948546, ic: 0.1003774238830063
train 11, step: 500, loss: 0.9934944586453534, grad_norm: 0.05651016162637348, ic: -0.008038989515186345
train 11, step: 1000, loss: 1.0519050231514588, grad_norm: 0.3182143782716813, ic: 0.05413224411592963
train 11, step: 1500, loss: 0.6959035898804571, grad_norm: 0.0027952011996217625, ic: 0.07069417273741013
train 11, step: 2000, loss: 1.1460070017389317, grad_norm: 0.22049165843364435, ic: -0.18666774524360663
Epoch 11: 2022-04-20 15:24:43.773156: train loss: 1.641566703895481
Eval step 0: eval loss: 1.0118704540218535
Eval: 2022-04-20 15:24:48.081055: total loss: 1.0873105630333555, mse:4.724812687096462, ic :0.11818038786643612, sharpe5:6.753551554977894, irr5:211.02467346191406, ndcg5:0.8451015501746856, pnl5:2.42887544631958 
train 12, step: 0, loss: 1.3968332268892585, grad_norm: 0.22143652134325956, ic: 0.04979369317585254
train 12, step: 500, loss: 0.8111920074486977, grad_norm: 0.30168004971900414, ic: 0.023307729870836794
train 12, step: 1000, loss: 1.2090191602077835, grad_norm: 0.43669540133536905, ic: 0.5817981051290996
train 12, step: 1500, loss: 1.0986127474256977, grad_norm: 0.18383038727549997, ic: -0.11855250546786414
train 12, step: 2000, loss: 1.11191795642391, grad_norm: 0.06368196190394496, ic: 0.11801952330997703
Epoch 12: 2022-04-20 15:25:56.341505: train loss: 1.6401395732138457
Eval step 0: eval loss: 1.0043501771080172
Eval: 2022-04-20 15:26:00.634295: total loss: 1.0874004691796513, mse:4.730599569533589, ic :0.12168053402436803, sharpe5:7.926185864210129, irr5:226.12281799316406, ndcg5:0.861460667169194, pnl5:3.1373558044433594 
train 13, step: 0, loss: 1.0799898814006024, grad_norm: 0.1070393617932012, ic: 0.43253503580084995
train 13, step: 500, loss: 1.141256504204437, grad_norm: 0.010868145892829383, ic: -0.16901796252850232
train 13, step: 1000, loss: 1.3896849337381982, grad_norm: 0.38294478908511886, ic: 0.06369202386567252
train 13, step: 1500, loss: 0.7755350841597698, grad_norm: 0.0008047743585114178, ic: -0.05288744429265711
train 13, step: 2000, loss: 1.043631136142713, grad_norm: 0.04756971548443948, ic: 0.019883842343942096
Epoch 13: 2022-04-20 15:27:08.141393: train loss: 1.6407213721683975
Eval step 0: eval loss: 0.9977016840689178
Eval: 2022-04-20 15:27:12.560421: total loss: 1.0902682363010763, mse:4.786374893399846, ic :0.1129251860921653, sharpe5:7.679705528318881, irr5:223.07278442382812, ndcg5:0.8519331031153746, pnl5:3.0061330795288086 
train 14, step: 0, loss: 1.7352819927668168, grad_norm: 1.5629910137376142, ic: 0.15251720133052402
train 14, step: 500, loss: 1.2778905998863426, grad_norm: 0.20595898488466338, ic: 0.16447566032995647
train 14, step: 1000, loss: 1.0699521403667356, grad_norm: 0.14958261005036055, ic: 0.18072370758074158
train 14, step: 1500, loss: 0.9893164513568129, grad_norm: 0.1110237262272169, ic: 0.15817858442135316
train 14, step: 2000, loss: 2.319331556509992, grad_norm: 0.7288432039304412, ic: -0.1738009294873777
Epoch 14: 2022-04-20 15:28:19.620317: train loss: 1.6400957008414516
Eval step 0: eval loss: 0.9997443530106305
Eval: 2022-04-20 15:28:23.431827: total loss: 1.0887160517412304, mse:4.742583510931435, ic :0.11710926241537514, sharpe5:7.224929985702038, irr5:213.56277465820312, ndcg5:0.8433941793617586, pnl5:2.695773124694824 
train 15, step: 0, loss: 0.978128370816291, grad_norm: 0.18299204631057356, ic: 0.07022517395492853
train 15, step: 500, loss: 1.2287943630932487, grad_norm: 0.0026092290660231624, ic: 0.013627084828523501
train 15, step: 1000, loss: 1.7633596354166667, grad_norm: 0.12100148658113807, ic: -0.12615011983387572
train 15, step: 1500, loss: 5.4183907564167635, grad_norm: 1.0326941354168915, ic: 0.020497237927523965
train 15, step: 2000, loss: 0.9332356500467193, grad_norm: 0.021006726558436786, ic: -0.146018008846981
Epoch 15: 2022-04-20 15:29:32.838365: train loss: 1.6402374304283283
Eval step 0: eval loss: 1.0076328978656528
Eval: 2022-04-20 15:29:36.932687: total loss: 1.0874912039833018, mse:4.7165365594523925, ic :0.12345520993229499, sharpe5:7.496606944799423, irr5:214.5576934814453, ndcg5:0.8587226576338961, pnl5:3.011323928833008 
train 16, step: 0, loss: 6.364220778802556, grad_norm: 1.143172102449715, ic: -0.04894028130009871
train 16, step: 500, loss: 1.3882116892981151, grad_norm: 0.9956633585049405, ic: -0.03251668001159666
train 16, step: 1000, loss: 0.8213795086340401, grad_norm: 0.22905076539459854, ic: 0.021751529367153785
train 16, step: 1500, loss: 1.2184028421181619, grad_norm: 0.3192678156555584, ic: 0.11493655699304764
train 16, step: 2000, loss: 0.9763301726310484, grad_norm: 0.5354699311674352, ic: 0.5174172371963046
Epoch 16: 2022-04-20 15:30:44.501144: train loss: 1.6385519817403225
Eval step 0: eval loss: 0.9990374508376119
Eval: 2022-04-20 15:30:48.906864: total loss: 1.0835995379735412, mse:4.722632548051511, ic :0.12365870236289646, sharpe5:7.824723980426788, irr5:223.7313690185547, ndcg5:0.8323350444077515, pnl5:3.1016619205474854 
train 17, step: 0, loss: 1.192557305646089, grad_norm: 0.017126339285086636, ic: 0.11907619719954901
train 17, step: 500, loss: 1.0427434277184442, grad_norm: 0.0946555756446078, ic: -0.03455773111817928
train 17, step: 1000, loss: 3.430219291460396, grad_norm: 0.7070530710628358, ic: -0.018508911484541816
train 17, step: 1500, loss: 0.8910573817379652, grad_norm: 0.00431554447696432, ic: -0.02707689824087709
train 17, step: 2000, loss: 0.9948447822724412, grad_norm: 0.46895620458734916, ic: 0.5139251273778447
Epoch 17: 2022-04-20 15:31:56.405541: train loss: 1.6399742924946472
Eval step 0: eval loss: 0.9990584708440297
Eval: 2022-04-20 15:32:00.643445: total loss: 1.0867764462421863, mse:4.736466337906115, ic :0.11561549718466868, sharpe5:7.6315418288111685, irr5:220.87557983398438, ndcg5:0.8586266850887571, pnl5:3.5206830501556396 
train 18, step: 0, loss: 0.8560562929154972, grad_norm: 0.0077460827008715115, ic: -0.0025040716934518342
train 18, step: 500, loss: 2.5103024535230074, grad_norm: 0.9800065261661627, ic: 0.12773699261007546
train 18, step: 1000, loss: 1.3862872007081835, grad_norm: 0.31169972445930477, ic: 0.5044869104168218
train 18, step: 1500, loss: 1.7822050739826354, grad_norm: 0.5950469310156966, ic: 0.3545396212744757
train 18, step: 2000, loss: 1.2766281119114673, grad_norm: 0.39520135164476955, ic: 0.0997698275675513
Epoch 18: 2022-04-20 15:33:10.553679: train loss: 1.6391019130478253
Eval step 0: eval loss: 1.0031855273334649
Eval: 2022-04-20 15:33:14.929931: total loss: 1.0870856207497959, mse:4.723383413419706, ic :0.12390898147716872, sharpe5:7.608598400652408, irr5:218.18426513671875, ndcg5:0.8481796473570121, pnl5:2.8284964561462402 
train 19, step: 0, loss: 2.2359048482928463, grad_norm: 0.7302748518160287, ic: 0.056290898438867296
train 19, step: 500, loss: 1.0167625249818313, grad_norm: 0.05184836265049115, ic: -0.09603295894100335
train 19, step: 1000, loss: 1.055081472478576, grad_norm: 0.05684780366264233, ic: 0.4422238045714189
train 19, step: 1500, loss: 1.586086697048611, grad_norm: 0.03845654101634503, ic: 0.10717069370931406
train 19, step: 2000, loss: 1.905612175536543, grad_norm: 1.7777438014294247, ic: 0.6080227714049639
Epoch 19: 2022-04-20 15:34:18.963373: train loss: 1.6407059640530282
Eval step 0: eval loss: 1.000782304214389
Eval: 2022-04-20 15:34:22.156874: total loss: 1.085907118930887, mse:4.724234744903505, ic :0.12452437166907444, sharpe5:7.863673890531063, irr5:221.752197265625, ndcg5:0.840612616667075, pnl5:2.7727913856506348 
train 20, step: 0, loss: 1.2381413714249532, grad_norm: 0.38275562882672237, ic: 0.44143505159509544
train 20, step: 500, loss: 1.2228709682143812, grad_norm: 0.4551748740859264, ic: -0.024279784121385106
train 20, step: 1000, loss: 1.5716391826445872, grad_norm: 0.6296768586968791, ic: 0.09556170242657672
train 20, step: 1500, loss: 0.8420274018355018, grad_norm: 0.43200271135884294, ic: 0.5520792521438957
train 20, step: 2000, loss: 1.3499858489225445, grad_norm: 0.25707084415472214, ic: -0.032084268321062044
Epoch 20: 2022-04-20 15:35:19.927706: train loss: 1.6388848762765287
Eval step 0: eval loss: 1.0782913601731174
Eval: 2022-04-20 15:35:22.937896: total loss: 1.1496131184226495, mse:5.188648355105785, ic :0.11441937967476173, sharpe5:7.306344865858555, irr5:211.00091552734375, ndcg5:0.8561167633404171, pnl5:4.112745761871338 
train 21, step: 0, loss: 1.232649075255102, grad_norm: 2.2648712186228974, ic: 0.3093745547321788
train 21, step: 500, loss: 1.1140105897630546, grad_norm: 0.07370170380620938, ic: -0.08714326380727569
train 21, step: 1000, loss: 0.9293324228379211, grad_norm: 0.2193734384296616, ic: 0.08047498511014882
train 21, step: 1500, loss: 0.7761652480903951, grad_norm: 0.11109948292186558, ic: 0.5482383217541549
train 21, step: 2000, loss: 1.1715121052163637, grad_norm: 0.011541357076891514, ic: 0.04064553359836166
Epoch 21: 2022-04-20 15:36:21.130806: train loss: 1.6390699877312265
Eval step 0: eval loss: 0.9981791017682002
Eval: 2022-04-20 15:36:24.201617: total loss: 1.0844017630025269, mse:4.718342242890636, ic :0.1215445476219068, sharpe5:7.0562525126338, irr5:203.47030639648438, ndcg5:0.8330665726841279, pnl5:3.818852424621582 
train 22, step: 0, loss: 1.0726951607298365, grad_norm: 0.2758027345538424, ic: 0.06850817160850241
train 22, step: 500, loss: 1.0294021246001477, grad_norm: 0.004802569855421503, ic: 0.035347402414616404
train 22, step: 1000, loss: 0.922363001058005, grad_norm: 0.01408034465086855, ic: 0.10645506772403969
train 22, step: 1500, loss: 1.0257373465184483, grad_norm: 0.019763943935162585, ic: 0.14049776722073695
train 22, step: 2000, loss: 1.0543415868005086, grad_norm: 0.17142696092212184, ic: 0.023056099113943965
Epoch 22: 2022-04-20 15:37:22.440392: train loss: 1.6400940398795165
Eval step 0: eval loss: 1.0066772910907056
Eval: 2022-04-20 15:37:25.470425: total loss: 1.0870785062729584, mse:4.7197403455930775, ic :0.11974164116901403, sharpe5:8.270039319992065, irr5:229.5760498046875, ndcg5:0.8576082058799773, pnl5:3.0493955612182617 
train 23, step: 0, loss: 1.274493398621468, grad_norm: 0.8326457594243991, ic: -0.015221371697732952
train 23, step: 500, loss: 0.9414822085873112, grad_norm: 0.1804536521694987, ic: 0.5230825724878653
train 23, step: 1000, loss: 2.2855652145651746, grad_norm: 1.0527840063964304, ic: 0.07714464799960577
train 23, step: 1500, loss: 0.8017418764278721, grad_norm: 0.3924847960592779, ic: 0.6670701085445533
train 23, step: 2000, loss: 1.4975734027334893, grad_norm: 0.4043111865519306, ic: 0.4070927618256281
Epoch 23: 2022-04-20 15:38:23.717236: train loss: 1.635378068924992
Eval step 0: eval loss: 1.0167669584526395
Eval: 2022-04-20 15:38:26.751460: total loss: 1.0909734616994595, mse:4.70393530622512, ic :0.1552755105660402, sharpe5:13.840580706596374, irr5:454.94903564453125, ndcg5:0.8571972033654613, pnl5:4.443141937255859 
train 24, step: 0, loss: 1.1832552693208431, grad_norm: 0.6730196926938591, ic: 0.29803842482985543
train 24, step: 500, loss: 1.273317012597731, grad_norm: 0.5533956783016754, ic: 0.008588932715645488
train 24, step: 1000, loss: 1.0766292665062882, grad_norm: 0.5221947365238971, ic: 0.06595964451477732
train 24, step: 1500, loss: 1.1992372047244095, grad_norm: 0.09131616841223311, ic: 0.03392789058929212
train 24, step: 2000, loss: 1.357009574323657, grad_norm: 0.5281633602603989, ic: 0.4500130848995481
Epoch 24: 2022-04-20 15:39:25.027083: train loss: 1.6302930800297608
Eval step 0: eval loss: 1.0069916269664954
Eval: 2022-04-20 15:39:28.015524: total loss: 1.0816286794270824, mse:4.67759367620802, ic :0.16422409534043247, sharpe5:14.509913011193275, irr5:486.66998291015625, ndcg5:0.8635727660259935, pnl5:4.2569355964660645 
train 25, step: 0, loss: 1.3241437261705389, grad_norm: 0.7120307381760149, ic: 0.16244957492294362
train 25, step: 500, loss: 1.5054053764838677, grad_norm: 1.0921024106997879, ic: 0.09024189071612874
train 25, step: 1000, loss: 1.3783160446017826, grad_norm: 0.3677407383756857, ic: 0.19976995276434276
train 25, step: 1500, loss: 2.894081619916485, grad_norm: 2.413508913533021, ic: 0.21911052945048845
train 25, step: 2000, loss: 1.1999878702284414, grad_norm: 0.140701590611734, ic: 0.1600258669422597
Epoch 25: 2022-04-20 15:40:26.318701: train loss: 1.6300541766076166
Eval step 0: eval loss: 1.007968767998782
Eval: 2022-04-20 15:40:29.404451: total loss: 1.0831100173693318, mse:4.6748216517418735, ic :0.1704089840378615, sharpe5:15.256222858428954, irr5:510.9023742675781, ndcg5:0.8584983806187643, pnl5:7.284430503845215 
train 26, step: 0, loss: 1.6200319602272726, grad_norm: 0.38854393864746817, ic: 0.19306858293220092
train 26, step: 500, loss: 1.021683178089051, grad_norm: 0.28240461682139456, ic: -0.05427955553449412
train 26, step: 1000, loss: 1.8374098651514363, grad_norm: 0.9655322071470747, ic: 0.1345621028978249
train 26, step: 1500, loss: 0.9236956025782902, grad_norm: 0.021456984951414806, ic: -0.018729142495786145
train 26, step: 2000, loss: 1.0058650459830216, grad_norm: 0.2826361002379229, ic: 0.11822818455535224
Epoch 26: 2022-04-20 15:41:27.610005: train loss: 1.6315834411106707
Eval step 0: eval loss: 1.0057705381533042
Eval: 2022-04-20 15:41:30.684208: total loss: 1.083741883728462, mse:4.691879639389147, ic :0.1637923736369972, sharpe5:14.489092240333557, irr5:473.1496276855469, ndcg5:0.8277594199761416, pnl5:8.546249389648438 
train 27, step: 0, loss: 1.659275836255177, grad_norm: 1.1761038446742789, ic: 0.6466640246107938
train 27, step: 500, loss: 1.5277477400855366, grad_norm: 1.70346105945671, ic: 0.06517117275935959
train 27, step: 1000, loss: 2.5634446933275057, grad_norm: 2.891829683161728, ic: 0.4063388705164187
train 27, step: 1500, loss: 0.8817817216776543, grad_norm: 1.4623025706747836, ic: 0.5240428868374116
train 27, step: 2000, loss: 1.3587762741815477, grad_norm: 0.9018598142698575, ic: -0.038382651366926764
Epoch 27: 2022-04-20 15:42:28.770144: train loss: 1.6305624780035561
Eval step 0: eval loss: 1.0029053891439572
Eval: 2022-04-20 15:42:31.807674: total loss: 1.0833019428769566, mse:4.697430565601661, ic :0.14723600046892496, sharpe5:13.214949223995209, irr5:394.7235107421875, ndcg5:0.8409879557491613, pnl5:6.5854997634887695 
train 28, step: 0, loss: 1.1877999603060045, grad_norm: 0.15873239109905013, ic: 0.10253221250253654
train 28, step: 500, loss: 2.9426637552126236, grad_norm: 0.800021434640444, ic: 0.151559901002379
train 28, step: 1000, loss: 2.782894188758886, grad_norm: 3.367566454079906, ic: -0.06931755104044218
train 28, step: 1500, loss: 1.0250269358947515, grad_norm: 0.025347607199403425, ic: 0.20235996925199412
train 28, step: 2000, loss: 1.7697986336641534, grad_norm: 0.5795228737688419, ic: 0.0889989895442315
Epoch 28: 2022-04-20 15:43:29.826055: train loss: 1.6253086543146644
Eval step 0: eval loss: 1.0081116654736044
Eval: 2022-04-20 15:43:32.883628: total loss: 1.0828907843503905, mse:4.701888193442204, ic :0.15680798678548186, sharpe5:15.203301152586937, irr5:494.6454772949219, ndcg5:0.8612766847860865, pnl5:9.161130905151367 
train 29, step: 0, loss: 1.503610652897555, grad_norm: 0.19723934280704997, ic: 0.08717027378513417
train 29, step: 500, loss: 2.5282221735996706, grad_norm: 2.0666154324085317, ic: -0.08947463085925737
train 29, step: 1000, loss: 1.679874026816609, grad_norm: 1.2388730585152086, ic: 0.48087736583584983
train 29, step: 1500, loss: 3.9902857454374665, grad_norm: 3.1174262260979986, ic: 0.1344709431070979
train 29, step: 2000, loss: 0.937450963763652, grad_norm: 0.2820312967588447, ic: 0.4644407790586384
Epoch 29: 2022-04-20 15:44:31.014363: train loss: 1.625626224088735
Eval step 0: eval loss: 1.0056662094975974
Eval: 2022-04-20 15:44:34.061902: total loss: 1.082549101159111, mse:4.684860090755506, ic :0.1586128836680532, sharpe5:14.915690547823905, irr5:493.1322021484375, ndcg5:0.840587043720449, pnl5:8.420075416564941 
train 30, step: 0, loss: 1.259408377590367, grad_norm: 0.1409439638764889, ic: 0.9908069748006552
train 30, step: 500, loss: 1.9454534989369066, grad_norm: 0.3293533096891856, ic: 0.16015919109934537
train 30, step: 1000, loss: 3.415090375598975, grad_norm: 0.8760839354685416, ic: 0.44180735894067746
train 30, step: 1500, loss: 1.094295626889033, grad_norm: 0.45351384308923054, ic: 0.1383840690171135
train 30, step: 2000, loss: 1.1008451054505177, grad_norm: 0.33369940526674874, ic: 0.4380456554494074
Epoch 30: 2022-04-20 15:45:32.109193: train loss: 1.62539821113988
Eval step 0: eval loss: 0.9995562014547129
Eval: 2022-04-20 15:45:35.167725: total loss: 1.0861972161224576, mse:4.729205815978157, ic :0.15780957056602102, sharpe5:15.035000157952307, irr5:492.6634216308594, ndcg5:0.8597454276676352, pnl5:5.833877086639404 
train 31, step: 0, loss: 1.1792174998112923, grad_norm: 0.27571051014048, ic: 0.16321651476996013
train 31, step: 500, loss: 0.8237201448707909, grad_norm: 0.19196015437283642, ic: 0.24330471551171529
train 31, step: 1000, loss: 5.011190570282102, grad_norm: 0.6084419970359626, ic: 0.038354114762835984
train 31, step: 1500, loss: 1.6848674697522217, grad_norm: 0.5103931793636333, ic: 0.22540385840098187
train 31, step: 2000, loss: 0.9992301619372606, grad_norm: 0.4807601037334123, ic: 0.21938644283900371
Epoch 31: 2022-04-20 15:46:33.634868: train loss: 1.6247873798121903
Eval step 0: eval loss: 1.0050104752912716
Eval: 2022-04-20 15:46:36.670000: total loss: 1.0842174110597593, mse:4.68656379540737, ic :0.15944430778365162, sharpe5:14.496685186028479, irr5:448.7989501953125, ndcg5:0.8560257925531582, pnl5:8.419577598571777 
train 32, step: 0, loss: 0.8575686555273881, grad_norm: 0.3325565103672337, ic: 0.11000911340589652
train 32, step: 500, loss: 1.1031248511337652, grad_norm: 0.29272446193252577, ic: 0.045097389184826614
train 32, step: 1000, loss: 1.394077771497931, grad_norm: 0.5059922232336287, ic: 0.061689494116849805
train 32, step: 1500, loss: 2.0986139161667956, grad_norm: 1.5930834111387626, ic: 0.4433228472957062
train 32, step: 2000, loss: 1.0639980966470781, grad_norm: 0.4833862342034819, ic: 0.466212467749676
Epoch 32: 2022-04-20 15:47:34.876597: train loss: 1.6244101405435685
Eval step 0: eval loss: 1.0084435501620919
Eval: 2022-04-20 15:47:37.956985: total loss: 1.0823674873771665, mse:4.679240190640945, ic :0.16771994629367, sharpe5:15.154416657686232, irr5:506.9184265136719, ndcg5:0.8549936313656815, pnl5:6.384542942047119 
train 33, step: 0, loss: 1.1678971304430863, grad_norm: 0.02728437773979119, ic: -0.005931754590918513
train 33, step: 500, loss: 3.166487017198309, grad_norm: 0.6480098074021906, ic: 0.5198774895172197
train 33, step: 1000, loss: 5.245737763451384, grad_norm: 2.71875255937455, ic: -0.014438006836730523
train 33, step: 1500, loss: 1.2971367068407011, grad_norm: 1.9369141138503254, ic: 0.03232675581239042
train 33, step: 2000, loss: 1.8601388384205426, grad_norm: 0.5705449639060862, ic: 0.1075345629111673
Epoch 33: 2022-04-20 15:48:36.217926: train loss: 1.6246672661835673
Eval step 0: eval loss: 1.0096632247852488
Eval: 2022-04-20 15:48:39.264460: total loss: 1.087606555682392, mse:4.689838533747896, ic :0.16437690293952884, sharpe5:14.706534075736998, irr5:488.2908630371094, ndcg5:0.853231172526795, pnl5:7.315098285675049 
train 34, step: 0, loss: 0.7157486856644959, grad_norm: 0.3831504692072189, ic: 0.15632234780724105
train 34, step: 500, loss: 1.81298828125, grad_norm: 0.9925376492112563, ic: 0.8606541594061138
train 34, step: 1000, loss: 0.6901209758890086, grad_norm: 0.13279856078498437, ic: 0.4867932758596291
train 34, step: 1500, loss: 1.6536575708633814, grad_norm: 1.549118549238885, ic: 0.6411928429201996
train 34, step: 2000, loss: 3.0083494484915567, grad_norm: 0.6794980959252431, ic: 0.08508583143304554
Epoch 34: 2022-04-20 15:49:37.446977: train loss: 1.6246540959516897
Eval step 0: eval loss: 1.0034196400654949
Eval: 2022-04-20 15:49:40.550912: total loss: 1.0806830044954345, mse:4.676016690394719, ic :0.16904390980643988, sharpe5:15.4471258020401, irr5:515.1764526367188, ndcg5:0.8600042438635387, pnl5:8.15530776977539 
train 35, step: 0, loss: 1.0413126885136472, grad_norm: 0.5489822871704081, ic: -0.012832790782729997
train 35, step: 500, loss: 3.328341397372159, grad_norm: 1.4404518205716774, ic: -0.08327235014776896
train 35, step: 1000, loss: 1.3249946044156544, grad_norm: 0.13316204162661083, ic: 0.5233312329697993
train 35, step: 1500, loss: 1.6551534666769043, grad_norm: 0.5799067728090324, ic: 0.08945621224033529
train 35, step: 2000, loss: 1.3108957949925422, grad_norm: 0.5724086073527104, ic: -0.003486960129444404
Epoch 35: 2022-04-20 15:50:38.872041: train loss: 1.6248776455242477
Eval step 0: eval loss: 1.0022518405040481
Eval: 2022-04-20 15:50:41.951297: total loss: 1.0826394335080018, mse:4.694477217645272, ic :0.1552809491966625, sharpe5:13.046468503475188, irr5:420.30621337890625, ndcg5:0.8394548364513422, pnl5:4.3792724609375 
train 36, step: 0, loss: 9.044018535418312, grad_norm: 1.684665139187474, ic: -0.11646864580594615
train 36, step: 500, loss: 0.861685742039648, grad_norm: 0.059531475647938814, ic: 0.09359125831099425
train 36, step: 1000, loss: 1.9694126674107142, grad_norm: 2.586183196232385, ic: -0.021595212268319113
train 36, step: 1500, loss: 1.0565476931398465, grad_norm: 0.2328607227502858, ic: 0.08062149612627509
train 36, step: 2000, loss: 2.1999895388831665, grad_norm: 1.6537517691358106, ic: 0.36832060980094716
Epoch 36: 2022-04-20 15:51:39.931982: train loss: 1.6248603774482466
Eval step 0: eval loss: 1.0044981528106898
Eval: 2022-04-20 15:51:42.967249: total loss: 1.0838465413026388, mse:4.685088462857765, ic :0.16393860558595166, sharpe5:14.402581658363342, irr5:476.88763427734375, ndcg5:0.8552860798484033, pnl5:6.920338153839111 
train 37, step: 0, loss: 1.2020147614189576, grad_norm: 0.15379530653358411, ic: 0.15501336959593837
train 37, step: 500, loss: 2.337942289613589, grad_norm: 0.16834547511858577, ic: 0.2350723170152199
train 37, step: 1000, loss: 0.7450065310519017, grad_norm: 0.46500768083156274, ic: 0.1678348069315074
train 37, step: 1500, loss: 3.1367283545169733, grad_norm: 2.2250353001791052, ic: 0.18959620355553444
train 37, step: 2000, loss: 3.140641709244296, grad_norm: 2.370102686834116, ic: -0.021949420313634567
Epoch 37: 2022-04-20 15:52:40.717193: train loss: 1.6235674504635544
Eval step 0: eval loss: 1.0049763418863547
Eval: 2022-04-20 15:52:43.794426: total loss: 1.0818028531446102, mse:4.688518347160009, ic :0.1676536203856007, sharpe5:14.784247548580169, irr5:499.77001953125, ndcg5:0.85180254597139, pnl5:7.15169620513916 
train 38, step: 0, loss: 1.333941650390625, grad_norm: 0.6452365781500117, ic: -0.2695835112112409
train 38, step: 500, loss: 1.7486806943435078, grad_norm: 2.355330330302717, ic: 0.19341985571464754
train 38, step: 1000, loss: 1.83499469142773, grad_norm: 0.7407334559744878, ic: 0.12704094244142736
train 38, step: 1500, loss: 1.0672676831447, grad_norm: 0.21011272693292987, ic: 0.5025530157227842
train 38, step: 2000, loss: 0.7496016388567386, grad_norm: 0.03683371637146135, ic: 0.5770179757785296
Epoch 38: 2022-04-20 15:53:41.877859: train loss: 1.6265490717430384
Eval step 0: eval loss: 0.9978092910742495
Eval: 2022-04-20 15:53:44.940232: total loss: 1.080393883459199, mse:4.695467020356648, ic :0.16112049499242623, sharpe5:14.376103305816649, irr5:464.2568359375, ndcg5:0.8592332244347376, pnl5:8.680215835571289 
train 39, step: 0, loss: 0.8680846107326224, grad_norm: 0.0714937005384675, ic: 0.54105476523129
train 39, step: 500, loss: 1.2371284833600642, grad_norm: 0.9708739379345613, ic: 0.03548012160756019
train 39, step: 1000, loss: 1.378230701793324, grad_norm: 0.2785048182284021, ic: 0.09146980867826374
train 39, step: 1500, loss: 2.4366765323271387, grad_norm: 0.4502919285256856, ic: -0.07104351243294552
train 39, step: 2000, loss: 2.8334338592837227, grad_norm: 1.8702332698454147, ic: 0.23344734141624085
Epoch 39: 2022-04-20 15:54:42.867198: train loss: 1.6229454316995173
Eval step 0: eval loss: 1.0012063040991968
Eval: 2022-04-20 15:54:45.923570: total loss: 1.0805709245695974, mse:4.685930008654138, ic :0.16210157509148806, sharpe5:14.912183055281638, irr5:496.4692077636719, ndcg5:0.8664748659553906, pnl5:5.6369242668151855 

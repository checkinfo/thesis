Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='AdjSeqTimeDataset', dout=0.3, epochs=40, gnn_layers=2, gpu=0, hidden_dim=128, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=3, mask_adj=True, mask_type='soft', model_type='GNNModel', normalize_adj=False, num_days=1, num_heads=1, print_inteval=500, relation_num=1, seed=10086, shuffle=True, side_info=False, sparse_adj_path=None, stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=False)
73707
GNNModel(
  (fc1): Linear(in_features=9, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
  (fc4): Linear(in_features=128, out_features=1, bias=True)
  (gnns): ModuleList(
    (0): GraphConv(128, 128)
    (1): GraphConv(128, 128)
  )
  (dropout): Dropout(p=0.3, inplace=False)
  (relu): LeakyReLU(negative_slope=0.01)
)
train 0, step: 0, loss: 2.073332509881423, grad_norm: 0.4717636939295498, ic: 0.06189800434704834
train 0, step: 500, loss: 1.367263944335197, grad_norm: 0.8612953747237372, ic: -0.03713539274032232
train 0, step: 1000, loss: 1.5058547798818536, grad_norm: 0.032735689257369985, ic: 0.15860126109828698
train 0, step: 1500, loss: 1.1801354351820714, grad_norm: 0.09267414215686713, ic: 0.056029249970486396
train 0, step: 2000, loss: 1.5605837193931023, grad_norm: 0.05083553168070675, ic: 0.056659360539463174
Epoch 0: 2022-04-04 01:46:32.272839: train loss: 1.6478988772219951
Eval step 0: eval loss: 1.0058598892509214
Eval: 2022-04-04 01:46:34.792257: total loss: 1.0907845519653916, mse:4.886951995025454, ic :0.03283778249191291, sharpe5:6.805333420336246, irr5:205.66102600097656, ndcg5:0.8438908344527715, pnl5:2.39924955368042 
train 1, step: 0, loss: 0.6431612071424427, grad_norm: 0.06648862182550071, ic: 0.0550392509076897
train 1, step: 500, loss: 1.2598094786779492, grad_norm: 0.31212816172876556, ic: 0.2575670722583807
train 1, step: 1000, loss: 0.8764226899730215, grad_norm: 0.06219460854424112, ic: 0.08104618579361349
train 1, step: 1500, loss: 1.8595510343225992, grad_norm: 0.5642013665198499, ic: 0.08315770201094749
train 1, step: 2000, loss: 1.3731628698375287, grad_norm: 0.23741814481235857, ic: 0.10711279759232198
Epoch 1: 2022-04-04 01:46:56.117857: train loss: 1.6454834504016047
Eval step 0: eval loss: 1.0036531742652381
Eval: 2022-04-04 01:46:58.565978: total loss: 1.0886290738913942, mse:4.874645486788224, ic :0.061234699620868846, sharpe5:7.0467785936594005, irr5:212.68212890625, ndcg5:0.86310155476582, pnl5:3.143108606338501 
train 2, step: 0, loss: 1.3280892721036586, grad_norm: 0.5031059957986457, ic: 0.08134364276144235
train 2, step: 500, loss: 0.9521604778191389, grad_norm: 0.28518938321709836, ic: 0.08611271884160618
train 2, step: 1000, loss: 3.0814558325965726, grad_norm: 1.7696702939594362, ic: 0.1567049113315747
train 2, step: 1500, loss: 2.3040578843675656, grad_norm: 0.8465156286551894, ic: 0.07303519622221584
train 2, step: 2000, loss: 1.4569727600546811, grad_norm: 0.2711888233187922, ic: -0.09931013705508665
Epoch 2: 2022-04-04 01:47:19.814828: train loss: 1.6443243347091694
Eval step 0: eval loss: 0.9959153049302264
Eval: 2022-04-04 01:47:22.405586: total loss: 1.0885933916197472, mse:4.8645706038820355, ic :0.07458668030765948, sharpe5:6.884776518344879, irr5:205.38624572753906, ndcg5:0.841471361325027, pnl5:2.7510581016540527 
train 3, step: 0, loss: 1.8315257836409717, grad_norm: 0.06604934747655176, ic: -0.12553253484634186
train 3, step: 500, loss: 0.776766008423957, grad_norm: 0.020342347781280436, ic: 0.30506254445514785
train 3, step: 1000, loss: 1.3951292458916, grad_norm: 0.4486138348488646, ic: 0.249830753368392
train 3, step: 1500, loss: 2.618408391942189, grad_norm: 0.4154642267784403, ic: -0.06088815321393529
train 3, step: 2000, loss: 1.3555560487689393, grad_norm: 0.1661308151386253, ic: 0.07197138518510912
Epoch 3: 2022-04-04 01:47:43.685660: train loss: 1.6405673051173937
Eval step 0: eval loss: 1.0025438707461163
Eval: 2022-04-04 01:47:46.288898: total loss: 1.0899249352513036, mse:4.727773453129636, ic :0.11916934649704561, sharpe5:7.912156839966774, irr5:226.01983642578125, ndcg5:0.8623072433290374, pnl5:2.979203701019287 
train 4, step: 0, loss: 1.1480932134108637, grad_norm: 0.1620762673323385, ic: 0.07218466284205227
train 4, step: 500, loss: 0.9946979057958412, grad_norm: 0.004366922033406259, ic: 0.10719116296304965
train 4, step: 1000, loss: 1.3310385790605932, grad_norm: 0.06420356330815956, ic: 0.07237002119861521
train 4, step: 1500, loss: 1.0525302984775642, grad_norm: 0.12092807391540307, ic: 0.6049390138452104
train 4, step: 2000, loss: 4.177379785233084, grad_norm: 0.8884056350378392, ic: -0.023720478954597564
Epoch 4: 2022-04-04 01:48:08.253134: train loss: 1.6376499874498227
Eval step 0: eval loss: 1.0221320740356765
Eval: 2022-04-04 01:48:10.781803: total loss: 1.1029701935417275, mse:4.775815224704025, ic :0.11242194458630851, sharpe5:7.409575157761574, irr5:212.0326690673828, ndcg5:0.8479853206166365, pnl5:3.0684213638305664 
train 5, step: 0, loss: 0.9922399353817594, grad_norm: 0.1871464853807684, ic: -0.059909926416047005
train 5, step: 500, loss: 0.7904277397746347, grad_norm: 0.03297560265553687, ic: 0.15180221597959925
train 5, step: 1000, loss: 1.0959092297834865, grad_norm: 0.05036626364441048, ic: 0.3995715968616268
train 5, step: 1500, loss: 1.763205824441057, grad_norm: 0.3669925840606196, ic: -0.07051217584210626
train 5, step: 2000, loss: 2.1771685599774293, grad_norm: 0.8416087097120547, ic: 0.018984168666102946
Epoch 5: 2022-04-04 01:48:32.239766: train loss: 1.6386036901842131
Eval step 0: eval loss: 0.9975810922278172
Eval: 2022-04-04 01:48:34.729783: total loss: 1.0860868914341382, mse:4.715752139501399, ic :0.12528000565747138, sharpe5:8.184606147408484, irr5:236.53045654296875, ndcg5:0.8548801505598368, pnl5:4.138286590576172 
train 6, step: 0, loss: 0.7850523105963381, grad_norm: 0.016409390091870014, ic: -0.08486807628737804
train 6, step: 500, loss: 1.4139958431846216, grad_norm: 0.2631007706779717, ic: 0.10386614578004343
train 6, step: 1000, loss: 1.2307279960000967, grad_norm: 0.1855001775939545, ic: 0.20192264605695215
train 6, step: 1500, loss: 1.0532947007665094, grad_norm: 0.36887300835012354, ic: 0.06827170178986913
train 6, step: 2000, loss: 2.2828838641826925, grad_norm: 1.0357412254195237, ic: 0.08135441894563034
Epoch 6: 2022-04-04 01:48:55.917651: train loss: 1.636974405386013
Eval step 0: eval loss: 1.0018181341330963
Eval: 2022-04-04 01:48:58.774112: total loss: 1.0847961174048322, mse:4.704446543318388, ic :0.13966702064430978, sharpe5:13.601986080408096, irr5:414.5562438964844, ndcg5:0.8517413442520627, pnl5:5.465049743652344 
train 7, step: 0, loss: 1.4494993910561675, grad_norm: 0.5536966491343825, ic: 0.2228433556869302
train 7, step: 500, loss: 1.3551362308686528, grad_norm: 0.1414693650483564, ic: 0.1772809727175384
train 7, step: 1000, loss: 0.6393385079374565, grad_norm: 0.03718695197128557, ic: 0.24181265399139645
train 7, step: 1500, loss: 1.003790924938843, grad_norm: 0.15563560997428577, ic: 0.09748761778747408
train 7, step: 2000, loss: 1.5688205725039621, grad_norm: 0.594640300446411, ic: 0.416590585163863
Epoch 7: 2022-04-04 01:49:20.165123: train loss: 1.6321343584941113
Eval step 0: eval loss: 0.9963751095354462
Eval: 2022-04-04 01:49:22.680261: total loss: 1.0822664281848218, mse:4.697632042136464, ic :0.15485827745458375, sharpe5:14.342775505185127, irr5:473.7987365722656, ndcg5:0.8442077000644194, pnl5:6.344086170196533 
train 8, step: 0, loss: 1.1978968037248223, grad_norm: 0.09620304921685396, ic: 0.10869124399629358
train 8, step: 500, loss: 5.512260604427899, grad_norm: 1.6967987103121183, ic: 0.08686033693836122
train 8, step: 1000, loss: 1.8835004280611745, grad_norm: 0.5556582570735206, ic: 0.06764922607477948
train 8, step: 1500, loss: 1.0808355364551023, grad_norm: 0.36305653957216705, ic: 0.6443108124248162
train 8, step: 2000, loss: 1.1253712972005208, grad_norm: 0.5048347795339347, ic: 0.02933664237087025
Epoch 8: 2022-04-04 01:49:44.277847: train loss: 1.6320280977527153
Eval step 0: eval loss: 1.0072402030056937
Eval: 2022-04-04 01:49:46.789142: total loss: 1.0869684730281515, mse:4.693820259270792, ic :0.1579389862395477, sharpe5:13.92887719631195, irr5:451.5329895019531, ndcg5:0.8500541489820961, pnl5:6.984355449676514 
train 9, step: 0, loss: 1.0969764671407254, grad_norm: 0.022983041338437038, ic: 0.4786357137374247
train 9, step: 500, loss: 3.123851015506088, grad_norm: 1.0858172689796732, ic: 0.20424496941671946
train 9, step: 1000, loss: 0.8791533539606989, grad_norm: 0.12128243164829393, ic: 0.20569034222090604
train 9, step: 1500, loss: 2.160788562348055, grad_norm: 1.1068840593759386, ic: 0.013825374412370525
train 9, step: 2000, loss: 0.6046777420584186, grad_norm: 0.011934173385065786, ic: 0.0787098014457986
Epoch 9: 2022-04-04 01:50:08.391977: train loss: 1.6288119752887626
Eval step 0: eval loss: 1.0100604193407714
Eval: 2022-04-04 01:50:10.856792: total loss: 1.0929971102248335, mse:4.768911690773148, ic :0.13591243145440468, sharpe5:12.604065669178961, irr5:391.460205078125, ndcg5:0.8474111642738554, pnl5:4.7218852043151855 
train 10, step: 0, loss: 1.300264161981113, grad_norm: 0.4760465644986934, ic: 0.3829874188303255
train 10, step: 500, loss: 0.8989968578231615, grad_norm: 0.008847284590147065, ic: 0.10491903680315981
train 10, step: 1000, loss: 1.5170741911037677, grad_norm: 0.5713229623614013, ic: 0.05210181063416404
train 10, step: 1500, loss: 3.014377596995476, grad_norm: 1.2067337478304283, ic: 0.11567235768898071
train 10, step: 2000, loss: 1.3707690021549677, grad_norm: 0.2339644767478763, ic: 0.17641469709173646
Epoch 10: 2022-04-04 01:50:32.672202: train loss: 1.6289949089124343
Eval step 0: eval loss: 1.006166768488349
Eval: 2022-04-04 01:50:35.190789: total loss: 1.0834024735967813, mse:4.681588465114015, ic :0.16207934683253813, sharpe5:14.486474863886832, irr5:472.0854797363281, ndcg5:0.8562827704368537, pnl5:5.395828723907471 
train 11, step: 0, loss: 4.70352738345387, grad_norm: 1.6185883569974195, ic: 0.4327279084045772
train 11, step: 500, loss: 0.9865970172091014, grad_norm: 0.05715287252715966, ic: 0.050472316638585486
train 11, step: 1000, loss: 1.0357561729774505, grad_norm: 0.36113236245592323, ic: 0.06678742097439644
train 11, step: 1500, loss: 0.6940208680011746, grad_norm: 0.002682725863096231, ic: 0.06315645214926198
train 11, step: 2000, loss: 1.1276050260839763, grad_norm: 0.05964919825820769, ic: -0.17741447340198105
Epoch 11: 2022-04-04 01:50:57.125854: train loss: 1.6266744437041507
Eval step 0: eval loss: 0.9987179724526065
Eval: 2022-04-04 01:50:59.649426: total loss: 1.0817482057065084, mse:4.691646118981775, ic :0.1570104503780579, sharpe5:14.07644160747528, irr5:438.140380859375, ndcg5:0.8219205471226835, pnl5:4.701770782470703 
train 12, step: 0, loss: 1.3788502740316064, grad_norm: 0.40763897709994884, ic: 0.1910456734965222
train 12, step: 500, loss: 0.8280857872003256, grad_norm: 0.6369296322265929, ic: 0.008491458256759473
train 12, step: 1000, loss: 1.1719402222645943, grad_norm: 0.39193568823530456, ic: 0.6196169457864796
train 12, step: 1500, loss: 1.0834835880757836, grad_norm: 0.2461095366149093, ic: 0.08891711498740203
train 12, step: 2000, loss: 1.112289700095023, grad_norm: 0.061867225879406774, ic: 0.11634614560937079
Epoch 12: 2022-04-04 01:51:21.503254: train loss: 1.626321179850531
Eval step 0: eval loss: 1.004170189285479
Eval: 2022-04-04 01:51:24.041878: total loss: 1.0847226147133542, mse:4.694938507423096, ic :0.15613417625970116, sharpe5:13.150425739288329, irr5:411.01275634765625, ndcg5:0.8490504577919997, pnl5:4.949600696563721 
train 13, step: 0, loss: 1.0756973721365726, grad_norm: 0.04602594340668267, ic: 0.44198069084337555
train 13, step: 500, loss: 1.1523693754472806, grad_norm: 0.01852985654699156, ic: -0.16334709816180903
train 13, step: 1000, loss: 1.3772911954169944, grad_norm: 0.6679326423598484, ic: 0.1127814831977384
train 13, step: 1500, loss: 0.7761094835069444, grad_norm: 0.012442678346085322, ic: -0.00296463004470746
train 13, step: 2000, loss: 1.0355756205897177, grad_norm: 0.03607799383973058, ic: 0.05187657962884573
Epoch 13: 2022-04-04 01:51:45.888629: train loss: 1.6271122743880877
Eval step 0: eval loss: 0.9928816744627106
Eval: 2022-04-04 01:51:48.354196: total loss: 1.085626240924319, mse:4.735248652061252, ic :0.13200448523366157, sharpe5:11.12736401259899, irr5:337.7352294921875, ndcg5:0.846222133699925, pnl5:3.6850476264953613 
train 14, step: 0, loss: 1.7675297623973782, grad_norm: 0.5476877865487366, ic: 0.1666840290204853
train 14, step: 500, loss: 1.261980111418534, grad_norm: 0.1577910144701158, ic: 0.2405966901915863
train 14, step: 1000, loss: 1.0695762445118802, grad_norm: 0.18470698829508883, ic: 0.14825991656030513
train 14, step: 1500, loss: 0.9744880564677155, grad_norm: 0.14310250678331532, ic: 0.167433632726709
train 14, step: 2000, loss: 2.296801717985318, grad_norm: 0.5927072487385838, ic: -0.0802712552369952
Epoch 14: 2022-04-04 01:52:10.157693: train loss: 1.6262371908273177
Eval step 0: eval loss: 1.0066322298537058
Eval: 2022-04-04 01:52:12.690719: total loss: 1.085774106055469, mse:4.684628923885423, ic :0.1656670775494756, sharpe5:14.835768338441849, irr5:487.1907043457031, ndcg5:0.849674605348924, pnl5:8.0841646194458 
train 15, step: 0, loss: 0.9684232451491421, grad_norm: 0.17997870504994265, ic: 0.14306891522122625
train 15, step: 500, loss: 1.2241593281488732, grad_norm: 0.012840522476236647, ic: 0.07329936443184876
train 15, step: 1000, loss: 1.7518884114583335, grad_norm: 0.04745412636496331, ic: 0.02422559459523278
train 15, step: 1500, loss: 5.388637887906032, grad_norm: 0.9852907845815695, ic: 0.01161876505062856
train 15, step: 2000, loss: 0.9303646319992386, grad_norm: 0.02349511989097471, ic: 0.04303558222356722
Epoch 15: 2022-04-04 01:52:34.515145: train loss: 1.6269942793749317
Eval step 0: eval loss: 1.0073869573624274
Eval: 2022-04-04 01:52:36.960142: total loss: 1.0827380538331903, mse:4.675588344862092, ic :0.16842778495903823, sharpe5:15.221584004759787, irr5:511.96124267578125, ndcg5:0.8443143540424115, pnl5:8.219465255737305 
train 16, step: 0, loss: 6.342145474804204, grad_norm: 1.2964958659044254, ic: 0.15328160511471897
train 16, step: 500, loss: 1.3219099741133433, grad_norm: 1.9953802509090217, ic: 0.005282521958650817
train 16, step: 1000, loss: 0.8374403124370468, grad_norm: 0.20321297823406048, ic: -0.023013582983325877
train 16, step: 1500, loss: 1.2246278676716718, grad_norm: 0.34961229735214405, ic: 0.1532284016294032
train 16, step: 2000, loss: 0.9538767391490414, grad_norm: 0.32794611969020737, ic: 0.5432988570837433
Epoch 16: 2022-04-04 01:52:58.677117: train loss: 1.6243549187892434
Eval step 0: eval loss: 1.0009000676754212
Eval: 2022-04-04 01:53:01.234780: total loss: 1.0803430084913161, mse:4.699791851724937, ic :0.1650844762583079, sharpe5:14.497667056918143, irr5:475.49737548828125, ndcg5:0.8548544783452654, pnl5:5.608881950378418 
train 17, step: 0, loss: 1.180631298229007, grad_norm: 0.015387686659384215, ic: 0.12418626275099158
train 17, step: 500, loss: 1.040497075091762, grad_norm: 0.03448666912059554, ic: -0.02039649217205049
train 17, step: 1000, loss: 3.3766163237417492, grad_norm: 1.383130365908376, ic: -0.01195713806505178
train 17, step: 1500, loss: 0.8825898895757485, grad_norm: 0.011459060065664505, ic: 0.0674191480175653
train 17, step: 2000, loss: 1.0191005629981125, grad_norm: 0.7199134857679326, ic: 0.5729366476666597
Epoch 17: 2022-04-04 01:53:22.612001: train loss: 1.6265544867161947
Eval step 0: eval loss: 1.007357002246248
Eval: 2022-04-04 01:53:25.322252: total loss: 1.0852284916036443, mse:4.712266536916949, ic :0.15583265280349218, sharpe5:14.818489113450049, irr5:477.1964111328125, ndcg5:0.8488124277375186, pnl5:4.720170021057129 
train 18, step: 0, loss: 0.8482533862520047, grad_norm: 0.003544002118817006, ic: 0.042512562019568316
train 18, step: 500, loss: 2.5388630950852504, grad_norm: 1.104324372172425, ic: 0.0866213053703675
train 18, step: 1000, loss: 1.3667720218356565, grad_norm: 0.7379912308671761, ic: 0.5337172973205676
train 18, step: 1500, loss: 1.6649667005650186, grad_norm: 1.7449147442823107, ic: 0.33402200499839674
train 18, step: 2000, loss: 1.2498600880993644, grad_norm: 0.34711647174098614, ic: 0.22127583294717407
Epoch 18: 2022-04-04 01:53:46.920041: train loss: 1.6237342547101608
Eval step 0: eval loss: 1.0012674999588598
Eval: 2022-04-04 01:53:49.473405: total loss: 1.08177673752678, mse:4.681429963066821, ic :0.1700986287998601, sharpe5:15.405249670743942, irr5:520.52099609375, ndcg5:0.8594716372122655, pnl5:6.038880348205566 
train 19, step: 0, loss: 2.226762370289786, grad_norm: 0.9010040562824266, ic: 0.24968703076031268
train 19, step: 500, loss: 1.018517214752907, grad_norm: 0.058398171835800775, ic: 0.0736800245463361
train 19, step: 1000, loss: 0.9663256530158206, grad_norm: 0.17161065346293758, ic: 0.5687611843883127
train 19, step: 1500, loss: 1.5731625027126734, grad_norm: 0.06686847989908104, ic: 0.16165292559354918
train 19, step: 2000, loss: 1.6402224417536737, grad_norm: 2.185408912296859, ic: 0.6365111237683883
Epoch 19: 2022-04-04 01:54:11.203692: train loss: 1.6253141558086297
Eval step 0: eval loss: 1.0010596783051935
Eval: 2022-04-04 01:54:13.902462: total loss: 1.0809517796150807, mse:4.6810897540994105, ic :0.16561119472962355, sharpe5:14.914720973968505, irr5:492.1067199707031, ndcg5:0.8548104778134141, pnl5:4.688486576080322 
train 20, step: 0, loss: 1.2479056265586035, grad_norm: 0.32901696937165986, ic: 0.4660822792340238
train 20, step: 500, loss: 1.2292404624313737, grad_norm: 0.5043195368131019, ic: 0.046106904981652215
train 20, step: 1000, loss: 1.564113215077422, grad_norm: 0.5157026122104909, ic: 0.18884698076777962
train 20, step: 1500, loss: 0.8856500675243959, grad_norm: 0.6474359987984065, ic: 0.5681561805768147
train 20, step: 2000, loss: 1.3548583984375, grad_norm: 0.16406135531797944, ic: -0.049504375990064665
Epoch 20: 2022-04-04 01:54:35.707906: train loss: 1.6268297771627656
Eval step 0: eval loss: 0.9976821425338993
Eval: 2022-04-04 01:54:38.211695: total loss: 1.0894662495480425, mse:4.739898843253346, ic :0.1603063756896685, sharpe5:16.06312965273857, irr5:531.3785400390625, ndcg5:0.8460199809719272, pnl5:5.533267021179199 
train 21, step: 0, loss: 1.3771327783345482, grad_norm: 0.3358795739191412, ic: 0.2959308097877623
train 21, step: 500, loss: 1.1150337575315608, grad_norm: 0.14698150168298285, ic: 0.051444817970225556
train 21, step: 1000, loss: 0.9136915747611956, grad_norm: 0.2570348671206394, ic: 0.10071926558310865
train 21, step: 1500, loss: 0.7402004162094868, grad_norm: 0.22106133260619143, ic: 0.6335521190603045
train 21, step: 2000, loss: 1.122179387074385, grad_norm: 0.10208406369484954, ic: 0.30365731316297323
Epoch 21: 2022-04-04 01:54:59.726441: train loss: 1.6231518632718485
Eval step 0: eval loss: 1.0063395567979856
Eval: 2022-04-04 01:55:02.273027: total loss: 1.0818676760946322, mse:4.68923773729808, ic :0.1591130035219503, sharpe5:13.6425653475523, irr5:421.5344543457031, ndcg5:0.8687855962710314, pnl5:4.52439546585083 
train 22, step: 0, loss: 1.03420618186043, grad_norm: 0.4641637760056056, ic: 0.07877936716982344
train 22, step: 500, loss: 1.0291332815575787, grad_norm: 0.0025007864510529793, ic: -0.011145118691235191
train 22, step: 1000, loss: 0.9090768570378251, grad_norm: 0.023380470162366343, ic: 0.13513276163334959
train 22, step: 1500, loss: 0.9999005564276674, grad_norm: 0.035743971816459004, ic: 0.2661461409623317
train 22, step: 2000, loss: 1.0456633811773255, grad_norm: 0.12323638123869077, ic: 0.1405894240803937
Epoch 22: 2022-04-04 01:55:23.832836: train loss: 1.622982867064784
Eval step 0: eval loss: 1.0101457849937465
Eval: 2022-04-04 01:55:26.314398: total loss: 1.0813858949856092, mse:4.6835893072193, ic :0.16467815144644374, sharpe5:14.085594384670257, irr5:454.7702331542969, ndcg5:0.8556913186748272, pnl5:4.0902252197265625 
train 23, step: 0, loss: 1.3097648201407968, grad_norm: 1.053078533442141, ic: -0.004143569389875798
train 23, step: 500, loss: 0.9006134703919129, grad_norm: 0.15334854959184674, ic: 0.5954092541304923
train 23, step: 1000, loss: 2.265314697652536, grad_norm: 1.0472355806542037, ic: 0.12036016162809507
train 23, step: 1500, loss: 0.7732787767216057, grad_norm: 0.3040633620432786, ic: 0.719060622345044
train 23, step: 2000, loss: 1.473151312934028, grad_norm: 0.41348012741855494, ic: 0.41057021865544874
Epoch 23: 2022-04-04 01:55:47.722297: train loss: 1.6227672152584571
Eval step 0: eval loss: 1.0078455406217086
Eval: 2022-04-04 01:55:50.315853: total loss: 1.0893962545082085, mse:4.699707934773241, ic :0.15666485280569437, sharpe5:14.16679926931858, irr5:429.263916015625, ndcg5:0.859277163363539, pnl5:5.502450942993164 
train 24, step: 0, loss: 1.1745965676229508, grad_norm: 0.5978430024189094, ic: 0.3403777448007874
train 24, step: 500, loss: 1.238692899772359, grad_norm: 0.27722649929036125, ic: 0.016660696247436317
train 24, step: 1000, loss: 1.0436713986280488, grad_norm: 0.363542643791125, ic: 0.10710427436767977
train 24, step: 1500, loss: 1.2012529027743601, grad_norm: 0.07479865893005676, ic: 0.08152086452558831
train 24, step: 2000, loss: 1.3669134042588202, grad_norm: 0.41210901429404895, ic: 0.4542772858747072
Epoch 24: 2022-04-04 01:56:11.874688: train loss: 1.623165545168118
Eval step 0: eval loss: 1.0219441153238547
Eval: 2022-04-04 01:56:14.412769: total loss: 1.0874840852020702, mse:4.715215635899099, ic :0.16458658017571834, sharpe5:15.403066474199294, irr5:522.228759765625, ndcg5:0.8536111369042466, pnl5:7.94852352142334 
train 25, step: 0, loss: 1.3150945161060434, grad_norm: 0.5218923810383204, ic: 0.20108952207020026
train 25, step: 500, loss: 1.5161810540533687, grad_norm: 1.1918613602849728, ic: 0.09343376141327839
train 25, step: 1000, loss: 1.3655735605951695, grad_norm: 0.24377887964676284, ic: 0.26689035329427513
train 25, step: 1500, loss: 2.8942351607888526, grad_norm: 1.0893512010523294, ic: 0.2358799386527627
train 25, step: 2000, loss: 1.1996477344368077, grad_norm: 0.24164275909908392, ic: 0.1589496953979595
Epoch 25: 2022-04-04 01:56:36.406018: train loss: 1.6242391544751091
Eval step 0: eval loss: 1.0048659065009544
Eval: 2022-04-04 01:56:38.902197: total loss: 1.0810702835766335, mse:4.675335002508581, ic :0.1702257942824666, sharpe5:15.05350246489048, irr5:504.6500549316406, ndcg5:0.8633645012036525, pnl5:4.825827598571777 
train 26, step: 0, loss: 1.6025893110795453, grad_norm: 0.3640901318070206, ic: 0.23585116748173723
train 26, step: 500, loss: 1.0146364009860311, grad_norm: 0.1835577330209489, ic: -0.043335535403091596
train 26, step: 1000, loss: 1.8140925042932974, grad_norm: 0.6197433182095602, ic: 0.18700116206919776
train 26, step: 1500, loss: 0.9252094809147067, grad_norm: 0.05312597142950295, ic: -0.009426912988941709
train 26, step: 2000, loss: 0.9877376045767716, grad_norm: 0.15222225861484037, ic: 0.16354059011127414
Epoch 26: 2022-04-04 01:57:00.309043: train loss: 1.6241660914173286
Eval step 0: eval loss: 0.9998965070020405
Eval: 2022-04-04 01:57:02.881887: total loss: 1.0827433650496832, mse:4.685324838992175, ic :0.16460764804117986, sharpe5:14.819677196145056, irr5:480.2710266113281, ndcg5:0.8543115649805518, pnl5:4.724344253540039 
train 27, step: 0, loss: 1.6329242752259037, grad_norm: 0.46945987887197305, ic: 0.6652008159045296
train 27, step: 500, loss: 1.5064639362910672, grad_norm: 0.6593678073156101, ic: 0.07108571854798461
train 27, step: 1000, loss: 2.601057145979021, grad_norm: 1.136243467220614, ic: 0.40344384652789134
train 27, step: 1500, loss: 0.8554053852576335, grad_norm: 0.6341517005980903, ic: 0.5524895300480387
train 27, step: 2000, loss: 1.3534704346078148, grad_norm: 1.1930362030226227, ic: -0.03115899884793315
Epoch 27: 2022-04-04 01:57:24.648716: train loss: 1.6238276393715214
Eval step 0: eval loss: 1.0105008752550684
Eval: 2022-04-04 01:57:27.111637: total loss: 1.0799570786940718, mse:4.683710937571505, ic :0.16947066634983493, sharpe5:14.516276253461838, irr5:477.77130126953125, ndcg5:0.824528304983637, pnl5:4.055785179138184 
train 28, step: 0, loss: 1.1609312414297055, grad_norm: 0.14340489198606388, ic: 0.11458013017601888
train 28, step: 500, loss: 2.9515656372271417, grad_norm: 0.8739822306153686, ic: 0.10430479907110743
train 28, step: 1000, loss: 2.772536146697275, grad_norm: 2.6012081403032763, ic: -0.0402281600629637
train 28, step: 1500, loss: 1.0221573634230179, grad_norm: 0.002464578722776462, ic: 0.20499776664933084
train 28, step: 2000, loss: 1.7650543922601745, grad_norm: 0.3465434741538571, ic: 0.08401999863011211
Epoch 28: 2022-04-04 01:57:48.290030: train loss: 1.6218532939684098
Eval step 0: eval loss: 1.0030876910956423
Eval: 2022-04-04 01:57:51.014654: total loss: 1.081305357404538, mse:4.68600131512472, ic :0.1637909791478136, sharpe5:14.593058935403823, irr5:476.03826904296875, ndcg5:0.8620951591439261, pnl5:4.176856517791748 
train 29, step: 0, loss: 1.5166687520730666, grad_norm: 0.1990566414903458, ic: 0.08288908255213832
train 29, step: 500, loss: 2.5821808716021417, grad_norm: 2.3268465727638463, ic: -0.07547262404848837
train 29, step: 1000, loss: 1.7141753622404843, grad_norm: 0.9753134813168081, ic: 0.48093952970332554
train 29, step: 1500, loss: 3.98974399699745, grad_norm: 1.2487312666265915, ic: 0.11287600184856561
train 29, step: 2000, loss: 0.923628273071224, grad_norm: 0.23600853989377937, ic: 0.46993555162335743
Epoch 29: 2022-04-04 01:58:12.262903: train loss: 1.6237692438589504
Eval step 0: eval loss: 1.0037379613859267
Eval: 2022-04-04 01:58:14.932373: total loss: 1.0811407571441187, mse:4.681964184915744, ic :0.16795783404104137, sharpe5:14.969261158704757, irr5:497.4891662597656, ndcg5:0.8439845324999835, pnl5:5.007876873016357 
train 30, step: 0, loss: 1.2474980668350208, grad_norm: 0.04215000565651634, ic: 0.979732988885644
train 30, step: 500, loss: 1.9365340607075752, grad_norm: 0.3358157998648676, ic: 0.15835926362893854
train 30, step: 1000, loss: 3.413410920460178, grad_norm: 0.9353650766337379, ic: 0.4291442953449752
train 30, step: 1500, loss: 1.0776197821090603, grad_norm: 0.19745694575319353, ic: 0.1456554275462303
train 30, step: 2000, loss: 1.0957608128372958, grad_norm: 0.10802667912605635, ic: 0.4420894964072325
Epoch 30: 2022-04-04 01:58:36.716784: train loss: 1.6210782178332837
Eval step 0: eval loss: 1.0077556109918049
Eval: 2022-04-04 01:58:39.198967: total loss: 1.0851624030786484, mse:4.708548064258357, ic :0.1527573928465462, sharpe5:13.025487871170043, irr5:412.71917724609375, ndcg5:0.8473803295944263, pnl5:3.783245801925659 
train 31, step: 0, loss: 1.1636955027802938, grad_norm: 0.29132647051424687, ic: 0.20343238025230748
train 31, step: 500, loss: 0.8266029925484534, grad_norm: 0.07524312105949822, ic: 0.22881258935633164
train 31, step: 1000, loss: 5.192154061284047, grad_norm: 1.9393813276728522, ic: -0.011948557554919307
train 31, step: 1500, loss: 1.6845810667624612, grad_norm: 0.4789397489274001, ic: 0.27546113521298965
train 31, step: 2000, loss: 0.9026355027238985, grad_norm: 0.6256710356107678, ic: 0.21327282720560622
Epoch 31: 2022-04-04 01:59:00.303059: train loss: 1.6254827005218406
Eval step 0: eval loss: 1.0094185699093272
Eval: 2022-04-04 01:59:02.676851: total loss: 1.08232594802559, mse:4.675441251871343, ic :0.16739229022563493, sharpe5:15.023017171025275, irr5:497.3636169433594, ndcg5:0.8559764225206681, pnl5:4.936261177062988 
train 32, step: 0, loss: 0.8855915199725171, grad_norm: 0.3958235619594739, ic: 0.11200421573959503
train 32, step: 500, loss: 1.0974927762659585, grad_norm: 0.3496904113325571, ic: 0.16544553111702662
train 32, step: 1000, loss: 1.3869054074345968, grad_norm: 0.07084452338492224, ic: 0.07608540731755262
train 32, step: 1500, loss: 2.0694651884191178, grad_norm: 0.5485959185027718, ic: 0.437906332646737
train 32, step: 2000, loss: 1.076627833003808, grad_norm: 0.4876358159699084, ic: 0.46604933311800034
Epoch 32: 2022-04-04 01:59:23.627737: train loss: 1.620956234719695
Eval step 0: eval loss: 1.008431593828166
Eval: 2022-04-04 01:59:26.015701: total loss: 1.0808306108615797, mse:4.674223474745001, ic :0.17135756319296375, sharpe5:15.4045099568367, irr5:512.524169921875, ndcg5:0.8503345770713421, pnl5:6.636723518371582 
train 33, step: 0, loss: 1.1621543237323337, grad_norm: 0.01437187446899087, ic: 0.03306839028865771
train 33, step: 500, loss: 3.1666649152094544, grad_norm: 1.0464054261318625, ic: 0.5261237035559084
train 33, step: 1000, loss: 5.183656341041515, grad_norm: 3.6070861605379543, ic: 0.04034748771588504
train 33, step: 1500, loss: 1.3117056497713415, grad_norm: 1.6730818217123518, ic: 0.01094387238671542
train 33, step: 2000, loss: 1.8670701610949612, grad_norm: 0.3466749170537042, ic: 0.07430322468307096
Epoch 33: 2022-04-04 01:59:46.675375: train loss: 1.6239074199119423
Eval step 0: eval loss: 1.0182348234268035
Eval: 2022-04-04 01:59:49.084017: total loss: 1.0901258512383962, mse:4.697886077907493, ic :0.16539556164696018, sharpe5:14.70923469364643, irr5:467.45831298828125, ndcg5:0.850521276578579, pnl5:5.419898986816406 
train 34, step: 0, loss: 0.7160365955576466, grad_norm: 0.3675689570524853, ic: 0.15314048463520774
train 34, step: 500, loss: 1.8241311004113687, grad_norm: 0.5275034238640872, ic: 0.8132370659429755
train 34, step: 1000, loss: 0.6928098481276939, grad_norm: 0.1118955424502989, ic: 0.4798514530016953
train 34, step: 1500, loss: 1.6479795798277244, grad_norm: 0.867583995292849, ic: 0.6472046149319084
train 34, step: 2000, loss: 2.9929090622425867, grad_norm: 0.4296531151107314, ic: 0.08197824476310926
Epoch 34: 2022-04-04 02:00:10.129453: train loss: 1.6229272527097505
Eval step 0: eval loss: 1.0066499715104988
Eval: 2022-04-04 02:00:12.528095: total loss: 1.0811220728636821, mse:4.6737676272956055, ic :0.17086638129252588, sharpe5:15.559194350838661, irr5:518.4405517578125, ndcg5:0.8449525196049325, pnl5:4.422039985656738 
train 35, step: 0, loss: 1.045097447648833, grad_norm: 0.4656349694164422, ic: -0.023771359512331468
train 35, step: 500, loss: 3.315286162405303, grad_norm: 1.7480332752046719, ic: -0.035638849760420706
train 35, step: 1000, loss: 1.339917413119612, grad_norm: 0.06650225468969652, ic: 0.5091155576825773
train 35, step: 1500, loss: 1.627446005131552, grad_norm: 0.39127615165091284, ic: 0.10693972068378016
train 35, step: 2000, loss: 1.2878979924461122, grad_norm: 0.06038508065909945, ic: -0.08425640818711735
Epoch 35: 2022-04-04 02:00:33.325859: train loss: 1.620398138842573
Eval step 0: eval loss: 1.0049488937434174
Eval: 2022-04-04 02:00:35.837894: total loss: 1.0835263333177108, mse:4.685812398905456, ic :0.16293278437975933, sharpe5:14.17627176940441, irr5:446.4609375, ndcg5:0.8417594000179015, pnl5:4.405555725097656 
train 36, step: 0, loss: 8.959923169889503, grad_norm: 1.231584106992028, ic: -0.17104329946094554
train 36, step: 500, loss: 0.8636464444549584, grad_norm: 0.010268981289380261, ic: 0.07986300327159819
train 36, step: 1000, loss: 1.9655958366973785, grad_norm: 2.3376141300722955, ic: 0.08351190740459342
train 36, step: 1500, loss: 1.06127222443511, grad_norm: 0.21504858920859288, ic: 0.07960830073007795
train 36, step: 2000, loss: 2.127009597787301, grad_norm: 1.571043354043441, ic: 0.37985215793406535
Epoch 36: 2022-04-04 02:00:56.102636: train loss: 1.6214872096157271
Eval step 0: eval loss: 1.020765709337151
Eval: 2022-04-04 02:00:58.485210: total loss: 1.0879864762560114, mse:4.688449724582485, ic :0.16674343266540498, sharpe5:14.743230317831038, irr5:492.3311767578125, ndcg5:0.8488096842800346, pnl5:4.018402099609375 
train 37, step: 0, loss: 1.188016666442941, grad_norm: 0.2793347586862257, ic: 0.16898562869489825
train 37, step: 500, loss: 2.336144563667012, grad_norm: 0.03133648183665818, ic: 0.15625082089998313
train 37, step: 1000, loss: 0.7763507437970484, grad_norm: 0.35596312836678895, ic: 0.15859102186546908
train 37, step: 1500, loss: 3.1300575527442893, grad_norm: 0.7082975142375085, ic: 0.2046336919612017
train 37, step: 2000, loss: 3.148998187975285, grad_norm: 1.9248309837487605, ic: -0.029649083861233556
Epoch 37: 2022-04-04 02:01:19.316301: train loss: 1.6236026477529713
Eval step 0: eval loss: 1.0080515623971498
Eval: 2022-04-04 02:01:21.756712: total loss: 1.0810453763836045, mse:4.678367425547284, ic :0.16984930267663428, sharpe5:15.414862167835235, irr5:517.6445922851562, ndcg5:0.8513906449744425, pnl5:4.769552707672119 
train 38, step: 0, loss: 1.3455563631924716, grad_norm: 0.5046188008547133, ic: -0.283669726145318
train 38, step: 500, loss: 1.6378277919089148, grad_norm: 1.063749157917956, ic: 0.24302843091705087
train 38, step: 1000, loss: 1.8269221327572664, grad_norm: 0.6731957136906798, ic: 0.14728873798665598
train 38, step: 1500, loss: 1.0843832537034532, grad_norm: 0.31933772785007203, ic: 0.47565876984723326
train 38, step: 2000, loss: 0.7489497599451302, grad_norm: 0.07745437066274281, ic: 0.5811837394449914
Epoch 38: 2022-04-04 02:01:42.809688: train loss: 1.6196741633518739
Eval step 0: eval loss: 0.9996430455790876
Eval: 2022-04-04 02:01:45.173032: total loss: 1.0801335086706068, mse:4.6868611299641625, ic :0.16894142858063682, sharpe5:15.443429124355315, irr5:505.9783020019531, ndcg5:0.84448952951647, pnl5:5.359097957611084 
train 39, step: 0, loss: 0.8658213924269352, grad_norm: 0.046115671494798366, ic: 0.5416048816505908
train 39, step: 500, loss: 1.2338812368434242, grad_norm: 0.3927119373587937, ic: 0.05108214211726938
train 39, step: 1000, loss: 1.3923996434067234, grad_norm: 0.3375970620641811, ic: 0.07094955061243091
train 39, step: 1500, loss: 2.43835672270816, grad_norm: 0.5127597028596027, ic: -0.07529532711469525
train 39, step: 2000, loss: 2.965499545688396, grad_norm: 2.530780657376556, ic: 0.18334457017944633
Epoch 39: 2022-04-04 02:02:05.881527: train loss: 1.6214502723501294
Eval step 0: eval loss: 1.0012534223398828
Eval: 2022-04-04 02:02:08.261040: total loss: 1.078788001417533, mse:4.674895097459729, ic :0.17538929503688036, sharpe5:15.584735291004181, irr5:526.3936157226562, ndcg5:0.8540430010669319, pnl5:6.1191086769104 

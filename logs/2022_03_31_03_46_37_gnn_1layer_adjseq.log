Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', batch_size=1, dataset_type='AdjSeqTimeDataset', dout=0.3, epochs=20, gnn_layers=1, hidden_dim=128, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=3, mask_adj=True, mask_type='soft', model_type='GNNModel', num_days=1, num_heads=1, print_inteval=500, relation_num=1, seed=10086, shuffle=True, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=False)
93746
GNNModel(
  (fc1): Linear(in_features=9, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
  (fc4): Linear(in_features=128, out_features=1, bias=True)
  (gnns): ModuleList(
    (0): GraphConv(128, 128)
  )
  (dropout): Dropout(p=0.3, inplace=False)
  (relu): LeakyReLU(negative_slope=0.01)
)
train 0, step: 0, loss: 0.8711773880428226, grad_norm: 0.0003193853186562495, ic: 0.07495164622926319
train 0, step: 500, loss: 0.9847862887095257, grad_norm: 0.13918249984758727, ic: 0.028647122868522102
train 0, step: 1000, loss: 1.0700454219117, grad_norm: 0.022893729467266716, ic: -0.06975838941196985
train 0, step: 1500, loss: 0.9537895781765676, grad_norm: 0.10234904932428997, ic: 0.14419448738410404
train 0, step: 2000, loss: 1.072284536300597, grad_norm: 0.3244554202385959, ic: 0.12623765473095477
Epoch 0: train loss: 1.6473589137867186
Eval step 0: eval loss: 1.0125072895068128
Eval: total loss: 1.0912947252504093, mse:4.887409638933619, ic :0.024988317395637758, sharpe5:7.070680244565009, irr5:209.71078491210938, ndcg5:0.8438647613070356 
train 1, step: 0, loss: 0.9399624768745543, grad_norm: 0.0770733125605212, ic: 0.15560203274637086
train 1, step: 500, loss: 1.6792566418105084, grad_norm: 0.12293708747018446, ic: -0.07830724174501036
train 1, step: 1000, loss: 1.127135861118334, grad_norm: 0.37048945756752505, ic: 0.03396517262713718
train 1, step: 1500, loss: 0.8950199321377258, grad_norm: 0.1353338251517847, ic: -0.1081745026647227
train 1, step: 2000, loss: 4.702517988907349, grad_norm: 1.6209617629063835, ic: 0.05399527015811472
Epoch 1: train loss: 1.6450413537391386
Eval step 0: eval loss: 0.9987904175511781
Eval: total loss: 1.0889910459521357, mse:4.877047798335312, ic :0.05275519444870934, sharpe5:7.186587832868099, irr5:215.14715576171875, ndcg5:0.851990134320317 
train 2, step: 0, loss: 0.9646930883139258, grad_norm: 0.12531027807823727, ic: 0.009713006603311704
train 2, step: 500, loss: 1.3048687559185606, grad_norm: 0.09592914515625442, ic: 0.20409681661706994
train 2, step: 1000, loss: 1.066696821110191, grad_norm: 0.010991999820187111, ic: 0.011070890442331649
train 2, step: 1500, loss: 0.96847233534181, grad_norm: 0.3331619538104564, ic: -0.029780457704574798
train 2, step: 2000, loss: 1.7263895823543234, grad_norm: 0.10881542295408288, ic: 0.10657375913354891
Epoch 2: train loss: 1.6440268238784586
Eval step 0: eval loss: 0.9918549082164955
Eval: total loss: 1.0901369456653383, mse:4.883738925939885, ic :0.06528052819848452, sharpe5:7.329834566116332, irr5:216.14480590820312, ndcg5:0.8364259470744961 
train 3, step: 0, loss: 0.8413603087375195, grad_norm: 0.06752707824538215, ic: 0.2720587026494234
train 3, step: 500, loss: 1.2072307770582231, grad_norm: 0.01114850287681947, ic: 0.4776042027061069
train 3, step: 1000, loss: 0.9024856656615498, grad_norm: 0.02262030561252136, ic: 0.20704615910158908
train 3, step: 1500, loss: 4.377761083126432, grad_norm: 0.7046555550310307, ic: 0.08395042066774273
train 3, step: 2000, loss: 1.7020686940617458, grad_norm: 0.4363140264955116, ic: -0.05892447487153098
Epoch 3: train loss: 1.6397425922613005
Eval step 0: eval loss: 0.9995777999934176
Eval: total loss: 1.088019572210688, mse:4.723520074609754, ic :0.11998942655957343, sharpe5:7.5512114524841305, irr5:218.6002960205078, ndcg5:0.8627289582122808 
train 4, step: 0, loss: 1.2953179996670472, grad_norm: 0.22206222720543742, ic: 0.026875597820155746
train 4, step: 500, loss: 0.8443230562848854, grad_norm: 0.04918483917419576, ic: 0.4771477513641609
train 4, step: 1000, loss: 1.9467340783227849, grad_norm: 0.22447619677788264, ic: 0.15930983368816531
train 4, step: 1500, loss: 1.1702207507031894, grad_norm: 0.013820789605447, ic: 0.21001626483078178
train 4, step: 2000, loss: 6.643766472138554, grad_norm: 1.0605855541822857, ic: -0.03200885270402873
Epoch 4: train loss: 1.6381423655017087
Eval step 0: eval loss: 1.0002926087743549
Eval: total loss: 1.086433226077014, mse:4.714640132036308, ic :0.12532424167925657, sharpe5:7.755906938910484, irr5:222.776611328125, ndcg5:0.8444305548002914 
train 5, step: 0, loss: 3.749391726230053, grad_norm: 0.5605656667105424, ic: 0.30426122704872716
train 5, step: 500, loss: 3.4415128731433255, grad_norm: 0.7197745865678147, ic: -0.06096803562604181
train 5, step: 1000, loss: 1.0436052034138867, grad_norm: 0.05027854895146083, ic: 0.06591811557015809
train 5, step: 1500, loss: 1.4956624183886917, grad_norm: 1.1298775126600937, ic: 0.4629987902058373
train 5, step: 2000, loss: 1.7537681779611423, grad_norm: 0.7208075622393331, ic: 0.03224271876760127
Epoch 5: train loss: 1.638371984480195
Eval step 0: eval loss: 1.0028227875896853
Eval: total loss: 1.0869685294512115, mse:4.715548972001003, ic :0.1253922599031892, sharpe5:7.607124175429344, irr5:218.6720428466797, ndcg5:0.8378137057351496 
train 6, step: 0, loss: 1.1023052014802632, grad_norm: 0.021642281864177382, ic: 0.4353219755501751
train 6, step: 500, loss: 1.8386265364445475, grad_norm: 0.12272362033929236, ic: 0.19567541851454107
train 6, step: 1000, loss: 0.8726860466904528, grad_norm: 0.17943705379268773, ic: 0.05782522012425348
train 6, step: 1500, loss: 0.8487580969887955, grad_norm: 0.003691625626755511, ic: 0.09467612312218822
train 6, step: 2000, loss: 1.9256255247882592, grad_norm: 0.2504686776695484, ic: 0.05718174273195026
Epoch 6: train loss: 1.6363501306172292
Eval step 0: eval loss: 0.9961647166271721
Eval: total loss: 1.0850626897872444, mse:4.724988634215333, ic :0.13034220184996897, sharpe5:11.113016211390494, irr5:326.85015869140625, ndcg5:0.8440099542525085 
train 7, step: 0, loss: 0.8150234923935201, grad_norm: 0.09396621896365817, ic: 0.5317456466068738
train 7, step: 500, loss: 1.1170016538221668, grad_norm: 0.07234996176421353, ic: 0.21229221701568138
train 7, step: 1000, loss: 1.0985331387118555, grad_norm: 0.03162080761809813, ic: 0.045098543113977756
train 7, step: 1500, loss: 1.105599722756527, grad_norm: 0.06319581075549646, ic: 0.43645148607749784
train 7, step: 2000, loss: 0.7190131011058847, grad_norm: 0.11811474288813249, ic: -0.0034519391417699146
Epoch 7: train loss: 1.6320563051033692
Eval step 0: eval loss: 1.0056030209156135
Eval: total loss: 1.0969786418888654, mse:4.811732802925474, ic :0.12168244459066252, sharpe5:14.040022521615027, irr5:429.6028747558594, ndcg5:0.8462324324299234 
train 8, step: 0, loss: 2.0249350515849285, grad_norm: 0.3649443522947225, ic: -0.05103634929993843
train 8, step: 500, loss: 0.9152163972189873, grad_norm: 0.7505512666537811, ic: 0.5645816703719946
train 8, step: 1000, loss: 0.7361902928614354, grad_norm: 0.12421180498882617, ic: 0.14504499944260085
train 8, step: 1500, loss: 0.8495987664232237, grad_norm: 0.04093194451765661, ic: 0.1836811536910804
train 8, step: 2000, loss: 1.4647549541560292, grad_norm: 0.8193875261268323, ic: 0.14137466867630288
Epoch 8: train loss: 1.6305096982381602
Eval step 0: eval loss: 1.0047888974254542
Eval: total loss: 1.0865841470981221, mse:4.703044706565478, ic :0.14413618466896838, sharpe5:12.58658401608467, irr5:382.02838134765625, ndcg5:0.8494459271888818 
train 9, step: 0, loss: 0.7706789453660836, grad_norm: 0.08450333582601377, ic: 0.541781385810902
train 9, step: 500, loss: 1.7680103870016273, grad_norm: 0.06122311179057356, ic: -0.11109037789727608
train 9, step: 1000, loss: 0.7783481294074944, grad_norm: 0.021743882328889744, ic: 0.15750058536142375
train 9, step: 1500, loss: 1.0627715028734215, grad_norm: 0.1090911677139224, ic: -0.07899871274938401
train 9, step: 2000, loss: 4.481263786764706, grad_norm: 2.292813845384302, ic: 0.24168057124570497
Epoch 9: train loss: 1.6290441408297656
Eval step 0: eval loss: 1.0014978843717086
Eval: total loss: 1.0881890818594038, mse:4.733145288063256, ic :0.14678109608428008, sharpe5:14.723494523763655, irr5:470.7997741699219, ndcg5:0.8471866222634662 
train 10, step: 0, loss: 0.7966933272813967, grad_norm: 0.003148906196019413, ic: 0.11375986219923422
train 10, step: 500, loss: 0.7965911020874505, grad_norm: 0.11059643486530665, ic: -0.021389429628239434
train 10, step: 1000, loss: 1.0073007354288857, grad_norm: 0.47772195055446964, ic: -0.004567854198647725
train 10, step: 1500, loss: 1.3260925789189533, grad_norm: 0.16863138293373592, ic: 0.08720785295720107
train 10, step: 2000, loss: 1.23987944122265, grad_norm: 0.5264984829488633, ic: -0.1731663321587478
Epoch 10: train loss: 1.6288984044087265
Eval step 0: eval loss: 1.00374406811562
Eval: total loss: 1.0820861926701468, mse:4.699992138463748, ic :0.15580916867002767, sharpe5:14.802894582152366, irr5:477.5599670410156, ndcg5:0.8384995803951611 
train 11, step: 0, loss: 1.5312699562931262, grad_norm: 0.02800439574895518, ic: 0.18506959078655105
train 11, step: 500, loss: 1.3459038672509132, grad_norm: 0.2756312553820836, ic: 0.1472851827879409
train 11, step: 1000, loss: 2.261246155776865, grad_norm: 0.9294054510861589, ic: 0.25542803897827937
train 11, step: 1500, loss: 1.410377963524879, grad_norm: 2.6438830983175654, ic: 0.030369810326880742
train 11, step: 2000, loss: 3.6889841928904428, grad_norm: 3.3495970504095283, ic: 0.20303306933041398
Epoch 11: train loss: 1.626353336556913
Eval step 0: eval loss: 1.01361839290416
Eval: total loss: 1.0887305957965172, mse:4.699322578182441, ic :0.15164892624847126, sharpe5:13.595630405545235, irr5:424.90283203125, ndcg5:0.8561095248687822 
train 12, step: 0, loss: 1.0076399178340516, grad_norm: 0.1391009565646522, ic: 0.09197602392739745
train 12, step: 500, loss: 1.2087277434593022, grad_norm: 0.13665165938496876, ic: 0.10971180944108859
train 12, step: 1000, loss: 1.1358270430197213, grad_norm: 7.902391763428262, ic: 0.6112005038468833
train 12, step: 1500, loss: 0.7543206791230588, grad_norm: 0.10618729377973098, ic: 0.6129125238895727
train 12, step: 2000, loss: 2.764511159092089, grad_norm: 0.5858883981692565, ic: -0.029449564178683586
Epoch 12: train loss: 1.6281336610926458
Eval step 0: eval loss: 1.0023077652917654
Eval: total loss: 1.083157402167619, mse:4.688211973618505, ic :0.1565486209200919, sharpe5:13.819094004034996, irr5:418.503662109375, ndcg5:0.848125340087382 
train 13, step: 0, loss: 1.3470148446452443, grad_norm: 0.5972220613069356, ic: 0.1500797818449759
train 13, step: 500, loss: 1.4269709245980784, grad_norm: 0.16084467046610781, ic: -0.09809829403489931
train 13, step: 1000, loss: 2.1972828631722083, grad_norm: 1.2144693890267508, ic: 0.04904297539184728
train 13, step: 1500, loss: 1.5775218743833859, grad_norm: 1.9238335847988786, ic: -0.0785251168886137
train 13, step: 2000, loss: 0.7188297513010408, grad_norm: 0.037464937069119686, ic: -0.05316898500074115
Epoch 13: train loss: 1.6270799639268922
Eval step 0: eval loss: 1.0134322340705633
Eval: total loss: 1.083160799055756, mse:4.681602593245116, ic :0.16519089581321167, sharpe5:14.74729212284088, irr5:483.9666748046875, ndcg5:0.8462586345565775 
train 14, step: 0, loss: 1.962349437429458, grad_norm: 0.86160744991806, ic: 0.13479544636262672
train 14, step: 500, loss: 2.758255611501338, grad_norm: 2.010035192708816, ic: -0.12921196759677703
train 14, step: 1000, loss: 1.0578923547334194, grad_norm: 0.09439533164730388, ic: 0.15034453164243217
train 14, step: 1500, loss: 3.0524348857239905, grad_norm: 1.3486463289464679, ic: 0.13568278371623727
train 14, step: 2000, loss: 0.8027601868141698, grad_norm: 0.03104540791671388, ic: -0.028302109674695163
Epoch 14: train loss: 1.62717712129559
Eval step 0: eval loss: 1.0089288101879277
Eval: total loss: 1.083974122416451, mse:4.688262829124408, ic :0.1601172255911338, sharpe5:14.507223744392395, irr5:465.30279541015625, ndcg5:0.8552944340978332 
train 15, step: 0, loss: 1.2436417538283997, grad_norm: 0.29950088219297466, ic: 0.5323696866837995
train 15, step: 500, loss: 1.811254040948276, grad_norm: 1.0066422593415123, ic: -0.0030600345364674188
train 15, step: 1000, loss: 1.7381718333174543, grad_norm: 0.5404727202476436, ic: 0.17694945904032316
train 15, step: 1500, loss: 1.4540920736336032, grad_norm: 0.46475570202935457, ic: -0.0910503571170513
train 15, step: 2000, loss: 3.1175728852789657, grad_norm: 0.10869380740065988, ic: 0.19139166851824263
Epoch 15: train loss: 1.6257770055825886
Eval step 0: eval loss: 1.0039235416872365
Eval: total loss: 1.0841190301464123, mse:4.695850285712259, ic :0.16477065280371747, sharpe5:15.597827848792075, irr5:518.4984130859375, ndcg5:0.8679032251400566 
train 16, step: 0, loss: 1.7912712779471545, grad_norm: 0.7115554144346411, ic: 0.20596006761670932
train 16, step: 500, loss: 1.336915773766063, grad_norm: 0.40009722361927763, ic: 0.347789405056786
train 16, step: 1000, loss: 0.9145254147280554, grad_norm: 0.011566911545778748, ic: 0.004332101067967008
train 16, step: 1500, loss: 1.3545845983349856, grad_norm: 1.1159674732460887, ic: 0.232764225154128
train 16, step: 2000, loss: 1.252337096438993, grad_norm: 0.16648008622774696, ic: 0.21292511583969245
Epoch 16: train loss: 1.6254592056901802
Eval step 0: eval loss: 1.0118586262506581
Eval: total loss: 1.0841095728125494, mse:4.683496454461085, ic :0.16771224448416888, sharpe5:15.07842855334282, irr5:495.0995178222656, ndcg5:0.8715290470104397 
train 17, step: 0, loss: 1.5469197005010897, grad_norm: 0.5377369404087748, ic: 0.13482764196435146
train 17, step: 500, loss: 2.2268419156962924, grad_norm: 1.105108645860474, ic: 0.15202120780854664
train 17, step: 1000, loss: 0.9615689703150107, grad_norm: 0.007014511951477795, ic: 0.15424984260815056
train 17, step: 1500, loss: 0.8546646218624269, grad_norm: 0.17843547219359523, ic: 0.28436873302830545
train 17, step: 2000, loss: 3.2034595344640033, grad_norm: 1.3522851917791396, ic: 0.05773535711217853
Epoch 17: train loss: 1.62614742288718
Eval step 0: eval loss: 1.0132380400663177
Eval: total loss: 1.0843605434021109, mse:4.685223360370776, ic :0.16364225220492426, sharpe5:14.107910664081572, irr5:451.8184814453125, ndcg5:0.850249594973404 
train 18, step: 0, loss: 1.068280709672498, grad_norm: 0.3970804552433644, ic: -0.014756398651038716
train 18, step: 500, loss: 0.8063731317934782, grad_norm: 0.10254090366740912, ic: -0.033036951144368415
train 18, step: 1000, loss: 1.1699220600952427, grad_norm: 1.2785501966659425, ic: 0.044047167903024466
train 18, step: 1500, loss: 0.93843356918239, grad_norm: 0.018657202051032835, ic: 0.11380507274677298
train 18, step: 2000, loss: 1.7533186229455018, grad_norm: 0.9369946966945206, ic: 0.4791002008242904
Epoch 18: train loss: 1.6247316568853383
Eval step 0: eval loss: 0.9939949634264744
Eval: total loss: 1.0811305602895653, mse:4.696984634529835, ic :0.16161922094349165, sharpe5:14.874994931817055, irr5:486.2979736328125, ndcg5:0.8483391533270553 
train 19, step: 0, loss: 1.0825798146535923, grad_norm: 0.7473053959069276, ic: 0.051260206159613075
train 19, step: 500, loss: 2.244936630955771, grad_norm: 0.7417950383459915, ic: 0.223996197676112
train 19, step: 1000, loss: 1.3053260454671636, grad_norm: 0.11134267741955758, ic: 0.5649326862727031
train 19, step: 1500, loss: 1.5052096306072609, grad_norm: 0.12995376249214155, ic: 0.4645378227041469
train 19, step: 2000, loss: 1.1503889515303694, grad_norm: 0.3988915836673545, ic: 0.17975185527599558
Epoch 19: train loss: 1.6250147062884035
Eval step 0: eval loss: 1.0028309513230647
Eval: total loss: 1.083260825059374, mse:4.6865488388545815, ic :0.15910629636712, sharpe5:14.551256586313247, irr5:455.6566467285156, ndcg5:0.8590488370711292 

Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='AdjSeqTimeDataset', dout=0.3, epochs=40, glstm_layers=1, gnn_layers=1, gpu=0, graph_attn=True, hidden_dim=128, inner_prod=False, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=1, market=None, mask_adj=True, mask_type='soft', model_type='BiGLSTM', normalize_adj=True, num_days=8, num_heads=1, print_inteval=500, rank_loss=False, relation_num=1, rsr_data_path=None, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_250_0.8/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
58486
BiGLSTM(
  (input_to_hidden): Linear(in_features=9, out_features=128, bias=True)
  (forward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (attention): ModuleList(
            (0): GraphAttentionLayer (128 -> 128)
          )
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
  )
  (backward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (attention): ModuleList(
            (0): GraphAttentionLayer (128 -> 128)
          )
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
  )
  (fc0): ModuleList(
    (0): Linear(in_features=256, out_features=128, bias=True)
  )
  (w_out): Linear(in_features=128, out_features=1, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
)
train 0, step: 0, loss: 4.939038906738663, grad_norm: 4.425279322819397, ic: -0.04507333263499234
train 0, step: 500, loss: 0.8657885208647325, grad_norm: 0.02552291668208772, ic: 0.05579693852540267
train 0, step: 1000, loss: 1.9386151529352598, grad_norm: 0.4236180647073222, ic: -0.003635108771348773
train 0, step: 1500, loss: 0.942141373826581, grad_norm: 0.01932691304569225, ic: 0.014651439775548867
train 0, step: 2000, loss: 0.9997992738705903, grad_norm: 0.12994682828726317, ic: -0.010210469555411071
Epoch 0: 2022-04-27 13:14:13.100852: train loss: 1.648966094671224
Eval step 0: eval loss: 0.8360480578857679
Eval: 2022-04-27 13:14:26.527354: total loss: 1.0792340037735546, mse:4.823301532515632, ic :0.009763974271013566, sharpe5:8.246612523794173, irr5:231.17117309570312, ndcg5:0.8464848821901763, pnl5:2.8293323516845703 
train 1, step: 0, loss: 2.764708488218246, grad_norm: 0.7373678915848509, ic: 0.06670874962474649
train 1, step: 500, loss: 1.7507445597663627, grad_norm: 0.6521994968171414, ic: 0.13640332654946652
train 1, step: 1000, loss: 0.8744845103068524, grad_norm: 0.14940395293295997, ic: 0.041936335077648434
train 1, step: 1500, loss: 1.7071265209680315, grad_norm: 0.17906073649807974, ic: 0.010094375389466545
train 1, step: 2000, loss: 2.172925, grad_norm: 0.8141112315758631, ic: -0.016633524397026395
Epoch 1: 2022-04-27 13:18:40.049939: train loss: 1.6467484671134538
Eval step 0: eval loss: 0.835673164391794
Eval: 2022-04-27 13:18:53.624294: total loss: 1.0791198466631633, mse:4.823243057464011, ic :0.018724309980539627, sharpe5:8.893033561706542, irr5:252.1104736328125, ndcg5:0.8511143134657974, pnl5:2.140695571899414 
train 2, step: 0, loss: 2.141185724431818, grad_norm: 0.006952417986632003, ic: 0.0654146123027453
train 2, step: 500, loss: 3.292296694664515, grad_norm: 0.2556953754150698, ic: -0.032834684177059134
train 2, step: 1000, loss: 2.0740144576149424, grad_norm: 1.8270176523053813e-05, ic: 0.33894022286904657
train 2, step: 1500, loss: 1.4801739175811068, grad_norm: 0.05092340490457611, ic: -0.018975772172096332
train 2, step: 2000, loss: 3.2172179236778846, grad_norm: 0.72824921941981, ic: 0.1037747697438867
Epoch 2: 2022-04-27 13:23:05.159369: train loss: 1.6466149497872273
Eval step 0: eval loss: 0.83660663568559
Eval: 2022-04-27 13:23:18.556329: total loss: 1.0793850221686099, mse:4.82212354695045, ic :0.0284330059742699, sharpe5:11.45754222035408, irr5:374.8428649902344, ndcg5:0.8512469780870842, pnl5:2.8763065338134766 
train 3, step: 0, loss: 1.5231456229357216, grad_norm: 0.49454432317259467, ic: 0.0018008674166535305
train 3, step: 500, loss: 1.4925148052075177, grad_norm: 0.3237566344337633, ic: 0.01384394446749029
train 3, step: 1000, loss: 3.685039759643063, grad_norm: 0.6788937729676708, ic: 0.056174384138497
train 3, step: 1500, loss: 1.9675466784088584, grad_norm: 0.9656898395657862, ic: -0.041531367953615075
train 3, step: 2000, loss: 0.900580394847973, grad_norm: 0.0013899510726455562, ic: -0.002782419739900491
Epoch 3: 2022-04-27 13:27:30.633972: train loss: 1.6473483793183286
Eval step 0: eval loss: 0.8352809701001053
Eval: 2022-04-27 13:27:43.854753: total loss: 1.0789480633656485, mse:4.820107053542329, ic :0.0942762848334953, sharpe5:11.911223326921462, irr5:400.80975341796875, ndcg5:0.8477656488184837, pnl5:3.450690746307373 
train 4, step: 0, loss: 1.439749681122449, grad_norm: 0.04280738758629813, ic: 0.0673955878267984
train 4, step: 500, loss: 1.6467794583538387, grad_norm: 0.5673991312150306, ic: -0.1114010577505131
train 4, step: 1000, loss: 2.9676506228563264, grad_norm: 0.8190257862372475, ic: 0.0047450609479074805
train 4, step: 1500, loss: 2.1446999851661395, grad_norm: 0.4787697489716132, ic: -0.041108650188953655
train 4, step: 2000, loss: 1.0836760667768273, grad_norm: 0.39042881549139324, ic: 0.19528067866277457
Epoch 4: 2022-04-27 13:31:57.489078: train loss: 1.641687734693283
Eval step 0: eval loss: 0.8601376500345758
Eval: 2022-04-27 13:32:10.794817: total loss: 1.0900856534796135, mse:4.698555036863156, ic :0.1401036787642156, sharpe5:11.259923204183577, irr5:389.69219970703125, ndcg5:0.8543587249856207, pnl5:3.415938377380371 
train 5, step: 0, loss: 1.339248145186661, grad_norm: 0.21779087288506627, ic: 0.4341573764208579
train 5, step: 500, loss: 0.8643728160933782, grad_norm: 0.030439833739632285, ic: 0.9407787232569989
train 5, step: 1000, loss: 0.9883561759159483, grad_norm: 0.15686217375092484, ic: -0.023918474101949798
train 5, step: 1500, loss: 1.5263956020290965, grad_norm: 0.15054069679936935, ic: 0.047468754078567876
train 5, step: 2000, loss: 1.1608075984945982, grad_norm: 0.9835889002792335, ic: 0.12820641024246857
Epoch 5: 2022-04-27 13:36:24.205349: train loss: 1.635343613174281
Eval step 0: eval loss: 0.8354276088316649
Eval: 2022-04-27 13:36:37.772650: total loss: 1.07497250218022, mse:4.646023004076171, ic :0.1379305477821468, sharpe5:11.361862780451775, irr5:389.7050476074219, ndcg5:0.8702790366248792, pnl5:3.221320390701294 
train 6, step: 0, loss: 1.3374385559958135, grad_norm: 0.41966095119598856, ic: 0.12427341266112202
train 6, step: 500, loss: 1.0081158998731816, grad_norm: 0.04310246092039278, ic: 0.07505302232949009
train 6, step: 1000, loss: 1.0852218801984315, grad_norm: 0.0977022918920295, ic: 0.8022958512989856
train 6, step: 1500, loss: 1.57757376678719, grad_norm: 0.6940186829016741, ic: -0.010441068112215061
train 6, step: 2000, loss: 0.7998166599685999, grad_norm: 0.08973637121742453, ic: 0.3542059145609746
Epoch 6: 2022-04-27 13:40:54.738675: train loss: 1.6333731527355577
Eval step 0: eval loss: 0.8277861873518176
Eval: 2022-04-27 13:41:08.065388: total loss: 1.0720076241066687, mse:4.63018620253687, ic :0.14805303028120617, sharpe5:13.161425909399986, irr5:453.86077880859375, ndcg5:0.8472719775791568, pnl5:3.0721065998077393 
train 7, step: 0, loss: 0.9937224388122559, grad_norm: 0.04411223788892775, ic: 0.03645013011806242
train 7, step: 500, loss: 0.652617666134356, grad_norm: 0.0018845256706864623, ic: 0.020553113306553364
train 7, step: 1000, loss: 1.0263217249083683, grad_norm: 0.20011298155463447, ic: -0.008972270694742997
train 7, step: 1500, loss: 2.235750875033494, grad_norm: 0.6761709173723298, ic: 0.4233425550779033
train 7, step: 2000, loss: 0.9067869910515953, grad_norm: 0.03794897049541175, ic: 0.004647335107669107
Epoch 7: 2022-04-27 13:45:26.765813: train loss: 1.628374202818116
Eval step 0: eval loss: 0.8282626345989199
Eval: 2022-04-27 13:45:39.695186: total loss: 1.071855422489946, mse:4.614474675102098, ic :0.1651812044638539, sharpe5:16.288708341121673, irr5:525.2476806640625, ndcg5:0.8379571294681929, pnl5:6.329342365264893 
train 8, step: 0, loss: 3.5914642776268115, grad_norm: 1.0715474625329495, ic: 0.2155675262465493
train 8, step: 500, loss: 2.772336640981193, grad_norm: 0.8680143779142375, ic: 0.05176791144726316
train 8, step: 1000, loss: 3.074589206861413, grad_norm: 0.8446505218253009, ic: 0.00148499721688412
train 8, step: 1500, loss: 0.6987301677134711, grad_norm: 0.02524978968053645, ic: 0.5910246889880392
train 8, step: 2000, loss: 1.0541983857639965, grad_norm: 0.32840577527255954, ic: 0.6620629867053976
Epoch 8: 2022-04-27 13:49:55.504885: train loss: 1.6297976034934958
Eval step 0: eval loss: 0.8235559815224908
Eval: 2022-04-27 13:50:08.483442: total loss: 1.0718112890315545, mse:4.653712208452038, ic :0.16412496850635827, sharpe5:16.29689627408981, irr5:528.6748046875, ndcg5:0.8486204032620194, pnl5:5.373199462890625 
train 9, step: 0, loss: 5.43782318455941, grad_norm: 0.8414193868485524, ic: -0.11356184694770549
train 9, step: 500, loss: 1.3233413957033922, grad_norm: 0.8363671835963906, ic: 0.3204643003011889
train 9, step: 1000, loss: 0.9334257780428982, grad_norm: 0.40619934698814414, ic: 0.07297260061134259
train 9, step: 1500, loss: 1.0760025226666052, grad_norm: 0.02841342699232274, ic: 0.49244198822620305
train 9, step: 2000, loss: 1.066512721063641, grad_norm: 0.2450671153209562, ic: 0.3078588572653578
Epoch 9: 2022-04-27 13:54:20.231281: train loss: 1.6267175082591492
Eval step 0: eval loss: 0.8240519806004676
Eval: 2022-04-27 13:54:33.533069: total loss: 1.0720519261218373, mse:4.652110234934687, ic :0.1554917740435365, sharpe5:15.910837504863737, irr5:519.05322265625, ndcg5:0.8412594246532602, pnl5:5.464433670043945 
train 10, step: 0, loss: 7.152436281432216, grad_norm: 0.9427755665800065, ic: 0.27531338108379944
train 10, step: 500, loss: 1.1217462608541013, grad_norm: 0.04854314766950654, ic: 0.08029903505931635
train 10, step: 1000, loss: 2.396148681640625, grad_norm: 0.771070452678416, ic: 0.1601974481727322
train 10, step: 1500, loss: 1.0939021915584417, grad_norm: 0.21953614456751142, ic: 1.8900484223351166e-05
train 10, step: 2000, loss: 2.728702255295403, grad_norm: 1.1667294507861838, ic: 0.5388419872210815
Epoch 10: 2022-04-27 13:58:45.785128: train loss: 1.6264948761581082
Eval step 0: eval loss: 0.8244931187845758
Eval: 2022-04-27 13:58:59.132797: total loss: 1.0717680003580843, mse:4.639930514399407, ic :0.1566653040751864, sharpe5:15.369820969104767, irr5:506.3540344238281, ndcg5:0.8502158616920613, pnl5:4.7002854347229 
train 11, step: 0, loss: 1.2484705807714618, grad_norm: 0.011699354725521551, ic: 0.20816813125181705
train 11, step: 500, loss: 0.6347800260778105, grad_norm: 0.04810565415740585, ic: 0.659742994655101
train 11, step: 1000, loss: 0.9461681998080689, grad_norm: 0.12633990502835063, ic: 0.07510430540804065
train 11, step: 1500, loss: 1.054192258600603, grad_norm: 0.04270091334045966, ic: 0.18691460792479012
train 11, step: 2000, loss: 0.7934923217194905, grad_norm: 0.03342245811415836, ic: 0.04322300911981315
Epoch 11: 2022-04-27 14:03:13.186592: train loss: 1.6260638398259735
Eval step 0: eval loss: 0.8279274236037935
Eval: 2022-04-27 14:03:26.916655: total loss: 1.0710729953915064, mse:4.602490641258039, ic :0.16754721251820093, sharpe5:16.000696663856505, irr5:520.6739501953125, ndcg5:0.832823387595178, pnl5:4.854367733001709 
train 12, step: 0, loss: 0.9644836584726969, grad_norm: 0.07031635989080491, ic: 0.407709138824474
train 12, step: 500, loss: 0.9405816505425881, grad_norm: 0.7444749755360355, ic: 0.1671896000547047
train 12, step: 1000, loss: 3.000548150129379, grad_norm: 0.20696428389502414, ic: 0.2313384947906238
train 12, step: 1500, loss: 0.9381448436309977, grad_norm: 0.11195150988704261, ic: -0.03863615540728624
train 12, step: 2000, loss: 0.8751552616361404, grad_norm: 0.011836176629755918, ic: 0.11389775520588269
Epoch 12: 2022-04-27 14:07:42.273649: train loss: 1.6267217077569391
Eval step 0: eval loss: 0.8248229273001185
Eval: 2022-04-27 14:07:55.898068: total loss: 1.0715044127775148, mse:4.614762975980213, ic :0.1576644188773903, sharpe5:14.140961308479309, irr5:477.2547302246094, ndcg5:0.8393750839919777, pnl5:3.3450615406036377 
train 13, step: 0, loss: 2.030778347124142, grad_norm: 1.05812173170752, ic: 0.42296870467017506
train 13, step: 500, loss: 0.8252257051767139, grad_norm: 0.07492700392564447, ic: 0.5808633391449862
train 13, step: 1000, loss: 0.9446257930473992, grad_norm: 0.32149897127606086, ic: 0.5876032822970136
train 13, step: 1500, loss: 2.370087456088993, grad_norm: 0.21006924223808615, ic: -0.0762684782722447
train 13, step: 2000, loss: 1.465218324492398, grad_norm: 0.07356922998634209, ic: 0.21206223550484643
Epoch 13: 2022-04-27 14:12:10.067010: train loss: 1.6252717803611203
Eval step 0: eval loss: 0.8219504803576132
Eval: 2022-04-27 14:12:23.565121: total loss: 1.0688752416028295, mse:4.603018209892589, ic :0.17452541757041892, sharpe5:16.63777573943138, irr5:532.7756958007812, ndcg5:0.8353013712836378, pnl5:4.9728498458862305 
train 14, step: 0, loss: 4.553010128217629, grad_norm: 1.185709814285438, ic: 0.11496986225182064
train 14, step: 500, loss: 0.8285389938121177, grad_norm: 0.0034019326343947844, ic: 0.15445433325917607
train 14, step: 1000, loss: 1.808095458428246, grad_norm: 1.4717933117796091, ic: 0.4708267579674154
train 14, step: 1500, loss: 1.121115212912088, grad_norm: 0.06326544340589169, ic: 0.03605839589327196
train 14, step: 2000, loss: 1.1363116129368473, grad_norm: 0.16054094760917947, ic: 0.12437100466308203
Epoch 14: 2022-04-27 14:16:39.092725: train loss: 1.6252189718228043
Eval step 0: eval loss: 0.8326715724611432
Eval: 2022-04-27 14:16:52.703184: total loss: 1.0727479106068292, mse:4.615652913154945, ic :0.17702577633439642, sharpe5:16.63397879362106, irr5:522.1337280273438, ndcg5:0.8470436725599252, pnl5:4.60105037689209 
train 15, step: 0, loss: 3.3459957137645917, grad_norm: 0.530470718176435, ic: 0.08805828354001391
train 15, step: 500, loss: 1.2598936821358064, grad_norm: 0.013765615957906614, ic: -0.005983399327740519
train 15, step: 1000, loss: 1.3087978952299288, grad_norm: 0.1333488540195228, ic: 0.0775091226821025
train 15, step: 1500, loss: 0.8532177542138287, grad_norm: 0.17670848033508182, ic: 0.04262882772113249
train 15, step: 2000, loss: 1.452165539137983, grad_norm: 0.5207524010826904, ic: 0.05077569989093267
Epoch 15: 2022-04-27 14:21:10.008276: train loss: 1.6262349875602562
Eval step 0: eval loss: 0.834869223977542
Eval: 2022-04-27 14:21:24.120646: total loss: 1.073132268801186, mse:4.6019500953975205, ic :0.1822998615003338, sharpe5:16.853571664094925, irr5:555.8975830078125, ndcg5:0.8543357738447859, pnl5:5.879997253417969 
train 16, step: 0, loss: 0.6883163150113816, grad_norm: 0.22555904510968905, ic: -0.03896594793279908
train 16, step: 500, loss: 1.5659142206938195, grad_norm: 0.2686465940675008, ic: 0.17056204992898585
train 16, step: 1000, loss: 0.8751505533854167, grad_norm: 0.004448085873660947, ic: -0.0027800128205391454
train 16, step: 1500, loss: 0.8462214188091017, grad_norm: 0.22195397769903125, ic: 0.15346763692319745
train 16, step: 2000, loss: 3.3480213521237614, grad_norm: 0.8707678171083273, ic: 0.050189831912628574
Epoch 16: 2022-04-27 14:25:42.523841: train loss: 1.6248357454352762
Eval step 0: eval loss: 0.8295504828273181
Eval: 2022-04-27 14:25:55.936677: total loss: 1.0704930327219693, mse:4.618248223658078, ic :0.1569541356107684, sharpe5:11.788488519787787, irr5:407.85076904296875, ndcg5:0.848333649454398, pnl5:2.8569936752319336 
train 17, step: 0, loss: 1.2805936049403182, grad_norm: 0.23385156407307053, ic: -0.1208725910656259
train 17, step: 500, loss: 1.7721383278285907, grad_norm: 0.7584175702818787, ic: 0.16305389369094228
train 17, step: 1000, loss: 1.281842617063229, grad_norm: 0.07956363868974106, ic: 0.150671729751402

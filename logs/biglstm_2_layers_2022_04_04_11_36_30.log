Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='AdjSeqTimeDataset', dout=0.3, epochs=40, glstm_layers=2, gnn_layers=1, gpu=0, hidden_dim=128, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=1, mask_adj=True, mask_type='soft', model_type='BiGLSTM', normalize_adj=True, num_days=8, num_heads=1, print_inteval=500, relation_num=1, seed=10086, shuffle=True, side_info=False, sparse_adj_path=None, stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
76320
BiGLSTM(
  (input_to_hidden): Linear(in_features=9, out_features=128, bias=True)
  (forward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
    (1): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
  )
  (backward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
    (1): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
  )
  (fc0): ModuleList(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Linear(in_features=256, out_features=128, bias=True)
  )
  (w_out): Linear(in_features=128, out_features=1, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
)
train 0, step: 0, loss: 4.865364176114151, grad_norm: 1.5549274707063447, ic: 0.04295398928142538
train 0, step: 500, loss: 0.8704151420909476, grad_norm: 0.031031462687903924, ic: -0.019483662409893222
train 0, step: 1000, loss: 1.9423824553081566, grad_norm: 0.42700331758531346, ic: -0.018854003328011255
train 0, step: 1500, loss: 0.9392493206521739, grad_norm: 0.013096233993937105, ic: 0.012017206174629824
train 0, step: 2000, loss: 1.0013251088350432, grad_norm: 0.12919089862139818, ic: -0.0042208723667514075
Epoch 0: 2022-04-04 23:41:42.493997: train loss: 1.6487373368420868
Eval step 0: eval loss: 0.8364900964831401
Eval: 2022-04-04 23:41:56.677491: total loss: 1.0793690386116395, mse:4.82318328193269, ic :0.006857813784911427, sharpe5:8.396430130004882, irr5:237.27197265625, ndcg5:0.8657012508063573, pnl5:2.888078212738037 
train 1, step: 0, loss: 2.768890380859375, grad_norm: 0.7342102066127625, ic: 0.08246549444804765
train 1, step: 500, loss: 1.7458374714836375, grad_norm: 0.6416174084805042, ic: 0.06649945030035156
train 1, step: 1000, loss: 0.8753499660930655, grad_norm: 0.14884034756459397, ic: 0.08607889708924493
train 1, step: 1500, loss: 1.708093822961566, grad_norm: 0.1780537986338287, ic: -0.021403808226492967
train 1, step: 2000, loss: 2.165862109375, grad_norm: 0.8215035597567677, ic: -0.031078369164411562
Epoch 1: 2022-04-04 23:47:07.851102: train loss: 1.6468176161663246
Eval step 0: eval loss: 0.8364398019708245
Eval: 2022-04-04 23:47:22.269940: total loss: 1.0793526572321026, mse:4.823198259772655, ic :0.005822392480573191, sharpe5:8.655154055356979, irr5:241.69114685058594, ndcg5:0.8561618410438446, pnl5:2.6350784301757812 
train 2, step: 0, loss: 2.140241477272727, grad_norm: 0.006270818792553239, ic: 0.12480562719644922
train 2, step: 500, loss: 3.289056004866002, grad_norm: 0.2542078972047006, ic: 0.07851915730589396
train 2, step: 1000, loss: 2.074041397270115, grad_norm: 3.890360342309156e-05, ic: 0.16337023564894293
train 2, step: 1500, loss: 1.4802700828959923, grad_norm: 0.05093052788744312, ic: 0.002767594341759161
train 2, step: 2000, loss: 3.2152689302884614, grad_norm: 0.7277558294521698, ic: 0.18635796761137918
Epoch 2: 2022-04-04 23:52:31.744638: train loss: 1.6466481447781038
Eval step 0: eval loss: 0.8365554407600104
Eval: 2022-04-04 23:52:46.038769: total loss: 1.0793878331428362, mse:4.823147548042522, ic :0.006959944619506441, sharpe5:7.618702779114246, irr5:216.25271606445312, ndcg5:0.8459982655200786, pnl5:2.6661243438720703 
train 3, step: 0, loss: 1.5218825425558944, grad_norm: 0.4901670880931189, ic: 0.0010731063820952182
train 3, step: 500, loss: 1.5126430239636355, grad_norm: 0.3642353310477878, ic: 0.0442314087488808
train 3, step: 1000, loss: 3.682721758959413, grad_norm: 0.6787268792599581, ic: -0.06942228804533976
train 3, step: 1500, loss: 1.9618069762684125, grad_norm: 1.012036705173524, ic: 0.03438547983975517
train 3, step: 2000, loss: 0.9060690720016892, grad_norm: 0.010206216716032, ic: 0.004903953115245749
Epoch 3: 2022-04-04 23:57:57.875208: train loss: 1.6470199935330523
Eval step 0: eval loss: 0.8364924761467663
Eval: 2022-04-04 23:58:12.322393: total loss: 1.0793675937851885, mse:4.823188107039333, ic :0.00429449628225294, sharpe5:6.868596459031105, irr5:195.90135192871094, ndcg5:0.8338788412690983, pnl5:2.381042718887329 
train 4, step: 0, loss: 1.437445292570153, grad_norm: 0.04069350009335936, ic: 0.10623844523890573
train 4, step: 500, loss: 1.6290648452878937, grad_norm: 0.574883275093163, ic: 0.00187732651143405
train 4, step: 1000, loss: 2.9750113138338414, grad_norm: 0.6564504948507836, ic: -0.044320052862273265
train 4, step: 1500, loss: 2.1556803385416665, grad_norm: 0.44326623030555745, ic: -0.05043758935758667
train 4, step: 2000, loss: 1.102688850177391, grad_norm: 0.3802769228431749, ic: 0.12213917684781907
Epoch 4: 2022-04-05 00:03:24.768235: train loss: 1.6468182335043637
Eval step 0: eval loss: 0.8687827750428082
Eval: 2022-04-05 00:03:39.359857: total loss: 1.096991954151129, mse:4.866519948808027, ic :0.012315529164638003, sharpe5:8.407132333517074, irr5:223.30517578125, ndcg5:0.8538845467980508, pnl5:3.1297121047973633 
train 5, step: 0, loss: 1.3922707372063758, grad_norm: 0.21878788972912955, ic: 0.012934613119572454
train 5, step: 500, loss: 0.890382311440573, grad_norm: 0.005979612803087555, ic: -0.0003100766324763268
train 5, step: 1000, loss: 0.9941759832974139, grad_norm: 0.15300942536222467, ic: -0.042328509307960546
train 5, step: 1500, loss: 1.5217982433839012, grad_norm: 0.13547834325797167, ic: 1.7252798146962303e-05
train 5, step: 2000, loss: 1.108390011532954, grad_norm: 0.02906959806436067, ic: 0.15342787620224818
Epoch 5: 2022-04-05 00:08:57.912708: train loss: 1.6458374322963214
Eval step 0: eval loss: 0.8352589742903714
Eval: 2022-04-05 00:09:12.154255: total loss: 1.0777930984459556, mse:4.7413865557097274, ic :0.12658761086969106, sharpe5:11.41847170472145, irr5:394.6772155761719, ndcg5:0.8340740501721259, pnl5:3.44803786277771 
train 6, step: 0, loss: 1.3444483512136165, grad_norm: 0.42970597006559974, ic: 0.028716260659515484
train 6, step: 500, loss: 1.0065110397923047, grad_norm: 0.037761770773849644, ic: 0.03282404042459167
train 6, step: 1000, loss: 1.1123954743940114, grad_norm: 0.07270281803563156, ic: 0.6821885602917688
train 6, step: 1500, loss: 1.5757116396565083, grad_norm: 0.6796745227211624, ic: 0.013619383558294597
train 6, step: 2000, loss: 0.8097535157031875, grad_norm: 0.04122715018708076, ic: 0.1803867387099217
Epoch 6: 2022-04-05 00:14:14.772944: train loss: 1.6407602255933849
Eval step 0: eval loss: 0.8304200247793729
Eval: 2022-04-05 00:14:29.468455: total loss: 1.0759223388884753, mse:4.740677771855078, ic :0.127144605123925, sharpe5:11.31461000740528, irr5:393.3868103027344, ndcg5:0.8485757662643304, pnl5:3.5730984210968018 
train 7, step: 0, loss: 1.006263828277588, grad_norm: 0.04971939184750242, ic: 0.013733370937361763
train 7, step: 500, loss: 0.662027469159622, grad_norm: 0.005961269892962211, ic: -0.02324462645122328
train 7, step: 1000, loss: 1.0408540422101105, grad_norm: 0.2217347356814861, ic: 0.016837351522612176
train 7, step: 1500, loss: 2.254776573385584, grad_norm: 0.6814494472494981, ic: 0.42191582920826426
train 7, step: 2000, loss: 0.9276549011131866, grad_norm: 0.06942310572590436, ic: -0.0015148933923044908
Epoch 7: 2022-04-05 00:19:31.684862: train loss: 1.6408618508069488
Eval step 0: eval loss: 0.8333051418228068
Eval: 2022-04-05 00:19:45.802447: total loss: 1.0767994330584447, mse:4.736250178029173, ic :0.12906923980936524, sharpe5:11.415770140886305, irr5:395.2298278808594, ndcg5:0.8420645893953016, pnl5:3.0475683212280273 
train 8, step: 0, loss: 3.615471439085145, grad_norm: 1.044910529296103, ic: -0.04260055724171527
train 8, step: 500, loss: 2.7494176615335295, grad_norm: 0.9087217483532176, ic: -0.07690897419826637
train 8, step: 1000, loss: 3.0610443557518114, grad_norm: 0.8475077701115643, ic: 0.05919047721973264
train 8, step: 1500, loss: 0.729253315014257, grad_norm: 0.0540135998532575, ic: 0.3767855436766292
train 8, step: 2000, loss: 1.0897499254856158, grad_norm: 0.30316224623471794, ic: 0.5138655023358831
Epoch 8: 2022-04-05 00:24:48.273995: train loss: 1.640698833103482
Eval step 0: eval loss: 0.8299556044808679
Eval: 2022-04-05 00:25:02.086288: total loss: 1.0752093525139026, mse:4.720169503096413, ic :0.13382322137730565, sharpe5:11.58513057231903, irr5:400.6542663574219, ndcg5:0.8495259445518133, pnl5:2.9963021278381348 
train 9, step: 0, loss: 5.4101749401913874, grad_norm: 0.7264132772753323, ic: 0.09639751572966913
train 9, step: 500, loss: 1.3398757903280931, grad_norm: 1.0355718511798022, ic: 0.3062920028520185
train 9, step: 1000, loss: 0.9364021689629515, grad_norm: 0.013428111284539189, ic: 0.005537520184707956
train 9, step: 1500, loss: 1.0878055892742085, grad_norm: 0.01742072536368454, ic: 0.4787278383659156
train 9, step: 2000, loss: 1.089705420152975, grad_norm: 0.25442241699024326, ic: 0.17833269670629315
Epoch 9: 2022-04-05 00:30:05.768791: train loss: 1.63793306415457
Eval step 0: eval loss: 0.8291130106114989
Eval: 2022-04-05 00:30:19.534107: total loss: 1.071846295763793, mse:4.624053061600462, ic :0.15385767209092893, sharpe5:12.610378777384758, irr5:415.74798583984375, ndcg5:0.8475097786072635, pnl5:4.825160503387451 
train 10, step: 0, loss: 7.149189851721939, grad_norm: 1.4398425275146707, ic: 0.15710781469729457
train 10, step: 500, loss: 1.1266572434262168, grad_norm: 0.049405550502867414, ic: -0.03457081081340162
train 10, step: 1000, loss: 2.3943260520513805, grad_norm: 0.6814885395836427, ic: 0.04306170350668499
train 10, step: 1500, loss: 1.1165180949421674, grad_norm: 0.36215776654482934, ic: 0.01822704232826411
train 10, step: 2000, loss: 2.7845158446523555, grad_norm: 0.4328697489653093, ic: 0.4927973157136579
Epoch 10: 2022-04-05 00:35:15.891096: train loss: 1.634160409380179
Eval step 0: eval loss: 0.8287977373386459
Eval: 2022-04-05 00:35:29.276416: total loss: 1.0711291583350726, mse:4.625375238419151, ic :0.15725090916176487, sharpe5:12.726199813485145, irr5:413.0425720214844, ndcg5:0.8566855998123278, pnl5:5.681173324584961 
train 11, step: 0, loss: 1.2717532506767208, grad_norm: 0.007871786973782111, ic: 0.11991367044222988
train 11, step: 500, loss: 0.6719957149169413, grad_norm: 0.031667984418970535, ic: 0.5798187688563815
train 11, step: 1000, loss: 0.9472370446465376, grad_norm: 0.13190740482636792, ic: -0.007416996499551544
train 11, step: 1500, loss: 1.05417894062243, grad_norm: 0.043071131119515035, ic: 0.17877020086104053
train 11, step: 2000, loss: 0.795365078942659, grad_norm: 0.0006576143560003107, ic: 0.029928546740749365
Epoch 11: 2022-04-05 00:40:27.057737: train loss: 1.6334050823124426
Eval step 0: eval loss: 0.8342793889744138
Eval: 2022-04-05 00:40:40.541604: total loss: 1.07192951457142, mse:4.610849784058618, ic :0.16249870029779803, sharpe5:12.560434845685958, irr5:418.0746154785156, ndcg5:0.8461979149699539, pnl5:4.946042537689209 
train 12, step: 0, loss: 1.0003493626912434, grad_norm: 0.06762045895283375, ic: 0.2966926718243671
train 12, step: 500, loss: 0.9418239484157453, grad_norm: 0.0757695803225245, ic: 0.07064879729909196
train 12, step: 1000, loss: 2.9889950114450636, grad_norm: 0.19553042460650974, ic: 0.283992757614726
train 12, step: 1500, loss: 0.9380150567640899, grad_norm: 0.10335162994456183, ic: -0.050986733906209364
train 12, step: 2000, loss: 0.8752176797642088, grad_norm: 0.0035849998613515428, ic: 0.1778160923768713
Epoch 12: 2022-04-05 00:45:38.045108: train loss: 1.6329618526753575
Eval step 0: eval loss: 0.8310263887974183
Eval: 2022-04-05 00:45:51.710605: total loss: 1.0702866724832845, mse:4.610175598406804, ic :0.16225983552343407, sharpe5:12.553022571802138, irr5:421.4488220214844, ndcg5:0.8622184713064236, pnl5:5.863033771514893 
train 13, step: 0, loss: 2.0642156872855066, grad_norm: 0.6718360058138401, ic: 0.43612765369577916
train 13, step: 500, loss: 0.8246614006011255, grad_norm: 0.0722020312316263, ic: 0.5773637406147846
train 13, step: 1000, loss: 0.9474490581742868, grad_norm: 0.3184194773108847, ic: 0.5792374509136089
train 13, step: 1500, loss: 2.371328551912568, grad_norm: 0.16040001820990715, ic: -0.10913409430983523
train 13, step: 2000, loss: 1.4970524577198805, grad_norm: 0.025073199761769572, ic: 0.05131599169729542
Epoch 13: 2022-04-05 00:50:51.110829: train loss: 1.6323514586716645
Eval step 0: eval loss: 0.8273723188265608
Eval: 2022-04-05 00:51:04.866391: total loss: 1.0698612397537803, mse:4.62112806829893, ic :0.16111035538852436, sharpe5:12.572730934023857, irr5:419.8781433105469, ndcg5:0.8387761483595649, pnl5:4.893186092376709 
train 14, step: 0, loss: 4.541707293291732, grad_norm: 1.2136692808441665, ic: 0.17497808507363782
train 14, step: 500, loss: 0.8277614021884556, grad_norm: 0.002653596495281063, ic: 0.11688649202438335
train 14, step: 1000, loss: 1.8752539655704252, grad_norm: 0.12146249939579906, ic: 0.4081328012795867
train 14, step: 1500, loss: 1.1241755942160518, grad_norm: 0.05819024411997416, ic: 0.021130503146745343
train 14, step: 2000, loss: 1.1355153236477669, grad_norm: 0.15093938951730362, ic: 0.10587017700241008
Epoch 14: 2022-04-05 00:56:06.440658: train loss: 1.6324309284112084
Eval step 0: eval loss: 0.8363334245752106
Eval: 2022-04-05 00:56:19.936786: total loss: 1.071998780185814, mse:4.612427390392536, ic :0.16337155804925188, sharpe5:12.4796783298254, irr5:416.1197814941406, ndcg5:0.8467536110890785, pnl5:5.850545883178711 
train 15, step: 0, loss: 3.35122735286965, grad_norm: 0.44811598128423563, ic: 0.054141680489484895
train 15, step: 500, loss: 1.265158636611596, grad_norm: 0.017127001704151455, ic: -0.042741455625133595
train 15, step: 1000, loss: 1.3198559768800813, grad_norm: 0.12432841164969875, ic: -0.07567219943997441
train 15, step: 1500, loss: 0.8598373292937992, grad_norm: 0.16569172858768821, ic: 0.03899290282888186
train 15, step: 2000, loss: 1.4607702184606481, grad_norm: 0.5007205393731031, ic: -0.036719748924540795
Epoch 15: 2022-04-05 01:01:18.026079: train loss: 1.6316571099140886
Eval step 0: eval loss: 0.8375527127650816
Eval: 2022-04-05 01:01:31.661517: total loss: 1.073182933534463, mse:4.611341055388185, ic :0.16473999595418998, sharpe5:12.574074148535727, irr5:424.4005126953125, ndcg5:0.8445571426667408, pnl5:5.564584732055664 
train 16, step: 0, loss: 0.6987326917248119, grad_norm: 0.183643332182258, ic: -0.08987647082829295
train 16, step: 500, loss: 1.5583900625330864, grad_norm: 0.2010229102093144, ic: 0.15548547325016837
train 16, step: 1000, loss: 0.8764119466145833, grad_norm: 0.008289464891243575, ic: 0.015860978651691136
train 16, step: 1500, loss: 0.8540525804644405, grad_norm: 0.21730166645862925, ic: 0.16605203841798222
train 16, step: 2000, loss: 3.357884149527766, grad_norm: 0.8856841451393238, ic: 0.005915820831304588
Epoch 16: 2022-04-05 01:06:29.092256: train loss: 1.631638717963465
Eval step 0: eval loss: 0.8294713750905558
Eval: 2022-04-05 01:06:43.001998: total loss: 1.0700811814387117, mse:4.612005812137931, ic :0.16557783814195468, sharpe5:11.800847039222717, irr5:404.640380859375, ndcg5:0.8444165075696006, pnl5:5.214353561401367 
train 17, step: 0, loss: 1.2772795092838196, grad_norm: 0.23857633675579687, ic: -0.07247402728900587
train 17, step: 500, loss: 1.7758699081131437, grad_norm: 0.39819384689986137, ic: 0.14518963130793666
train 17, step: 1000, loss: 1.2747576198800372, grad_norm: 0.07032080364624826, ic: 0.14214243549570849
train 17, step: 1500, loss: 4.560923579858559, grad_norm: 0.9700546094542843, ic: 0.10294918351122984
train 17, step: 2000, loss: 1.282167032586267, grad_norm: 0.6467983977809366, ic: 0.019242792913410772
Epoch 17: 2022-04-05 01:11:41.967568: train loss: 1.631352461908372
Eval step 0: eval loss: 0.8378692723425974
Eval: 2022-04-05 01:11:55.341056: total loss: 1.0715583838871992, mse:4.610727510210146, ic :0.16503567133799393, sharpe5:12.024935894608497, irr5:410.2010803222656, ndcg5:0.8535545219972318, pnl5:4.4920783042907715 
train 18, step: 0, loss: 1.4046418604937057, grad_norm: 0.40027840528231984, ic: 0.11438712458223509
train 18, step: 500, loss: 1.4846025887182204, grad_norm: 0.5815450408929649, ic: -0.008428030697029708
train 18, step: 1000, loss: 0.6673727124357877, grad_norm: 0.05325782239318509, ic: 0.5711916820595867
train 18, step: 1500, loss: 1.4242010343084563, grad_norm: 0.03807403401401274, ic: 0.2335399049059802
train 18, step: 2000, loss: 0.9124553704717357, grad_norm: 0.006259651777984188, ic: 0.0008129585010906056
Epoch 18: 2022-04-05 01:16:54.938626: train loss: 1.6312160559671693
Eval step 0: eval loss: 0.8272964911666886
Eval: 2022-04-05 01:17:08.455718: total loss: 1.0690474640721586, mse:4.614564577204865, ic :0.1645416968691758, sharpe5:11.860774270892144, irr5:404.5072021484375, ndcg5:0.8433490233028775, pnl5:5.59055233001709 
train 19, step: 0, loss: 1.4683983212425595, grad_norm: 0.6756140921226016, ic: 0.021718122308655212
train 19, step: 500, loss: 0.872317420111762, grad_norm: 0.05274166408184701, ic: 0.23025126012521946
train 19, step: 1000, loss: 0.9674550536553247, grad_norm: 0.002374925552346999, ic: 0.11943153626290927
train 19, step: 1500, loss: 3.982661726436226, grad_norm: 0.7429995087477694, ic: -0.03696143586024381
train 19, step: 2000, loss: 1.00998046875, grad_norm: 0.07502479956380687, ic: 0.15105265059347767
Epoch 19: 2022-04-05 01:22:05.777387: train loss: 1.6309150368938454
Eval step 0: eval loss: 0.8354209843626514
Eval: 2022-04-05 01:22:19.115469: total loss: 1.0700839554370654, mse:4.622195832538436, ic :0.1646750976222195, sharpe5:12.139527227282523, irr5:417.9078369140625, ndcg5:0.8453791810004321, pnl5:4.645960330963135 
train 20, step: 0, loss: 2.309395071640316, grad_norm: 0.5386935436443263, ic: 0.03346757355940361
train 20, step: 500, loss: 3.205334161931818, grad_norm: 0.4039416780493908, ic: 0.10243321511809042
train 20, step: 1000, loss: 0.9797088623046876, grad_norm: 0.11901570535571858, ic: 0.08365462785646083
train 20, step: 1500, loss: 1.9340446437117151, grad_norm: 0.34403328830543145, ic: 0.20379106194176883
train 20, step: 2000, loss: 1.0315822582649368, grad_norm: 0.05855869188762822, ic: 0.010008664118581694
Epoch 20: 2022-04-05 01:27:19.145024: train loss: 1.630302837238566
Eval step 0: eval loss: 0.837080253062434
Eval: 2022-04-05 01:27:32.916274: total loss: 1.0714930916861483, mse:4.609786188516333, ic :0.16708714528623198, sharpe5:12.71067055106163, irr5:428.20654296875, ndcg5:0.8463678199276885, pnl5:6.8865838050842285 
train 21, step: 0, loss: 1.0120720183185545, grad_norm: 0.25589633983071197, ic: -0.004334440138259701
train 21, step: 500, loss: 0.7750152317823562, grad_norm: 0.009592282202646261, ic: 0.1794339082189923
train 21, step: 1000, loss: 0.9356538872969777, grad_norm: 0.44075010216254323, ic: 0.12771481483662178
train 21, step: 1500, loss: 1.02340937724982, grad_norm: 0.16600875178708155, ic: 0.1869366396638944
train 21, step: 2000, loss: 0.9367382433987402, grad_norm: 0.03494531306638679, ic: 0.10342308045218206
Epoch 21: 2022-04-05 01:32:31.375390: train loss: 1.6295126237714992
Eval step 0: eval loss: 0.831130901051271
Eval: 2022-04-05 01:32:45.481805: total loss: 1.0710468606049717, mse:4.681742659325826, ic :0.156169419530728, sharpe5:12.365065240859984, irr5:427.02471923828125, ndcg5:0.8480093753693745, pnl5:4.504647254943848 
train 22, step: 0, loss: 1.0555344921047405, grad_norm: 0.005993737492564362, ic: 0.11290234601781927
train 22, step: 500, loss: 3.243259336890244, grad_norm: 0.4879879715501975, ic: -0.21052202996295039
train 22, step: 1000, loss: 1.2004191315932082, grad_norm: 0.053403831862416255, ic: 0.45014309842527683
train 22, step: 1500, loss: 0.9765162840792181, grad_norm: 0.051587003759838074, ic: 0.10635247248544727
train 22, step: 2000, loss: 1.7805134260735545, grad_norm: 0.46488145403594716, ic: 0.11395298380859897
Epoch 22: 2022-04-05 01:37:46.205772: train loss: 1.6290060777197473
Eval step 0: eval loss: 0.8326800620719178
Eval: 2022-04-05 01:37:59.953159: total loss: 1.0688458833308423, mse:4.6235460744614585, ic :0.16977979475327457, sharpe5:12.532262340188026, irr5:440.3596496582031, ndcg5:0.8522718310729601, pnl5:4.077108860015869 
train 23, step: 0, loss: 0.9911598579340779, grad_norm: 0.14502450620048826, ic: 0.17717447146170404
train 23, step: 500, loss: 1.4284463879452023, grad_norm: 0.07743800511504895, ic: 0.08998694939256494
train 23, step: 1000, loss: 1.6468055216471356, grad_norm: 0.06145087798503445, ic: 0.2607336224312683
train 23, step: 1500, loss: 1.1065856512015542, grad_norm: 0.14018618064502786, ic: 0.08647600100914071
train 23, step: 2000, loss: 1.8924948653411278, grad_norm: 0.5862883638486592, ic: 0.45508114053942067
Epoch 23: 2022-04-05 01:42:57.794431: train loss: 1.6287881677072111
Eval step 0: eval loss: 0.835381752070436
Eval: 2022-04-05 01:43:11.207019: total loss: 1.0696111004015139, mse:4.603402913834258, ic :0.17237810662291303, sharpe5:13.481227312088013, irr5:450.3441467285156, ndcg5:0.843846407657701, pnl5:5.827075958251953 
train 24, step: 0, loss: 2.2165067978705957, grad_norm: 0.0640361525539708, ic: 0.06776795517026736
train 24, step: 500, loss: 1.2296992795476656, grad_norm: 0.04408400154613971, ic: 0.0036753008007579385
train 24, step: 1000, loss: 0.9040698786187543, grad_norm: 0.015152815976689708, ic: 0.5315662175291804
train 24, step: 1500, loss: 2.598017529820177, grad_norm: 0.5651380392333165, ic: 0.01986862074851506
train 24, step: 2000, loss: 0.935482507035707, grad_norm: 0.011935765222476188, ic: 0.06783245825784934
Epoch 24: 2022-04-05 01:48:11.516034: train loss: 1.6265194376817138
Eval step 0: eval loss: 0.8263743393539251
Eval: 2022-04-05 01:48:25.083837: total loss: 1.0677449178333056, mse:4.599327848370075, ic :0.17910451691622195, sharpe5:14.735195624828338, irr5:484.5673828125, ndcg5:0.8592463438099847, pnl5:9.120712280273438 
train 25, step: 0, loss: 0.8611532675253379, grad_norm: 0.2243294485293738, ic: 0.6040365100198218
train 25, step: 500, loss: 0.8667411688951567, grad_norm: 0.5400316911630891, ic: 0.2296276017926503
train 25, step: 1000, loss: 2.1244615146610815, grad_norm: 0.3283640222793388, ic: 0.23320210189628787
train 25, step: 1500, loss: 1.1477253956465663, grad_norm: 0.3787052458856477, ic: 0.5514122110401327
train 25, step: 2000, loss: 1.0146657187933725, grad_norm: 0.5555174390156428, ic: 0.6066557587789544
Epoch 25: 2022-04-05 01:53:22.661468: train loss: 1.6249664488263178
Eval step 0: eval loss: 0.8266690960674065
Eval: 2022-04-05 01:53:36.284236: total loss: 1.0672697053164584, mse:4.587086200246082, ic :0.18878076602427635, sharpe5:15.731652688980102, irr5:528.5463256835938, ndcg5:0.8499074600448526, pnl5:7.150115489959717 
train 26, step: 0, loss: 6.679732740115814, grad_norm: 0.25038964287526694, ic: 0.11008143907123635
train 26, step: 500, loss: 3.812741277365129, grad_norm: 0.5114765065230285, ic: 0.3836800027042661
train 26, step: 1000, loss: 1.2561069650215857, grad_norm: 0.7328056444655884, ic: 0.013924664316443357
train 26, step: 1500, loss: 0.834830217230432, grad_norm: 0.14380430001317937, ic: 0.29320762863883243
train 26, step: 2000, loss: 0.9525505684193056, grad_norm: 0.08452328167700088, ic: 0.15191976129487744
Epoch 26: 2022-04-05 01:58:33.682473: train loss: 1.6248837828533504
Eval step 0: eval loss: 0.8286855072568163
Eval: 2022-04-05 01:58:47.121961: total loss: 1.0672190049443109, mse:4.58791230370556, ic :0.18850767462760512, sharpe5:16.23375384092331, irr5:534.1591796875, ndcg5:0.8439995595677073, pnl5:7.743469715118408 
train 27, step: 0, loss: 0.8271855851715686, grad_norm: 0.0513085504425737, ic: 0.07116551043002874
train 27, step: 500, loss: 0.8995105467429428, grad_norm: 0.3424870188369825, ic: 0.30210296346568805
train 27, step: 1000, loss: 0.7494516748839908, grad_norm: 0.10038861261393643, ic: 0.18866632628622637
train 27, step: 1500, loss: 0.6333331916485311, grad_norm: 0.04152551091809695, ic: 0.5126480579550707
train 27, step: 2000, loss: 1.3804324533148253, grad_norm: 0.007640562674298689, ic: 0.039104299715532816
Epoch 27: 2022-04-05 02:03:42.873604: train loss: 1.6238706970024455
Eval step 0: eval loss: 0.8283607796446917
Eval: 2022-04-05 02:03:56.047278: total loss: 1.06722958368122, mse:4.595337257882095, ic :0.18614124513884864, sharpe5:15.851291481256483, irr5:533.5264892578125, ndcg5:0.8497567775931543, pnl5:5.967345237731934 
train 28, step: 0, loss: 1.526234654017857, grad_norm: 0.1109299587819664, ic: 0.19846545636600113
train 28, step: 500, loss: 1.387085847977222, grad_norm: 0.19356905302473265, ic: 0.14619464216959538
train 28, step: 1000, loss: 0.9002596227134146, grad_norm: 0.16697162840278948, ic: 0.5702494053000446
train 28, step: 1500, loss: 1.0402966716443278, grad_norm: 0.02212792408480845, ic: -0.004426249849443946
train 28, step: 2000, loss: 1.044411126821319, grad_norm: 0.04197317458385086, ic: 0.1030769483657043
Epoch 28: 2022-04-05 02:08:54.391085: train loss: 1.6236496534839473
Eval step 0: eval loss: 0.8219084825103727
Eval: 2022-04-05 02:09:08.137880: total loss: 1.067083261863747, mse:4.622247868689795, ic :0.17846651471184188, sharpe5:15.310098057389258, irr5:510.7257995605469, ndcg5:0.8414502925134507, pnl5:6.9110283851623535 
train 29, step: 0, loss: 0.902743740819276, grad_norm: 0.01667785775422291, ic: 0.11577227061895166
train 29, step: 500, loss: 1.1077199186637552, grad_norm: 0.14964399497111897, ic: 0.617084702585083
train 29, step: 1000, loss: 1.0838343868416636, grad_norm: 0.42478888774877277, ic: 0.056789780033094234
train 29, step: 1500, loss: 2.3573113351385637, grad_norm: 0.15593422075935945, ic: -0.1602034464578339
train 29, step: 2000, loss: 4.532057397159529, grad_norm: 0.7180446615429142, ic: 0.21271535254585894
Epoch 29: 2022-04-05 02:14:07.919903: train loss: 1.6231633516282813
Eval step 0: eval loss: 0.8292260124761262
Eval: 2022-04-05 02:14:21.915010: total loss: 1.0669499369676583, mse:4.600382737465889, ic :0.18730104315226134, sharpe5:16.851165229082106, irr5:560.406005859375, ndcg5:0.8348528363850168, pnl5:6.347442150115967 
train 30, step: 0, loss: 1.0067012233698212, grad_norm: 0.07413308873816735, ic: 0.516312824762025
train 30, step: 500, loss: 1.4102387651251027, grad_norm: 1.0897641847857975, ic: 0.07430915031554268
train 30, step: 1000, loss: 0.9770624334161931, grad_norm: 0.025632092642451067, ic: -0.0415913674904541
train 30, step: 1500, loss: 1.5088667376640332, grad_norm: 0.609821035250071, ic: 0.1676535163739074
train 30, step: 2000, loss: 1.8335582963728958, grad_norm: 0.17798660273874295, ic: 0.06341000207742056
Epoch 30: 2022-04-05 02:19:21.759093: train loss: 1.6237493970162078
Eval step 0: eval loss: 0.8288299592704491
Eval: 2022-04-05 02:19:35.360735: total loss: 1.0663899515560384, mse:4.591609546338978, ic :0.18901259930241918, sharpe5:16.440644820928572, irr5:558.4854125976562, ndcg5:0.8416125504600409, pnl5:7.956323623657227 
train 31, step: 0, loss: 1.0477972905867607, grad_norm: 0.03344449473426991, ic: 0.3326911291494536
train 31, step: 500, loss: 1.4879486963091564, grad_norm: 0.4448677761367917, ic: 0.022640085478903206
train 31, step: 1000, loss: 4.307842841286105, grad_norm: 1.0858571718862233, ic: 0.46301091046487153
train 31, step: 1500, loss: 0.7757535850636652, grad_norm: 0.027480697168677005, ic: 0.7019091164124641
train 31, step: 2000, loss: 1.2372692537162804, grad_norm: 0.36141534841278894, ic: 0.14524591872595635
Epoch 31: 2022-04-05 02:23:56.656118: train loss: 1.6230066710832047
Eval step 0: eval loss: 0.8305151470091873
Eval: 2022-04-05 02:24:07.816936: total loss: 1.0672174758919728, mse:4.596150648886964, ic :0.18783169501337985, sharpe5:17.007600531578063, irr5:563.3013305664062, ndcg5:0.8424549884819561, pnl5:6.5716047286987305 
train 32, step: 0, loss: 1.1365678509231294, grad_norm: 0.02581326116311771, ic: 0.13654060962393189
train 32, step: 500, loss: 1.4892007181963582, grad_norm: 0.730069900169733, ic: 0.08695837138236312
train 32, step: 1000, loss: 1.0430340855319067, grad_norm: 0.2432937774421168, ic: 0.5178217225042001
train 32, step: 1500, loss: 1.0038274769379292, grad_norm: 0.26062577397635156, ic: 0.06085888123940876
train 32, step: 2000, loss: 0.955514294802591, grad_norm: 0.07269814756462475, ic: 0.5389000401399099
Epoch 32: 2022-04-05 02:28:26.787172: train loss: 1.623604698868832
Eval step 0: eval loss: 0.8255390131059009
Eval: 2022-04-05 02:28:37.993003: total loss: 1.067780427445139, mse:4.609094173903254, ic :0.17877544575170273, sharpe5:16.098800511360167, irr5:532.9140625, ndcg5:0.8423098925883304, pnl5:7.452076435089111 
train 33, step: 0, loss: 1.2741134127238571, grad_norm: 0.1709581335839747, ic: 0.20314143689847564
train 33, step: 500, loss: 1.0022885619091386, grad_norm: 0.11014197842175927, ic: 0.10259304693916321
train 33, step: 1000, loss: 1.0515962950286375, grad_norm: 0.20858878150343496, ic: 0.23734285434094038
train 33, step: 1500, loss: 0.8996034669706406, grad_norm: 0.025091522736095374, ic: 0.541786237806507
train 33, step: 2000, loss: 0.8144275888965927, grad_norm: 0.023567106061875558, ic: 0.25058386683302497
Epoch 33: 2022-04-05 02:32:59.637933: train loss: 1.6228494289739985
Eval step 0: eval loss: 0.8229032462213514
Eval: 2022-04-05 02:33:10.935278: total loss: 1.0654873880857572, mse:4.612406351309809, ic :0.1879287281136749, sharpe5:16.781832658052444, irr5:568.1674194335938, ndcg5:0.87265082396128, pnl5:6.639886379241943 
train 34, step: 0, loss: 1.0171066167700382, grad_norm: 0.3360008195215141, ic: 0.6062592220793377
train 34, step: 500, loss: 0.7901824111238532, grad_norm: 0.03970730808880596, ic: 0.22053553550305682
train 34, step: 1000, loss: 3.2629387030769967, grad_norm: 0.7556944692790074, ic: 0.2393665009736783
train 34, step: 1500, loss: 0.7897220288755215, grad_norm: 0.26568752318557276, ic: 0.6898538080753238
train 34, step: 2000, loss: 6.944957730199458, grad_norm: 1.4728957391450763, ic: 0.4541071245223104
Epoch 34: 2022-04-05 02:37:32.753819: train loss: 1.6242799963727237
Eval step 0: eval loss: 0.8256237162679465
Eval: 2022-04-05 02:37:44.063674: total loss: 1.066976803701981, mse:4.621800134717759, ic :0.18357208957474264, sharpe5:16.596209871768952, irr5:556.5194091796875, ndcg5:0.8593743511508687, pnl5:9.824817657470703 
train 35, step: 0, loss: 1.2220148782169116, grad_norm: 0.525344993680304, ic: 0.5490361563292889
train 35, step: 500, loss: 1.1780164442584833, grad_norm: 0.4022767366128896, ic: 0.01680240086968418
train 35, step: 1000, loss: 1.9303359499402866, grad_norm: 0.5444261769675307, ic: 0.060945296042666894
train 35, step: 1500, loss: 1.638233156132519, grad_norm: 0.7372821946131665, ic: 0.028968722333192504
train 35, step: 2000, loss: 0.7747076513932988, grad_norm: 0.046915866804078714, ic: 0.5700315951543231
Epoch 35: 2022-04-05 02:42:06.514263: train loss: 1.623303475769993
Eval step 0: eval loss: 0.8302124152067966
Eval: 2022-04-05 02:42:17.685876: total loss: 1.066102843734551, mse:4.587518428359245, ic :0.19300562031889537, sharpe5:16.71538705229759, irr5:561.1016235351562, ndcg5:0.8444514942837822, pnl5:6.832449913024902 
train 36, step: 0, loss: 1.829044264190051, grad_norm: 0.5642348914756002, ic: 0.14474279741299353
train 36, step: 500, loss: 0.839735724026054, grad_norm: 0.012256720562202618, ic: 0.18487229472731181
train 36, step: 1000, loss: 1.6287769886363634, grad_norm: 0.22314656801596716, ic: 0.22744550309394038
train 36, step: 1500, loss: 0.7747280029138238, grad_norm: 0.04777654769606253, ic: 0.381644385785497
train 36, step: 2000, loss: 1.1272605792978057, grad_norm: 0.34114398235236515, ic: 0.7775268944897787
Epoch 36: 2022-04-05 02:46:49.060221: train loss: 1.6230980819500174
Eval step 0: eval loss: 0.8229973394074354
Eval: 2022-04-05 02:47:00.294033: total loss: 1.0660842271228823, mse:4.61732703229937, ic :0.1844602378055251, sharpe5:16.668026443719864, irr5:556.835693359375, ndcg5:0.8479625847143567, pnl5:8.520275115966797 
train 37, step: 0, loss: 2.0424389685825037, grad_norm: 0.7641994014957486, ic: 0.1710681634860901
train 37, step: 500, loss: 2.3304664400234505, grad_norm: 0.4630900648209889, ic: -0.044655001253410806
train 37, step: 1000, loss: 1.07447989128496, grad_norm: 0.04537116775152948, ic: 0.04603591516288019
train 37, step: 1500, loss: 2.0444148137019234, grad_norm: 0.6551031222864878, ic: 0.6090481144720676
train 37, step: 2000, loss: 1.3170819963727678, grad_norm: 0.04786705833086903, ic: 0.14181008095754027
Epoch 37: 2022-04-05 02:51:21.227926: train loss: 1.623471555670876
Eval step 0: eval loss: 0.8272319186726158
Eval: 2022-04-05 02:51:32.490361: total loss: 1.0665105054496613, mse:4.591421009128493, ic :0.19087301206361024, sharpe5:16.38324604868889, irr5:562.7783203125, ndcg5:0.8566234636470068, pnl5:7.937302589416504 
train 38, step: 0, loss: 1.3392776861423399, grad_norm: 0.311233277501776, ic: -0.08529293129869513
train 38, step: 500, loss: 0.9156798562885802, grad_norm: 0.04927561714202202, ic: 0.2384327688279414
train 38, step: 1000, loss: 0.9037055335968379, grad_norm: 0.17118193394450432, ic: 0.05351089132771632
train 38, step: 1500, loss: 0.9498240037134587, grad_norm: 0.007576217989208156, ic: 0.21083561317249272
train 38, step: 2000, loss: 2.301580792107251, grad_norm: 0.6725221645670594, ic: -0.0020530690365315133
Epoch 38: 2022-04-05 02:55:54.920597: train loss: 1.6225110125407736
Eval step 0: eval loss: 0.8278655523495125
Eval: 2022-04-05 02:56:06.155503: total loss: 1.0652450074383495, mse:4.597162909585394, ic :0.18922040065010737, sharpe5:16.214536414146423, irr5:552.7946166992188, ndcg5:0.8552990079118031, pnl5:7.869933128356934 
train 39, step: 0, loss: 0.9739961303337634, grad_norm: 0.0010357934917850054, ic: 0.03618147652151478
train 39, step: 500, loss: 0.9055930158892198, grad_norm: 0.07101395018770887, ic: 0.22862193411554468
train 39, step: 1000, loss: 0.9370010271384711, grad_norm: 0.025915184513777403, ic: 0.18904120398706858
train 39, step: 1500, loss: 2.0885634626337164, grad_norm: 0.10523323887864751, ic: 0.16432040099219192
train 39, step: 2000, loss: 0.6227755915685476, grad_norm: 0.021160608487688602, ic: 0.06330170995758244
Epoch 39: 2022-04-05 03:00:28.217210: train loss: 1.6232222828424472
Eval step 0: eval loss: 0.8285907709184009
Eval: 2022-04-05 03:00:39.395037: total loss: 1.0655286042551821, mse:4.612955686410665, ic :0.19036663017663513, sharpe5:17.475682411193848, irr5:585.9290161132812, ndcg5:0.8450386847636231, pnl5:7.411630630493164 

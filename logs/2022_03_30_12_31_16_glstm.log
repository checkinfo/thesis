Namespace(train_path='./data/train_2305_1931_12.npy', test_path='./data/test_126_1931_12.npy', train_mask_path='./data/train_mask_2305_1931.npy', test_mask_path='./data/test_mask_126_1931.npy', label_cnt=3, batch_size=1, lr=0.001, adj_path='./data/concepts_graph_1931_233_3.npy', model_type='GLSTM', dataset_type='AdjTimeDataset', seed=10086, num_days=8, epochs=20, hidden_dim=128, input_dim=9, dout=0.3, lstm_layers=1, num_heads=1, gnn_layers=2, print_inteval=500, relation_num=1, mask_type='soft', shuffle=True, input_graph=True, use_adj=False, mask_adj=True)
785423
GLSTM(
  (input_to_hidden): Linear(in_features=9, out_features=128, bias=True)
  (glstm_cell): GLSTMCell(
    (dropout): Dropout(p=0.3, inplace=False)
    (Wh): Linear(in_features=128, out_features=640, bias=False)
    (Wn): Linear(in_features=128, out_features=640, bias=False)
    (Wt): Linear(in_features=128, out_features=640, bias=False)
    (U): Linear(in_features=128, out_features=640, bias=False)
    (V): Linear(in_features=128, out_features=640, bias=True)
    (relu): LeakyReLU(negative_slope=0.01)
    (gnn): ModuleList(
      (0): GraphConv(128, 128)
      (1): GraphConv(128, 128)
    )
  )
  (w_out): Linear(in_features=128, out_features=1, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
)
train 0, step: 0, loss: 1.3493549685230313, grad_norm: 4.052586705853734, ic: 0.07074475742014091
train 0, step: 500, loss: 2.0854702228823685, grad_norm: 2.131379708302826, ic: 0.20157850668298707
train 0, step: 1000, loss: 2.4914188399603097, grad_norm: 0.39468464725628416, ic: 0.055449026630469786
train 0, step: 1500, loss: 2.0597962644609256, grad_norm: 1.8983574205439249, ic: 0.019562274246138177
train 0, step: 2000, loss: 1.4536540576534334, grad_norm: 0.5864033226464131, ic: 0.08429711448645301
Epoch 0: train loss: 1.6320199859314362
Eval step 0: eval loss: 0.8325607998864534
Eval: total loss: 1.0731757663514607, mse:4.6318450672693725, ic :-0.0012166182960452819, sharpe5:0.879680643081665, irr5:10.7606782913208, ndcg5:0.8436111562404828 
train 1, step: 0, loss: 1.9992439516129032, grad_norm: 0.0007195923698974316, ic: 0.06898858342430665
train 1, step: 500, loss: 1.184051109708747, grad_norm: 0.3575053693488447, ic: 0.08391467083666942
train 1, step: 1000, loss: 1.028288914835834, grad_norm: 0.012953668396012575, ic: 0.05611775078703952
train 1, step: 1500, loss: 8.880295741705247, grad_norm: 1.5615324703412472, ic: 0.06164086550717007
train 1, step: 2000, loss: 1.2853291197593166, grad_norm: 0.09240229795355093, ic: 0.07623070144665003
Epoch 1: train loss: 1.6282401663017803
Eval step 0: eval loss: 0.8385429522939705
Eval: total loss: 1.074936815704939, mse:4.6295206297792655, ic :0.00046466821288985164, sharpe5:0.7006773858144879, irr5:8.134916305541992, ndcg5:0.8380078913484313 
train 2, step: 0, loss: 1.4814426275284762, grad_norm: 1.151425685927297, ic: -0.08793507297313241
train 2, step: 500, loss: 1.750841284579918, grad_norm: 0.9158051138475739, ic: 0.01971910822824104
train 2, step: 1000, loss: 1.2481925059959156, grad_norm: 0.2934386496845801, ic: -0.0074444982406980924
train 2, step: 1500, loss: 1.464898003472222, grad_norm: 0.23188172227932558, ic: 0.04429224393287459
train 2, step: 2000, loss: 0.8735907859466642, grad_norm: 0.35456759062051535, ic: -0.06281207422436887
Epoch 2: train loss: 1.6279188005647978
Eval step 0: eval loss: 0.8303882183056871
Eval: total loss: 1.0741128212004263, mse:4.643993078434983, ic :0.002522364555968565, sharpe5:0.6334691274538636, irr5:7.155337333679199, ndcg5:0.8383786629679857 
train 3, step: 0, loss: 0.7356350970070118, grad_norm: 0.03700081085459959, ic: -0.0026322193587937615
train 3, step: 500, loss: 0.8165637191157348, grad_norm: 0.020273639677944447, ic: 0.06305839943184914
train 3, step: 1000, loss: 3.1958089688929117, grad_norm: 0.6978510697991183, ic: 0.1521072842920737
train 3, step: 1500, loss: 1.3268806639022765, grad_norm: 0.031085381452259406, ic: 0.05265457878732913
train 3, step: 2000, loss: 1.121753764016731, grad_norm: 0.007668282175576406, ic: 0.06070719187876868
Epoch 3: train loss: 1.6287216896127035
Eval step 0: eval loss: 0.8349116979742627
Eval: total loss: 1.0735171380241177, mse:4.6287331129141265, ic :0.0024453924748425435, sharpe5:1.0259966687858104, irr5:11.502955436706543, ndcg5:0.8339555989391145 
train 4, step: 0, loss: 3.2610229774105077, grad_norm: 0.6905972255259449, ic: 0.08822798520561159
train 4, step: 500, loss: 0.7866697078506575, grad_norm: 1.5627018687666508e-05, ic: 0.0007710134335991371
train 4, step: 1000, loss: 1.1040455042469575, grad_norm: 0.17537382919830932, ic: -0.06812048832543266
train 4, step: 1500, loss: 0.8834688356892966, grad_norm: 0.0066286807581417435, ic: -0.0032734692684009627
train 4, step: 2000, loss: 1.0402262432247698, grad_norm: 0.0324733311748936, ic: 0.08773598409514564
Epoch 4: train loss: 1.6282806421312008
Eval step 0: eval loss: 0.8359206582823195
Eval: total loss: 1.0737796998646787, mse:4.628350932721805, ic :0.0035906725478589887, sharpe5:0.4314534485712647, irr5:4.393321514129639, ndcg5:0.8401289209999955 
train 5, step: 0, loss: 1.1005221038658952, grad_norm: 0.0212393843412608, ic: 0.011816465771728448
train 5, step: 500, loss: 3.3941754481589146, grad_norm: 0.2083077926305744, ic: 0.06383364167538902
train 5, step: 1000, loss: 1.1733113235171708, grad_norm: 0.21697149573699848, ic: -0.011747811178862477
train 5, step: 1500, loss: 1.0639773202741722, grad_norm: 0.08827208663918774, ic: 0.056737174238987054
train 5, step: 2000, loss: 0.9342573008381766, grad_norm: 0.05951743132079665, ic: 0.04196784445270987
Epoch 5: train loss: 1.6281897597783357
Eval step 0: eval loss: 0.8368143621025869
Eval: total loss: 1.074072463701037, mse:4.628344153606161, ic :0.00397655686851303, sharpe5:0.6016416832432151, irr5:6.4333014488220215, ndcg5:0.8280761247943152 
train 6, step: 0, loss: 1.0520435333251954, grad_norm: 0.010522897512620593, ic: 0.030196201911797945
train 6, step: 500, loss: 5.401569994190071, grad_norm: 0.6379097785351348, ic: 0.04962856081128585
train 6, step: 1000, loss: 2.9683515090710486, grad_norm: 0.6685152677736854, ic: 0.03366741914992541
train 6, step: 1500, loss: 0.8665303703482824, grad_norm: 0.027983975455340763, ic: 0.07562193511604948
train 6, step: 2000, loss: 2.8422272748860182, grad_norm: 0.7638897424437896, ic: -0.027489524127022335
Epoch 6: train loss: 1.6279621954575076
Eval step 0: eval loss: 0.8509429562022774
Eval: total loss: 1.0819863306632995, mse:4.649109816706134, ic :0.00561845208611536, sharpe5:0.1265662348922342, irr5:0.41643500328063965, ndcg5:0.8419309886777595 
train 7, step: 0, loss: 1.644454503540184, grad_norm: 0.3635794675316726, ic: -0.10242529558590814
train 7, step: 500, loss: 1.2778552020037615, grad_norm: 0.262186257037504, ic: -0.029882030809853473
train 7, step: 1000, loss: 1.685421953788482, grad_norm: 0.007649207427385163, ic: 0.24402972940740952
train 7, step: 1500, loss: 1.6738948931709265, grad_norm: 0.1326207151222047, ic: 0.1936149576946901
train 7, step: 2000, loss: 0.7928903929520164, grad_norm: 0.000763030656383872, ic: 0.04452626508414258
Epoch 7: train loss: 1.6279420957828157
Eval step 0: eval loss: 0.8414471200919892
Eval: total loss: 1.0761240627714947, mse:4.631330230694469, ic :0.009915074897546018, sharpe5:-0.21085890188813208, irr5:-3.4026780128479004, ndcg5:0.8416950562525742 
train 8, step: 0, loss: 1.3307851584984172, grad_norm: 0.42552684957487324, ic: 0.019754832920619424
train 8, step: 500, loss: 1.1869760577598314, grad_norm: 0.5324584931289373, ic: 0.08315520188062678
train 8, step: 1000, loss: 1.1752055183785861, grad_norm: 0.010954063585199236, ic: -0.0483814493223277
train 8, step: 1500, loss: 1.1864482137140466, grad_norm: 0.4851743087874575, ic: -0.032888351662896886
train 8, step: 2000, loss: 0.9715245627572017, grad_norm: 0.04340210588618869, ic: 0.05171162847303536
Epoch 8: train loss: 1.6273754464806929
Eval step 0: eval loss: 0.8485786875905081
Eval: total loss: 1.080240412532403, mse:4.64151760188939, ic :0.017664489397616938, sharpe5:1.9269997780770063, irr5:18.420257568359375, ndcg5:0.847570695402727 
train 9, step: 0, loss: 0.8801310594657875, grad_norm: 0.16432091467961413, ic: 0.046627453904753716
train 9, step: 500, loss: 1.234713815004771, grad_norm: 0.10656828822364275, ic: -0.01383434348020619
train 9, step: 1000, loss: 0.8909703091404417, grad_norm: 0.23462870246729814, ic: 0.12769953889904057
train 9, step: 1500, loss: 0.9458961052999432, grad_norm: 0.09226912699681135, ic: 0.134926096789726
train 9, step: 2000, loss: 0.815085188673419, grad_norm: 0.011952899474211787, ic: 0.011204537118075583
Epoch 9: train loss: 1.6273671430454186
Eval step 0: eval loss: 0.8390775161269088
Eval: total loss: 1.0742630804823121, mse:4.624746737607257, ic :0.033341439233677474, sharpe5:1.7690506397187709, irr5:15.715921401977539, ndcg5:0.861801862853336 
train 10, step: 0, loss: 2.0457625912274686, grad_norm: 0.631917977288936, ic: 0.021979745552354053
train 10, step: 500, loss: 1.1199136751401026, grad_norm: 0.35982950421198734, ic: 0.023303434330862426
train 10, step: 1000, loss: 1.8886094772421091, grad_norm: 0.21316996368148813, ic: 0.09142002290295918
train 10, step: 1500, loss: 0.8628607930222603, grad_norm: 0.2235455153929383, ic: 0.004059763148315373
train 10, step: 2000, loss: 1.124517312806874, grad_norm: 0.3459152501899973, ic: 0.08171547211201433
Epoch 10: train loss: 1.6278187803805924
Eval step 0: eval loss: 0.8380485643142772
Eval: total loss: 1.0739604993288303, mse:4.625194783304315, ic :0.03507343197102501, sharpe5:2.6737566934525967, irr5:25.1209774017334, ndcg5:0.846114563410206 
train 11, step: 0, loss: 1.1072304377480158, grad_norm: 0.2648160296148939, ic: 0.08494757907009906
train 11, step: 500, loss: 0.9386048520345824, grad_norm: 0.010416166263193291, ic: 0.049267275005387995
train 11, step: 1000, loss: 2.0928680699899656, grad_norm: 0.006423040264792926, ic: -0.004327771979084472
train 11, step: 1500, loss: 1.828712995087115, grad_norm: 0.5947364594744927, ic: -0.10144802548561109
train 11, step: 2000, loss: 1.3615573631983147, grad_norm: 0.027376703465093945, ic: 0.22759864608592195
Epoch 11: train loss: 1.626957751529643
Eval step 0: eval loss: 0.8381621494865719
Eval: total loss: 1.0736878080620504, mse:4.628328696867385, ic :0.025426428394286674, sharpe5:2.818407180458307, irr5:28.711942672729492, ndcg5:0.8603152234638678 
train 12, step: 0, loss: 2.4121417176263247, grad_norm: 0.5983764312203187, ic: -0.0422776100191303
train 12, step: 500, loss: 1.0608022759885205, grad_norm: 0.1913584430754798, ic: 0.025660736436498268
train 12, step: 1000, loss: 0.879324196904285, grad_norm: 0.012627595080578506, ic: -0.03996378357069883
train 12, step: 1500, loss: 1.6793846420094938, grad_norm: 0.35420503016306926, ic: -0.16278488047137082
train 12, step: 2000, loss: 1.761912314544821, grad_norm: 0.7736881842616785, ic: -0.14094458053776085
Epoch 12: train loss: 1.6269826876762974
Eval step 0: eval loss: 0.8384969268364928
Eval: total loss: 1.0744279025746366, mse:4.625564594041739, ic :0.02963292390245462, sharpe5:0.18784616989083588, irr5:0.6168792247772217, ndcg5:0.8397855911781003 
train 13, step: 0, loss: 0.9035235755088326, grad_norm: 0.023864563102044323, ic: 0.039572005307217384
train 13, step: 500, loss: 1.1903264923404795, grad_norm: 0.2521750175881698, ic: -0.11133642204349395
train 13, step: 1000, loss: 1.5050235337387796, grad_norm: 0.21190905483101746, ic: -0.12550792022466858
train 13, step: 1500, loss: 2.780787397591248, grad_norm: 0.7421393451630667, ic: -0.03827777475906861
train 13, step: 2000, loss: 0.8469137244873965, grad_norm: 0.0005622318450363136, ic: -0.02483212664694993
Epoch 13: train loss: 1.6273502994153917
Eval step 0: eval loss: 0.8393500691153238
Eval: total loss: 1.0735224717576346, mse:4.623374664329218, ic :0.03664979084117248, sharpe5:1.214450965449214, irr5:10.042940139770508, ndcg5:0.8592733204958727 
train 14, step: 0, loss: 1.2174876165933934, grad_norm: 0.26388546167720023, ic: 0.1284058386407573
train 14, step: 500, loss: 1.1182140214794178, grad_norm: 0.046032759255679866, ic: 0.3539947860532602
train 14, step: 1000, loss: 1.3414864532218491, grad_norm: 0.06610478035004674, ic: 0.11788272976236765
train 14, step: 1500, loss: 2.2848298362803683, grad_norm: 0.07616352550792216, ic: 0.03263813132647245
train 14, step: 2000, loss: 1.270280334291543, grad_norm: 0.4627353484342124, ic: 0.08341743023465414
Epoch 14: train loss: 1.6265925185917014
Eval step 0: eval loss: 0.8362688704375657
Eval: total loss: 1.0737860383040148, mse:4.6263380201106035, ic :0.024413051866571854, sharpe5:0.44825019232928753, irr5:3.380038261413574, ndcg5:0.85924326478946 
train 15, step: 0, loss: 1.350167982263975, grad_norm: 0.009279690096124352, ic: 0.10651580793683503
train 15, step: 500, loss: 1.2061500738832949, grad_norm: 0.30486670809331584, ic: 0.030956106769669794
train 15, step: 1000, loss: 0.9175965139557978, grad_norm: 0.1195556055907254, ic: -0.0018955869509330438
train 15, step: 1500, loss: 0.9098323636528806, grad_norm: 0.0021538265703666556, ic: -0.07881851643198541
train 15, step: 2000, loss: 8.140131045458947, grad_norm: 3.9583222277302044, ic: 0.03354347377264902
Epoch 15: train loss: 1.6285409090934189
Eval step 0: eval loss: 0.8392042789790679
Eval: total loss: 1.0730904759584923, mse:4.620185916566711, ic :0.046748019079024525, sharpe5:0.9684035679325461, irr5:8.743059158325195, ndcg5:0.8420579921819658 
train 16, step: 0, loss: 1.168392648173787, grad_norm: 0.21131765369785696, ic: 0.03763394683608697
train 16, step: 500, loss: 0.8693128896745742, grad_norm: 0.00040526273448600715, ic: 0.006292102655449409
train 16, step: 1000, loss: 1.0192250360841275, grad_norm: 0.029232783792216277, ic: -0.03638177790580308
train 16, step: 1500, loss: 1.0963057112754453, grad_norm: 0.01733653666079968, ic: 0.13452938476257845
train 16, step: 2000, loss: 0.9911149250430374, grad_norm: 0.4817812198613094, ic: 0.039502342263625916
Epoch 16: train loss: 1.6275010960075342
Eval step 0: eval loss: 0.8383969050322537
Eval: total loss: 1.0732189431172774, mse:4.622110148574332, ic :0.04017986648050589, sharpe5:1.9574898015707731, irr5:16.9110050201416, ndcg5:0.8402030995235285 
train 17, step: 0, loss: 1.0949463633823249, grad_norm: 0.2894129908947706, ic: 0.16786626377116462
train 17, step: 500, loss: 0.9970704011494644, grad_norm: 0.13505719746999645, ic: 0.2337881390648891
train 17, step: 1000, loss: 2.1240031517629374, grad_norm: 0.07427071433191404, ic: 0.044781792873406355
train 17, step: 1500, loss: 0.8935061302124604, grad_norm: 0.4723362791037003, ic: 0.15950371193100277
train 17, step: 2000, loss: 1.128674140512428, grad_norm: 0.11501603592959066, ic: 0.28322141231305314
Epoch 17: train loss: 1.6271350101926991
Eval step 0: eval loss: 0.8339983883376119
Eval: total loss: 1.0721010358279763, mse:4.627868275141579, ic :0.03875121766066709, sharpe5:0.43663431325927377, irr5:3.6667423248291016, ndcg5:0.8489179609821851 
train 18, step: 0, loss: 0.9358829185993688, grad_norm: 0.2217381627867716, ic: 0.15195394126447562
train 18, step: 500, loss: 1.005316044280888, grad_norm: 0.10973152374992046, ic: 0.1992884930767525
train 18, step: 1000, loss: 0.9336193506314499, grad_norm: 0.7272974997921489, ic: 0.023748394925173666
train 18, step: 1500, loss: 7.591871643066407, grad_norm: 2.6385867356724226, ic: 0.12052314877939949
train 18, step: 2000, loss: 0.7839846678622546, grad_norm: 0.10709409167003832, ic: 0.08363963257076236
Epoch 18: train loss: 1.6268703888429346
Eval step 0: eval loss: 0.840284205914297
Eval: total loss: 1.0735577323236243, mse:4.621372108345045, ic :0.04506664169317375, sharpe5:0.49824857387691734, irr5:4.017437934875488, ndcg5:0.8610578869627464 
train 19, step: 0, loss: 1.2917817521913806, grad_norm: 0.16557786755229692, ic: 0.1488794187556745
train 19, step: 500, loss: 1.447908155284069, grad_norm: 0.44532826126895597, ic: 0.026682987836739377
train 19, step: 1000, loss: 1.8983809876933728, grad_norm: 0.024658342126136507, ic: 0.3422155763327859
train 19, step: 1500, loss: 1.4304049958321163, grad_norm: 0.29320331487293627, ic: -0.03498008509904657
train 19, step: 2000, loss: 1.348812937483413, grad_norm: 0.04174979635879371, ic: 0.2602352014019579
Epoch 19: train loss: 1.6267061596001973
Eval step 0: eval loss: 0.8381531500954449
Eval: total loss: 1.072207158357954, mse:4.622597364624567, ic :0.047362308659326426, sharpe5:2.910629498362541, irr5:28.487445831298828, ndcg5:0.8475807578917629 

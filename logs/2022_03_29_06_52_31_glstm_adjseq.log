Namespace(train_path='./data/train_2305_1931_12.npy', test_path='./data/test_126_1931_12.npy', train_mask_path='./data/train_mask_2305_1931.npy', test_mask_path='./data/test_mask_126_1931.npy', label_cnt=3, batch_size=1, lr=0.001, adj_path='./data/concepts_graph_1931_233_3.npy', model_type='GLSTM', dataset_type='AdjSeqTimeDataset', seed=10086, num_days=8, epochs=20, hidden_dim=128, input_dim=9, dout=0.3, lstm_layers=1, num_heads=1, gnn_layers=2, print_inteval=500, relation_num=1, mask_type='soft', shuffle=True, input_graph=True, use_adj=False, mask_adj=True)
689021
GLSTM(
  (input_to_hidden): Linear(in_features=9, out_features=128, bias=True)
  (glstm_cell): GLSTMCell(
    (dropout): Dropout(p=0.3, inplace=False)
    (Wh): Linear(in_features=128, out_features=640, bias=False)
    (Wn): Linear(in_features=128, out_features=640, bias=False)
    (Wt): Linear(in_features=128, out_features=640, bias=False)
    (U): Linear(in_features=128, out_features=640, bias=False)
    (V): Linear(in_features=128, out_features=640, bias=True)
    (relu): LeakyReLU(negative_slope=0.01)
    (gnn): ModuleList(
      (0): GraphConv(128, 128)
      (1): GraphConv(128, 128)
    )
  )
  (w_out): Linear(in_features=128, out_features=1, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
)
train 0, step: 0, loss: 1.3493402230265672, grad_norm: 4.052388886787653, ic: 0.07072324317823409
train 0, step: 500, loss: 2.085492782876394, grad_norm: 2.1338488700921316, ic: 0.2015411786265999
train 0, step: 1000, loss: 2.491406698307192, grad_norm: 0.39499583327872356, ic: 0.05557294151983231
train 0, step: 1500, loss: 2.0592363536266323, grad_norm: 1.8947232544172676, ic: 0.016831243177742324
train 0, step: 2000, loss: 1.450511038366583, grad_norm: 0.44969342823932246, ic: 0.09386935531439089
Epoch 0: train loss: 1.6319355019315664
Eval step 0: eval loss: 0.8326975263502171
Eval: total loss: 1.0731831780893266, mse:4.631513471943367, ic :-0.0010563696956772824, sharpe5:0.727836213670671, irr5:8.808436393737793, ndcg5:0.8361424022453008 
train 1, step: 0, loss: 1.9991569460445469, grad_norm: 0.0007957738746357467, ic: 0.08834141717776203
train 1, step: 500, loss: 1.1851414429151625, grad_norm: 0.36302962721357523, ic: 0.08216091027251805
train 1, step: 1000, loss: 1.028865014401062, grad_norm: 0.013537491952591317, ic: 0.05945506652326621
train 1, step: 1500, loss: 8.876268174913195, grad_norm: 1.794792440961736, ic: 0.028109774941394217
train 1, step: 2000, loss: 1.2860930069633152, grad_norm: 0.10350788105752003, ic: 0.07755936597368852
Epoch 1: train loss: 1.628258481339179
Eval step 0: eval loss: 0.8388216120120786
Eval: total loss: 1.0750505797291372, mse:4.629657318180317, ic :0.0005027878997672441, sharpe5:0.609931776188314, irr5:6.970436096191406, ndcg5:0.844461622960402 
train 2, step: 0, loss: 1.4788720549698058, grad_norm: 1.1586927530582303, ic: -0.07983150532923707
train 2, step: 500, loss: 1.7476220969945355, grad_norm: 0.8402833710537625, ic: 0.019718539116613535
train 2, step: 1000, loss: 1.2376874094676102, grad_norm: 0.2500103383689897, ic: 0.017898760195086627
train 2, step: 1500, loss: 1.4651924957786338, grad_norm: 0.2263354817612787, ic: 0.04419497761023303
train 2, step: 2000, loss: 0.8741654829545454, grad_norm: 0.3658007305941397, ic: -0.03537597339040606
Epoch 2: train loss: 1.6278918932229713
Eval step 0: eval loss: 0.8306058750082279
Eval: total loss: 1.074018580453462, mse:4.642804946823877, ic :0.0024900296616028918, sharpe5:0.5751094129309058, irr5:6.412100315093994, ndcg5:0.8352670745772632 
train 3, step: 0, loss: 0.7371718810866084, grad_norm: 0.03502859947817254, ic: -0.002321294233857911
train 3, step: 500, loss: 0.8160479760138979, grad_norm: 0.021409604989247037, ic: 0.06250094260156915
train 3, step: 1000, loss: 3.196919511004192, grad_norm: 0.7225972392901143, ic: 0.1174332770072589
train 3, step: 1500, loss: 1.3264736961008, grad_norm: 0.031388023186978885, ic: 0.062117593417590176
train 3, step: 2000, loss: 1.1218744437805126, grad_norm: 0.007612758112437995, ic: 0.046618577863510806
Epoch 3: train loss: 1.6287747713761744
Eval step 0: eval loss: 0.8348472880463401
Eval: total loss: 1.0735002661742383, mse:4.628788835123533, ic :0.00225189763201844, sharpe5:1.0724753198772667, irr5:12.135756492614746, ndcg5:0.8418863496197901 
train 4, step: 0, loss: 3.261994653339107, grad_norm: 0.6957355374364663, ic: 0.08622812339294131
train 4, step: 500, loss: 0.7866891993532795, grad_norm: 1.4450074179425837e-05, ic: 0.0012183487030728766
train 4, step: 1000, loss: 1.1038338826910075, grad_norm: 0.17572772452535182, ic: -0.06724268453673597
train 4, step: 1500, loss: 0.8834863798340583, grad_norm: 0.006709430782705772, ic: 0.0005667535790551455
train 4, step: 2000, loss: 1.040052084582454, grad_norm: 0.03247382266992547, ic: 0.08819293102465263
Epoch 4: train loss: 1.628268001371507
Eval step 0: eval loss: 0.835844549145932
Eval: total loss: 1.0737554191474599, mse:4.6283929540138224, ic :0.003323334361921564, sharpe5:0.8429168264195323, irr5:9.217617988586426, ndcg5:0.8323252422008458 
train 5, step: 0, loss: 1.1002756961195952, grad_norm: 0.02093658138200291, ic: 0.013325897470038813
train 5, step: 500, loss: 3.393783309108527, grad_norm: 0.20717034646659915, ic: 0.06256259163009693
train 5, step: 1000, loss: 1.1730371762628424, grad_norm: 0.21745728137083895, ic: -0.007516541221383737
train 5, step: 1500, loss: 1.0639975821494276, grad_norm: 0.0884219946058812, ic: 0.0559129585924941
train 5, step: 2000, loss: 0.9339465764063584, grad_norm: 0.05919305398476656, ic: 0.04225992930807589
Epoch 5: train loss: 1.628183114877971
Eval step 0: eval loss: 0.8367811929181477
Eval: total loss: 1.0740609238131615, mse:4.628365075299149, ic :0.0038266098713075573, sharpe5:0.6231987390294671, irr5:6.74769926071167, ndcg5:0.8390866833524896 
train 6, step: 0, loss: 1.0521148681640626, grad_norm: 0.01058484838225141, ic: 0.029821389407113555
train 6, step: 500, loss: 5.402478181863133, grad_norm: 0.6368604481888084, ic: 0.046729998729058045
train 6, step: 1000, loss: 2.968085291900171, grad_norm: 0.6687720501066148, ic: 0.030668700090990937
train 6, step: 1500, loss: 0.8664766966841603, grad_norm: 0.027908730832211504, ic: 0.07592920629306639
train 6, step: 2000, loss: 2.841010653139248, grad_norm: 0.762623140202348, ic: -0.024047313267216153
Epoch 6: train loss: 1.6279588504148808
Eval step 0: eval loss: 0.8509885316901987
Eval: total loss: 1.0820169806585807, mse:4.649322455992365, ic :0.0051420588941624625, sharpe5:0.09253564840648323, irr5:0.09064102172851562, ndcg5:0.8381123950972151 
train 7, step: 0, loss: 1.6425962255801454, grad_norm: 0.36182693753116646, ic: -0.10401540307486973
train 7, step: 500, loss: 1.2786107946325231, grad_norm: 0.26184782141053364, ic: 0.006588902878589091
train 7, step: 1000, loss: 1.6881417114516986, grad_norm: 0.0038023709298095304, ic: 0.22461844044037146
train 7, step: 1500, loss: 1.6762221071285943, grad_norm: 0.11803589535428206, ic: 0.09002029656554728
train 7, step: 2000, loss: 0.7933535901418173, grad_norm: 0.0012698982569135586, ic: 0.03291444332756689
Epoch 7: train loss: 1.6279621746084472
Eval step 0: eval loss: 0.8415072874498091
Eval: total loss: 1.0762460255238264, mse:4.632051052599961, ic :0.004997808923681797, sharpe5:-0.009708868815796448, irr5:-1.1159865856170654, ndcg5:0.8321363905070627 
train 8, step: 0, loss: 1.3296932709372602, grad_norm: 0.4187116991402821, ic: 0.022177629987673714
train 8, step: 500, loss: 1.1802454268590044, grad_norm: 0.45761368304846256, ic: 0.08927208423656235
train 8, step: 1000, loss: 1.1731711465804304, grad_norm: 0.011511925424460254, ic: -0.02022516443123744
train 8, step: 1500, loss: 1.1921983122168047, grad_norm: 0.47767402756989613, ic: -0.0420678468309207
train 8, step: 2000, loss: 0.9724192427019033, grad_norm: 0.0430240025885068, ic: 0.05818304779973513
Epoch 8: train loss: 1.6277113011726223
Eval step 0: eval loss: 0.8509619192050092
Eval: total loss: 1.0817324894275793, mse:4.646450035723962, ic :0.007456040683593234, sharpe5:0.6294416713714599, irr5:5.545342445373535, ndcg5:0.8454754966390584 
train 9, step: 0, loss: 0.874305841755065, grad_norm: 0.15010356745027195, ic: 0.018353198603349902
train 9, step: 500, loss: 1.2350494617724237, grad_norm: 0.1035802460252873, ic: -0.009039342860981722
train 9, step: 1000, loss: 0.906430576255864, grad_norm: 0.22231447423432749, ic: 0.09732468378037337
train 9, step: 1500, loss: 0.9459675520635898, grad_norm: 0.08721807528342654, ic: 0.09812236312315208
train 9, step: 2000, loss: 0.8166281960227273, grad_norm: 0.013038923908166583, ic: 0.0021795159613186197
Epoch 9: train loss: 1.6282372434524461
Eval step 0: eval loss: 0.8374672679288441
Eval: total loss: 1.074347258208912, mse:4.628651597883547, ic :0.0059419149521331305, sharpe5:0.2260072370711714, irr5:1.6839213371276855, ndcg5:0.8433536114632127 
train 10, step: 0, loss: 2.034389770890478, grad_norm: 0.5592045516836157, ic: 0.0078648857102552
train 10, step: 500, loss: 1.0946555094153685, grad_norm: 0.3530336008876794, ic: 0.029375094751914736
train 10, step: 1000, loss: 1.8981093479359121, grad_norm: 0.2195365023243722, ic: 0.11699048211588345
train 10, step: 1500, loss: 0.8547885675299657, grad_norm: 0.22408800965829384, ic: 0.018851447921060995
train 10, step: 2000, loss: 1.1271487172028438, grad_norm: 0.336856699161907, ic: 0.05775732587696018
Epoch 10: train loss: 1.6279993908986772
Eval step 0: eval loss: 0.8370504032755726
Eval: total loss: 1.0741931329753382, mse:4.6286819208309025, ic :0.006412787305228691, sharpe5:-0.04653004515683278, irr5:-1.522982120513916, ndcg5:0.8390833555958641 
train 11, step: 0, loss: 1.103740970672123, grad_norm: 0.26935355484047546, ic: 0.06950529843734247
train 11, step: 500, loss: 0.9365405042024586, grad_norm: 0.007278384002514642, ic: -0.02680960287714471
train 11, step: 1000, loss: 2.089729892369075, grad_norm: 0.005487321328427139, ic: 0.06130453610746114
train 11, step: 1500, loss: 1.8364940377456442, grad_norm: 0.5994453562416018, ic: -0.042628010473824175
train 11, step: 2000, loss: 1.3625232996201566, grad_norm: 0.02802145118597786, ic: 0.1634284271352035
Epoch 11: train loss: 1.6279317315261705
Eval step 0: eval loss: 0.8424567232136979
Eval: total loss: 1.0766950261468882, mse:4.632557813916087, ic :0.009590695659836794, sharpe5:1.6692976889759301, irr5:15.721778869628906, ndcg5:0.8568257332661147 
train 12, step: 0, loss: 2.4416424435796746, grad_norm: 0.6299718894873223, ic: 0.033995102683438146
train 12, step: 500, loss: 1.0558791055484695, grad_norm: 0.18478464172964726, ic: -0.01909017465708656
train 12, step: 1000, loss: 0.8744235978593561, grad_norm: 0.009917622049207304, ic: 0.1198718549645288
train 12, step: 1500, loss: 1.690869140625, grad_norm: 0.3659859260317137, ic: -0.10584823007309002
train 12, step: 2000, loss: 1.7599627714201878, grad_norm: 0.7626415483113281, ic: -0.036324058831112394
Epoch 12: train loss: 1.6280355003888378
Eval step 0: eval loss: 0.838130780180358
Eval: total loss: 1.0746592658866156, mse:4.629075193204668, ic :0.008660444783583642, sharpe5:0.4841320810653269, irr5:4.0747199058532715, ndcg5:0.8385181724419668 
train 13, step: 0, loss: 0.9082286266321045, grad_norm: 0.030799156389413926, ic: 0.0158160199565927
train 13, step: 500, loss: 1.1835274809039502, grad_norm: 0.20754047632245676, ic: 0.04748482520879163
train 13, step: 1000, loss: 1.4930258591362682, grad_norm: 0.20116675677302306, ic: -0.07262326394583578
train 13, step: 1500, loss: 2.777334934875393, grad_norm: 0.7592915924078714, ic: -0.03524208815048829
train 13, step: 2000, loss: 0.8501055554575808, grad_norm: 0.0006937287290648571, ic: -0.03522830130843885
Epoch 13: train loss: 1.6262079974721027
Eval step 0: eval loss: 0.8358243647972616
Eval: total loss: 1.073758412639677, mse:4.6285507187598, ic :0.0075105418053514, sharpe5:1.0018075747042894, irr5:8.718500137329102, ndcg5:0.8585039604264034 
train 14, step: 0, loss: 1.20852106478731, grad_norm: 0.2612712209894426, ic: 0.06075493404640949
train 14, step: 500, loss: 1.1260687348806313, grad_norm: 0.0360884485183071, ic: 0.14722180785087688
train 14, step: 1000, loss: 1.343479024083161, grad_norm: 0.06271062364830172, ic: 0.008027060566051753
train 14, step: 1500, loss: 2.2813403090713167, grad_norm: 0.04621949735834441, ic: -0.0010089748715025686
train 14, step: 2000, loss: 1.2595967369192786, grad_norm: 0.49188622810456234, ic: 0.18029894249173628
Epoch 14: train loss: 1.6248393731294932
Eval step 0: eval loss: 0.8312519027284097
Eval: total loss: 1.0699080235730878, mse:4.5877560737191345, ic :0.08196250303831347, sharpe5:11.791926013827323, irr5:213.03463745117188, ndcg5:0.857725824863175 
train 15, step: 0, loss: 1.3505126775309542, grad_norm: 0.009947845896667707, ic: 0.1069987559137558
train 15, step: 500, loss: 1.1869382513085522, grad_norm: 0.29251070431167037, ic: 0.015310398434205253
train 15, step: 1000, loss: 0.9297230728902552, grad_norm: 0.1242060619283912, ic: -0.031137234694032477
train 15, step: 1500, loss: 0.8986617041944702, grad_norm: 0.0006667218680989923, ic: 0.1411903208871248
train 15, step: 2000, loss: 8.04452701394268, grad_norm: 0.795842416177506, ic: 0.34177690089609275
Epoch 15: train loss: 1.6251594185333198
Eval step 0: eval loss: 0.831942284590574
Eval: total loss: 1.0712162714129865, mse:4.5918773357676725, ic :0.07976180984404757, sharpe5:11.30424833714962, irr5:207.72129821777344, ndcg5:0.8354125467028828 
train 16, step: 0, loss: 1.1620399271217916, grad_norm: 0.14466777640194584, ic: 0.11562918820400878
train 16, step: 500, loss: 0.8716546992219181, grad_norm: 0.0006042945656387525, ic: 0.021235300473381204
train 16, step: 1000, loss: 0.9855422928885631, grad_norm: 0.01873766880669954, ic: 0.26329718816722547
train 16, step: 1500, loss: 1.068849752877505, grad_norm: 0.009384111505398054, ic: 0.2557837787369208
train 16, step: 2000, loss: 0.9962177816564651, grad_norm: 1.0827268480797043, ic: -0.01341363368006419
Epoch 16: train loss: 1.6401652394843136
Eval step 0: eval loss: 0.8347736216018299
Eval: total loss: 1.0728783244126832, mse:4.610578534848631, ic :0.062537254579506, sharpe5:12.495500829219818, irr5:204.7810821533203, ndcg5:0.8386769236371826 
train 17, step: 0, loss: 1.128328970759608, grad_norm: 3.931897476087431, ic: 0.004675984504603032
train 17, step: 500, loss: 0.9985252275099855, grad_norm: 0.15883679212861565, ic: 0.1562555113705244
train 17, step: 1000, loss: 2.0972156580266033, grad_norm: 0.189086205401417, ic: 0.09830142004121314
train 17, step: 1500, loss: 0.876630731694483, grad_norm: 1.347524398034738, ic: -0.027093978303177203
train 17, step: 2000, loss: 1.1123891165345823, grad_norm: 0.07761108026767342, ic: 0.15602022059847634
Epoch 17: train loss: 1.6389897491698473
Eval step 0: eval loss: 0.8287883194074183
Eval: total loss: 1.0686920261725206, mse:4.587380118453231, ic :0.08832973339080302, sharpe5:11.705658534765243, irr5:204.0609130859375, ndcg5:0.8190441632426305 
train 18, step: 0, loss: 0.9417294047675975, grad_norm: 0.47444947802044396, ic: 0.09818014692815955
train 18, step: 500, loss: 1.0204273120777028, grad_norm: 0.32222625418927764, ic: 0.08196309431829898
train 18, step: 1000, loss: 0.9063213566806758, grad_norm: 0.46338846401959, ic: 0.33595841640593094
train 18, step: 1500, loss: 7.626719665527344, grad_norm: 1.4220920341080319, ic: 0.3352833437980324
train 18, step: 2000, loss: 0.7913056917512951, grad_norm: 0.16818928853934134, ic: 0.08348831708317996
Epoch 18: train loss: 1.6213512743941607
Eval step 0: eval loss: 0.832553343248091
Eval: total loss: 1.0701043049969097, mse:4.588152937043676, ic :0.08663532840169466, sharpe5:11.685433697104454, irr5:198.7923126220703, ndcg5:0.8473767415625996 
train 19, step: 0, loss: 1.287810766583729, grad_norm: 0.14977264237573995, ic: 0.1423764431286495
train 19, step: 500, loss: 1.4430377776292769, grad_norm: 0.2315411443071434, ic: 0.012161898123988962
train 19, step: 1000, loss: 1.899167124236058, grad_norm: 0.03427937330395665, ic: 0.2699875414910841
train 19, step: 1500, loss: 1.422136823707652, grad_norm: 0.38574734962598956, ic: -0.016832730829291206
train 19, step: 2000, loss: 1.3590607531764198, grad_norm: 0.036628670008759266, ic: 0.07591608401396055
Epoch 19: train loss: 1.6206614381267959
Eval step 0: eval loss: 0.8301479345625987
Eval: total loss: 1.0686998970945187, mse:4.5847256019956255, ic :0.09206943081261111, sharpe5:11.942144692540168, irr5:207.19151306152344, ndcg5:0.845004459292944 

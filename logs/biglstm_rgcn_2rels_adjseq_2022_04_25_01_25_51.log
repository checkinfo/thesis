Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='RGCNSeqTimeDataset', dout=0.3, epochs=40, glstm_layers=1, gnn_layers=1, gpu=0, graph_attn=False, hidden_dim=128, inner_prod=False, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=1, market=None, mask_adj=True, mask_type='soft', model_type='BiGLSTM', normalize_adj=True, num_days=8, num_heads=1, print_inteval=500, rank_loss=False, relation_num=2, rsr_data_path=None, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_250_0.8/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
load 2305 train graphs successful!
load 126 test graphs successful!
4677
BiGLSTM(
  (input_to_hidden): Linear(in_features=9, out_features=128, bias=True)
  (forward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
            (1): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
  )
  (backward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
            (1): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
  )
  (fc0): ModuleList(
    (0): Linear(in_features=256, out_features=128, bias=True)
  )
  (w_out): Linear(in_features=128, out_features=1, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
)
train 0, step: 0, loss: 4.81497958304828, grad_norm: 5.25894194229995, ic: 0.026913900202296143
train 0, step: 500, loss: 0.8642548688300679, grad_norm: 0.02465001985061648, ic: 0.030358306442981584
train 0, step: 1000, loss: 1.9482182556464887, grad_norm: 0.43860024797776387, ic: -0.013874524862735544
train 0, step: 1500, loss: 0.9464780061141305, grad_norm: 0.02785839657097456, ic: 0.07499509459057382
train 0, step: 2000, loss: 1.0014956030080093, grad_norm: 0.13156919610208695, ic: 0.025591212817375197
Epoch 0: 2022-04-25 13:35:04.418030: train loss: 1.6494746041411175
Eval step 0: eval loss: 0.8363911153393374
Eval: 2022-04-25 13:35:35.449817: total loss: 1.0793401214920124, mse:4.823159501972148, ic :0.009393751497579832, sharpe5:10.075748128294943, irr5:295.6517333984375, ndcg5:0.8700396464129944, pnl5:2.791635036468506 
train 1, step: 0, loss: 2.7686377740675403, grad_norm: 0.7385270099707584, ic: 0.026513442555286735
train 1, step: 500, loss: 1.7463975045724514, grad_norm: 0.6480429162783147, ic: 0.1444486534967968
train 1, step: 1000, loss: 0.8754151460244386, grad_norm: 0.14931291693892076, ic: 0.06054204785513011
train 1, step: 1500, loss: 1.707994623293822, grad_norm: 0.178389460114162, ic: -0.0035408983602292013
train 1, step: 2000, loss: 2.1697158203125, grad_norm: 0.828536904707793, ic: -0.007294928584121584
Epoch 1: 2022-04-25 13:43:25.006017: train loss: 1.6467908903097008
Eval step 0: eval loss: 0.8362617774054926
Eval: 2022-04-25 13:43:56.443378: total loss: 1.07929828185228, mse:4.823162488091652, ic :0.011079452038805582, sharpe5:7.48252920538187, irr5:210.6926727294922, ndcg5:0.8613476783317536, pnl5:2.9230947494506836 
train 2, step: 0, loss: 2.1404783380681818, grad_norm: 0.00648140446104828, ic: 0.08372439234547221
train 2, step: 500, loss: 3.289661580594679, grad_norm: 0.25467519984625503, ic: 0.015926155828248578
train 2, step: 1000, loss: 2.0740818067528735, grad_norm: 1.4625716872059676e-05, ic: 0.23797734382106636
train 2, step: 1500, loss: 1.4810239369632634, grad_norm: 0.0516783222518892, ic: -0.05960442973505489
train 2, step: 2000, loss: 3.215578425480769, grad_norm: 0.7281345555598215, ic: 0.13350609707001126
Epoch 2: 2022-04-25 13:51:58.670678: train loss: 1.646631189320994
Eval step 0: eval loss: 0.8366202705150158
Eval: 2022-04-25 13:52:29.722638: total loss: 1.0794083775693417, mse:4.82290909265387, ic :0.017604918238647734, sharpe5:9.476070955395699, irr5:269.4620361328125, ndcg5:0.8563036081806978, pnl5:2.052927255630493 
train 3, step: 0, loss: 1.5227987646087398, grad_norm: 0.49178286413316535, ic: 0.0023489791960807724
train 3, step: 500, loss: 1.4943705224953505, grad_norm: 0.32427320639506324, ic: 0.05752997141872404
train 3, step: 1000, loss: 3.686045557174727, grad_norm: 0.6791471049786292, ic: -0.030700895355010374
train 3, step: 1500, loss: 1.958288714070172, grad_norm: 0.9445717460389953, ic: 0.012716894977201113
train 3, step: 2000, loss: 0.8995307221283784, grad_norm: 0.00039506355787232654, ic: -0.009489659735573584
Epoch 3: 2022-04-25 14:00:13.901140: train loss: 1.647075749470721
Eval step 0: eval loss: 0.8361220847191122
Eval: 2022-04-25 14:00:44.599923: total loss: 1.0791568409729442, mse:4.817042712155852, ic :0.05418961183708563, sharpe5:9.68029726266861, irr5:299.0033264160156, ndcg5:0.851243739384854, pnl5:2.819608449935913 
train 4, step: 0, loss: 1.4372039421237246, grad_norm: 0.0432892022797835, ic: 0.10101974305671865
train 4, step: 500, loss: 1.6474155696358268, grad_norm: 0.5507927963314121, ic: -0.079797284156049
train 4, step: 1000, loss: 2.9557688643292686, grad_norm: 0.6841673193748272, ic: 0.003663641824404349
train 4, step: 1500, loss: 2.1489805841244727, grad_norm: 0.4793575347243277, ic: -0.05218874801719449
train 4, step: 2000, loss: 1.0817197144124222, grad_norm: 0.38468589168388356, ic: 0.1928803432345505
Epoch 4: 2022-04-25 14:08:35.873476: train loss: 1.6469914651911375
Eval step 0: eval loss: 0.8446006332735115
Eval: 2022-04-25 14:09:08.122895: total loss: 1.082692645230268, mse:4.743973904796892, ic :0.1253013756217743, sharpe5:11.025695917010307, irr5:389.95086669921875, ndcg5:0.8517132921384959, pnl5:3.331390142440796 
train 5, step: 0, loss: 1.3190269931050755, grad_norm: 0.14310407313753146, ic: 0.33980100570517524
train 5, step: 500, loss: 0.8892280161144429, grad_norm: 0.009810914716727848, ic: 0.7677250438372885
train 5, step: 1000, loss: 0.9896675197557472, grad_norm: 0.15276456159048488, ic: -0.053550594686709974
train 5, step: 1500, loss: 1.5303279298370502, grad_norm: 0.14751526962700126, ic: 0.015336657094986855
train 5, step: 2000, loss: 1.1061254797844764, grad_norm: 0.02862184547519509, ic: 0.15663939251149994
Epoch 5: 2022-04-25 14:17:04.879810: train loss: 1.6408105754653148
Eval step 0: eval loss: 0.837942977599776
Eval: 2022-04-25 14:17:35.953754: total loss: 1.0785651424263134, mse:4.720195163358763, ic :0.13096686786717945, sharpe5:11.575837798118592, irr5:402.93170166015625, ndcg5:0.863164580710192, pnl5:3.3083157539367676 
train 6, step: 0, loss: 1.3522079930160984, grad_norm: 0.4683199024675092, ic: 0.07745672124893732
train 6, step: 500, loss: 1.0088522474397015, grad_norm: 0.04041364288204699, ic: 0.04603631940071948
train 6, step: 1000, loss: 1.0964609820579847, grad_norm: 0.08566739376575491, ic: 0.7879894073827475
train 6, step: 1500, loss: 1.5804066051136363, grad_norm: 0.686671433251089, ic: 0.010023612797391673
train 6, step: 2000, loss: 0.7929156313331915, grad_norm: 0.06480670546432538, ic: 0.35770901347672884
Epoch 6: 2022-04-25 14:25:34.370867: train loss: 1.6375184631172766
Eval step 0: eval loss: 0.8308403248279438
Eval: 2022-04-25 14:26:06.399949: total loss: 1.0718245330505842, mse:4.619928045979453, ic :0.1503169589620957, sharpe5:12.67556913971901, irr5:428.4739074707031, ndcg5:0.842771567062428, pnl5:2.901461362838745 
train 7, step: 0, loss: 0.9961261749267578, grad_norm: 0.04560178565639541, ic: 0.0475109212010285
train 7, step: 500, loss: 0.6541653433106953, grad_norm: 0.029810040458712078, ic: -0.07097732577383638
train 7, step: 1000, loss: 1.0154533763923268, grad_norm: 0.643712344453591, ic: 0.2078511108453888
train 7, step: 1500, loss: 2.248765951567524, grad_norm: 0.6939114530260528, ic: 0.42348864667424974
train 7, step: 2000, loss: 0.9056664684092286, grad_norm: 0.035223386629468, ic: 0.03977762651466582
Epoch 7: 2022-04-25 14:34:06.741408: train loss: 1.6332409528412268
Eval step 0: eval loss: 0.8338955556630334
Eval: 2022-04-25 14:34:36.844289: total loss: 1.0724617480866627, mse:4.615415082260082, ic :0.16007640403313428, sharpe5:15.150519443750381, irr5:496.0926208496094, ndcg5:0.8541289182459841, pnl5:4.943648338317871 
train 8, step: 0, loss: 3.588434810914855, grad_norm: 1.4836650752031137, ic: 0.19218704952699445
train 8, step: 500, loss: 2.7511624507266337, grad_norm: 0.8624469698239899, ic: -0.006848870118487706
train 8, step: 1000, loss: 3.0676856884057973, grad_norm: 0.8674698058374799, ic: 0.1055612281954034
train 8, step: 1500, loss: 0.6977734736243835, grad_norm: 0.05215466330394991, ic: 0.5932854875784881
train 8, step: 2000, loss: 1.0428400157994726, grad_norm: 0.3981318849870942, ic: 0.6636289220821859
Epoch 8: 2022-04-25 14:42:34.471930: train loss: 1.6271489050757995
Eval step 0: eval loss: 0.8279456891300052
Eval: 2022-04-25 14:43:04.103505: total loss: 1.0698909725644665, mse:4.608573775255748, ic :0.16648211524272988, sharpe5:15.884270235300063, irr5:522.3670654296875, ndcg5:0.8396878155232566, pnl5:5.370716094970703 
train 9, step: 0, loss: 5.426057709080941, grad_norm: 0.7646695176590972, ic: 0.02059095254832824
train 9, step: 500, loss: 1.3293063202217192, grad_norm: 0.9439586615042478, ic: 0.3262836212134294
train 9, step: 1000, loss: 0.93326221585078, grad_norm: 0.010968928317739393, ic: 0.05892843337578579
train 9, step: 1500, loss: 1.0761262109950294, grad_norm: 0.009144591560112384, ic: 0.4922551783215792
train 9, step: 2000, loss: 1.0639468509656018, grad_norm: 0.38159922438793487, ic: 0.29724772259520954
Epoch 9: 2022-04-25 14:51:01.882303: train loss: 1.626572788226883
Eval step 0: eval loss: 0.8304559769946983
Eval: 2022-04-25 14:51:29.673380: total loss: 1.0722483250230557, mse:4.603857131374436, ic :0.1738204220174427, sharpe5:17.700144907236098, irr5:577.0421142578125, ndcg5:0.8518109295505146, pnl5:4.199867248535156 
train 10, step: 0, loss: 7.122058924016035, grad_norm: 4.311521662920944, ic: 0.2697580702653707
train 10, step: 500, loss: 1.125500641587765, grad_norm: 0.27130108341440184, ic: 0.07670517286826142
train 10, step: 1000, loss: 2.3934196987035086, grad_norm: 0.6638969004800596, ic: 0.1651473864613601
train 10, step: 1500, loss: 1.1115315424931516, grad_norm: 0.2826144810005451, ic: 0.02909584109566685
train 10, step: 2000, loss: 2.7080028035358095, grad_norm: 0.24816804139628246, ic: 0.5354664019606108
Epoch 10: 2022-04-25 14:59:31.749114: train loss: 1.6260512001688394
Eval step 0: eval loss: 0.8241880073185589
Eval: 2022-04-25 15:00:01.719666: total loss: 1.0670782457950345, mse:4.601276539449704, ic :0.18507031743433697, sharpe5:17.26820117354393, irr5:570.1309814453125, ndcg5:0.8545778437430351, pnl5:6.318475246429443 
train 11, step: 0, loss: 1.2561569508894046, grad_norm: 0.051884288932591276, ic: 0.19367099646413877
train 11, step: 500, loss: 0.6450390574172666, grad_norm: 0.030068377063461403, ic: 0.645118053343448
train 11, step: 1000, loss: 0.9393167645107687, grad_norm: 0.12308141859158037, ic: 0.0440502706165304
train 11, step: 1500, loss: 1.0565429152103891, grad_norm: 0.04818340945139665, ic: 0.1856435103784433
train 11, step: 2000, loss: 0.7918798558143266, grad_norm: 0.0002854592847957387, ic: 0.06974271558175368
Epoch 11: 2022-04-25 15:08:00.888532: train loss: 1.625063206731221
Eval step 0: eval loss: 0.8329781631775224
Eval: 2022-04-25 15:08:30.949882: total loss: 1.0686309930945155, mse:4.594313046901979, ic :0.1793537902761428, sharpe5:15.319825011491774, irr5:506.46533203125, ndcg5:0.844843022571065, pnl5:4.756789207458496 
train 12, step: 0, loss: 0.961122194925944, grad_norm: 0.07196611077196488, ic: 0.40032720289455637
train 12, step: 500, loss: 0.9356618470388002, grad_norm: 0.13474773832382336, ic: 0.18259919227097887
train 12, step: 1000, loss: 2.9844185410031847, grad_norm: 0.2661817101413863, ic: 0.2892832601202394
train 12, step: 1500, loss: 0.944075248119764, grad_norm: 0.10493046437247117, ic: -0.11043353681631254
train 12, step: 2000, loss: 0.8756748902473565, grad_norm: 0.0027311037373275076, ic: 0.15224287995903624
Epoch 12: 2022-04-25 15:16:14.908661: train loss: 1.6258092165281106
Eval step 0: eval loss: 0.8317845367656743
Eval: 2022-04-25 15:16:45.401626: total loss: 1.0683063184121684, mse:4.593764433595189, ic :0.18435837561217114, sharpe5:17.353867989778518, irr5:555.2666015625, ndcg5:0.8444986295239565, pnl5:7.52377462387085 
train 13, step: 0, loss: 2.053990397307286, grad_norm: 0.6908880952589939, ic: 0.4455500741552141
train 13, step: 500, loss: 0.8155858975315484, grad_norm: 0.058816609850673204, ic: 0.5883803627544821
train 13, step: 1000, loss: 0.9360047615614513, grad_norm: 0.3775944354723843, ic: 0.5962229219285936
train 13, step: 1500, loss: 2.36219071709114, grad_norm: 0.16782547403419723, ic: -0.09766818775711614
train 13, step: 2000, loss: 1.4621337702679946, grad_norm: 0.06440244074297713, ic: 0.1849702353915778
Epoch 13: 2022-04-25 15:24:53.324590: train loss: 1.623745104985968
Eval step 0: eval loss: 0.8282092529554136
Eval: 2022-04-25 15:25:25.806782: total loss: 1.0676949437825174, mse:4.6057593257857485, ic :0.18142026636913744, sharpe5:17.639270803928376, irr5:567.8319702148438, ndcg5:0.8358176859288916, pnl5:5.149783134460449 
train 14, step: 0, loss: 4.5444297850039, grad_norm: 1.2995584949734826, ic: 0.16279642927518667
train 14, step: 500, loss: 0.8275272474376434, grad_norm: 0.0015903850388681187, ic: 0.0764647446102901
train 14, step: 1000, loss: 1.813499919917426, grad_norm: 0.3038396904829309, ic: 0.4573857038536922
train 14, step: 1500, loss: 1.1253534673334478, grad_norm: 0.06234209397161474, ic: -0.016390630067596355
train 14, step: 2000, loss: 1.1399057481239123, grad_norm: 0.16461325193438855, ic: 0.10934117541087195
Epoch 14: 2022-04-25 15:33:45.325310: train loss: 1.6244809526630821
Eval step 0: eval loss: 0.836715842951462
Eval: 2022-04-25 15:34:17.785719: total loss: 1.0695985908747543, mse:4.5981471157702005, ic :0.186194582169751, sharpe5:17.40056834220886, irr5:581.8982543945312, ndcg5:0.8508685581177736, pnl5:5.600396633148193 
train 15, step: 0, loss: 3.3356243920233464, grad_norm: 0.6429541693477603, ic: 0.0906311590543729
train 15, step: 500, loss: 1.2558394865700333, grad_norm: 0.022235845413901577, ic: 0.06641151490394309
train 15, step: 1000, loss: 1.315305235327744, grad_norm: 0.12247329268755333, ic: 0.0961522588000297
train 15, step: 1500, loss: 0.8504315714197834, grad_norm: 0.16137538899458398, ic: 0.0613172874031815
train 15, step: 2000, loss: 1.4578912461629427, grad_norm: 0.5288230879174795, ic: 0.054065549746341736
Epoch 15: 2022-04-25 15:44:01.275573: train loss: 1.624249747203413
Eval step 0: eval loss: 0.8398809242047549
Eval: 2022-04-25 15:44:37.793192: total loss: 1.0730146497161244, mse:4.595882674138281, ic :0.18673431410626562, sharpe5:17.594816079139708, irr5:577.1921997070312, ndcg5:0.8429528358178817, pnl5:6.467569828033447 
train 16, step: 0, loss: 0.6931035879200069, grad_norm: 0.30760994397454117, ic: 0.009706114543718553
train 16, step: 500, loss: 1.5834097592145315, grad_norm: 0.3206471088308501, ic: 0.16806658404402192
train 16, step: 1000, loss: 0.8750371759588068, grad_norm: 0.0038342581879849767, ic: -0.051471280553042495
train 16, step: 1500, loss: 0.8547834632338456, grad_norm: 0.2061317033232011, ic: 0.08033868423620383
train 16, step: 2000, loss: 3.3631098878767545, grad_norm: 0.9008493098090457, ic: 0.021037544768347644
Epoch 16: 2022-04-25 15:56:01.807227: train loss: 1.6242783226257207
Eval step 0: eval loss: 0.830597599138073
Eval: 2022-04-25 15:56:31.835701: total loss: 1.0680959836776025, mse:4.5931358908842395, ic :0.1825993930779729, sharpe5:16.579868059158326, irr5:550.2091064453125, ndcg5:0.8559277404228157, pnl5:4.826833724975586 
train 17, step: 0, loss: 1.2791180112317637, grad_norm: 0.24033997406492, ic: -0.07656892962024725
train 17, step: 500, loss: 1.7697165057588076, grad_norm: 0.4250238775648183, ic: 0.16578181915042225
train 17, step: 1000, loss: 1.285037933705594, grad_norm: 0.08312289534181047, ic: 0.15381068806994047
train 17, step: 1500, loss: 4.554080108261388, grad_norm: 0.9715635679965857, ic: 0.21036469041457
train 17, step: 2000, loss: 1.2562633626690534, grad_norm: 0.5627978793948282, ic: 0.09050037905139012
Epoch 17: 2022-04-25 16:04:23.690029: train loss: 1.623301191637831
Eval step 0: eval loss: 0.8368873073630136
Eval: 2022-04-25 16:04:54.054579: total loss: 1.0695358321677286, mse:4.586591857681557, ic :0.18899252777225684, sharpe5:18.405001451969145, irr5:598.4813842773438, ndcg5:0.8418094804981392, pnl5:7.362844467163086 
train 18, step: 0, loss: 1.415523502040716, grad_norm: 0.5400040370560548, ic: 0.1751053176511665
train 18, step: 500, loss: 1.4719148625088276, grad_norm: 0.6352000123594889, ic: 0.030313764204366402
train 18, step: 1000, loss: 0.6554028654751712, grad_norm: 0.022687026547520927, ic: 0.5751090935868558
train 18, step: 1500, loss: 1.4347974572583948, grad_norm: 0.030661027486740385, ic: 0.14086092253755425
train 18, step: 2000, loss: 0.9122325143996318, grad_norm: 0.007609452805057574, ic: -0.014396626188967627
Epoch 18: 2022-04-25 16:12:49.469155: train loss: 1.623658334456124
Eval step 0: eval loss: 0.8280989523305782
Eval: 2022-04-25 16:13:20.467439: total loss: 1.066193763130389, mse:4.593707239625402, ic :0.18928615659719528, sharpe5:17.7107127892971, irr5:583.9683227539062, ndcg5:0.8453173001273014, pnl5:9.598779678344727 
train 19, step: 0, loss: 1.4663613940042162, grad_norm: 0.677851043963402, ic: 0.05032636178125719
train 19, step: 500, loss: 0.8715146382649739, grad_norm: 0.05163160044276529, ic: 0.2260597282187385
train 19, step: 1000, loss: 0.958127009479404, grad_norm: 0.004045779124710202, ic: 0.1956029228769022
train 19, step: 1500, loss: 3.9642333126537244, grad_norm: 0.7687505709322553, ic: 0.16191463899556405
train 19, step: 2000, loss: 1.0098379281850962, grad_norm: 0.08777768788735628, ic: 0.22632760102645322
Epoch 19: 2022-04-25 16:21:06.022315: train loss: 1.6244735878439687
Eval step 0: eval loss: 0.8337888566912539
Eval: 2022-04-25 16:21:36.383781: total loss: 1.0679069276757547, mse:4.590598598840601, ic :0.18648812677014348, sharpe5:17.171391352415085, irr5:578.2318725585938, ndcg5:0.8395513599517985, pnl5:5.804999828338623 
train 20, step: 0, loss: 2.3198836616847824, grad_norm: 0.7628596352837741, ic: 0.04227122329960997
train 20, step: 500, loss: 3.199785511363636, grad_norm: 0.4174278315813442, ic: 0.10836024318727915
train 20, step: 1000, loss: 0.9711335182189942, grad_norm: 0.0777718891292641, ic: 0.21135781916293034
train 20, step: 1500, loss: 1.9050259319965543, grad_norm: 1.0210101208835016, ic: 0.22937386827393383
train 20, step: 2000, loss: 1.0457570510042822, grad_norm: 0.055437357944442094, ic: -0.027511391182764387
Epoch 20: 2022-04-25 16:29:24.827807: train loss: 1.6231454713339148
Eval step 0: eval loss: 0.8360542964633825
Eval: 2022-04-25 16:29:55.615984: total loss: 1.0688241240232714, mse:4.59298346779748, ic :0.18724825886969387, sharpe5:16.82135154247284, irr5:553.1784057617188, ndcg5:0.8555765534831484, pnl5:4.795742511749268 
train 21, step: 0, loss: 1.0106927448333811, grad_norm: 0.30786208120039715, ic: 0.05271441958289051
train 21, step: 500, loss: 0.7751722082627558, grad_norm: 0.015535901515131914, ic: 0.19677828479383502
train 21, step: 1000, loss: 0.9363531815378289, grad_norm: 0.4470405732382407, ic: 0.11797196847478666
train 21, step: 1500, loss: 1.0027338828518717, grad_norm: 0.21599870966414905, ic: 0.3107024059509782
train 21, step: 2000, loss: 0.939096579652028, grad_norm: 0.04857707670963722, ic: 0.08614096501578483
Epoch 21: 2022-04-25 16:37:52.790746: train loss: 1.6242568778383717
Eval step 0: eval loss: 0.829973484115681
Eval: 2022-04-25 16:38:24.559608: total loss: 1.0673270153754915, mse:4.606931703368823, ic :0.19122394797250244, sharpe5:17.82706165194511, irr5:606.9759521484375, ndcg5:0.8422635593408203, pnl5:8.389232635498047 
train 22, step: 0, loss: 1.0392514676024012, grad_norm: 0.026142495078405794, ic: 0.2217701045883306
train 22, step: 500, loss: 3.2718222021087398, grad_norm: 0.6428673877443798, ic: -0.2043561562745223
train 22, step: 1000, loss: 1.1926647737536127, grad_norm: 0.11050440017935739, ic: 0.461606172643155
train 22, step: 1500, loss: 0.971753331565072, grad_norm: 0.05498268418387341, ic: 0.14327503466978903
train 22, step: 2000, loss: 1.7662771488803855, grad_norm: 0.4887709573191333, ic: 0.20927165797466618
Epoch 22: 2022-04-25 16:46:23.260225: train loss: 1.6236200934896885
Eval step 0: eval loss: 0.8305277527948827
Eval: 2022-04-25 16:46:54.012448: total loss: 1.0676882274155142, mse:4.598167918458353, ic :0.18689605376302776, sharpe5:17.477250756025313, irr5:569.3299560546875, ndcg5:0.8413106728835642, pnl5:4.804494380950928 
train 23, step: 0, loss: 0.9952612093614914, grad_norm: 0.041868137843625496, ic: 0.13756167131059524
train 23, step: 500, loss: 1.4326353926486461, grad_norm: 0.08689858913435317, ic: 0.026407137321344993
train 23, step: 1000, loss: 1.6591070556640626, grad_norm: 0.09579205880321723, ic: 0.2598545663527364
train 23, step: 1500, loss: 1.1140135781909535, grad_norm: 0.1906089895475797, ic: 0.08972450260750725
train 23, step: 2000, loss: 1.9218069638904927, grad_norm: 0.8580592896702561, ic: 0.44162523828037004
Epoch 23: 2022-04-25 16:54:54.480987: train loss: 1.623641413927535
Eval step 0: eval loss: 0.8320004430033258
Eval: 2022-04-25 16:55:25.816553: total loss: 1.066655876269333, mse:4.588153507713493, ic :0.18828125674074023, sharpe5:16.81779675364494, irr5:558.3171997070312, ndcg5:0.8548215466332052, pnl5:8.025299072265625 
train 24, step: 0, loss: 2.2018266989552098, grad_norm: 0.02136709135768011, ic: 0.11935802658474635
train 24, step: 500, loss: 1.2280355134362841, grad_norm: 0.06789456587905685, ic: 0.24684734164113434
train 24, step: 1000, loss: 0.9067958957999241, grad_norm: 0.07492247431194675, ic: 0.5252530705571328
train 24, step: 1500, loss: 2.610918741627164, grad_norm: 0.846089372446148, ic: 0.059216273613602884
train 24, step: 2000, loss: 0.9299268652582517, grad_norm: 0.06482044013662272, ic: 0.13961087706264996
Epoch 24: 2022-04-25 17:03:25.441306: train loss: 1.6230101219714481
Eval step 0: eval loss: 0.8293979270943097
Eval: 2022-04-25 17:03:56.447361: total loss: 1.066269590470033, mse:4.59004906849762, ic :0.18856566133395483, sharpe5:17.194678151607512, irr5:570.4088745117188, ndcg5:0.8417747041756901, pnl5:6.41182279586792 
train 25, step: 0, loss: 0.848562292150549, grad_norm: 0.42576417623200064, ic: 0.6100646324643222
train 25, step: 500, loss: 0.8738023464053059, grad_norm: 0.004047996035038878, ic: 0.14734956865827029
train 25, step: 1000, loss: 2.1174087698733817, grad_norm: 0.07185585209721654, ic: 0.23587109410863044
train 25, step: 1500, loss: 1.1416493004165258, grad_norm: 0.5801655274659459, ic: 0.5264831503126013
train 25, step: 2000, loss: 0.9843687312955413, grad_norm: 0.4078249246972167, ic: 0.6074442214560833
Epoch 25: 2022-04-25 17:11:56.746352: train loss: 1.624108930910784
Eval step 0: eval loss: 0.8318065968906414
Eval: 2022-04-25 17:12:27.989047: total loss: 1.0673144509747052, mse:4.5878323222276824, ic :0.188191726068001, sharpe5:16.863471722602842, irr5:561.65234375, ndcg5:0.8415223531345356, pnl5:6.4729228019714355 
train 26, step: 0, loss: 6.694154977036741, grad_norm: 0.29053349954313923, ic: 0.11017161301216122
train 26, step: 500, loss: 3.862596740006841, grad_norm: 1.0613355715497792, ic: 0.36297673974584493
train 26, step: 1000, loss: 1.2458302544274922, grad_norm: 0.8432511690124076, ic: 0.008004612732521777
train 26, step: 1500, loss: 0.8362660218388467, grad_norm: 0.16358421807565313, ic: 0.29524354617985216
train 26, step: 2000, loss: 0.9544507738739182, grad_norm: 0.11421830789449702, ic: 0.1440276526832147
Epoch 26: 2022-04-25 17:20:22.585498: train loss: 1.6227385442117386
Eval step 0: eval loss: 0.831436076832521
Eval: 2022-04-25 17:20:53.764847: total loss: 1.066070809082661, mse:4.585553786789955, ic :0.18973227800925438, sharpe5:17.31351669073105, irr5:573.46826171875, ndcg5:0.8472092028188333, pnl5:4.6225266456604 
train 27, step: 0, loss: 0.8320841950061274, grad_norm: 0.08032874326475162, ic: 0.07022066286613199
train 27, step: 500, loss: 0.9178830779348377, grad_norm: 0.752152999481071, ic: 0.2932154024534586
train 27, step: 1000, loss: 0.7624020794059359, grad_norm: 0.1469923225520876, ic: 0.19340995900540464
train 27, step: 1500, loss: 0.637797724046178, grad_norm: 0.06337910029969646, ic: 0.5137487815343031
train 27, step: 2000, loss: 1.381083958422314, grad_norm: 0.010413044430257874, ic: 0.055025274278273036
Epoch 27: 2022-04-25 17:28:42.436996: train loss: 1.6224152538844134
Eval step 0: eval loss: 0.8333854072337658
Eval: 2022-04-25 17:29:12.923971: total loss: 1.0669685772224438, mse:4.6033711876449, ic :0.18698840274981296, sharpe5:17.27081760406494, irr5:567.9230346679688, ndcg5:0.84819018013024, pnl5:6.474362850189209 
train 28, step: 0, loss: 1.5313455824686293, grad_norm: 0.2197622665624263, ic: 0.21182257443268104
train 28, step: 500, loss: 1.3617960725702207, grad_norm: 0.8043904201038236, ic: 0.1949672684757667
train 28, step: 1000, loss: 0.9078835588160569, grad_norm: 0.358099955386653, ic: 0.5785649027708063
train 28, step: 1500, loss: 1.0340468992812744, grad_norm: 0.019477802318869225, ic: 0.055237854395970044
train 28, step: 2000, loss: 1.037223394663056, grad_norm: 0.07181062387661857, ic: 0.14613840131318104
Epoch 28: 2022-04-25 17:37:10.283408: train loss: 1.6214090516813895
Eval step 0: eval loss: 0.8276810962608666
Eval: 2022-04-25 17:37:42.006034: total loss: 1.0706545350281487, mse:4.641331900929936, ic :0.1796350773020072, sharpe5:17.536094902753828, irr5:579.1795043945312, ndcg5:0.8510163641320915, pnl5:5.802922248840332 
train 29, step: 0, loss: 0.9039567624917078, grad_norm: 0.018919148290721815, ic: 0.11923365068529039
train 29, step: 500, loss: 1.1046431446803435, grad_norm: 0.12327004552106886, ic: 0.6137334044522809
train 29, step: 1000, loss: 1.0666200369939562, grad_norm: 0.5102444507944606, ic: 0.11264775607930631
train 29, step: 1500, loss: 2.362770860777713, grad_norm: 0.335764375733791, ic: -0.14334508045114838
train 29, step: 2000, loss: 4.496221094955632, grad_norm: 2.1423685891957396, ic: 0.20586380979192254
Epoch 29: 2022-04-25 17:45:39.340054: train loss: 1.6213880773168783
Eval step 0: eval loss: 0.8351374828149697
Eval: 2022-04-25 17:46:10.803623: total loss: 1.067031349853056, mse:4.587677443776504, ic :0.18943056600880026, sharpe5:17.602258622646332, irr5:577.3966064453125, ndcg5:0.8492419742042516, pnl5:7.280510902404785 
train 30, step: 0, loss: 1.0058910994879944, grad_norm: 0.051607765017620266, ic: 0.5142121869978125
train 30, step: 500, loss: 1.4125964545734209, grad_norm: 1.462754294611675, ic: -0.0019902243428459605
train 30, step: 1000, loss: 0.9730994947028883, grad_norm: 0.02685015396200019, ic: -0.007330895795473663
train 30, step: 1500, loss: 1.5181789960079672, grad_norm: 0.7986569623825834, ic: 0.15048892101829747
train 30, step: 2000, loss: 1.8336042478600802, grad_norm: 0.1600534743885414, ic: 0.1063420129192861
Epoch 30: 2022-04-25 17:54:07.054873: train loss: 1.6219128192397794
Eval step 0: eval loss: 0.8315272758331137
Eval: 2022-04-25 17:54:37.860023: total loss: 1.067021183482518, mse:4.605700679571187, ic :0.18936417944286954, sharpe5:17.353633400201797, irr5:577.81689453125, ndcg5:0.8494822366908279, pnl5:4.526306629180908 
train 31, step: 0, loss: 1.0544480065113018, grad_norm: 0.09143711684838673, ic: 0.32848687993514825
train 31, step: 500, loss: 1.5064646026234567, grad_norm: 0.700906500908951, ic: 0.029458947858017375
train 31, step: 1000, loss: 4.34947253427498, grad_norm: 1.010932682667223, ic: 0.4572521973377637
train 31, step: 1500, loss: 0.7702381525153962, grad_norm: 0.3292079230481041, ic: 0.7130115431754218
train 31, step: 2000, loss: 1.2468428684223025, grad_norm: 0.5678271679191319, ic: 0.10739695115724915
Epoch 31: 2022-04-25 18:02:31.970502: train loss: 1.6203835480475506
Eval step 0: eval loss: 0.83713710772853
Eval: 2022-04-25 18:03:02.842054: total loss: 1.0697555940543466, mse:4.5946958874634545, ic :0.18409344824706714, sharpe5:15.773769085407256, irr5:519.1267700195312, ndcg5:0.8490599191905543, pnl5:5.294051647186279 
train 32, step: 0, loss: 1.1413637014078333, grad_norm: 0.016996455189170985, ic: 0.1428863555602099
train 32, step: 500, loss: 1.486455674058809, grad_norm: 0.4357733907970215, ic: 0.1374053908719066
train 32, step: 1000, loss: 1.0392456809139368, grad_norm: 0.07489191673072318, ic: 0.510015547379941
train 32, step: 1500, loss: 1.0045187431469298, grad_norm: 0.38703145033713016, ic: 0.059169486025934706
train 32, step: 2000, loss: 0.9518533150109886, grad_norm: 0.11018304157578648, ic: 0.5399264191738113
Epoch 32: 2022-04-25 18:10:50.178708: train loss: 1.6218224975753446
Eval step 0: eval loss: 0.8257606433993019
Eval: 2022-04-25 18:11:22.197745: total loss: 1.065433471211783, mse:4.5947388171539645, ic :0.18895025985351074, sharpe5:17.04669942498207, irr5:583.7904663085938, ndcg5:0.8567491349748442, pnl5:5.019561290740967 
train 33, step: 0, loss: 1.2607446482406408, grad_norm: 0.22097931441296192, ic: 0.2031871144179686
train 33, step: 500, loss: 0.9928386038364209, grad_norm: 0.01042166974244563, ic: 0.16856518053077263
train 33, step: 1000, loss: 1.052345660210678, grad_norm: 0.8664649633801118, ic: 0.17237948175539747
train 33, step: 1500, loss: 0.8952514358828219, grad_norm: 0.0694425252446847, ic: 0.5504396003174575
train 33, step: 2000, loss: 0.8214420856651149, grad_norm: 0.024464813022931593, ic: 0.22245811137545776
Epoch 33: 2022-04-25 18:19:18.004087: train loss: 1.6221914251328189
Eval step 0: eval loss: 0.8311412558038066
Eval: 2022-04-25 18:19:49.818370: total loss: 1.0663295442385379, mse:4.59044580664377, ic :0.18770255116582168, sharpe5:17.630695041418075, irr5:584.3204345703125, ndcg5:0.8516715231739288, pnl5:6.8269758224487305 
train 34, step: 0, loss: 1.014708667890137, grad_norm: 0.8276592370822871, ic: 0.6033428524267828
train 34, step: 500, loss: 0.8111185896287271, grad_norm: 0.3308899983439222, ic: 0.2593146302197301
train 34, step: 1000, loss: 3.275934784826229, grad_norm: 1.4319045875485124, ic: 0.2985514194194801
train 34, step: 1500, loss: 0.7979723233574195, grad_norm: 0.5872051964314983, ic: 0.685918234875598
train 34, step: 2000, loss: 6.817400210592564, grad_norm: 3.0461824061518046, ic: 0.4184572357731988
Epoch 34: 2022-04-25 18:27:50.637616: train loss: 1.6210869832430148
Eval step 0: eval loss: 0.825932365071786
Eval: 2022-04-25 18:28:18.579340: total loss: 1.0668411596384901, mse:4.605873625139789, ic :0.1883887280514595, sharpe5:17.980040541887284, irr5:588.4996337890625, ndcg5:0.855857857932918, pnl5:5.533142566680908 
train 35, step: 0, loss: 1.2146849149816175, grad_norm: 0.8357915225569255, ic: 0.5569102247527394
train 35, step: 500, loss: 1.1729218302841373, grad_norm: 0.4257415894122924, ic: 0.04481741092453703
train 35, step: 1000, loss: 1.9136295521082138, grad_norm: 3.048342513615363, ic: 0.08719351747963278
train 35, step: 1500, loss: 1.635457295582707, grad_norm: 0.7458821045015873, ic: 0.037569272500854504
train 35, step: 2000, loss: 0.7795268176073696, grad_norm: 0.0558518139659889, ic: 0.5640651335627778
Epoch 35: 2022-04-25 18:36:16.126672: train loss: 1.6224492159182182
Eval step 0: eval loss: 0.8329644640328635
Eval: 2022-04-25 18:36:45.112775: total loss: 1.066311520695662, mse:4.58017586198266, ic :0.19363686316745032, sharpe5:17.297797297239303, irr5:595.1359252929688, ndcg5:0.8594742624568305, pnl5:9.304747581481934 
train 36, step: 0, loss: 1.8355082417582418, grad_norm: 0.8437308215087449, ic: 0.11885062401045982
train 36, step: 500, loss: 0.8410371340006896, grad_norm: 0.030650782393386353, ic: 0.15816646440307175
train 36, step: 1000, loss: 1.6301441761363635, grad_norm: 1.3181401532671668, ic: 0.23756413084801137
train 36, step: 1500, loss: 0.7632657671377517, grad_norm: 0.05105563031271986, ic: 0.39019611303757806
train 36, step: 2000, loss: 1.124520832816223, grad_norm: 0.7584691574664009, ic: 0.7786533948835878
Epoch 36: 2022-04-25 18:44:37.310339: train loss: 1.6215436604321118
Eval step 0: eval loss: 0.8301953073547813
Eval: 2022-04-25 18:45:05.543825: total loss: 1.0658787431012238, mse:4.5909359538647605, ic :0.18947555413793424, sharpe5:17.543208264112472, irr5:585.1459350585938, ndcg5:0.8436189456081008, pnl5:5.485762596130371 
train 37, step: 0, loss: 2.0428771505312024, grad_norm: 1.1813169569115574, ic: 0.17458296844550752
train 37, step: 500, loss: 2.330951933370718, grad_norm: 0.7124656003332164, ic: -0.028059248578639617
train 37, step: 1000, loss: 1.065247975527968, grad_norm: 0.0705342859000986, ic: 0.1108499717101935
train 37, step: 1500, loss: 2.0233922745781006, grad_norm: 0.850686519278665, ic: 0.6108178282014662
train 37, step: 2000, loss: 1.3198753179505813, grad_norm: 0.21564680279628404, ic: 0.1374236115584952
Epoch 37: 2022-04-25 18:53:03.457767: train loss: 1.6211260439780375
Eval step 0: eval loss: 0.8298297395696127
Eval: 2022-04-25 18:53:33.492549: total loss: 1.0672853908604596, mse:4.597580033204579, ic :0.18833862753209069, sharpe5:17.41656772971153, irr5:601.5692749023438, ndcg5:0.8443944606433487, pnl5:8.331175804138184 
train 38, step: 0, loss: 1.34242937041492, grad_norm: 0.34820522007461874, ic: -0.06867064109791958
train 38, step: 500, loss: 0.8984159493152006, grad_norm: 0.11844668161414428, ic: 0.2643683573855877
train 38, step: 1000, loss: 0.9052634016798419, grad_norm: 0.12240151766905236, ic: 0.04807258060942393
train 38, step: 1500, loss: 0.9526687888548786, grad_norm: 0.014960595859024827, ic: 0.21474174296340984
train 38, step: 2000, loss: 2.3344114366975077, grad_norm: 2.0425990774665665, ic: 0.06553821221223848
Epoch 38: 2022-04-25 19:01:37.546784: train loss: 1.6208877114474245
Eval step 0: eval loss: 0.8309750652413724
Eval: 2022-04-25 19:02:08.194665: total loss: 1.0676733232473132, mse:4.5962100185385495, ic :0.19110869059902436, sharpe5:17.27342646718025, irr5:586.9152221679688, ndcg5:0.858310637999953, pnl5:4.561001300811768 
train 39, step: 0, loss: 0.9739473208739488, grad_norm: 0.0024991209663184875, ic: 0.053577028118308556
train 39, step: 500, loss: 0.8962635037351077, grad_norm: 0.06358506814811075, ic: 0.23629623723174992
train 39, step: 1000, loss: 0.9406229732423362, grad_norm: 0.03141575313832254, ic: 0.19185797467057736
train 39, step: 1500, loss: 2.0869804176777933, grad_norm: 0.42587924535094474, ic: 0.1908623875697438
train 39, step: 2000, loss: 0.6212198218274833, grad_norm: 0.042923177581630584, ic: 0.09787502378813873
Epoch 39: 2022-04-25 19:09:56.955339: train loss: 1.6212983949540833
Eval step 0: eval loss: 0.832756339938422
Eval: 2022-04-25 19:10:27.592008: total loss: 1.066897498469872, mse:4.6013067263489145, ic :0.18712371920071277, sharpe5:17.247428644895553, irr5:570.728515625, ndcg5:0.8445630343430406, pnl5:6.268817901611328 

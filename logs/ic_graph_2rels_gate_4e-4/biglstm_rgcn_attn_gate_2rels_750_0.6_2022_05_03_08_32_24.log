Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='RGCNSeqTimeDataset', dout=0.3, epochs=60, glstm_layers=1, gnn_layers=1, gpu=0, graph_attn=True, hidden_dim=128, inner_prod=False, input_dim=9, input_graph=True, label_cnt=3, lr=0.0004, lstm_layers=1, market=None, mask_adj=True, mask_type='soft', model_type='BiGLSTM', normalize_adj=True, num_days=8, num_heads=1, print_inteval=500, rank_loss=False, relation_num=2, rsr_data_path=None, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_750_0.6/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
load 2305 train graphs successful!
load 126 test graphs successful!
58978
BiGLSTM(
  (input_to_hidden): Linear(in_features=9, out_features=128, bias=True)
  (forward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (attention): ModuleList(
            (0): GraphAttentionLayer (128 -> 128)
            (1): GraphAttentionLayer (128 -> 128)
          )
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
            (1): Linear(in_features=128, out_features=128, bias=False)
          )
          (lin_gate): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (backward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (attention): ModuleList(
            (0): GraphAttentionLayer (128 -> 128)
            (1): GraphAttentionLayer (128 -> 128)
          )
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
            (1): Linear(in_features=128, out_features=128, bias=False)
          )
          (lin_gate): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (fc0): ModuleList(
    (0): Linear(in_features=256, out_features=128, bias=True)
  )
  (w_out): Linear(in_features=128, out_features=1, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
)
train 0, step: 0, loss: 4.795774744673573, grad_norm: 4.817218221298496, ic: 0.02270863337888009
train 0, step: 500, loss: 0.8631226597824039, grad_norm: 0.026549237281156386, ic: 0.045193131822234334
train 0, step: 1000, loss: 1.9500711883344002, grad_norm: 0.5127995481333927, ic: 0.015527021288626517
train 0, step: 1500, loss: 0.9563922384510869, grad_norm: 0.04906209016929995, ic: 0.015414801976631753
train 0, step: 2000, loss: 1.0022219609150018, grad_norm: 0.1581866340081763, ic: 0.02557371458901702
Epoch 0: 2022-05-03 20:40:14.375926: train loss: 1.6484909492282218
Eval step 0: eval loss: 0.8363104640369796
Eval: 2022-05-03 20:40:38.638726: total loss: 1.0793434821112164, mse:4.822846111618704, ic :0.008499435321772098, sharpe5:7.9187035918235775, irr5:224.28302001953125, ndcg5:0.8429830260684602, pnl5:2.6084134578704834 
train 1, step: 0, loss: 2.7747594033518146, grad_norm: 0.8787000167262742, ic: 0.05709070526980353
train 1, step: 500, loss: 1.7554849440980964, grad_norm: 0.7706102503642542, ic: 0.09701601079338087
train 1, step: 1000, loss: 0.8777501251454682, grad_norm: 0.17538870840543627, ic: 0.08005678742106653
train 1, step: 1500, loss: 1.713238314924569, grad_norm: 0.20665445133803018, ic: -0.03189760177853898
train 1, step: 2000, loss: 2.1773017578125002, grad_norm: 0.887636219154873, ic: -0.04560806866399808
Epoch 1: 2022-05-03 20:46:51.429247: train loss: 1.6467364168765375
Eval step 0: eval loss: 0.8346051456302687
Eval: 2022-05-03 20:47:15.806063: total loss: 1.0789700140367233, mse:4.823394968547264, ic :0.008559413014173735, sharpe5:7.641909174621105, irr5:214.98397827148438, ndcg5:0.8564932482409259, pnl5:2.532038927078247 
train 2, step: 0, loss: 2.141761008522727, grad_norm: 0.009287884595479638, ic: 0.1322735036586654
train 2, step: 500, loss: 3.300041950924296, grad_norm: 0.28492133621526355, ic: 0.04844935306768088
train 2, step: 1000, loss: 2.0723217492816093, grad_norm: 0.00020626629044093216, ic: 0.19046955708708976
train 2, step: 1500, loss: 1.485540631709208, grad_norm: 0.05974259644604477, ic: -0.03793666250107901
train 2, step: 2000, loss: 3.235121319110577, grad_norm: 0.787591430556288, ic: 0.20603064062331494
Epoch 2: 2022-05-03 20:53:27.144472: train loss: 1.646494238949449
Eval step 0: eval loss: 0.8358989108601158
Eval: 2022-05-03 20:53:51.757899: total loss: 1.0793841821216015, mse:4.822524748652724, ic :0.012913322334197064, sharpe5:7.509958686232567, irr5:212.90841674804688, ndcg5:0.8537492194944719, pnl5:2.8993852138519287 
train 3, step: 0, loss: 1.5227561888655996, grad_norm: 0.5247968491481284, ic: -0.000703975431939988
train 3, step: 500, loss: 1.5014640790182068, grad_norm: 0.3425052691421103, ic: 0.09558204321844471
train 3, step: 1000, loss: 3.679412578259931, grad_norm: 0.7057805835500112, ic: -0.049633078376916655
train 3, step: 1500, loss: 1.9806981063318332, grad_norm: 1.2396081153385938, ic: -0.06385603713046019
train 3, step: 2000, loss: 0.8988506915118243, grad_norm: 0.0010493637958676671, ic: 0.009344314560815498
Epoch 3: 2022-05-03 21:00:03.994425: train loss: 1.6459040610333857
Eval step 0: eval loss: 0.835219806313389
Eval: 2022-05-03 21:00:28.423680: total loss: 1.0788635044054415, mse:4.821990846821499, ic :0.022549059547800458, sharpe5:7.802827219069004, irr5:224.66995239257812, ndcg5:0.851395311877341, pnl5:2.7793047428131104 
train 4, step: 0, loss: 1.4319094786352042, grad_norm: 0.043712820050291076, ic: 0.11851434244930834
train 4, step: 500, loss: 1.6488988681102361, grad_norm: 0.5609975581844475, ic: 0.039996157030571106
train 4, step: 1000, loss: 2.9629029064643673, grad_norm: 0.7738409979791676, ic: 0.06211648801420006
train 4, step: 1500, loss: 2.1479704394119197, grad_norm: 0.48159211153420595, ic: 0.017005660544865166
train 4, step: 2000, loss: 1.0816075160381027, grad_norm: 0.3950114768203655, ic: 0.24409386627055552
Epoch 4: 2022-05-03 21:06:32.278177: train loss: 1.64523966264527
Eval step 0: eval loss: 0.8550381595141266
Eval: 2022-05-03 21:06:56.857553: total loss: 1.0863241672456543, mse:4.826987795805839, ic :0.05510090980224427, sharpe5:9.92795858681202, irr5:296.05096435546875, ndcg5:0.8552665980526035, pnl5:2.868565082550049 
train 5, step: 0, loss: 1.3675754214293203, grad_norm: 0.21046139412520165, ic: 0.015467282728439273
train 5, step: 500, loss: 0.88935686273295, grad_norm: 0.009711829231008584, ic: 0.04574963843832007
train 5, step: 1000, loss: 0.9823511584051724, grad_norm: 0.1520716023961246, ic: 0.0014347083884147342
train 5, step: 1500, loss: 1.5301797817165965, grad_norm: 0.15322461358816844, ic: 0.026934755395125097
train 5, step: 2000, loss: 1.107048441805032, grad_norm: 0.028203311917840704, ic: 0.11594256708039628
Epoch 5: 2022-05-03 21:13:06.894274: train loss: 1.6447712292162082
Eval step 0: eval loss: 0.8400785006009615
Eval: 2022-05-03 21:13:31.522034: total loss: 1.0790541229283923, mse:4.8108809964905, ic :0.05738556360161671, sharpe5:10.932368048429488, irr5:340.5028381347656, ndcg5:0.8648656242069773, pnl5:2.991908073425293 
train 6, step: 0, loss: 1.3349929639217006, grad_norm: 0.4252233155339563, ic: 0.1052226579018197
train 6, step: 500, loss: 1.0069935259738707, grad_norm: 0.043394399568126005, ic: 0.047256643211812985
train 6, step: 1000, loss: 1.113099861870247, grad_norm: 0.08571116039913165, ic: 0.7420082599623415
train 6, step: 1500, loss: 1.6074680801265495, grad_norm: 1.5540160383275592, ic: 0.006667241044861301
train 6, step: 2000, loss: 0.8150106999662229, grad_norm: 0.12412280415030454, ic: 0.34246068439092237
Epoch 6: 2022-05-03 21:19:41.940226: train loss: 1.6435309098146254
Eval step 0: eval loss: 0.8624973759384879
Eval: 2022-05-03 21:20:06.387967: total loss: 1.1043346523866597, mse:4.948031788195157, ic :0.07645379594673832, sharpe5:12.183593176603317, irr5:393.6826171875, ndcg5:0.8526301598696293, pnl5:3.808725357055664 
train 7, step: 0, loss: 0.9960538864135743, grad_norm: 0.06252830297714135, ic: 0.026305704457504887
train 7, step: 500, loss: 0.6496110817581687, grad_norm: 0.0020933404554332085, ic: 0.05456829919523431
train 7, step: 1000, loss: 1.0345031319913842, grad_norm: 0.37027952624907845, ic: 0.05672463505352109
train 7, step: 1500, loss: 2.2631480062633975, grad_norm: 0.8059885725352064, ic: 0.4429087772837067
train 7, step: 2000, loss: 0.9196485479351778, grad_norm: 0.1011373036011288, ic: -0.041701232321014824
Epoch 7: 2022-05-03 21:26:15.312942: train loss: 1.6345413086896616
Eval step 0: eval loss: 0.830276859070403
Eval: 2022-05-03 21:26:39.692388: total loss: 1.0727954187394375, mse:4.689822984779246, ic :0.16311805213100988, sharpe5:16.186154859066008, irr5:529.3336181640625, ndcg5:0.8544266622604816, pnl5:9.278794288635254 
train 8, step: 0, loss: 3.581017181838768, grad_norm: 1.228897905543834, ic: 0.16183290483947815
train 8, step: 500, loss: 2.7640147107712765, grad_norm: 0.9420272065500885, ic: 0.037554161031905425
train 8, step: 1000, loss: 3.0574024145153986, grad_norm: 0.9627349742009119, ic: 0.10561607446108691
train 8, step: 1500, loss: 0.7197733736802558, grad_norm: 0.059412725016828996, ic: 0.4141062534569189
train 8, step: 2000, loss: 1.0939176573646867, grad_norm: 0.46481767724349937, ic: 0.514773574105591
Epoch 8: 2022-05-03 21:32:51.360629: train loss: 1.6284092858115855
Eval step 0: eval loss: 0.8232946687302423
Eval: 2022-05-03 21:33:15.621005: total loss: 1.0690915547824957, mse:4.679671705735627, ic :0.16960801105653361, sharpe5:17.195989204645155, irr5:555.6709594726562, ndcg5:0.8540965962285424, pnl5:8.046771049499512 
train 9, step: 0, loss: 5.444848749626196, grad_norm: 1.221623198249693, ic: -0.006690310336709734
train 9, step: 500, loss: 1.3446986106512733, grad_norm: 2.566670220640025, ic: 0.3263914651355067
train 9, step: 1000, loss: 0.9219635961873973, grad_norm: 0.0797296532464345, ic: 0.13192161578946765
train 9, step: 1500, loss: 1.080488022367452, grad_norm: 0.0553702232700337, ic: 0.4367734993834096
train 9, step: 2000, loss: 1.0597976983762254, grad_norm: 0.7546277371770902, ic: 0.2980646939194477
Epoch 9: 2022-05-03 21:39:27.003019: train loss: 1.6271072757225968
Eval step 0: eval loss: 0.8238005723541227
Eval: 2022-05-03 21:39:51.731697: total loss: 1.0701393658386964, mse:4.693222186224253, ic :0.16141705406885862, sharpe5:16.57621489405632, irr5:534.6992797851562, ndcg5:0.8519778453479288, pnl5:5.183224201202393 
train 10, step: 0, loss: 7.092764184356779, grad_norm: 3.335522782466718, ic: 0.25297496509789297
train 10, step: 500, loss: 1.1290849479064462, grad_norm: 0.09326665792700156, ic: 0.07251099046375592
train 10, step: 1000, loss: 2.4045653547977377, grad_norm: 1.6229039278400854, ic: 0.123818491969654
train 10, step: 1500, loss: 1.1184474400111608, grad_norm: 0.8881824135875247, ic: -0.008951379736463943
train 10, step: 2000, loss: 2.7566511623765195, grad_norm: 0.9532469184507388, ic: 0.4159276870183627
Epoch 10: 2022-05-03 21:46:01.158473: train loss: 1.6270196238456724
Eval step 0: eval loss: 0.8238527963234326
Eval: 2022-05-03 21:46:25.362923: total loss: 1.068266804564435, mse:4.681143892051026, ic :0.17140911571507894, sharpe5:18.13715312719345, irr5:601.2766723632812, ndcg5:0.8670425153483754, pnl5:12.423266410827637 
train 11, step: 0, loss: 1.2450280657869297, grad_norm: 0.03438629459981542, ic: 0.2220384810275568
train 11, step: 500, loss: 0.662384943859516, grad_norm: 0.02361590282911318, ic: 0.5122447703158937
train 11, step: 1000, loss: 0.9450919079760923, grad_norm: 0.36464480705380553, ic: -0.006842459886252171
train 11, step: 1500, loss: 1.0488196925113076, grad_norm: 0.09255562475526388, ic: 0.17998672315738257
train 11, step: 2000, loss: 0.7845355812783866, grad_norm: 0.008418280895620814, ic: 0.12493171583598481
Epoch 11: 2022-05-03 21:52:36.611190: train loss: 1.6256723802020758
Eval step 0: eval loss: 0.8264455363170112
Eval: 2022-05-03 21:53:00.947597: total loss: 1.068887627764438, mse:4.6631520508120525, ic :0.1788463240473756, sharpe5:18.005073519945142, irr5:593.2872314453125, ndcg5:0.8673423987831663, pnl5:10.673253059387207 
train 12, step: 0, loss: 0.9559524059295654, grad_norm: 0.466392047258684, ic: 0.40564077177637986
train 12, step: 500, loss: 0.9190608843929157, grad_norm: 0.30658569327055546, ic: 0.18575470352379775
train 12, step: 1000, loss: 2.926749648561903, grad_norm: 0.710585545736092, ic: 0.25499200415043444
train 12, step: 1500, loss: 0.9371620521051505, grad_norm: 0.2859204779117277, ic: -0.10906647428626043
train 12, step: 2000, loss: 0.8728720673621602, grad_norm: 0.0065549516630960284, ic: 0.1978262468525393
Epoch 12: 2022-05-03 21:59:12.147523: train loss: 1.624755421676572
Eval step 0: eval loss: 0.8272889662844112
Eval: 2022-05-03 21:59:36.795010: total loss: 1.0691228143751286, mse:4.660302830798539, ic :0.17567470740412597, sharpe5:17.72047285079956, irr5:579.4896850585938, ndcg5:0.8403323080226072, pnl5:6.809747219085693 
train 13, step: 0, loss: 2.071203213684662, grad_norm: 1.2613602739461975, ic: 0.3759572716055781
train 13, step: 500, loss: 0.826945431073073, grad_norm: 0.13958325379865966, ic: 0.5372487286426249
train 13, step: 1000, loss: 0.9717611223259228, grad_norm: 0.5579178035827439, ic: 0.5363129672328948
train 13, step: 1500, loss: 2.445944483069867, grad_norm: 1.459383828878238, ic: -0.0564795367196043
train 13, step: 2000, loss: 1.4723429455951693, grad_norm: 0.1827825965465747, ic: 0.125291564020938
Epoch 13: 2022-05-03 22:05:47.262622: train loss: 1.6241445245503656
Eval step 0: eval loss: 0.8221878035679003
Eval: 2022-05-03 22:06:11.624811: total loss: 1.067547838359061, mse:4.6280132004248715, ic :0.1813562875108713, sharpe5:17.467102864980696, irr5:569.923828125, ndcg5:0.8500228266597154, pnl5:6.519367218017578 
train 14, step: 0, loss: 4.4780197262578, grad_norm: 3.935779329650541, ic: 0.19936853070136284
train 14, step: 500, loss: 0.8265721499008506, grad_norm: 0.04044083868698585, ic: 0.12006349559819338
train 14, step: 1000, loss: 1.8201330557137434, grad_norm: 1.222334691459022, ic: 0.43881557952748174
train 14, step: 1500, loss: 1.122063413706829, grad_norm: 0.22828668945602382, ic: -0.03939969528361057
train 14, step: 2000, loss: 1.1539289647078015, grad_norm: 1.6060294228200436, ic: 0.06177787068276058
Epoch 14: 2022-05-03 22:12:25.054737: train loss: 1.6206501413888985
Eval step 0: eval loss: 0.8305787547747628
Eval: 2022-05-03 22:12:49.687011: total loss: 1.066681644386456, mse:4.583944697556296, ic :0.19021543751668818, sharpe5:17.10077043056488, irr5:560.6520385742188, ndcg5:0.845256619992904, pnl5:6.884433746337891 
train 15, step: 0, loss: 3.4380080404912454, grad_norm: 2.0834964500664395, ic: 0.14211116097534648
train 15, step: 500, loss: 1.2669026286822007, grad_norm: 0.058843696940310344, ic: -0.0007460140816463318
train 15, step: 1000, loss: 1.3147901581554877, grad_norm: 0.16751732694623628, ic: 0.03974817363256908
train 15, step: 1500, loss: 0.8520402082308071, grad_norm: 0.4102371843580635, ic: 0.06078805665068526
train 15, step: 2000, loss: 1.4779584457716888, grad_norm: 1.2174829829089795, ic: 0.06799865971792102
Epoch 15: 2022-05-03 22:19:01.590584: train loss: 1.6191508725813633
Eval step 0: eval loss: 0.8358685540700737
Eval: 2022-05-03 22:19:26.152259: total loss: 1.0708096102989162, mse:4.587041957367302, ic :0.19038894751978575, sharpe5:17.604994239807127, irr5:586.8668212890625, ndcg5:0.8445057150131324, pnl5:5.763986587524414 
train 16, step: 0, loss: 0.6893858558491686, grad_norm: 3.6272937154928577, ic: 0.02235910204542469
train 16, step: 500, loss: 1.6006006712380891, grad_norm: 0.8834731565280897, ic: 0.17948148079809878
train 16, step: 1000, loss: 0.8788274591619318, grad_norm: 0.014014630979346378, ic: -0.0788812666242571
train 16, step: 1500, loss: 0.8325700331523346, grad_norm: 0.349036688124393, ic: 0.11107385011223658
train 16, step: 2000, loss: 3.34758004425578, grad_norm: 4.4644307806567225, ic: -0.03260200445938605
Epoch 16: 2022-05-03 22:25:39.083259: train loss: 1.6188596722393769
Eval step 0: eval loss: 0.8276773016621114
Eval: 2022-05-03 22:26:03.430643: total loss: 1.0656081644750643, mse:4.582587614299272, ic :0.19472436290278317, sharpe5:18.827277824878692, irr5:617.86328125, ndcg5:0.8477358123411534, pnl5:7.5332159996032715 
train 17, step: 0, loss: 1.2610374875663128, grad_norm: 1.3955665709637533, ic: -0.11938611997442486
train 17, step: 500, loss: 1.7837255462398374, grad_norm: 3.1634161462853854, ic: 0.24843723644821156
train 17, step: 1000, loss: 1.277512292467524, grad_norm: 0.1593168709097394, ic: 0.1532893663035253
train 17, step: 1500, loss: 4.5266785968497425, grad_norm: 2.1295389608882043, ic: 0.19601450086171057
train 17, step: 2000, loss: 1.2866892666691527, grad_norm: 2.7377323254784836, ic: 0.10429603197212287
Epoch 17: 2022-05-03 22:32:07.975828: train loss: 1.6178717505262823
Eval step 0: eval loss: 0.8381314212328766
Eval: 2022-05-03 22:32:32.345684: total loss: 1.070817401296978, mse:4.664806459935686, ic :0.1839274571272546, sharpe5:18.303011741638183, irr5:622.3159790039062, ndcg5:0.8432022650292812, pnl5:6.786678314208984 
train 18, step: 0, loss: 1.4040205600597462, grad_norm: 2.0892526472883937, ic: 0.2565660362447203
train 18, step: 500, loss: 1.4829262155405063, grad_norm: 3.4002640805657682, ic: -0.06568863689639269
train 18, step: 1000, loss: 0.6545252969820206, grad_norm: 0.04234818112747128, ic: 0.5729021738804726
train 18, step: 1500, loss: 1.4184996208921992, grad_norm: 0.04885792045193781, ic: 0.18174435853244864
train 18, step: 2000, loss: 0.9121092778102607, grad_norm: 0.011260308636258681, ic: -0.04623711551579304
Epoch 18: 2022-05-03 22:38:39.606714: train loss: 1.6182842140122142
Eval step 0: eval loss: 0.8229766299023643
Eval: 2022-05-03 22:39:04.461971: total loss: 1.0634886476875396, mse:4.582145510438278, ic :0.1973059044431043, sharpe5:18.587175393104552, irr5:613.030029296875, ndcg5:0.8507191669291732, pnl5:6.318282127380371 
train 19, step: 0, loss: 1.4939202202690973, grad_norm: 1.3068352659952325, ic: -0.014862529055142612
train 19, step: 500, loss: 0.8571209377712673, grad_norm: 0.032933136691520856, ic: 0.240142766533509
train 19, step: 1000, loss: 0.9540990599195616, grad_norm: 0.06402676602574092, ic: 0.21517814623092701
train 19, step: 1500, loss: 3.9443829470089597, grad_norm: 1.674067838737756, ic: 0.13532621706633563
train 19, step: 2000, loss: 1.0101318359375, grad_norm: 0.42850214076628634, ic: 0.16524506156432445
Epoch 19: 2022-05-03 22:46:54.783105: train loss: 1.617941944356775
Eval step 0: eval loss: 0.8280883403171101
Eval: 2022-05-03 22:48:44.757652: total loss: 1.0659848687577087, mse:4.588137656421417, ic :0.19713098549686614, sharpe5:18.79693252801895, irr5:624.80712890625, ndcg5:0.8481472889522575, pnl5:9.242955207824707 
train 20, step: 0, loss: 2.3319652451828063, grad_norm: 3.9698258780489617, ic: 0.04602146749683427
train 20, step: 500, loss: 3.2459133522727273, grad_norm: 2.356735931391768, ic: 0.09703106639531787
train 20, step: 1000, loss: 0.9512175559997559, grad_norm: 0.1746757737607901, ic: 0.23120075247297175
train 20, step: 1500, loss: 1.7887237689031394, grad_norm: 8.854158849593318, ic: 0.25763926080186295
train 20, step: 2000, loss: 1.0168223046556384, grad_norm: 0.4389847257226261, ic: 0.04590497373635019
Epoch 20: 2022-05-03 23:19:51.592704: train loss: 1.6164324603885414
Eval step 0: eval loss: 0.841116805724776
Eval: 2022-05-03 23:27:51.489443: total loss: 1.0710491894755054, mse:4.595791689969822, ic :0.18998796306985807, sharpe5:17.161181030273436, irr5:558.0098266601562, ndcg5:0.8490567598979586, pnl5:7.38773775100708 
train 21, step: 0, loss: 0.9939943454722063, grad_norm: 0.4031817885286215, ic: 0.06459029637052877
train 21, step: 500, loss: 0.7604314078271917, grad_norm: 0.022794136195135765, ic: 0.22653631087254697
train 21, step: 1000, loss: 0.9334425005996436, grad_norm: 2.6505941207554233, ic: 0.1825479490383547
train 21, step: 1500, loss: 0.9842477445554355, grad_norm: 0.3568807552451846, ic: 0.3157877849201377
train 21, step: 2000, loss: 0.9433058425041528, grad_norm: 0.3206277781983962, ic: 0.07726498245209731
Epoch 21: 2022-05-04 00:05:14.678569: train loss: 1.6174307940174795
Eval step 0: eval loss: 0.8247180291548669
Eval: 2022-05-04 00:08:44.357960: total loss: 1.0647320968445462, mse:4.581082380273187, ic :0.1947779282900289, sharpe5:18.07880464553833, irr5:604.8646240234375, ndcg5:0.8566045785630062, pnl5:4.5924201011657715 
train 22, step: 0, loss: 1.0471508651129944, grad_norm: 0.09753178594979683, ic: 0.20161080888634084
train 22, step: 500, loss: 3.2823901168699186, grad_norm: 2.3599929577705714, ic: -0.22273635708433084
train 22, step: 1000, loss: 1.190951273482659, grad_norm: 0.033635442121805234, ic: 0.46496666977685475
train 22, step: 1500, loss: 0.9724344135802468, grad_norm: 0.1990178915675283, ic: 0.10811441156445956
train 22, step: 2000, loss: 1.6992630385487528, grad_norm: 2.6558006950300754, ic: 0.19410269786357254
Epoch 22: 2022-05-04 00:53:17.826854: train loss: 1.6166865433972586
Eval step 0: eval loss: 0.8226361450581203
Eval: 2022-05-04 00:56:04.400980: total loss: 1.0702566916585445, mse:4.674948298798454, ic :0.1773032142127104, sharpe5:17.659642260074616, irr5:591.754150390625, ndcg5:0.8532723813200495, pnl5:9.087468147277832 
train 23, step: 0, loss: 0.9733399141075288, grad_norm: 0.08882520769898854, ic: 0.1939323258385684
train 23, step: 500, loss: 1.4257746386565444, grad_norm: 0.3044393175583987, ic: 0.05407744715466922
train 23, step: 1000, loss: 1.6436316935221356, grad_norm: 0.10478014404906946, ic: 0.25890810805800846
train 23, step: 1500, loss: 1.145790176215944, grad_norm: 2.708149315994757, ic: 0.07115671853337839
train 23, step: 2000, loss: 1.6197922305018282, grad_norm: 9.606399048899876, ic: 0.4298147939054762
Epoch 23: 2022-05-04 01:41:03.584272: train loss: 1.6174615187651316
Eval step 0: eval loss: 0.8297570633561643
Eval: 2022-05-04 01:43:44.996851: total loss: 1.0655701708242253, mse:4.575933364289479, ic :0.19555056751671795, sharpe5:17.641382110118865, irr5:598.1080932617188, ndcg5:0.8563187333133572, pnl5:5.895737171173096 
train 24, step: 0, loss: 2.201736656086019, grad_norm: 0.03691418620455096, ic: 0.1509109017881795
train 24, step: 500, loss: 1.2117144751641538, grad_norm: 0.27787719166843905, ic: 0.22183641685241481
train 24, step: 1000, loss: 0.9207504035491223, grad_norm: 0.898636686386067, ic: 0.48669020606694685
train 24, step: 1500, loss: 2.621122732893652, grad_norm: 4.614570602666365, ic: 0.02254776444041999
train 24, step: 2000, loss: 0.9293926211033007, grad_norm: 0.16822927832631257, ic: 0.12886880945046753
Epoch 24: 2022-05-04 02:27:55.865364: train loss: 1.6118637654065313
Eval step 0: eval loss: 0.8222991975516991
Eval: 2022-05-04 02:30:38.469329: total loss: 1.0666642467066343, mse:4.614376510905337, ic :0.19484312538777282, sharpe5:18.39880563855171, irr5:615.2954711914062, ndcg5:0.8411685927811422, pnl5:7.0464019775390625 
train 25, step: 0, loss: 0.8352469779349663, grad_norm: 0.08313772567879665, ic: 0.6164203024456089
train 25, step: 500, loss: 0.8679413118391238, grad_norm: 0.04985610740634609, ic: 0.21442448362735725
train 25, step: 1000, loss: 2.095950240682121, grad_norm: 0.1223770953102768, ic: 0.2557008819812833
train 25, step: 1500, loss: 1.1310678360749324, grad_norm: 0.5035708534525665, ic: 0.53035538895732
train 25, step: 2000, loss: 0.9897920924867712, grad_norm: 1.0513219431481953, ic: 0.606500120172991
Epoch 25: 2022-05-04 03:15:02.885011: train loss: 1.6142567081675754
Eval step 0: eval loss: 0.8260745017370258
Eval: 2022-05-04 03:17:41.891601: total loss: 1.0633765107917177, mse:4.584724167451544, ic :0.1992038728983589, sharpe5:18.67493081331253, irr5:617.9517211914062, ndcg5:0.844019885649474, pnl5:7.091554164886475 
train 26, step: 0, loss: 6.71426030850639, grad_norm: 1.8746657999060132, ic: 0.1773134459755591
train 26, step: 500, loss: 3.9212202679094994, grad_norm: 4.816673968919778, ic: 0.36705780173420666
train 26, step: 1000, loss: 1.267556183005053, grad_norm: 1.1308973373745037, ic: -0.02898736421434979
train 26, step: 1500, loss: 0.8283711707169649, grad_norm: 0.20708397895672348, ic: 0.31603944751341406
train 26, step: 2000, loss: 0.9531279773246951, grad_norm: 0.725350087444622, ic: 0.15939790441940552
Epoch 26: 2022-05-04 04:02:48.164207: train loss: 1.614851513387762
Eval step 0: eval loss: 0.8260462030344441
Eval: 2022-05-04 04:05:26.634514: total loss: 1.064603547364118, mse:4.586704036530262, ic :0.1934579778106796, sharpe5:18.270854051113126, irr5:611.11181640625, ndcg5:0.8509319624825918, pnl5:8.425390243530273 
train 27, step: 0, loss: 0.8247905177696078, grad_norm: 0.021207977655831184, ic: 0.1342792357831586
train 27, step: 500, loss: 0.9227260256877535, grad_norm: 3.1560890771219405, ic: 0.2815597048031449
train 27, step: 1000, loss: 0.73777323735378, grad_norm: 0.7859796157892469, ic: 0.1976073472469682
train 27, step: 1500, loss: 0.6387807287770335, grad_norm: 0.07248584825351222, ic: 0.5091943844062788
train 27, step: 2000, loss: 1.3812852771153665, grad_norm: 0.0631979206699736, ic: 0.02072444347198897
Epoch 27: 2022-05-04 04:49:49.516568: train loss: 1.6131802071803065
Eval step 0: eval loss: 0.8273504516472932
Eval: 2022-05-04 04:52:35.555551: total loss: 1.0656715766269989, mse:4.59032192907009, ic :0.19204012948723576, sharpe5:17.376575882434842, irr5:586.813720703125, ndcg5:0.8577757119305837, pnl5:5.250204563140869 
train 28, step: 0, loss: 1.5458805275699807, grad_norm: 2.5911677305149188, ic: 0.2662155068106174
train 28, step: 500, loss: 1.388073327889184, grad_norm: 3.3757566563575256, ic: 0.1121623670088387
train 28, step: 1000, loss: 0.9143766077553354, grad_norm: 0.3494728286530976, ic: 0.5791806123811813
train 28, step: 1500, loss: 1.0378946276163072, grad_norm: 0.054218129614250266, ic: 0.024615963208165826
train 28, step: 2000, loss: 1.0454114668208399, grad_norm: 0.5475749828764725, ic: 0.1174756632311202
Epoch 28: 2022-05-04 05:37:14.331357: train loss: 1.6082261663216715
Eval step 0: eval loss: 0.8257186455520613
Eval: 2022-05-04 05:40:00.008752: total loss: 1.0863320122937343, mse:4.737258159720889, ic :0.1777266548455731, sharpe5:17.841063244342802, irr5:598.5604858398438, ndcg5:0.843845154559726, pnl5:6.339401721954346 
train 29, step: 0, loss: 0.9062239015707922, grad_norm: 0.12757843977922678, ic: 0.11165377827840546
train 29, step: 500, loss: 1.0971995794416103, grad_norm: 0.23930360088312783, ic: 0.6156290931106819
train 29, step: 1000, loss: 1.0615578195450404, grad_norm: 1.8275212906911364, ic: 0.07630945813864523
train 29, step: 1500, loss: 2.3896076521028493, grad_norm: 0.7162867499619607, ic: 0.00858604805631108
train 29, step: 2000, loss: 3.960239740065586, grad_norm: 10.047701519781072, ic: 0.22909197012039761
Epoch 29: 2022-05-04 06:24:20.694183: train loss: 1.6102602840102311
Eval step 0: eval loss: 0.8285948870933219
Eval: 2022-05-04 06:27:05.128115: total loss: 1.0640065375694543, mse:4.576815900799342, ic :0.2004601573358913, sharpe5:18.14446702480316, irr5:613.8373413085938, ndcg5:0.8426277871053636, pnl5:4.165079593658447 
train 30, step: 0, loss: 1.001920327703233, grad_norm: 0.13441409963661077, ic: 0.5237689061717922
train 30, step: 500, loss: 1.4280081569806193, grad_norm: 2.722121299542021, ic: 0.08024876066588581
train 30, step: 1000, loss: 0.9872004653468277, grad_norm: 0.24489025019370622, ic: -0.03644492792546625
train 30, step: 1500, loss: 1.495311375410083, grad_norm: 6.492265257267782, ic: 0.18649026252013137
train 30, step: 2000, loss: 1.8446906979246365, grad_norm: 0.9412242322737823, ic: 0.10643010082775164
Epoch 30: 2022-05-04 07:11:15.574886: train loss: 1.6109865894039468
Eval step 0: eval loss: 0.8336817075128424
Eval: 2022-05-04 07:13:56.666808: total loss: 1.072968468086539, mse:4.677318945131911, ic :0.19385136144139128, sharpe5:17.236066185235977, irr5:607.7739868164062, ndcg5:0.8429206404274432, pnl5:3.3361589908599854 
train 31, step: 0, loss: 1.0423301006968049, grad_norm: 0.47643697312501404, ic: 0.3718202965162196
train 31, step: 500, loss: 1.4788683730388374, grad_norm: 2.2952642632354383, ic: 0.009063382445413437
train 31, step: 1000, loss: 4.445992510733801, grad_norm: 6.475638029617512, ic: 0.48353298440456033
train 31, step: 1500, loss: 0.7690007073901465, grad_norm: 0.1546139525222401, ic: 0.7060897820493595
train 31, step: 2000, loss: 1.2517352350577033, grad_norm: 7.565869238810593, ic: 0.16384705663636817
Epoch 31: 2022-05-04 07:58:18.886733: train loss: 1.60493549823731
Eval step 0: eval loss: 0.8289139549649301
Eval: 2022-05-04 08:01:05.291683: total loss: 1.0642153478725385, mse:4.58087180654601, ic :0.19375577618682743, sharpe5:17.058411877155304, irr5:565.01904296875, ndcg5:0.8379645525985757, pnl5:4.634066581726074 
train 32, step: 0, loss: 1.1255851382867303, grad_norm: 0.32113371608788055, ic: 0.20767642370032433
train 32, step: 500, loss: 1.5012662632258857, grad_norm: 2.5761271882655676, ic: 0.1085274540774098
train 32, step: 1000, loss: 1.0429430986364339, grad_norm: 0.2453812559149952, ic: 0.5200271753689555
train 32, step: 1500, loss: 0.9488900633462052, grad_norm: 2.7425157890153766, ic: 0.0751162872309673
train 32, step: 2000, loss: 0.934423843186112, grad_norm: 0.19965716978072495, ic: 0.5634179136847015
Epoch 32: 2022-05-04 08:46:14.150937: train loss: 1.6094099753947633
Eval step 0: eval loss: 0.8215259998188883
Eval: 2022-05-04 08:49:00.316354: total loss: 1.0628568576499062, mse:4.589192840124548, ic :0.20084841094419387, sharpe5:19.437447205781936, irr5:650.6841430664062, ndcg5:0.8344602229517663, pnl5:4.0985493659973145 
train 33, step: 0, loss: 1.2787672884606731, grad_norm: 0.9368996586058265, ic: 0.2330932798783522
train 33, step: 500, loss: 0.9872869691200343, grad_norm: 0.03166636282442548, ic: 0.1634972420531318
train 33, step: 1000, loss: 1.0476443177250803, grad_norm: 2.3197298183257544, ic: 0.21321422334962226
train 33, step: 1500, loss: 0.907793183060869, grad_norm: 0.20501864747330623, ic: 0.552372275176577
train 33, step: 2000, loss: 0.8093911245016591, grad_norm: 0.1370462390942394, ic: 0.27688694197287744
Epoch 33: 2022-05-04 09:33:28.370159: train loss: 1.6109779733588794
Eval step 0: eval loss: 0.8239055348146074
Eval: 2022-05-04 09:36:08.350848: total loss: 1.0631589096463643, mse:4.572521646969457, ic :0.20431766768737816, sharpe5:18.896339861154555, irr5:628.4794921875, ndcg5:0.8449134328026809, pnl5:5.385565280914307 
train 34, step: 0, loss: 0.9989031461441706, grad_norm: 0.8433066459897256, ic: 0.6052057384020371
train 34, step: 500, loss: 0.7894399100487386, grad_norm: 0.5293873195667673, ic: 0.31579703080141386
train 34, step: 1000, loss: 3.115416261640745, grad_norm: 1.3370804693343257, ic: 0.3357782430315009
train 34, step: 1500, loss: 0.8064831994003278, grad_norm: 0.9984328202610957, ic: 0.6921579069078686
train 34, step: 2000, loss: 5.341931142888265, grad_norm: 37.88945983250639, ic: 0.4632609142565556
Epoch 34: 2022-05-04 10:19:24.523089: train loss: 1.6039292652763337
Eval step 0: eval loss: 0.8204713586258561
Eval: 2022-05-04 10:22:10.394478: total loss: 1.0640286161303507, mse:4.602840478733164, ic :0.20114212664438674, sharpe5:18.736818948984144, irr5:638.9171752929688, ndcg5:0.8456164692164135, pnl5:4.787835597991943 
train 35, step: 0, loss: 1.1830641802619484, grad_norm: 0.7111408630829583, ic: 0.5568538827882937
train 35, step: 500, loss: 1.1734690007282298, grad_norm: 1.9360590453238367, ic: 0.1428547671223679
train 35, step: 1000, loss: 1.6916897848659767, grad_norm: 6.967755329299486, ic: 0.04718752315684929
train 35, step: 1500, loss: 1.5800048828125002, grad_norm: 2.2408534047255833, ic: 0.05907447053828073
train 35, step: 2000, loss: 0.772214920125543, grad_norm: 0.07453341640687555, ic: 0.5780208432007586
Epoch 35: 2022-05-04 11:07:19.783899: train loss: 1.6099150131168132
Eval step 0: eval loss: 0.8305983066056375
Eval: 2022-05-04 11:10:07.703204: total loss: 1.0646867069197175, mse:4.585248684204856, ic :0.19718401683596246, sharpe5:18.06783947467804, irr5:604.2560424804688, ndcg5:0.8442996747607883, pnl5:7.311559200286865 
train 36, step: 0, loss: 1.8457897431809263, grad_norm: 7.405295033960321, ic: 0.09169481503968405
train 36, step: 500, loss: 0.8323039602726064, grad_norm: 0.06238232727664004, ic: 0.23680269586372626
train 36, step: 1000, loss: 1.6977398792613636, grad_norm: 3.009612034278695, ic: 0.2772716074318795
train 36, step: 1500, loss: 0.7662635094318551, grad_norm: 0.06249358770945776, ic: 0.3858516669683302
train 36, step: 2000, loss: 1.1277522540831015, grad_norm: 4.255338940362724, ic: 0.7701509005592262
Epoch 36: 2022-05-04 11:55:01.442763: train loss: 1.605268544351891
Eval step 0: eval loss: 0.8308515156785102
Eval: 2022-05-04 11:57:43.693309: total loss: 1.0643296409771297, mse:4.597629445620999, ic :0.19398508029299202, sharpe5:17.983644518852234, irr5:593.2989501953125, ndcg5:0.8518274785015655, pnl5:4.487213611602783 
train 37, step: 0, loss: 1.9875002243252298, grad_norm: 8.591671884284843, ic: 0.19418172927369695
train 37, step: 500, loss: 2.3321363937601958, grad_norm: 4.690956609238523, ic: -0.004124981910784064
train 37, step: 1000, loss: 1.074830959558124, grad_norm: 0.2656125397518238, ic: 0.04419610277772079
train 37, step: 1500, loss: 2.023679341027276, grad_norm: 2.789706989447187, ic: 0.5620625598415733
train 37, step: 2000, loss: 1.296026388276059, grad_norm: 0.4056271192309837, ic: 0.27069352334062347
Epoch 37: 2022-05-04 12:26:58.282759: train loss: 1.606606000807831
Eval step 0: eval loss: 0.8240917917297813
Eval: 2022-05-04 12:28:03.463850: total loss: 1.0659704251303945, mse:4.595221442381636, ic :0.19822586192453637, sharpe5:18.33473430633545, irr5:626.682373046875, ndcg5:0.8452793396247985, pnl5:6.0582966804504395 
train 38, step: 0, loss: 1.3405793352824886, grad_norm: 0.9051739257650446, ic: -0.079101236892095
train 38, step: 500, loss: 0.9034592616705247, grad_norm: 0.31741391872340263, ic: 0.2662383472368327
train 38, step: 1000, loss: 0.9056054880496541, grad_norm: 0.3098894060727965, ic: 0.13838620507982247
train 38, step: 1500, loss: 0.949464559011959, grad_norm: 0.07494423434887454, ic: 0.21171116094061107
train 38, step: 2000, loss: 2.299099925061367, grad_norm: 3.8624319491798724, ic: 0.09517264037252444
Epoch 38: 2022-05-04 12:43:32.416294: train loss: 1.6063392668897845
Eval step 0: eval loss: 0.8254213162292544
Eval: 2022-05-04 12:44:13.890608: total loss: 1.0628804774759792, mse:4.585206959963371, ic :0.1985626322237492, sharpe5:17.526306463479994, irr5:591.7457885742188, ndcg5:0.839451733042453, pnl5:7.181392669677734 
train 39, step: 0, loss: 0.9637405442170776, grad_norm: 0.048141059559991296, ic: 0.12096653933851106
train 39, step: 500, loss: 0.8800578018411318, grad_norm: 0.6078050340080744, ic: 0.23496555852849255
train 39, step: 1000, loss: 0.9360936347165366, grad_norm: 0.3078159409007026, ic: 0.2363720711534103
train 39, step: 1500, loss: 2.086793346374802, grad_norm: 0.6980164326038251, ic: 0.24205458729172363
train 39, step: 2000, loss: 0.6117788016513626, grad_norm: 0.05927032642401975, ic: 0.12764823309819703
Epoch 39: 2022-05-04 12:56:13.602085: train loss: 1.6032500769421383
Eval step 0: eval loss: 0.8262752295796562
Eval: 2022-05-04 12:57:01.904986: total loss: 1.0634983493033012, mse:4.5839229266925905, ic :0.2019785337533206, sharpe5:19.269821602106095, irr5:646.6088256835938, ndcg5:0.8426470727548867, pnl5:5.1563897132873535 
train 40, step: 0, loss: 0.864058074058845, grad_norm: 0.0557401126001714, ic: 0.2956301213662289
train 40, step: 500, loss: 1.0952313061585561, grad_norm: 0.10896965255526889, ic: 0.46990590050237974
train 40, step: 1000, loss: 1.3040871224752286, grad_norm: 1.3540691303023207, ic: 0.11698874746648324
train 40, step: 1500, loss: 2.625927493049835, grad_norm: 5.619879930326453, ic: -0.0693602762902242
train 40, step: 2000, loss: 0.9947538498955961, grad_norm: 6.050132878367253, ic: 0.1270960739477468
Epoch 40: 2022-05-04 13:09:06.793343: train loss: 1.6050842601996893
Eval step 0: eval loss: 0.8266500587583969
Eval: 2022-05-04 13:09:54.383761: total loss: 1.063243192454464, mse:4.57830347326148, ic :0.20102252455111924, sharpe5:18.77080605983734, irr5:615.8770751953125, ndcg5:0.8387025774989372, pnl5:6.285833835601807 
train 41, step: 0, loss: 1.6187814295977012, grad_norm: 0.4125250190746916, ic: 0.4092257652258806
train 41, step: 500, loss: 1.2251870020886597, grad_norm: 1.167331779401402, ic: 0.2573671822009461
train 41, step: 1000, loss: 1.0635440273139314, grad_norm: 0.7539845210343552, ic: 0.21045903901643442
train 41, step: 1500, loss: 3.1693549284224978, grad_norm: 2.67767737201378, ic: 0.09555315833873414
train 41, step: 2000, loss: 1.0413484184990103, grad_norm: 0.9902072841353391, ic: 0.17722547630236105
Epoch 41: 2022-05-04 13:21:46.888217: train loss: 1.595321693828041
Eval step 0: eval loss: 0.8331569595256519
Eval: 2022-05-04 13:22:35.082016: total loss: 1.0662881452799104, mse:4.599042921789872, ic :0.19446234646060329, sharpe5:19.13758118748665, irr5:630.91455078125, ndcg5:0.8451216541885428, pnl5:4.718867301940918 
train 42, step: 0, loss: 2.23483596743295, grad_norm: 28.05222330399735, ic: 0.07819562047947842
train 42, step: 500, loss: 1.4586883282045322, grad_norm: 1.6508102606438935, ic: 0.23016588991834613
train 42, step: 1000, loss: 3.2223441448775274, grad_norm: 4.709915472235432, ic: 0.1238528894834893
train 42, step: 1500, loss: 1.1888154543131897, grad_norm: 0.026087467323722056, ic: 0.5730432047337675
train 42, step: 2000, loss: 1.1764868587427746, grad_norm: 0.08291377246568474, ic: 0.485586490570082
Epoch 42: 2022-05-04 13:34:37.927734: train loss: 1.5997013570269683
Eval step 0: eval loss: 0.8286778537440727
Eval: 2022-05-04 13:35:27.319219: total loss: 1.0638754858824717, mse:4.571324235793521, ic :0.20363460219825977, sharpe5:18.58481436252594, irr5:621.3099365234375, ndcg5:0.8466825297968321, pnl5:5.969569683074951 
train 43, step: 0, loss: 0.8339328041559533, grad_norm: 0.39864418933010426, ic: 0.06098611698442452
train 43, step: 500, loss: 0.959906896953493, grad_norm: 1.8762899337577144, ic: 0.2551529667747135
train 43, step: 1000, loss: 1.6722580304311072, grad_norm: 2.466054237700078, ic: -0.10891580386440192
train 43, step: 1500, loss: 1.3943009929083958, grad_norm: 0.28513024955882404, ic: 0.1755615566477886
train 43, step: 2000, loss: 1.6475868525467519, grad_norm: 1.5790414188690947, ic: -0.03296088866346532
Epoch 43: 2022-05-04 13:47:55.982068: train loss: 1.6017078414738268
Eval step 0: eval loss: 0.8309367333624209
Eval: 2022-05-04 13:48:40.991312: total loss: 1.0645728823245302, mse:4.602691502737711, ic :0.19703954923615574, sharpe5:17.29730730772018, irr5:585.5386352539062, ndcg5:0.8536765788156827, pnl5:4.31547737121582 
train 44, step: 0, loss: 1.0454153546815588, grad_norm: 0.19970512390285583, ic: 0.048597686038351295
train 44, step: 500, loss: 2.054102943342498, grad_norm: 5.037612823226803, ic: 0.18130161278137666
train 44, step: 1000, loss: 1.7912949384269068, grad_norm: 0.8313591375982599, ic: 0.1253224924774585
train 44, step: 1500, loss: 1.0260573239187307, grad_norm: 0.1310938182771606, ic: 0.17671014262441298
train 44, step: 2000, loss: 0.9354108761518429, grad_norm: 0.3905174834867727, ic: 0.6970539191083743
Epoch 44: 2022-05-04 14:01:00.464566: train loss: 1.604768733823394
Eval step 0: eval loss: 0.8212718903327515
Eval: 2022-05-04 14:01:41.334962: total loss: 1.0641753499109898, mse:4.6059824177379385, ic :0.19953332909793967, sharpe5:18.619157141447065, irr5:616.375732421875, ndcg5:0.8426109866599027, pnl5:4.459042072296143 
train 45, step: 0, loss: 1.6183193579652257, grad_norm: 2.8488152991422053, ic: 0.07797139629160038
train 45, step: 500, loss: 0.9700644897109151, grad_norm: 0.12569922394805141, ic: 0.48330550906577174
train 45, step: 1000, loss: 1.527957777213748, grad_norm: 0.4904146568452338, ic: 0.8733583721965463
train 45, step: 1500, loss: 0.9872448001839739, grad_norm: 0.6522868354662092, ic: 0.18822027905746727
train 45, step: 2000, loss: 1.7202374387254902, grad_norm: 0.5944724907407315, ic: 0.43400983495450945

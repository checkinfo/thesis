Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='AdjSeqTimeDataset', dout=0.3, epochs=40, glstm_layers=1, gnn_layers=2, gpu=0, graph_attn=True, hidden_dim=128, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=3, mask_adj=True, mask_type='soft', model_type='RGCNModel', normalize_adj=True, num_days=1, num_heads=1, print_inteval=500, relation_num=1, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_250_0.8/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
43087
RGCNModel(
  (fc1): Linear(in_features=9, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
  (fc4): Linear(in_features=128, out_features=1, bias=True)
  (gnns): ModuleList(
    (0): RGCN(
      (attention): ModuleList(
        (0): GraphAttentionLayer (128 -> 128)
      )
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
    )
    (1): RGCN(
      (attention): ModuleList(
        (0): GraphAttentionLayer (128 -> 128)
      )
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
    )
  )
  (dropout): Dropout(p=0.3, inplace=False)
  (relu): LeakyReLU(negative_slope=0.01)
)
train 0, step: 0, loss: 2.079200376729249, grad_norm: 0.49913140972973674, ic: -0.10019895836214568
train 0, step: 500, loss: 1.366173178070508, grad_norm: 0.8563971953761017, ic: -0.04679141129493107
train 0, step: 1000, loss: 1.5055826689724836, grad_norm: 0.033107258136051934, ic: 0.25180213421539477
train 0, step: 1500, loss: 1.184658698537183, grad_norm: 0.09083954892340491, ic: 0.059362282248240965
train 0, step: 2000, loss: 1.5582764788371761, grad_norm: 0.04483696781505773, ic: 0.09477796909906552
Epoch 0: 2022-04-19 11:15:56.469042: train loss: 1.647504835875472
Eval step 0: eval loss: 1.0077341410158307
Eval: 2022-04-19 11:15:58.739891: total loss: 1.0903210392179974, mse:4.884493240224404, ic :0.03203996449715493, sharpe5:0.6522681003436446, irr5:5.429861068725586, ndcg5:0.8353601194648643, pnl5:0.8939996361732483 
train 1, step: 0, loss: 0.6429943424640315, grad_norm: 0.055140792423409725, ic: 0.04498597764809015
train 1, step: 500, loss: 1.2613522117962468, grad_norm: 0.29092757822820636, ic: 0.2577553153057751
train 1, step: 1000, loss: 0.8787766811790951, grad_norm: 0.060362398627100494, ic: 0.08963476500730103
train 1, step: 1500, loss: 1.8683175808045922, grad_norm: 0.5872412210160184, ic: 0.07987889083108932
train 1, step: 2000, loss: 1.3746504265170367, grad_norm: 0.21773296015826477, ic: 0.12891958594758052
Epoch 1: 2022-04-19 11:16:23.439254: train loss: 1.6463138256936283
Eval step 0: eval loss: 1.0033106831514942
Eval: 2022-04-19 11:16:25.692376: total loss: 1.08880154401554, mse:4.876443965421113, ic :0.053653740396684316, sharpe5:1.752711073681712, irr5:18.02338218688965, ndcg5:0.837974624099655, pnl5:1.0275509357452393 
train 2, step: 0, loss: 1.3138328490218496, grad_norm: 0.5212908218913735, ic: 0.059493366877935494
train 2, step: 500, loss: 0.9505358682959504, grad_norm: 0.31902387060676685, ic: 0.11154993697568488
train 2, step: 1000, loss: 3.0416755219668117, grad_norm: 1.5129603265838956, ic: 0.11717810567617187
train 2, step: 1500, loss: 2.299079429148493, grad_norm: 0.8761105202868781, ic: 0.05523676578729786
train 2, step: 2000, loss: 1.461439555332686, grad_norm: 0.27828672169451735, ic: -0.11174130027538753
Epoch 2: 2022-04-19 11:16:50.677080: train loss: 1.6446988319580989
Eval step 0: eval loss: 0.9989986248930357
Eval: 2022-04-19 11:16:52.969187: total loss: 1.0888619188823818, mse:4.880847198671872, ic :0.04666620946185877, sharpe5:3.079039747416973, irr5:28.96820068359375, ndcg5:0.8414852004926001, pnl5:1.342475414276123 
train 3, step: 0, loss: 1.8288082948785387, grad_norm: 0.06196174650832704, ic: -0.14627996868110207
train 3, step: 500, loss: 0.7853369077457957, grad_norm: 0.03336787023979341, ic: 0.07113644287464621
train 3, step: 1000, loss: 1.3168439937690257, grad_norm: 0.564260471892908, ic: 0.22269481222853743
train 3, step: 1500, loss: 2.638119773540217, grad_norm: 0.47155820680672494, ic: -0.07535918733918841
train 3, step: 2000, loss: 1.3593405983664772, grad_norm: 0.16455754259246747, ic: 0.07677796131812503
Epoch 3: 2022-04-19 11:17:16.863178: train loss: 1.6448960575499267
Eval step 0: eval loss: 1.0010089603080567
Eval: 2022-04-19 11:17:19.096433: total loss: 1.0899023190904786, mse:4.877891801583926, ic :0.05006726652173266, sharpe5:1.7277112030237913, irr5:16.22372055053711, ndcg5:0.8538463520524169, pnl5:1.0669690370559692 
train 4, step: 0, loss: 1.1591400192934265, grad_norm: 0.15803872789556608, ic: 0.08037647513644595
train 4, step: 500, loss: 0.9903659572849026, grad_norm: 0.006537858111633911, ic: 0.14629603503281877
train 4, step: 1000, loss: 1.3342711610888636, grad_norm: 0.0609707594023875, ic: 0.03196144631004889
train 4, step: 1500, loss: 1.0748567238832132, grad_norm: 0.11534421067735735, ic: 0.1890202678723456
train 4, step: 2000, loss: 4.183050532307238, grad_norm: 0.8666919891889906, ic: -0.028821702979552173
Epoch 4: 2022-04-19 11:17:43.634410: train loss: 1.644668845806887
Eval step 0: eval loss: 1.0045233511058451
Eval: 2022-04-19 11:17:45.985040: total loss: 1.0931470195729145, mse:4.885128734789105, ic :0.04762471488307598, sharpe5:6.69779065310955, irr5:178.2067413330078, ndcg5:0.8451394135204078, pnl5:2.817737340927124 
train 5, step: 0, loss: 0.9930508243883283, grad_norm: 0.173681232813762, ic: -0.15047476522133366
train 5, step: 500, loss: 0.7878500409600859, grad_norm: 0.014301826129290818, ic: 0.14491824798738823
train 5, step: 1000, loss: 1.1256325391367163, grad_norm: 0.05345683453587498, ic: -0.13185731963564223
train 5, step: 1500, loss: 1.744580475101626, grad_norm: 0.3106237445158151, ic: -0.13546713646099068
train 5, step: 2000, loss: 2.1856749742764205, grad_norm: 0.7910392363936745, ic: 0.027647163828143126
Epoch 5: 2022-04-19 11:18:10.779391: train loss: 1.6450858618609692
Eval step 0: eval loss: 0.9992166672837677
Eval: 2022-04-19 11:18:13.006886: total loss: 1.0899409288741728, mse:4.878125464704644, ic :0.05279325484717148, sharpe5:-0.9004113145172595, irr5:-12.001781463623047, ndcg5:0.8601121299276913, pnl5:1.005528211593628 
train 6, step: 0, loss: 0.783919170570243, grad_norm: 0.014659767269703982, ic: -0.08447942836494013
train 6, step: 500, loss: 1.450533504374543, grad_norm: 0.22231949425455746, ic: 0.0779629435420517
train 6, step: 1000, loss: 1.2342408453874227, grad_norm: 0.16688889985023975, ic: 0.18138016541615076
train 6, step: 1500, loss: 1.078980874115566, grad_norm: 0.32588745776641403, ic: 0.03322420064973752
train 6, step: 2000, loss: 2.262278555262889, grad_norm: 0.9479578402803202, ic: 0.10421748369494818
Epoch 6: 2022-04-19 11:18:38.006590: train loss: 1.6444941937498794
Eval step 0: eval loss: 1.0003716748535412
Eval: 2022-04-19 11:18:40.249018: total loss: 1.0891943997680993, mse:4.880661544772972, ic :0.04600447461002786, sharpe5:1.802016742005944, irr5:17.885299682617188, ndcg5:0.8424439631589583, pnl5:1.1552053689956665 
train 7, step: 0, loss: 1.4534314829592256, grad_norm: 0.5245448463702662, ic: 0.19467824100235845
train 7, step: 500, loss: 1.3248956853693183, grad_norm: 0.020628096604365907, ic: 0.0675797244631891
train 7, step: 1000, loss: 0.6484509124543637, grad_norm: 0.011910618630060625, ic: 0.28340278740160285
train 7, step: 1500, loss: 1.001861033582358, grad_norm: 0.11856525320595916, ic: 0.05992116085607432
train 7, step: 2000, loss: 1.592528136143027, grad_norm: 0.5284856192004798, ic: 0.13815499748748003
Epoch 7: 2022-04-19 11:19:05.147935: train loss: 1.6452517744739235
Eval step 0: eval loss: 0.989295288535907
Eval: 2022-04-19 11:19:07.393234: total loss: 1.0892380498265433, mse:4.891220328511276, ic :0.05073970043019511, sharpe5:-0.003875270583957899, irr5:-1.032580852508545, ndcg5:0.8408662337922239, pnl5:0.9993544220924377 
train 8, step: 0, loss: 1.2075152886798972, grad_norm: 0.08321439769342293, ic: 0.04975396789074438
train 8, step: 500, loss: 5.531533937842868, grad_norm: 1.0318733918129095, ic: 0.1302817715796077
train 8, step: 1000, loss: 1.8752964975697173, grad_norm: 0.5162663544015778, ic: 0.04851656676212814
train 8, step: 1500, loss: 1.1303771518300247, grad_norm: 0.3026605894356108, ic: 0.1042577450967391
train 8, step: 2000, loss: 1.1335100027231069, grad_norm: 0.544650604506066, ic: -0.0032489895123668337
Epoch 8: 2022-04-19 11:19:32.169319: train loss: 1.6451600965200581
Eval step 0: eval loss: 1.0045823613990916
Eval: 2022-04-19 11:19:34.396704: total loss: 1.092027060717124, mse:4.88385866233275, ic :0.046139818462902375, sharpe5:3.5300015540421006, irr5:29.850858688354492, ndcg5:0.8615792999820949, pnl5:1.2863423824310303 
train 9, step: 0, loss: 1.1492202117115111, grad_norm: 0.010754581935042234, ic: 0.03267096643816565
train 9, step: 500, loss: 3.0856435650922753, grad_norm: 2.1055691716281384, ic: 0.11305830184555306
train 9, step: 1000, loss: 0.860948626847592, grad_norm: 0.0724838440683698, ic: 0.25192759385118807
train 9, step: 1500, loss: 2.1565568574630265, grad_norm: 1.0980468014518325, ic: -0.04064064820759687
train 9, step: 2000, loss: 0.6065648857014654, grad_norm: 0.006423446802807323, ic: 0.08553248960125681
Epoch 9: 2022-04-19 11:20:00.856781: train loss: 1.6444658293958045
Eval step 0: eval loss: 0.9996303178687795
Eval: 2022-04-19 11:20:03.170586: total loss: 1.0881178984975053, mse:4.892200290109384, ic :0.04194911178463343, sharpe5:2.1048024782538413, irr5:22.71613883972168, ndcg5:0.8517118530423616, pnl5:1.0267927646636963 
train 10, step: 0, loss: 1.3128095750050053, grad_norm: 0.04075796239634936, ic: 0.18339534771665708
train 10, step: 500, loss: 0.8969826513931008, grad_norm: 0.00636478869428261, ic: 0.1015641846578701
train 10, step: 1000, loss: 1.5447425810522482, grad_norm: 0.49699027188878075, ic: 0.05742763121345189
train 10, step: 1500, loss: 3.0883028404061763, grad_norm: 1.2009552466398146, ic: 0.033432935332770794
train 10, step: 2000, loss: 1.3804950192344225, grad_norm: 0.13669490728118006, ic: 0.033925414769276865
Epoch 10: 2022-04-19 11:20:28.085720: train loss: 1.644844879391125
Eval step 0: eval loss: 1.0096118639744602
Eval: 2022-04-19 11:20:30.429063: total loss: 1.0919394607192832, mse:4.8848479884718135, ic :0.05304394790554397, sharpe5:3.7597487005591392, irr5:41.17256546020508, ndcg5:0.8503331136397535, pnl5:1.2477264404296875 
train 11, step: 0, loss: 4.887906811962471, grad_norm: 1.9501660175758584, ic: 0.1983028424968949
train 11, step: 500, loss: 0.9925885881696429, grad_norm: 0.06199468758822609, ic: 0.05197897439000852
train 11, step: 1000, loss: 1.0318939651268118, grad_norm: 0.3004818063253602, ic: 0.05684734988468776
train 11, step: 1500, loss: 0.6955265293106402, grad_norm: 0.0009096845403198663, ic: 0.09606784839757582
train 11, step: 2000, loss: 1.1327428871979082, grad_norm: 0.07252271676439272, ic: -0.18853321179418378
Epoch 11: 2022-04-19 11:20:54.794947: train loss: 1.640458375818904
Eval step 0: eval loss: 0.995292804189705
Eval: 2022-04-19 11:20:57.021601: total loss: 1.0851099732128315, mse:4.732836965951953, ic :0.11932055480330975, sharpe5:7.638297630250453, irr5:220.4786376953125, ndcg5:0.8464282895648066, pnl5:3.336386203765869 
train 12, step: 0, loss: 1.387851822421578, grad_norm: 0.2741395664551274, ic: 0.036002255286174435
train 12, step: 500, loss: 0.8036239371115331, grad_norm: 0.3121004337492755, ic: 0.02529866888854304
train 12, step: 1000, loss: 1.2203821670411443, grad_norm: 0.2954578184574248, ic: 0.5764779587489404
train 12, step: 1500, loss: 1.0911516195408066, grad_norm: 0.1963998599826464, ic: -0.083548761675887
train 12, step: 2000, loss: 1.1149410700839069, grad_norm: 0.05673139038395987, ic: 0.09512142088906708
Epoch 12: 2022-04-19 11:21:22.084748: train loss: 1.6400318712906023
Eval step 0: eval loss: 1.0012676928029554
Eval: 2022-04-19 11:21:24.324741: total loss: 1.0861152681860988, mse:4.731782642833796, ic :0.11947620109339477, sharpe5:7.311190370321273, irr5:212.2047882080078, ndcg5:0.8615897215548411, pnl5:3.1151833534240723 
train 13, step: 0, loss: 1.084525912036303, grad_norm: 0.06462983662922904, ic: 0.42706974560964417
train 13, step: 500, loss: 1.1419241635854007, grad_norm: 0.004168157086014708, ic: -0.13752213343169697
train 13, step: 1000, loss: 1.392962295928403, grad_norm: 0.41015228611469934, ic: -0.008572283208657303
train 13, step: 1500, loss: 0.7753046462524971, grad_norm: 0.0015783514633754634, ic: -0.049500187812217544
train 13, step: 2000, loss: 1.0407898605510753, grad_norm: 0.024867474096306186, ic: 0.03417270171008961
Epoch 13: 2022-04-19 11:21:49.071868: train loss: 1.6382304499193248
Eval step 0: eval loss: 0.9949936387161005
Eval: 2022-04-19 11:21:51.401842: total loss: 1.0894979599068269, mse:4.778030344470572, ic :0.11379460934852245, sharpe5:8.476588820815087, irr5:237.27394104003906, ndcg5:0.8510765368416101, pnl5:4.300826072692871 
train 14, step: 0, loss: 1.7317904456187103, grad_norm: 0.7135067931421752, ic: 0.1542859685817683
train 14, step: 500, loss: 1.2826036261250917, grad_norm: 0.15963318651514935, ic: 0.16788592596152735
train 14, step: 1000, loss: 1.0694483228951446, grad_norm: 0.11929629397533432, ic: 0.13293435929752925
train 14, step: 1500, loss: 0.9911609441156658, grad_norm: 0.07145080943549979, ic: 0.19520237081239142
train 14, step: 2000, loss: 2.303192785863581, grad_norm: 0.4973748731119473, ic: -0.06917519874928121
Epoch 14: 2022-04-19 11:22:16.281596: train loss: 1.6355935771473897
Eval step 0: eval loss: 1.0042862814310163
Eval: 2022-04-19 11:22:18.503613: total loss: 1.0867067306662006, mse:4.703593711427702, ic :0.14508789965885505, sharpe5:13.207362899780273, irr5:412.45452880859375, ndcg5:0.8568996378264734, pnl5:5.614024639129639 
train 15, step: 0, loss: 0.9755923673807861, grad_norm: 0.15113327478746136, ic: 0.1227761421450504
train 15, step: 500, loss: 1.2234131045884262, grad_norm: 0.007675111815517382, ic: 0.09976558864167068
train 15, step: 1000, loss: 1.7650885416666668, grad_norm: 0.07134210148013752, ic: -0.12186040092354627
train 15, step: 1500, loss: 5.419908280162413, grad_norm: 0.874801530879002, ic: 0.019395238011306198
train 15, step: 2000, loss: 0.9296475534027201, grad_norm: 0.011887269300234276, ic: -0.1151354257505303
Epoch 15: 2022-04-19 11:22:43.182587: train loss: 1.638825571913111
Eval step 0: eval loss: 0.9987319215088533
Eval: 2022-04-19 11:22:45.470857: total loss: 1.085779519665092, mse:4.716434992496338, ic :0.12335321979548237, sharpe5:7.094203525185585, irr5:204.9493408203125, ndcg5:0.8543502186364788, pnl5:3.342660427093506 
train 16, step: 0, loss: 6.342932440874897, grad_norm: 1.0583281287643196, ic: -0.0568436301193493
train 16, step: 500, loss: 1.3580951024615575, grad_norm: 0.7577287559132561, ic: -0.04537277643744307
train 16, step: 1000, loss: 0.8259396364763799, grad_norm: 0.12532930077043952, ic: 0.016775249680086604
train 16, step: 1500, loss: 1.2249031096081198, grad_norm: 0.27786138501460445, ic: 0.12118801182902414
train 16, step: 2000, loss: 0.9666618769733338, grad_norm: 0.2568784991934554, ic: 0.5189312113567076
Epoch 16: 2022-04-19 11:23:10.035470: train loss: 1.6365786038968082
Eval step 0: eval loss: 1.0020044215294233
Eval: 2022-04-19 11:23:12.360523: total loss: 1.0882367458634694, mse:4.7585324314569935, ic :0.13682780311117385, sharpe5:12.155852959156036, irr5:369.6060485839844, ndcg5:0.8618627403219151, pnl5:4.423513889312744 
train 17, step: 0, loss: 1.1856174586009394, grad_norm: 0.016197461767319933, ic: 0.10998676784333293
train 17, step: 500, loss: 1.0428568356188825, grad_norm: 0.03459638885453639, ic: -0.03225758244404619
train 17, step: 1000, loss: 3.3988419838077557, grad_norm: 1.4128654758158397, ic: -0.011708085791808884
train 17, step: 1500, loss: 0.8868812141295005, grad_norm: 0.04558172119196018, ic: 0.07749044555309065
train 17, step: 2000, loss: 0.9758236878670301, grad_norm: 0.41711168349612143, ic: 0.5735130393938216
Epoch 17: 2022-04-19 11:23:37.241765: train loss: 1.6326563656203839
Eval step 0: eval loss: 0.9988929463286598
Eval: 2022-04-19 11:23:39.534806: total loss: 1.085802411146612, mse:4.725350996086765, ic :0.14770664846922738, sharpe5:13.828563666343689, irr5:461.33502197265625, ndcg5:0.8530182568871537, pnl5:6.233308792114258 
train 18, step: 0, loss: 0.8536309408204691, grad_norm: 0.012133687522767903, ic: 0.025683894034454466
train 18, step: 500, loss: 2.5017830089359077, grad_norm: 0.9870223081639717, ic: 0.07520775303943251
train 18, step: 1000, loss: 1.3628449584082734, grad_norm: 0.33685510561121745, ic: 0.5358562515985781
train 18, step: 1500, loss: 1.7618804316758352, grad_norm: 0.6578043371196651, ic: 0.34577931171415965
train 18, step: 2000, loss: 1.2718768899389803, grad_norm: 0.3917716122462535, ic: 0.19864409901377952
Epoch 18: 2022-04-19 11:24:04.008228: train loss: 1.6309292297816338
Eval step 0: eval loss: 1.0019319121494865
Eval: 2022-04-19 11:24:06.313004: total loss: 1.0829278297781855, mse:4.691541758931495, ic :0.16420455290280123, sharpe5:14.76693143248558, irr5:499.5892028808594, ndcg5:0.8498358732160581, pnl5:5.770294189453125 
train 19, step: 0, loss: 2.2010980911079763, grad_norm: 0.7657326987127588, ic: 0.24655868505204992
train 19, step: 500, loss: 1.0192613468613736, grad_norm: 0.03952395402491417, ic: -0.0845110938309021
train 19, step: 1000, loss: 1.037794964362228, grad_norm: 0.02544263752620291, ic: 0.45751126199800185
train 19, step: 1500, loss: 1.569586294668692, grad_norm: 0.015375296062886384, ic: 0.15806592172740538
train 19, step: 2000, loss: 1.8248335387664347, grad_norm: 1.2705396436937766, ic: 0.6384613693024075
Epoch 19: 2022-04-19 11:24:30.399981: train loss: 1.6335510701895937
Eval step 0: eval loss: 0.9999507604742627
Eval: 2022-04-19 11:24:32.623994: total loss: 1.0813106512980355, mse:4.6864762692946735, ic :0.15947963416858385, sharpe5:14.454194203019142, irr5:458.8672790527344, ndcg5:0.8509031850349854, pnl5:5.208705425262451 
train 20, step: 0, loss: 1.2309658592775872, grad_norm: 0.3227886345569381, ic: 0.4641168563575396
train 20, step: 500, loss: 1.2164734900157337, grad_norm: 0.4360425219896623, ic: 0.02138627856978142
train 20, step: 1000, loss: 1.5885970689683695, grad_norm: 0.46779806958139675, ic: 0.1716794748920628
train 20, step: 1500, loss: 0.9036275303496747, grad_norm: 1.7039619067410239, ic: 0.5774009513792798
train 20, step: 2000, loss: 1.362293536372019, grad_norm: 0.1264636092397199, ic: -0.05057805764814987
Epoch 20: 2022-04-19 11:24:57.406004: train loss: 1.62781445883658
Eval step 0: eval loss: 1.0005175935525277
Eval: 2022-04-19 11:24:59.662993: total loss: 1.0816501100240452, mse:4.6881815521023, ic :0.1640923536349606, sharpe5:14.735224002599715, irr5:495.0099792480469, ndcg5:0.843774547893385, pnl5:5.493625164031982 
train 21, step: 0, loss: 1.3854319936680028, grad_norm: 0.3672724363547466, ic: 0.3363493364778184
train 21, step: 500, loss: 1.1107593352500955, grad_norm: 0.08093312236223031, ic: 0.06838655271027484
train 21, step: 1000, loss: 0.9164557601941249, grad_norm: 0.9398749620126962, ic: 0.049470332472794046
train 21, step: 1500, loss: 0.7325603477380149, grad_norm: 0.14329971430019894, ic: 0.6261186902335925
train 21, step: 2000, loss: 1.1481291873164463, grad_norm: 0.14150013274940282, ic: 0.22951243595797277
Epoch 21: 2022-04-19 11:25:24.557988: train loss: 1.6282163517518329
Eval step 0: eval loss: 1.0001379478097023
Eval: 2022-04-19 11:25:26.845265: total loss: 1.0825352439590328, mse:4.696862988316836, ic :0.1543755369800905, sharpe5:13.6179504686594, irr5:420.1094970703125, ndcg5:0.842929788347668, pnl5:5.958181381225586 
train 22, step: 0, loss: 1.0548350834003215, grad_norm: 0.28811348775920814, ic: 0.09251899078128438
train 22, step: 500, loss: 1.0281859390378938, grad_norm: 0.0019051215427582598, ic: -0.008173549731676236
train 22, step: 1000, loss: 0.9125729059571059, grad_norm: 0.04390854411879616, ic: 0.12507315590290252
train 22, step: 1500, loss: 1.0033688173858548, grad_norm: 0.015256348983806952, ic: 0.24878740489060253
train 22, step: 2000, loss: 1.0504458405250727, grad_norm: 0.10978145327527075, ic: 0.14717352863287586
Epoch 22: 2022-04-19 11:25:51.594506: train loss: 1.6265152326395753
Eval step 0: eval loss: 1.00600657932629
Eval: 2022-04-19 11:25:53.870865: total loss: 1.0825281632431716, mse:4.687036564907078, ic :0.1645260093046256, sharpe5:15.136778926849365, irr5:479.14324951171875, ndcg5:0.8567420066536249, pnl5:5.357321262359619 
train 23, step: 0, loss: 1.2797947379071821, grad_norm: 1.1014249844610828, ic: 0.0046829562606087866
train 23, step: 500, loss: 0.9052886124495623, grad_norm: 0.19463331694252098, ic: 0.5936701109232434
train 23, step: 1000, loss: 2.2944393974098656, grad_norm: 0.9490860107868153, ic: 0.06564754938983614
train 23, step: 1500, loss: 0.7727922484395399, grad_norm: 0.3849716447285218, ic: 0.7188516292663598
train 23, step: 2000, loss: 1.4982840955392573, grad_norm: 0.3563354123027251, ic: 0.41193264800565305
Epoch 23: 2022-04-19 11:26:18.439613: train loss: 1.6263173188062414
Eval step 0: eval loss: 0.9992053537634938
Eval: 2022-04-19 11:26:20.734666: total loss: 1.0839268705261311, mse:4.688287738370084, ic :0.15858540198709478, sharpe5:13.187362246513366, irr5:416.1058654785156, ndcg5:0.8563681502077487, pnl5:4.2702250480651855 
train 24, step: 0, loss: 1.1659412964724825, grad_norm: 0.44250399842958527, ic: 0.30721636198605595
train 24, step: 500, loss: 1.2714789744827422, grad_norm: 0.4055950728912322, ic: 0.020301675388505094
train 24, step: 1000, loss: 1.0619351456804973, grad_norm: 0.3085725433150498, ic: 0.11105365617298896
train 24, step: 1500, loss: 1.2101022314837597, grad_norm: 0.1029179537621131, ic: 0.04781867445529665
train 24, step: 2000, loss: 1.3572530721350051, grad_norm: 0.3862706878806201, ic: 0.44482780832450364
Epoch 24: 2022-04-19 11:26:45.568649: train loss: 1.6265464118546036
Eval step 0: eval loss: 1.0089145397248551
Eval: 2022-04-19 11:26:47.858034: total loss: 1.0823158135152557, mse:4.692463801992726, ic :0.16329360728968112, sharpe5:15.74190746963024, irr5:510.0784606933594, ndcg5:0.8421407287351679, pnl5:5.319585800170898 
train 25, step: 0, loss: 1.2900123378705817, grad_norm: 0.6790812128460725, ic: 0.2199347105386334
train 25, step: 500, loss: 1.488756055955763, grad_norm: 2.499478362885762, ic: 0.09570069731032824
train 25, step: 1000, loss: 1.3628801518024007, grad_norm: 0.2549112647604991, ic: 0.26985618057047983
train 25, step: 1500, loss: 2.9033490349264706, grad_norm: 1.3036199338957222, ic: 0.20587714345946
train 25, step: 2000, loss: 1.1891764387299744, grad_norm: 0.13809995075358744, ic: 0.16121328154006068
Epoch 25: 2022-04-19 11:27:10.145786: train loss: 1.6271348146497353
Eval step 0: eval loss: 1.0055319257257107
Eval: 2022-04-19 11:27:12.353586: total loss: 1.0806577047770238, mse:4.673428085186947, ic :0.1722593587144469, sharpe5:15.59726218521595, irr5:511.04278564453125, ndcg5:0.8608568659960876, pnl5:6.755760192871094 
train 26, step: 0, loss: 1.6249705255681817, grad_norm: 0.6860189149959265, ic: 0.20143774171638756
train 26, step: 500, loss: 1.0191424705988086, grad_norm: 0.32136550140003234, ic: -0.022872108563613554
train 26, step: 1000, loss: 1.8056953677924648, grad_norm: 0.5846138405012309, ic: 0.1995470361176892
train 26, step: 1500, loss: 0.9202176954983153, grad_norm: 0.07728635709122536, ic: 0.024044412671504603
train 26, step: 2000, loss: 0.999049773929626, grad_norm: 0.1261700503437107, ic: 0.13807127876623954
Epoch 26: 2022-04-19 11:27:37.393841: train loss: 1.6260790162809124
Eval step 0: eval loss: 0.9987849536351369
Eval: 2022-04-19 11:27:39.662566: total loss: 1.0827303662881969, mse:4.693473870081735, ic :0.16176803563493528, sharpe5:14.610388294458389, irr5:458.5898742675781, ndcg5:0.8663352969655218, pnl5:5.650504112243652 
train 27, step: 0, loss: 1.6199585328619166, grad_norm: 0.735110688040706, ic: 0.6506270675289697
train 27, step: 500, loss: 1.5721522875558904, grad_norm: 0.8557757652424138, ic: 0.06872594256940999
train 27, step: 1000, loss: 2.5952459541326727, grad_norm: 1.1340687005000578, ic: 0.39843179940391943
train 27, step: 1500, loss: 0.8849879098716169, grad_norm: 0.605317684842487, ic: 0.5241104319713856
train 27, step: 2000, loss: 1.3773026473694316, grad_norm: 0.5901962503096094, ic: 0.0009884631052597716
Epoch 27: 2022-04-19 11:28:05.105585: train loss: 1.6309574671217315
Eval step 0: eval loss: 0.9983455905040481
Eval: 2022-04-19 11:28:07.455582: total loss: 1.0814816146400543, mse:4.694220256371476, ic :0.15627626962756694, sharpe5:13.563032859563826, irr5:411.6402282714844, ndcg5:0.8534809797582644, pnl5:4.8606061935424805 
train 28, step: 0, loss: 1.1846579888676385, grad_norm: 0.1594479855144533, ic: 0.05575114427557158
train 28, step: 500, loss: 2.963200928941001, grad_norm: 0.6689389565680942, ic: 0.08019314867509705
train 28, step: 1000, loss: 2.804743039099526, grad_norm: 2.647214111845862, ic: -0.04992450287617581
train 28, step: 1500, loss: 1.0239664031965383, grad_norm: 0.010445009160213091, ic: 0.20057399000055362
train 28, step: 2000, loss: 1.768293868663699, grad_norm: 0.4204851549655463, ic: 0.09273688798842591
Epoch 28: 2022-04-19 11:28:32.648089: train loss: 1.6255929682361947
Eval step 0: eval loss: 1.0131130128110188
Eval: 2022-04-19 11:28:34.960333: total loss: 1.0823150946375661, mse:4.695951184509463, ic :0.16223590054605996, sharpe5:15.183826434016227, irr5:478.71319580078125, ndcg5:0.8597608874510301, pnl5:5.739276885986328 
train 29, step: 0, loss: 1.5115712290916414, grad_norm: 0.15656853497458936, ic: 0.08856978970418303
train 29, step: 500, loss: 2.577173776642298, grad_norm: 1.974455178534496, ic: -0.08471683619375703
train 29, step: 1000, loss: 1.7001397261570068, grad_norm: 1.6318512369599312, ic: 0.48574774517327857
train 29, step: 1500, loss: 3.9585985725308643, grad_norm: 1.1543616057059334, ic: 0.12935702258815285
train 29, step: 2000, loss: 0.9376013242125066, grad_norm: 0.24525726999267952, ic: 0.47002465941238103
Epoch 29: 2022-04-19 11:28:59.830165: train loss: 1.6256377420661743
Eval step 0: eval loss: 1.0054277899140995
Eval: 2022-04-19 11:29:02.099924: total loss: 1.0810309700407041, mse:4.683873722447339, ic :0.16320785397694093, sharpe5:14.435160285830497, irr5:462.6597900390625, ndcg5:0.8465169248661458, pnl5:5.669289588928223 
train 30, step: 0, loss: 1.2554324523325133, grad_norm: 0.0390550593102213, ic: 0.9915852446667247
train 30, step: 500, loss: 1.9378658246390428, grad_norm: 0.3087945271894075, ic: 0.1589793510880177
train 30, step: 1000, loss: 3.4596449908088234, grad_norm: 1.75358733940524, ic: 0.4197967305927601
train 30, step: 1500, loss: 1.0873466847474094, grad_norm: 0.30048973466159234, ic: 0.14299526693018763
train 30, step: 2000, loss: 1.0947954318069937, grad_norm: 0.21034818357751756, ic: 0.4386822220426242
Epoch 30: 2022-04-19 11:29:27.150789: train loss: 1.6260501203307598
Eval step 0: eval loss: 1.0064380358494602
Eval: 2022-04-19 11:29:29.413253: total loss: 1.080853328260168, mse:4.671304697352192, ic :0.17198215630694774, sharpe5:15.41949909567833, irr5:502.7886962890625, ndcg5:0.8413430261734001, pnl5:5.074592590332031 
train 31, step: 0, loss: 1.1696392065469001, grad_norm: 0.2989751534283381, ic: 0.16774715110682553
train 31, step: 500, loss: 0.8186549438380971, grad_norm: 0.1070308472354634, ic: 0.2562743600600148
train 31, step: 1000, loss: 5.084180447470818, grad_norm: 0.8876955544333828, ic: 0.010442459344893405
train 31, step: 1500, loss: 1.6812029076506956, grad_norm: 0.30396314944822467, ic: 0.2811900279641959
train 31, step: 2000, loss: 0.8958183668582376, grad_norm: 0.9082043964471527, ic: 0.12246099218112311
Epoch 31: 2022-04-19 11:29:53.956369: train loss: 1.6259371246265426
Eval step 0: eval loss: 1.0034060124160742
Eval: 2022-04-19 11:29:56.236625: total loss: 1.0835369094585543, mse:4.687481226476405, ic :0.15698965501334994, sharpe5:13.191354998946188, irr5:410.2459716796875, ndcg5:0.852450849798491, pnl5:5.060548782348633 
train 32, step: 0, loss: 0.8570287327047005, grad_norm: 0.45011337930644896, ic: 0.11525666161918657
train 32, step: 500, loss: 1.110887201820932, grad_norm: 0.33483202106527504, ic: 0.0745730237469934
train 32, step: 1000, loss: 1.3784853583405632, grad_norm: 0.04918046881646529, ic: 0.08729352290022899
train 32, step: 1500, loss: 2.0982463824859714, grad_norm: 0.8586394125642919, ic: 0.4514905696429291
train 32, step: 2000, loss: 1.0714689141906488, grad_norm: 0.37323442002225604, ic: 0.46446325789920595
Epoch 32: 2022-04-19 11:30:20.910963: train loss: 1.623939096158641
Eval step 0: eval loss: 1.001891929140337
Eval: 2022-04-19 11:30:23.274916: total loss: 1.0807515566526007, mse:4.675898708644994, ic :0.16831654070331292, sharpe5:15.289549713134765, irr5:498.7027893066406, ndcg5:0.8533570669511377, pnl5:7.301321506500244 
train 33, step: 0, loss: 1.1657746550324675, grad_norm: 0.01341748799943921, ic: 0.030134124476798963
train 33, step: 500, loss: 3.156267264363951, grad_norm: 0.3652647581963034, ic: 0.5204445532718238
train 33, step: 1000, loss: 5.233360740622724, grad_norm: 2.22691361526989, ic: -0.016727005151020748
train 33, step: 1500, loss: 1.3042236328125, grad_norm: 0.99214894382657, ic: 0.0034719612354895298
train 33, step: 2000, loss: 1.8714824824370155, grad_norm: 0.40872543127699806, ic: 0.06473244399749334
Epoch 33: 2022-04-19 11:30:48.143312: train loss: 1.6260377765888914
Eval step 0: eval loss: 1.0080659614229528
Eval: 2022-04-19 11:30:50.433909: total loss: 1.0852712375180689, mse:4.688905876547945, ic :0.16322334344610515, sharpe5:14.657905926704405, irr5:468.7159729003906, ndcg5:0.8495414006926859, pnl5:5.596407890319824 
train 34, step: 0, loss: 0.717522622666155, grad_norm: 0.3522067184430322, ic: 0.17335547156471054
train 34, step: 500, loss: 1.8734738015379582, grad_norm: 2.722486439100119, ic: 0.7756064021511478
train 34, step: 1000, loss: 0.6886177431303879, grad_norm: 0.028686612386597213, ic: 0.4818321010509782
train 34, step: 1500, loss: 1.6659358097956731, grad_norm: 2.20319837611117, ic: 0.6390927665478651
train 34, step: 2000, loss: 3.008235422351215, grad_norm: 0.6190709704938773, ic: 0.08302267773451658
Epoch 34: 2022-04-19 11:31:14.385603: train loss: 1.625509803709209
Eval step 0: eval loss: 1.004469483321814
Eval: 2022-04-19 11:31:16.687331: total loss: 1.081793918603686, mse:4.69048008967531, ic :0.16057203252348673, sharpe5:14.358457061648368, irr5:457.0170593261719, ndcg5:0.8549978438858795, pnl5:5.30825138092041 
train 35, step: 0, loss: 1.0500818566430974, grad_norm: 0.75847208871799, ic: 0.008652996623696204
train 35, step: 500, loss: 3.2985210996685606, grad_norm: 1.5508129959006098, ic: -0.09591372592501654
train 35, step: 1000, loss: 1.3369757673209737, grad_norm: 0.241693738998091, ic: 0.5110754592489035
train 35, step: 1500, loss: 1.6456422797975534, grad_norm: 0.4226135524563251, ic: 0.04845929708964358
train 35, step: 2000, loss: 1.2871537300327174, grad_norm: 0.10997835570775875, ic: -0.04373101475273039
Epoch 35: 2022-04-19 11:31:41.569240: train loss: 1.62497996144737
Eval step 0: eval loss: 0.999613090462908
Eval: 2022-04-19 11:31:43.896606: total loss: 1.0831533051853437, mse:4.696990316346148, ic :0.14906427087788438, sharpe5:12.96011399924755, irr5:390.1101989746094, ndcg5:0.8606414535250023, pnl5:3.7480509281158447 
train 36, step: 0, loss: 8.971045345797158, grad_norm: 1.3650911626773288, ic: -0.10037874365891389
train 36, step: 500, loss: 0.8631043820377555, grad_norm: 0.011651374541362173, ic: 0.07089910846419645
train 36, step: 1000, loss: 1.942280035975494, grad_norm: 2.4604896402753114, ic: 0.014882958572389594
train 36, step: 1500, loss: 1.0514250542031793, grad_norm: 0.1358512933357029, ic: 0.0713429224319212
train 36, step: 2000, loss: 2.1728735480889494, grad_norm: 1.6043832117939423, ic: 0.3863610356836174
Epoch 36: 2022-04-19 11:32:08.578672: train loss: 1.624209089059259
Eval step 0: eval loss: 1.0144525721802593
Eval: 2022-04-19 11:32:10.868824: total loss: 1.0839663855777486, mse:4.683572415686593, ic :0.16766002242452427, sharpe5:14.303139325976371, irr5:484.5664978027344, ndcg5:0.8428322676372383, pnl5:4.274541854858398 
train 37, step: 0, loss: 1.2015902419816724, grad_norm: 0.37589394180887103, ic: 0.15999714330548392
train 37, step: 500, loss: 2.34202257844917, grad_norm: 0.046538319316644955, ic: 0.15416797196003618
train 37, step: 1000, loss: 0.7574129180182746, grad_norm: 0.38557946918850755, ic: 0.16512572161676067
train 37, step: 1500, loss: 3.09904983443052, grad_norm: 1.048297134610627, ic: 0.20071491043535972
train 37, step: 2000, loss: 3.126204550855513, grad_norm: 1.8660927380436676, ic: -0.0015207153419734207
Epoch 37: 2022-04-19 11:32:35.466348: train loss: 1.6247605642214293
Eval step 0: eval loss: 1.0045221297599065
Eval: 2022-04-19 11:32:37.759296: total loss: 1.080146435117671, mse:4.677240303709278, ic :0.16770887151852398, sharpe5:15.186685967445372, irr5:507.6611328125, ndcg5:0.8533374906536799, pnl5:5.487166404724121 
train 38, step: 0, loss: 1.343196984493371, grad_norm: 0.4143557793676498, ic: -0.2633846172609392
train 38, step: 500, loss: 1.6883308351501938, grad_norm: 1.1524773159088109, ic: 0.16761553601882606
train 38, step: 1000, loss: 1.8638105729575807, grad_norm: 0.7350423756737349, ic: -0.009611765462842228
train 38, step: 1500, loss: 1.0690273666853367, grad_norm: 0.3102060567571266, ic: 0.4852547659719973
train 38, step: 2000, loss: 0.7559620212298525, grad_norm: 0.09058479874992324, ic: 0.5672496237626727
Epoch 38: 2022-04-19 11:33:02.576801: train loss: 1.6249944394290186
Eval step 0: eval loss: 0.997844902950566
Eval: 2022-04-19 11:33:04.868565: total loss: 1.0791381435792022, mse:4.692461552393225, ic :0.16840361587799832, sharpe5:15.610962027311324, irr5:514.3226318359375, ndcg5:0.851220962496225, pnl5:4.773522853851318 
train 39, step: 0, loss: 0.8740657667789791, grad_norm: 0.03941897649225952, ic: 0.5407655300717207
train 39, step: 500, loss: 1.2523101341657479, grad_norm: 0.47393072890233545, ic: 0.0355299903708273
train 39, step: 1000, loss: 1.3929327762488164, grad_norm: 0.35260699490617786, ic: 0.07411075467219
train 39, step: 1500, loss: 2.4513580220878324, grad_norm: 0.5363418583728494, ic: -0.05785072495557606
train 39, step: 2000, loss: 2.9499471525657195, grad_norm: 2.4671262759777215, ic: 0.19574238042085543
Epoch 39: 2022-04-19 11:33:29.810819: train loss: 1.6232351423996716
Eval step 0: eval loss: 1.0047266087825828
Eval: 2022-04-19 11:33:32.028021: total loss: 1.0794437225769091, mse:4.676237641032369, ic :0.1700459015452728, sharpe5:14.635904640555381, irr5:508.4870300292969, ndcg5:0.8531479704274249, pnl5:4.9568867683410645 

Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='SparseAdjSeqTimeDataset', dout=0.3, epochs=40, gnn_layers=2, gpu=0, hidden_dim=128, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=3, mask_adj=True, mask_type='soft', model_type='GNNModel', normalize_adj=False, num_days=1, num_heads=1, print_inteval=500, relation_num=1, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_250_0.8/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=False)
load 2305 train graphs successful!
load 126 test graphs successful!
67777
GNNModel(
  (fc1): Linear(in_features=9, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
  (fc4): Linear(in_features=128, out_features=1, bias=True)
  (gnns): ModuleList(
    (0): GraphConv(128, 128)
    (1): GraphConv(128, 128)
  )
  (dropout): Dropout(p=0.3, inplace=False)
  (relu): LeakyReLU(negative_slope=0.01)
)
train 0, step: 0, loss: 2.0732419945034586, grad_norm: 0.47046307914421737, ic: 0.0022216567802230934
train 0, step: 500, loss: 1.3668598814205837, grad_norm: 0.8518355789849245, ic: -0.012820955442348458
train 0, step: 1000, loss: 1.5062704382863645, grad_norm: 0.03211137659182093, ic: 0.17245702045943173
train 0, step: 1500, loss: 1.1838262559449462, grad_norm: 0.09791152878739581, ic: 0.0579279009799067
train 0, step: 2000, loss: 1.5628526268935785, grad_norm: 0.052016360673772986, ic: -0.020855077872263462
Epoch 0: 2022-04-04 02:07:00.161427: train loss: 1.6479031751551696
Eval step 0: eval loss: 1.0121277080453528
Eval: 2022-04-04 02:07:04.835250: total loss: 1.0920666726012387, mse:4.888885680176522, ic :0.018436182810536873, sharpe5:-0.1615940413903445, irr5:-3.226522445678711, ndcg5:0.849760541678801, pnl5:1.0376548767089844 
train 1, step: 0, loss: 0.6379261583384901, grad_norm: 0.049687363490400996, ic: 0.05036476954437738
train 1, step: 500, loss: 1.2569105542057641, grad_norm: 0.30530362344143075, ic: 0.24936435201016655
train 1, step: 1000, loss: 0.8757913966302918, grad_norm: 0.06292940968062119, ic: 0.0895330384310865
train 1, step: 1500, loss: 1.861523325850324, grad_norm: 0.5636884097388103, ic: 0.08473624148506925
train 1, step: 2000, loss: 1.3684001648042687, grad_norm: 0.23943992284627075, ic: 0.1555785450668073
Epoch 1: 2022-04-04 02:07:47.634304: train loss: 1.6454214256978887
Eval step 0: eval loss: 1.004247069798249
Eval: 2022-04-04 02:07:52.432904: total loss: 1.0890158804396406, mse:4.879241346552923, ic :0.047624479537462086, sharpe5:-0.4855964036285877, irr5:-8.010457992553711, ndcg5:0.852287462321567, pnl5:0.8900721669197083 
train 2, step: 0, loss: 1.3273127316899944, grad_norm: 0.509997836330851, ic: 0.044319460405213666
train 2, step: 500, loss: 0.9498376224037367, grad_norm: 0.27691524850143956, ic: 0.0876836964893859
train 2, step: 1000, loss: 3.050287389910909, grad_norm: 1.1994364105329633, ic: 0.19063569249362014
train 2, step: 1500, loss: 2.297265315226011, grad_norm: 0.8987153085099397, ic: 0.06840060783717387
train 2, step: 2000, loss: 1.4542052673689188, grad_norm: 0.2753342719333513, ic: -0.10763536504315979
Epoch 2: 2022-04-04 02:08:35.048052: train loss: 1.644359131558742
Eval step 0: eval loss: 0.9990031888699644
Eval: 2022-04-04 02:08:40.070291: total loss: 1.0890478603491043, mse:4.879256096118927, ic :0.047756827814014885, sharpe5:6.661210286915302, irr5:192.04397583007812, ndcg5:0.8385588427541026, pnl5:2.6214303970336914 
train 3, step: 0, loss: 1.832747794328615, grad_norm: 0.07164269787629622, ic: -0.15300790277319926
train 3, step: 500, loss: 0.7794810858920198, grad_norm: 0.020172902816392353, ic: 0.07498108456488031
train 3, step: 1000, loss: 1.3836426524448249, grad_norm: 0.500558551067445, ic: 0.22771798414728056
train 3, step: 1500, loss: 2.6121445705239754, grad_norm: 0.4426692237073294, ic: -0.05341149493493293
train 3, step: 2000, loss: 1.360019568241004, grad_norm: 0.1648172157493585, ic: 0.08014263597338973
Epoch 3: 2022-04-04 02:09:22.855556: train loss: 1.6449428615830206
Eval step 0: eval loss: 1.0044619624020865
Eval: 2022-04-04 02:09:27.675885: total loss: 1.0923051519874807, mse:4.884967973792017, ic :0.043745221612927404, sharpe5:0.8427053529024123, irr5:13.82393741607666, ndcg5:0.8468221399134958, pnl5:1.1723321676254272 
train 4, step: 0, loss: 1.1474785884584284, grad_norm: 0.1593725577274797, ic: 0.0802846100427484
train 4, step: 500, loss: 0.9916090059958643, grad_norm: 0.00532100204935037, ic: 0.12741124065926598
train 4, step: 1000, loss: 1.330946025368278, grad_norm: 0.06581184664842572, ic: 0.06995978673751044
train 4, step: 1500, loss: 1.0721329909104567, grad_norm: 0.11533952600282141, ic: 0.27936995666492054
train 4, step: 2000, loss: 4.171690982125295, grad_norm: 0.8914312072642354, ic: -0.015752049652560197
Epoch 4: 2022-04-04 02:10:10.345652: train loss: 1.6442164051580446
Eval step 0: eval loss: 1.0000926294472419
Eval: 2022-04-04 02:10:15.140008: total loss: 1.0923976377418654, mse:4.870782786651572, ic :0.06769213584814021, sharpe5:6.65065233707428, irr5:201.85964965820312, ndcg5:0.8608577412992874, pnl5:2.6360859870910645 
train 5, step: 0, loss: 0.9956445163747144, grad_norm: 0.1715674781243931, ic: -0.07801051040154247
train 5, step: 500, loss: 0.7891521725044431, grad_norm: 0.018739102937912866, ic: 0.1437472890381366
train 5, step: 1000, loss: 1.1220376882619538, grad_norm: 0.05369214743780519, ic: 0.07225805460927648
train 5, step: 1500, loss: 1.7735569899644308, grad_norm: 0.4075805478302316, ic: -0.061314567266118086
train 5, step: 2000, loss: 2.1715966304185472, grad_norm: 0.8459635894690456, ic: 0.05405881010793808
Epoch 5: 2022-04-04 02:10:58.026551: train loss: 1.6420564533850437
Eval step 0: eval loss: 1.004094851525474
Eval: 2022-04-04 02:11:02.821321: total loss: 1.0874477041038657, mse:4.717225078690638, ic :0.12041018000039247, sharpe5:6.5249534717202184, irr5:192.31153869628906, ndcg5:0.8350434465956929, pnl5:3.2543718814849854 
train 6, step: 0, loss: 0.7803678519100787, grad_norm: 0.011792642921082671, ic: -0.06512183267698006
train 6, step: 500, loss: 1.355577346177129, grad_norm: 0.7842848794898762, ic: 0.026235328977845442
train 6, step: 1000, loss: 1.2262858828185421, grad_norm: 0.18902952953510282, ic: 0.22504592026954184
train 6, step: 1500, loss: 1.0582698260613208, grad_norm: 0.3304491453175159, ic: 0.0873142910198981
train 6, step: 2000, loss: 2.3105240991970133, grad_norm: 1.1805697960297323, ic: 0.08772145147910469
Epoch 6: 2022-04-04 02:11:45.681755: train loss: 1.6377073588208397
Eval step 0: eval loss: 0.9994245532187993
Eval: 2022-04-04 02:11:50.713768: total loss: 1.08558894313322, mse:4.718717780893724, ic :0.11794733330039997, sharpe5:6.060297262072563, irr5:181.0684356689453, ndcg5:0.8527561635279577, pnl5:3.132927417755127 
train 7, step: 0, loss: 1.4526689959907846, grad_norm: 0.53638565619728, ic: 0.2067711237098276
train 7, step: 500, loss: 1.3501697387195435, grad_norm: 0.10967471914004114, ic: 0.1859132254591827
train 7, step: 1000, loss: 0.640452930094967, grad_norm: 0.018390957007418527, ic: 0.28962699154012067
train 7, step: 1500, loss: 1.0027020352671718, grad_norm: 0.13135027443908925, ic: 0.11371756386546447
train 7, step: 2000, loss: 1.5726135866514792, grad_norm: 0.5819734261970004, ic: 0.4197624672823492
Epoch 7: 2022-04-04 02:12:33.026023: train loss: 1.6376847025994017
Eval step 0: eval loss: 0.9942749087718864
Eval: 2022-04-04 02:12:37.773040: total loss: 1.0847488984477311, mse:4.728391239043243, ic :0.118402731462083, sharpe5:7.199299182593822, irr5:204.3265838623047, ndcg5:0.8481781237244564, pnl5:3.095161199569702 
train 8, step: 0, loss: 1.206925571435624, grad_norm: 0.08357344733511178, ic: 0.053175342190797004
train 8, step: 500, loss: 5.528750045919867, grad_norm: 1.2496757798999105, ic: 0.15918409081428664
train 8, step: 1000, loss: 1.883702759843873, grad_norm: 0.5728171566100517, ic: 0.051006450089051025
train 8, step: 1500, loss: 1.0712333281637718, grad_norm: 0.3771973441744613, ic: 0.6417430785378491
train 8, step: 2000, loss: 1.1297874450683594, grad_norm: 0.5590819385846681, ic: -0.008616193405027872
Epoch 8: 2022-04-04 02:13:20.517605: train loss: 1.6378390595203856
Eval step 0: eval loss: 0.9985510980285676
Eval: 2022-04-04 02:13:25.295646: total loss: 1.0874884804113212, mse:4.719706893328972, ic :0.1187890312536344, sharpe5:6.748788819015026, irr5:196.2686309814453, ndcg5:0.8534609157205933, pnl5:3.0941596031188965 
train 9, step: 0, loss: 1.1214460398754902, grad_norm: 0.032199104717896804, ic: 0.43589752489118505
train 9, step: 500, loss: 3.183497134227549, grad_norm: 1.142532265138501, ic: 0.05560391005043498
train 9, step: 1000, loss: 0.8845204328687842, grad_norm: 0.18141190852701866, ic: 0.21660867894152858
train 9, step: 1500, loss: 2.1598080429497566, grad_norm: 1.0037346776983396, ic: -0.0813993941456859
train 9, step: 2000, loss: 0.605462987436074, grad_norm: 0.005561343906223002, ic: 0.04433385649780342
Epoch 9: 2022-04-04 02:14:08.205465: train loss: 1.6371436860588477
Eval step 0: eval loss: 0.9963814733906002
Eval: 2022-04-04 02:14:12.895276: total loss: 1.0905884306890177, mse:4.784205830657264, ic :0.11394078510417452, sharpe5:7.744742177724838, irr5:234.75672912597656, ndcg5:0.8351225075465597, pnl5:2.595789670944214 
train 10, step: 0, loss: 1.3085640307995194, grad_norm: 0.03775269075292282, ic: 0.37713593808212126
train 10, step: 500, loss: 0.8975725499312927, grad_norm: 0.006612469286200885, ic: 0.10154175389217393
train 10, step: 1000, loss: 1.5298575243286845, grad_norm: 0.5295995778745564, ic: 0.03089002295482017
train 10, step: 1500, loss: 3.042454153041404, grad_norm: 1.3427230538544441, ic: 0.03027568449491087
train 10, step: 2000, loss: 1.380315253075133, grad_norm: 0.13224028797153559, ic: 0.0433581625877799
Epoch 10: 2022-04-04 02:14:55.848647: train loss: 1.6375843405443224
Eval step 0: eval loss: 1.0022951018628226
Eval: 2022-04-04 02:15:00.702759: total loss: 1.0858194696533094, mse:4.715662658049901, ic :0.11927255208931142, sharpe5:6.573459596335888, irr5:186.16273498535156, ndcg5:0.8459018501898786, pnl5:3.0478971004486084 
train 11, step: 0, loss: 4.811903296642885, grad_norm: 1.0774024051380626, ic: 0.09324408671552682
train 11, step: 500, loss: 0.9922512540802612, grad_norm: 0.05923904563143893, ic: 0.041515718985763915
train 11, step: 1000, loss: 1.0410440242717869, grad_norm: 0.3341184931619984, ic: 0.028709091462948422
train 11, step: 1500, loss: 0.6932294661866191, grad_norm: 0.00124395104912176, ic: 0.05819207716349829
train 11, step: 2000, loss: 1.124843123286454, grad_norm: 0.053259687510537085, ic: -0.1860522017611084
Epoch 11: 2022-04-04 02:15:43.693763: train loss: 1.6370110580068704
Eval step 0: eval loss: 0.9913068452968666
Eval: 2022-04-04 02:15:48.443362: total loss: 1.084286600102681, mse:4.72750604912218, ic :0.12066490725933547, sharpe5:7.162991243004798, irr5:208.27491760253906, ndcg5:0.8402756153447519, pnl5:3.1557843685150146 
train 12, step: 0, loss: 1.3868494534220532, grad_norm: 0.2519594349644959, ic: 0.050361020212902466
train 12, step: 500, loss: 0.8159445602308603, grad_norm: 0.34011222120139994, ic: 0.013453025350384763
train 12, step: 1000, loss: 1.2185089997062581, grad_norm: 0.26890213833595955, ic: 0.5738786648323793
train 12, step: 1500, loss: 1.0940280179364965, grad_norm: 0.19461893306858213, ic: -0.10357733054762362
train 12, step: 2000, loss: 1.1152991570074942, grad_norm: 0.05907432761953562, ic: 0.10416379553607666
Epoch 12: 2022-04-04 02:16:31.556786: train loss: 1.6372960287514853
Eval step 0: eval loss: 1.001006067646623
Eval: 2022-04-04 02:16:36.433836: total loss: 1.0866107667655496, mse:4.725452932875094, ic :0.12041153213686626, sharpe5:6.862550101876258, irr5:197.0656280517578, ndcg5:0.8421025621970485, pnl5:2.5912327766418457 
train 13, step: 0, loss: 1.0867193073279962, grad_norm: 0.053185772386886807, ic: 0.4220467725013146
train 13, step: 500, loss: 1.1464785976264313, grad_norm: 0.007303585927896893, ic: -0.16001545508353548
train 13, step: 1000, loss: 1.3874699002077597, grad_norm: 0.40462592538037784, ic: 0.06030521008018003
train 13, step: 1500, loss: 0.7764091317512128, grad_norm: 0.0027157029800175853, ic: -0.053154401366196424
train 13, step: 2000, loss: 1.0389258037514402, grad_norm: 0.024786658274302008, ic: 0.05316779707775316
Epoch 13: 2022-04-04 02:17:19.073597: train loss: 1.6372502390270327
Eval step 0: eval loss: 0.9906923154456292
Eval: 2022-04-04 02:17:23.896841: total loss: 1.085241110867513, mse:4.738010932575525, ic :0.11802582159498703, sharpe5:6.850472049415111, irr5:193.80316162109375, ndcg5:0.857521262843186, pnl5:3.060478687286377 
train 14, step: 0, loss: 1.7696341821702861, grad_norm: 0.5312669776494983, ic: 0.160287842461221
train 14, step: 500, loss: 1.2803060852544084, grad_norm: 0.1790127672705366, ic: 0.19607095508742017
train 14, step: 1000, loss: 1.075726368801653, grad_norm: 0.12627675105460381, ic: 0.11535164567889994
train 14, step: 1500, loss: 0.9722793261944284, grad_norm: 0.09695928254522763, ic: 0.21443348572804533
train 14, step: 2000, loss: 2.2883810569178222, grad_norm: 0.4660668918152405, ic: -0.07246826711608517
Epoch 14: 2022-04-04 02:18:07.192599: train loss: 1.6369737217636413
Eval step 0: eval loss: 1.003383513938257
Eval: 2022-04-04 02:18:12.047601: total loss: 1.0904739898712996, mse:4.731909598431216, ic :0.1155006107917448, sharpe5:6.8522078230977055, irr5:194.24586486816406, ndcg5:0.8392675972976071, pnl5:2.918243408203125 
train 15, step: 0, loss: 0.9773865963874202, grad_norm: 0.16757078964515099, ic: 0.13654501756684279
train 15, step: 500, loss: 1.223663306764467, grad_norm: 0.004636144073680808, ic: 0.05477847849202913
train 15, step: 1000, loss: 1.76094375, grad_norm: 0.06009857456315852, ic: -0.0938001882078131
train 15, step: 1500, loss: 5.42902815037703, grad_norm: 0.8498099543531833, ic: -0.012455753557849163
train 15, step: 2000, loss: 0.9306452720532253, grad_norm: 0.04290030969613838, ic: -0.04386922671318583
Epoch 15: 2022-04-04 02:18:54.678420: train loss: 1.6350796779839991
Eval step 0: eval loss: 1.0062673688248749
Eval: 2022-04-04 02:18:59.444192: total loss: 1.0836425272123236, mse:4.691038896653724, ic :0.14984870933912178, sharpe5:13.947146805524826, irr5:434.42852783203125, ndcg5:0.8514440907356122, pnl5:4.338551998138428 
train 16, step: 0, loss: 6.339609471609646, grad_norm: 1.3148105729141322, ic: 0.10939824176349636
train 16, step: 500, loss: 1.3845235188802083, grad_norm: 0.6525310222847126, ic: -0.021182049189391365
train 16, step: 1000, loss: 0.8319238359941579, grad_norm: 0.13403388608940967, ic: -0.07981250804917332
train 16, step: 1500, loss: 1.2282274008344491, grad_norm: 0.7496782494287086, ic: 0.01601004482440118
train 16, step: 2000, loss: 0.9623001107919964, grad_norm: 0.23247072382138748, ic: 0.5444839485278024
Epoch 16: 2022-04-04 02:19:42.447112: train loss: 1.6296848240841477
Eval step 0: eval loss: 0.9967018517147181
Eval: 2022-04-04 02:19:47.202270: total loss: 1.0818167403346268, mse:4.7076085261194605, ic :0.1451208654242987, sharpe5:12.80396625816822, irr5:395.7577819824219, ndcg5:0.8499236262511553, pnl5:5.181819438934326 
train 17, step: 0, loss: 1.1813716771412481, grad_norm: 0.011773872442753502, ic: 0.13940336597929298
train 17, step: 500, loss: 1.0485760189386215, grad_norm: 0.02412517945007879, ic: -0.028280244125597653
train 17, step: 1000, loss: 3.3772351356229375, grad_norm: 1.184523306571348, ic: -0.017416679288280976
train 17, step: 1500, loss: 0.8844922507079288, grad_norm: 0.008427117670817197, ic: 0.05347334743745066
train 17, step: 2000, loss: 1.0156995530096475, grad_norm: 0.5809533628339474, ic: 0.5518496284333718
Epoch 17: 2022-04-04 02:20:30.163773: train loss: 1.6289404369724292
Eval step 0: eval loss: 1.0025956815264612
Eval: 2022-04-04 02:20:34.815509: total loss: 1.0854648925523862, mse:4.720053278678512, ic :0.15073011230206054, sharpe5:12.815278583765028, irr5:429.636962890625, ndcg5:0.8524350800467384, pnl5:3.4752299785614014 
train 18, step: 0, loss: 0.851882016840417, grad_norm: 0.13085186911044722, ic: 0.01644373795545928
train 18, step: 500, loss: 2.5363406429745274, grad_norm: 1.0742203210347077, ic: 0.0793263372389651
train 18, step: 1000, loss: 1.3581186418053057, grad_norm: 0.33378685780178174, ic: 0.5277509747196387
train 18, step: 1500, loss: 1.7352885208858035, grad_norm: 0.9474725414750398, ic: 0.33302770650995683
train 18, step: 2000, loss: 1.2568542727289138, grad_norm: 0.32153470159458114, ic: 0.23171608977146485
Epoch 18: 2022-04-04 02:21:16.077635: train loss: 1.628661972310092
Eval step 0: eval loss: 1.0040495331630133
Eval: 2022-04-04 02:21:20.659684: total loss: 1.0827483147070096, mse:4.692049990040742, ic :0.1543379920198318, sharpe5:13.326649807691574, irr5:439.7726745605469, ndcg5:0.8480558506527092, pnl5:4.148758411407471 
train 19, step: 0, loss: 2.222666897295811, grad_norm: 1.2234022935854247, ic: 0.23829818098978262
train 19, step: 500, loss: 1.0223610101744185, grad_norm: 0.06272768536984638, ic: 0.04466672931723086
train 19, step: 1000, loss: 0.9917726057803229, grad_norm: 0.41136848997888364, ic: 0.539989791508631
train 19, step: 1500, loss: 1.5765935638804494, grad_norm: 0.16659433560471065, ic: 0.13480085574885003
train 19, step: 2000, loss: 1.7831887748936583, grad_norm: 1.438945242611549, ic: 0.6228627731253147
Epoch 19: 2022-04-04 02:22:01.994807: train loss: 1.6276940072049966
Eval step 0: eval loss: 1.0047965469079119
Eval: 2022-04-04 02:22:06.657603: total loss: 1.081589952323051, mse:4.690474119856568, ic :0.15547871000351568, sharpe5:13.033032574653625, irr5:441.6539306640625, ndcg5:0.8459860985583942, pnl5:3.547023296356201 
train 20, step: 0, loss: 1.2419319438220853, grad_norm: 0.3700176727148734, ic: 0.4632833043799889
train 20, step: 500, loss: 1.2356724629251472, grad_norm: 0.4817077007083869, ic: 0.011022501633907798
train 20, step: 1000, loss: 1.5721034246377052, grad_norm: 0.2776934338631318, ic: 0.14860673985821585
train 20, step: 1500, loss: 0.8569102234113616, grad_norm: 0.3152804764670725, ic: 0.560195061813982
train 20, step: 2000, loss: 1.3515191783612064, grad_norm: 0.11440424103997737, ic: -0.03916617448052172
Epoch 20: 2022-04-04 02:22:48.299064: train loss: 1.6270816616496582
Eval step 0: eval loss: 1.0030515649684044
Eval: 2022-04-04 02:22:52.919126: total loss: 1.0841886430891834, mse:4.701685389368735, ic :0.14447727864970708, sharpe5:10.924856452345848, irr5:344.5299377441406, ndcg5:0.8535112298691093, pnl5:3.396841287612915 
train 21, step: 0, loss: 1.4048799653790087, grad_norm: 0.28762917314571795, ic: 0.33083020788708895
train 21, step: 500, loss: 1.116852950757938, grad_norm: 0.0823248825598586, ic: -0.08314756070737175
train 21, step: 1000, loss: 0.9122168008871713, grad_norm: 0.1906581149223181, ic: 0.10333914506993029
train 21, step: 1500, loss: 0.7396433107117235, grad_norm: 0.1565791146706332, ic: 0.6245768155298334
train 21, step: 2000, loss: 1.1694300087187959, grad_norm: 0.05772862360612449, ic: 0.12392418830370101
Epoch 21: 2022-04-04 02:23:35.536880: train loss: 1.6297513621743436
Eval step 0: eval loss: 1.0065888399322012
Eval: 2022-04-04 02:23:40.158071: total loss: 1.0821087978714699, mse:4.6929607111659175, ic :0.15353813677359315, sharpe5:12.10688711464405, irr5:386.1272888183594, ndcg5:0.8420673408438994, pnl5:4.292379379272461 
train 22, step: 0, loss: 1.0544378642483923, grad_norm: 0.22464745156731633, ic: 0.10124471914777516
train 22, step: 500, loss: 1.0274487112450787, grad_norm: 0.015031715047022609, ic: 0.02330148706013673
train 22, step: 1000, loss: 0.9123591194649006, grad_norm: 0.017777605768521217, ic: 0.13182624703458762
train 22, step: 1500, loss: 1.0110211238682827, grad_norm: 0.009954366703322389, ic: 0.20300013294656344
train 22, step: 2000, loss: 1.0675986356513445, grad_norm: 0.12249293623828987, ic: 0.03475203473135881
Epoch 22: 2022-04-04 02:24:21.920667: train loss: 1.6292361105679025
Eval step 0: eval loss: 1.004399930884676
Eval: 2022-04-04 02:24:26.561124: total loss: 1.085521658096369, mse:4.719005569761783, ic :0.1158711226944773, sharpe5:7.173298995494842, irr5:210.8931884765625, ndcg5:0.8452325634046884, pnl5:2.706076145172119 
train 23, step: 0, loss: 1.2820569671678768, grad_norm: 0.8698520744111864, ic: 0.0035531405952726677
train 23, step: 500, loss: 0.8958208691942824, grad_norm: 0.20269540033019764, ic: 0.5905094847131481
train 23, step: 1000, loss: 2.288072782537639, grad_norm: 0.9495434096400146, ic: 0.06544270539234734
train 23, step: 1500, loss: 0.7845048630517706, grad_norm: 0.38735706193055985, ic: 0.7105582968447868
train 23, step: 2000, loss: 1.4561291476225908, grad_norm: 0.37866918540001787, ic: 0.4189677859941159
Epoch 23: 2022-04-04 02:25:08.136030: train loss: 1.6260043819211667
Eval step 0: eval loss: 1.014294247177791
Eval: 2022-04-04 02:25:12.811938: total loss: 1.087151867945067, mse:4.69801321372255, ic :0.1513030668001362, sharpe5:12.11966657102108, irr5:389.2383728027344, ndcg5:0.8470266273964818, pnl5:3.6905627250671387 
train 24, step: 0, loss: 1.185731362217018, grad_norm: 0.439631242769776, ic: 0.2744283483999994
train 24, step: 500, loss: 1.246175409545433, grad_norm: 0.7458770042829233, ic: -0.006126474362028388
train 24, step: 1000, loss: 1.03556135224133, grad_norm: 0.3785926583850245, ic: 0.119748372458647
train 24, step: 1500, loss: 1.2012779896653543, grad_norm: 0.10678992243181691, ic: 0.059368352374455376
train 24, step: 2000, loss: 1.3666638639991442, grad_norm: 0.38337754379558, ic: 0.44807031684947274
Epoch 24: 2022-04-04 02:25:54.754677: train loss: 1.6276165251897972
Eval step 0: eval loss: 1.0225699586953658
Eval: 2022-04-04 02:25:59.472190: total loss: 1.086983619237167, mse:4.69817561818894, ic :0.15148216079899532, sharpe5:13.013531370162964, irr5:449.9434509277344, ndcg5:0.8442041630526887, pnl5:3.55961275100708 
train 25, step: 0, loss: 1.3407813390820982, grad_norm: 0.44303255122027657, ic: 0.2155330640234807
train 25, step: 500, loss: 1.501918445933949, grad_norm: 1.3900364066959396, ic: 0.11949498763194262
train 25, step: 1000, loss: 1.366084444858755, grad_norm: 0.23588130092646067, ic: 0.27170328523446996
train 25, step: 1500, loss: 2.885849098754085, grad_norm: 1.075027794055706, ic: 0.17819888440000176
train 25, step: 2000, loss: 1.1998636752744265, grad_norm: 0.14461648096844776, ic: 0.13212179814710334
Epoch 25: 2022-04-04 02:26:41.478529: train loss: 1.6268787564371259
Eval step 0: eval loss: 1.0062467345066481
Eval: 2022-04-04 02:26:46.148344: total loss: 1.0816833306694502, mse:4.687025636801055, ic :0.15882192225114936, sharpe5:12.705096210837363, irr5:440.23876953125, ndcg5:0.8383782068265895, pnl5:4.28854513168335 
train 26, step: 0, loss: 1.6211370738636364, grad_norm: 0.24952773800689498, ic: 0.15766066802819276
train 26, step: 500, loss: 1.007338060741064, grad_norm: 0.1596080847287914, ic: -0.0627148560814781
train 26, step: 1000, loss: 1.8065668339534764, grad_norm: 0.5900866402759987, ic: 0.20538283662256274
train 26, step: 1500, loss: 0.9232415165003964, grad_norm: 0.015818745760273215, ic: 0.031683281615601654
train 26, step: 2000, loss: 0.9912820650836615, grad_norm: 0.18689967111752723, ic: 0.13865968538695783
Epoch 26: 2022-04-04 02:27:28.042863: train loss: 1.6262921250500275
Eval step 0: eval loss: 1.0055893932661926
Eval: 2022-04-04 02:27:32.670950: total loss: 1.0815389964595306, mse:4.676543760421409, ic :0.16927219998830906, sharpe5:14.843900461792945, irr5:513.2943115234375, ndcg5:0.8409851645731528, pnl5:3.9911961555480957 
train 27, step: 0, loss: 1.6392039103680347, grad_norm: 0.4298131585599997, ic: 0.652583291710095
train 27, step: 500, loss: 1.5138397928715495, grad_norm: 0.2945221101867207, ic: 0.06508685293855632
train 27, step: 1000, loss: 2.6267285232128983, grad_norm: 1.4912586305781483, ic: 0.4006118789958297
train 27, step: 1500, loss: 0.8760168855178695, grad_norm: 0.7589508918512651, ic: 0.5424984547649554
train 27, step: 2000, loss: 1.3247750981062787, grad_norm: 1.9171533895419455, ic: -0.002599564465658664
Epoch 27: 2022-04-04 02:28:14.491229: train loss: 1.6251630101446877
Eval step 0: eval loss: 1.0070539798907319
Eval: 2022-04-04 02:28:19.148029: total loss: 1.0798194505567302, mse:4.676902573249382, ic :0.17204035940078088, sharpe5:14.394210215806961, irr5:515.0307006835938, ndcg5:0.8461724869275268, pnl5:4.28456449508667 
train 28, step: 0, loss: 1.1576544429083069, grad_norm: 0.36879915941532637, ic: 0.17857477413338652
train 28, step: 500, loss: 2.9593592334225702, grad_norm: 0.9533636248614336, ic: 0.08020159945525249
train 28, step: 1000, loss: 2.785292012243286, grad_norm: 2.282870043506721, ic: -0.04349515751661596
train 28, step: 1500, loss: 1.0213937253542016, grad_norm: 0.008969237860783075, ic: 0.20677126594933098
train 28, step: 2000, loss: 1.7579395382903342, grad_norm: 0.38654750936193644, ic: 0.09053676445705067
Epoch 28: 2022-04-04 02:29:00.577311: train loss: 1.6256458931700273
Eval step 0: eval loss: 1.0135301988711163
Eval: 2022-04-04 02:29:05.231699: total loss: 1.0814324082170563, mse:4.684568371416695, ic :0.16058484774291557, sharpe5:14.43236980497837, irr5:484.5509033203125, ndcg5:0.843703974413726, pnl5:3.757810592651367 
train 29, step: 0, loss: 1.5178948229601024, grad_norm: 0.1617817352338046, ic: 0.06920703672248268
train 29, step: 500, loss: 2.5780711040465403, grad_norm: 2.4561436191414883, ic: -0.028974301689832595
train 29, step: 1000, loss: 1.7147721128892732, grad_norm: 1.1464716201124228, ic: 0.4824958932210423
train 29, step: 1500, loss: 3.9845935864533013, grad_norm: 1.1286764536895337, ic: 0.13010302856809913
train 29, step: 2000, loss: 0.9283804306656233, grad_norm: 0.31198032055061786, ic: 0.46682807765750334
Epoch 29: 2022-04-04 02:29:46.395929: train loss: 1.6256951746906327
Eval step 0: eval loss: 1.0123679917884412
Eval: 2022-04-04 02:29:51.155222: total loss: 1.0820513920446932, mse:4.687255007038218, ic :0.1606712987133037, sharpe5:14.301486793756485, irr5:481.4979553222656, ndcg5:0.831240544762611, pnl5:3.493245840072632 
train 30, step: 0, loss: 1.2541721987958934, grad_norm: 0.2965914847522582, ic: 0.9679626094732033
train 30, step: 500, loss: 1.9665069580078125, grad_norm: 4.709850422156591, ic: 0.1600560880775853
train 30, step: 1000, loss: 3.4640624354552214, grad_norm: 0.7460514895056466, ic: 0.34295248883278073
train 30, step: 1500, loss: 1.0855788789264897, grad_norm: 0.26612044977614363, ic: 0.18139505621568902
train 30, step: 2000, loss: 1.0958892929094952, grad_norm: 0.07390833152605437, ic: 0.4409030374750834
Epoch 30: 2022-04-04 02:30:33.172165: train loss: 1.6274900385721094
Eval step 0: eval loss: 1.0435531961723274
Eval: 2022-04-04 02:30:37.863982: total loss: 1.0920715209133223, mse:4.712209533942718, ic :0.1513933228883759, sharpe5:13.932668466567993, irr5:475.5511779785156, ndcg5:0.8436682440009876, pnl5:4.065634250640869 
train 31, step: 0, loss: 1.1664203637655999, grad_norm: 0.3083680300299758, ic: 0.14827414950137496
train 31, step: 500, loss: 0.8283396984509592, grad_norm: 1.1492345409768392, ic: 0.2014115891665692
train 31, step: 1000, loss: 5.183055690661479, grad_norm: 1.2379960618530894, ic: -0.11603982096828308
train 31, step: 1500, loss: 1.6637923227395672, grad_norm: 0.4795712848280688, ic: 0.29009034057297284
train 31, step: 2000, loss: 0.9802586581058429, grad_norm: 0.39967442869369946, ic: 0.1902359596862785
Epoch 31: 2022-04-04 02:31:19.597389: train loss: 1.6259364693228062
Eval step 0: eval loss: 1.0138907530484793
Eval: 2022-04-04 02:31:24.249876: total loss: 1.0834710380950447, mse:4.677692539294132, ic :0.16360969839876358, sharpe5:14.566932467222212, irr5:487.8121337890625, ndcg5:0.8514442985600744, pnl5:4.288657188415527 
train 32, step: 0, loss: 0.8892480764902388, grad_norm: 0.667724257901703, ic: 0.11282502722375998
train 32, step: 500, loss: 1.105681070467321, grad_norm: 0.47623143284047725, ic: 0.1605048346547493
train 32, step: 1000, loss: 1.3779992929958622, grad_norm: 0.023314160318479035, ic: 0.06794232768774584
train 32, step: 1500, loss: 2.0723117320530187, grad_norm: 0.6233109984202306, ic: 0.4308651354247133
train 32, step: 2000, loss: 1.0755750391311512, grad_norm: 0.41005965721706517, ic: 0.4678779561387291
Epoch 32: 2022-04-04 02:32:06.250619: train loss: 1.6228184212997017
Eval step 0: eval loss: 1.015175544694576
Eval: 2022-04-04 02:32:10.807641: total loss: 1.0823638461133998, mse:4.680660513195524, ic :0.1630584412268857, sharpe5:14.289486780166625, irr5:489.7812805175781, ndcg5:0.8673159933874818, pnl5:4.053488731384277 
train 33, step: 0, loss: 1.1646315397607907, grad_norm: 0.020637131929315433, ic: 0.03089266046201193
train 33, step: 500, loss: 3.163281099875096, grad_norm: 0.4814741830784942, ic: 0.51524895113127
train 33, step: 1000, loss: 5.234239148989439, grad_norm: 3.1995425607967403, ic: 0.0408906012209439
train 33, step: 1500, loss: 1.3220406881192834, grad_norm: 0.9593087165580132, ic: 0.021217278726439096
train 33, step: 2000, loss: 1.8590918725775194, grad_norm: 0.3208983505602081, ic: 0.07838895780703278
Epoch 33: 2022-04-04 02:32:52.721397: train loss: 1.6254482894854918
Eval step 0: eval loss: 1.0204714935286663
Eval: 2022-04-04 02:32:57.301766: total loss: 1.0895187480371211, mse:4.691440707944087, ic :0.17050010645572597, sharpe5:15.533670437335967, irr5:526.5590209960938, ndcg5:0.8450926806371539, pnl5:6.616663932800293 
train 34, step: 0, loss: 0.724419595322405, grad_norm: 0.3242208503552194, ic: 0.1354853957354588
train 34, step: 500, loss: 1.815620325355273, grad_norm: 0.7809345399059177, ic: 0.8827871859377586
train 34, step: 1000, loss: 0.691378594760237, grad_norm: 0.3728507363302878, ic: 0.4735230441245988
train 34, step: 1500, loss: 1.6640574919871796, grad_norm: 1.3614648955965796, ic: 0.6382115274606195
train 34, step: 2000, loss: 2.985944417988056, grad_norm: 0.5218198501485455, ic: 0.09658133463816941
Epoch 34: 2022-04-04 02:33:39.646365: train loss: 1.6252039301426469
Eval step 0: eval loss: 1.0155042795961688
Eval: 2022-04-04 02:33:44.341479: total loss: 1.0832823216027179, mse:4.689725815256507, ic :0.15582404744803532, sharpe5:13.06156074821949, irr5:413.3708190917969, ndcg5:0.8590296692849383, pnl5:3.8655214309692383 
train 35, step: 0, loss: 1.0529986031447784, grad_norm: 0.6824307427446706, ic: -0.01857914199547797
train 35, step: 500, loss: 3.336504941998106, grad_norm: 1.9577518620524645, ic: -0.11941765411691707
train 35, step: 1000, loss: 1.3507969775543691, grad_norm: 0.17417088137204662, ic: 0.49856858279913296
train 35, step: 1500, loss: 1.630153446681767, grad_norm: 0.4214725040769389, ic: 0.10856959869271876
train 35, step: 2000, loss: 1.294652737682833, grad_norm: 0.06819516420651975, ic: -0.11059297112125692
Epoch 35: 2022-04-04 02:34:26.481434: train loss: 1.6254370058815533
Eval step 0: eval loss: 1.0081513913572933
Eval: 2022-04-04 02:34:31.142895: total loss: 1.0814094284056952, mse:4.675526065183846, ic :0.16734603258319042, sharpe5:14.658726990222931, irr5:497.1864318847656, ndcg5:0.8403357262700789, pnl5:3.918686866760254 
train 36, step: 0, loss: 8.960498162490135, grad_norm: 1.2806868015512023, ic: -0.2067742170891691
train 36, step: 500, loss: 0.8571272798779334, grad_norm: 0.013091568528410768, ic: 0.10176710618627402
train 36, step: 1000, loss: 1.9877809101325037, grad_norm: 2.5408316258342674, ic: 0.09125499846511195
train 36, step: 1500, loss: 1.0540086872193655, grad_norm: 0.14502485830598766, ic: 0.0990890003543082
train 36, step: 2000, loss: 2.1403623225058857, grad_norm: 1.134738054595885, ic: 0.39437299843563905
Epoch 36: 2022-04-04 02:35:12.389492: train loss: 1.6241683014748012
Eval step 0: eval loss: 1.0206554025144812
Eval: 2022-04-04 02:35:17.028073: total loss: 1.0889778403253023, mse:4.696628548329519, ic :0.16205598403257807, sharpe5:15.321684701442718, irr5:497.0389099121094, ndcg5:0.8440315582962079, pnl5:6.595047950744629 
train 37, step: 0, loss: 1.1743824053193013, grad_norm: 0.20576726412968205, ic: 0.17749032443533574
train 37, step: 500, loss: 2.333292676996888, grad_norm: 0.040004653856886216, ic: 0.19120474791344483
train 37, step: 1000, loss: 0.7691045842722366, grad_norm: 0.421806487711821, ic: 0.14167558847212036
train 37, step: 1500, loss: 3.102066892052665, grad_norm: 1.3553539512452697, ic: 0.2522468178861452
train 37, step: 2000, loss: 3.122631000475285, grad_norm: 2.4827105254728434, ic: 0.02201520142848237
Epoch 37: 2022-04-04 02:35:58.693825: train loss: 1.6240507487940565
Eval step 0: eval loss: 1.0113997858659163
Eval: 2022-04-04 02:36:03.351989: total loss: 1.080202998913154, mse:4.671192693245355, ic :0.17136668760155382, sharpe5:15.85576854765415, irr5:536.514404296875, ndcg5:0.8641286089317401, pnl5:4.79964542388916 
train 38, step: 0, loss: 1.3564170143821024, grad_norm: 1.5598748776449793, ic: -0.17182487724954448
train 38, step: 500, loss: 1.674554679929748, grad_norm: 1.0467486744115158, ic: 0.20939830473058557
train 38, step: 1000, loss: 1.8233304079929302, grad_norm: 0.7205318395499047, ic: 0.13878814293564384
train 38, step: 1500, loss: 1.0933338443487328, grad_norm: 0.3004589387242523, ic: 0.46686523710116123
train 38, step: 2000, loss: 0.7507131652413408, grad_norm: 0.41747804474292, ic: 0.5782212799682085
Epoch 38: 2022-04-04 02:36:45.603035: train loss: 1.623061987117082
Eval step 0: eval loss: 1.0040082002451947
Eval: 2022-04-04 02:36:50.200118: total loss: 1.0791083692298142, mse:4.6751559490390635, ic :0.17462112826158738, sharpe5:15.687291610836981, irr5:551.8973999023438, ndcg5:0.8467968882492185, pnl5:4.248368740081787 
train 39, step: 0, loss: 0.8681078484461394, grad_norm: 0.32560076136366584, ic: 0.5390932614917121
train 39, step: 500, loss: 1.2611682099538892, grad_norm: 1.5432061921483855, ic: 0.012155701677325732
train 39, step: 1000, loss: 1.3907600171638257, grad_norm: 0.32520005276174196, ic: 0.07397227816714524
train 39, step: 1500, loss: 2.4422903472799002, grad_norm: 0.6455398506726566, ic: -0.07690039614958491
train 39, step: 2000, loss: 2.8942125576706053, grad_norm: 1.508945524209616, ic: 0.24663722617691947
Epoch 39: 2022-04-04 02:37:31.621297: train loss: 1.6227606987624956
Eval step 0: eval loss: 1.0054027201816744
Eval: 2022-04-04 02:37:36.266310: total loss: 1.0800180018654955, mse:4.681397288341662, ic :0.16269482767797602, sharpe5:13.309179505705833, irr5:433.77099609375, ndcg5:0.8427081662910227, pnl5:3.565180778503418 

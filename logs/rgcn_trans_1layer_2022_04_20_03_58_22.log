Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='AdjSeqTimeDataset', dout=0.3, epochs=40, glstm_layers=1, gnn_layers=1, gpu=0, graph_attn=True, hidden_dim=128, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=3, mask_adj=True, mask_type='soft', model_type='RGCNModel', normalize_adj=True, num_days=1, num_heads=1, print_inteval=500, relation_num=1, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_250_0.8/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
77864
RGCNModel(
  (fc1): Linear(in_features=9, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
  (fc4): Linear(in_features=128, out_features=1, bias=True)
  (gnns): ModuleList(
    (0): RGCN(
      (attention): ModuleList(
        (0): GraphAttentionLayer (128 -> 128)
      )
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
    )
  )
  (dropout): Dropout(p=0.3, inplace=False)
  (relu): LeakyReLU(negative_slope=0.01)
)
train 0, step: 0, loss: 2.064741461833004, grad_norm: 0.499221244988675, ic: 0.08046957104879454
train 0, step: 500, loss: 1.367417018100834, grad_norm: 0.8734838723456847, ic: -0.058243857778082594
train 0, step: 1000, loss: 1.505662384282938, grad_norm: 0.03288232447855562, ic: 0.0728852451362264
train 0, step: 1500, loss: 1.1826400815478477, grad_norm: 0.09716930828166247, ic: -0.012439093957950642
train 0, step: 2000, loss: 1.5527590309701316, grad_norm: 0.0409029762215397, ic: -0.05030907489587142
Epoch 0: 2022-04-20 15:58:50.470393: train loss: 1.6477852470892107
Eval step 0: eval loss: 1.0125364089652449
Eval: 2022-04-20 15:58:52.862805: total loss: 1.0915767037406194, mse:4.888726348494811, ic :0.012654967296258167, sharpe5:3.731846493333578, irr5:76.54743194580078, ndcg5:0.8429560961616527, pnl5:1.703021764755249 
train 1, step: 0, loss: 0.6409788226137066, grad_norm: 0.05334172301616508, ic: 0.061164567761431546
train 1, step: 500, loss: 1.2825438798592494, grad_norm: 0.34369396615856285, ic: 0.22194488075019841
train 1, step: 1000, loss: 0.8784516782607568, grad_norm: 0.06149158066299502, ic: 0.09176944071645965
train 1, step: 1500, loss: 1.8575733463938644, grad_norm: 0.561331425734227, ic: 0.047788422674544376
train 1, step: 2000, loss: 1.3793955594073029, grad_norm: 0.22625098892833254, ic: 0.06871550063007276
Epoch 1: 2022-04-20 15:59:16.178839: train loss: 1.6468190231628872
Eval step 0: eval loss: 1.0104697630743154
Eval: 2022-04-20 15:59:18.649431: total loss: 1.089934819333989, mse:4.8835011216075355, ic :0.04984797428155218, sharpe5:2.6795802851021286, irr5:32.585304260253906, ndcg5:0.8562348066723049, pnl5:1.2079410552978516 
train 2, step: 0, loss: 1.3287609745992701, grad_norm: 0.4804276972302001, ic: 0.010091708966001034
train 2, step: 500, loss: 0.9466491606600911, grad_norm: 0.25642236562680387, ic: 0.07469322729509548
train 2, step: 1000, loss: 3.002467440832427, grad_norm: 1.038174937679966, ic: 0.08253251602630741
train 2, step: 1500, loss: 2.306733557196669, grad_norm: 0.9125680503228917, ic: 0.09498886600800832
train 2, step: 2000, loss: 1.4546373543540474, grad_norm: 0.283805740493907, ic: -0.11863977596480932
Epoch 2: 2022-04-20 15:59:42.033929: train loss: 1.6452800371521952
Eval step 0: eval loss: 0.9972555713944838
Eval: 2022-04-20 15:59:44.485692: total loss: 1.0889201651190787, mse:4.880278123564087, ic :0.05006574994538549, sharpe5:7.587217168807983, irr5:217.80221557617188, ndcg5:0.857243765842183, pnl5:2.8903424739837646 
train 3, step: 0, loss: 1.8280704559583014, grad_norm: 0.061259328866502524, ic: -0.12556991053722905
train 3, step: 500, loss: 0.7805068397275227, grad_norm: 0.022086533536774908, ic: 0.09866954378928576
train 3, step: 1000, loss: 1.4040116726717085, grad_norm: 0.3956103287755333, ic: 0.22442120330566612
train 3, step: 1500, loss: 2.619461236586427, grad_norm: 0.4466325010798731, ic: -0.06901449282084822
train 3, step: 2000, loss: 1.3457623106060606, grad_norm: 0.17824101190542424, ic: 0.0711946376945554
Epoch 3: 2022-04-20 16:00:07.332867: train loss: 1.6446309387963356
Eval step 0: eval loss: 1.0060169929074512
Eval: 2022-04-20 16:00:09.776797: total loss: 1.090701948599739, mse:4.87470880112064, ic :0.06957280642048291, sharpe5:7.1971751064062115, irr5:214.33250427246094, ndcg5:0.8547469795403697, pnl5:3.9913814067840576 
train 4, step: 0, loss: 1.1640907415334856, grad_norm: 0.1455723560483165, ic: 0.07993310040379543
train 4, step: 500, loss: 0.9923387856563081, grad_norm: 0.0042805014295296704, ic: 0.12843121612436242
train 4, step: 1000, loss: 1.3339204068042048, grad_norm: 0.06112573876049442, ic: 0.03405783616060661
train 4, step: 1500, loss: 1.0452481783353365, grad_norm: 0.1313875388502853, ic: 0.6062857136857427
train 4, step: 2000, loss: 4.181859602429189, grad_norm: 0.9278269081693546, ic: -0.03340084479055716
Epoch 4: 2022-04-20 16:00:33.060836: train loss: 1.6406900794069303
Eval step 0: eval loss: 1.0063124943432398
Eval: 2022-04-20 16:00:35.466906: total loss: 1.0920383417596977, mse:4.731457931575655, ic :0.12146646597536621, sharpe5:7.383636455833911, irr5:210.90249633789062, ndcg5:0.8473239926973648, pnl5:3.4169511795043945 
train 5, step: 0, loss: 1.000656836830017, grad_norm: 0.19359208496585995, ic: -0.0873459928495175
train 5, step: 500, loss: 0.7872077736997679, grad_norm: 0.014402819845553907, ic: 0.14971897959874775
train 5, step: 1000, loss: 1.0937384037068556, grad_norm: 0.05931861341563495, ic: 0.4087086609136926
train 5, step: 1500, loss: 1.7656539792936992, grad_norm: 0.35415346675787285, ic: -0.08355507873939186
train 5, step: 2000, loss: 2.168576054666755, grad_norm: 0.8577193078119068, ic: 0.05853908533440094
Epoch 5: 2022-04-20 16:00:58.579444: train loss: 1.6399893563350514
Eval step 0: eval loss: 1.0020888229619207
Eval: 2022-04-20 16:01:01.017482: total loss: 1.0862547772069668, mse:4.711849346400463, ic :0.12613751323409156, sharpe5:7.6132585036754605, irr5:220.2228546142578, ndcg5:0.838208960903668, pnl5:3.4461700916290283 
train 6, step: 0, loss: 0.7808192029218001, grad_norm: 0.011614407992960197, ic: -0.08230186339529713
train 6, step: 500, loss: 1.4216523644519827, grad_norm: 0.24015204069244434, ic: 0.05313366396674915
train 6, step: 1000, loss: 1.2263352585133895, grad_norm: 0.18339132607467576, ic: 0.20789983743062623
train 6, step: 1500, loss: 1.0615344929245283, grad_norm: 0.33576589589297856, ic: 0.060341652844600524
train 6, step: 2000, loss: 2.289163992174714, grad_norm: 1.114375137163247, ic: 0.10456687014287297
Epoch 6: 2022-04-20 16:01:24.260222: train loss: 1.6373612343748705
Eval step 0: eval loss: 0.9989145448673643
Eval: 2022-04-20 16:01:26.746432: total loss: 1.0855489231020927, mse:4.71798713821642, ic :0.12208030189075735, sharpe5:8.23695273041725, irr5:238.0680694580078, ndcg5:0.8585322163484043, pnl5:4.057405948638916 
train 7, step: 0, loss: 1.4571079712919583, grad_norm: 0.5399910864787165, ic: 0.2207422229264114
train 7, step: 500, loss: 1.350674615933405, grad_norm: 0.09204870166480528, ic: 0.1777375038846327
train 7, step: 1000, loss: 0.6393048919125955, grad_norm: 0.01179549230943483, ic: 0.28837609106038675
train 7, step: 1500, loss: 1.0027721109339025, grad_norm: 0.1274252621446741, ic: 0.09273525478403537
train 7, step: 2000, loss: 1.5758813050960778, grad_norm: 0.5715739270689781, ic: 0.4197699700129807
Epoch 7: 2022-04-20 16:01:49.370233: train loss: 1.6376808300987793
Eval step 0: eval loss: 0.9889135857893957
Eval: 2022-04-20 16:01:51.799898: total loss: 1.0843598688031353, mse:4.729599556887264, ic :0.12340006744541031, sharpe5:7.746258969604969, irr5:222.82244873046875, ndcg5:0.8498255407381574, pnl5:3.049062490463257 
train 8, step: 0, loss: 1.2012414917185033, grad_norm: 0.07995096361261132, ic: 0.06347427650376333
train 8, step: 500, loss: 5.527995046777037, grad_norm: 1.0995743679509884, ic: 0.12312711538430612
train 8, step: 1000, loss: 1.874143494083857, grad_norm: 0.5418245427244744, ic: 0.12716748723596555
train 8, step: 1500, loss: 1.08170653691067, grad_norm: 0.39332644181878, ic: 0.6415402332965291
train 8, step: 2000, loss: 1.1277029575445712, grad_norm: 0.5199133202023076, ic: 0.01650599457828425
Epoch 8: 2022-04-20 16:02:14.460283: train loss: 1.6353382659819247
Eval step 0: eval loss: 1.0158189368787849
Eval: 2022-04-20 16:02:16.915219: total loss: 1.0878680726103163, mse:4.697003634578568, ic :0.15968485559338902, sharpe5:14.029148159623146, irr5:468.58013916015625, ndcg5:0.8554159401999185, pnl5:6.495724201202393 
train 9, step: 0, loss: 1.1003434500011138, grad_norm: 0.03220941936270663, ic: 0.4739383926319768
train 9, step: 500, loss: 3.130484059883942, grad_norm: 0.9914225548136475, ic: 0.18884387694850205
train 9, step: 1000, loss: 0.873752722445184, grad_norm: 0.10297145165420081, ic: 0.2559967703978655
train 9, step: 1500, loss: 2.1539377864794367, grad_norm: 1.077753845466835, ic: 0.001681587305372538
train 9, step: 2000, loss: 0.6052084741960071, grad_norm: 0.011331900838831453, ic: 0.062019852610197886
Epoch 9: 2022-04-20 16:02:40.409207: train loss: 1.630438250677061
Eval step 0: eval loss: 1.0154486762152777
Eval: 2022-04-20 16:02:42.790814: total loss: 1.0839194899371711, mse:4.710323321265157, ic :0.15335439117319616, sharpe5:14.622455468773842, irr5:461.6664123535156, ndcg5:0.8383263225947039, pnl5:4.939441204071045 
train 10, step: 0, loss: 1.2986023633542445, grad_norm: 0.03254392313737241, ic: 0.38370992399376225
train 10, step: 500, loss: 0.897382086926649, grad_norm: 0.005227029015924974, ic: 0.0944381498809019
train 10, step: 1000, loss: 1.532751332711022, grad_norm: 0.5808114489721696, ic: 0.04012449209901818
train 10, step: 1500, loss: 3.060765468258261, grad_norm: 0.9892403923861073, ic: 0.120880792502903
train 10, step: 2000, loss: 1.3722268890102582, grad_norm: 0.24782780712335434, ic: 0.16399923641338365
Epoch 10: 2022-04-20 16:03:05.428812: train loss: 1.6298017483971718
Eval step 0: eval loss: 1.0080756679090968
Eval: 2022-04-20 16:03:07.818577: total loss: 1.0859061776095633, mse:4.698535205835615, ic :0.1537236640503559, sharpe5:14.39480331122875, irr5:453.2828674316406, ndcg5:0.8579995926544733, pnl5:6.724206447601318 
train 11, step: 0, loss: 4.68412288042416, grad_norm: 1.7193222280035902, ic: 0.4188978683067592
train 11, step: 500, loss: 0.9855643886208717, grad_norm: 0.05836026214859133, ic: 0.038882520597001737
train 11, step: 1000, loss: 1.0410767067124334, grad_norm: 0.39922762835226683, ic: 0.06717315496638179
train 11, step: 1500, loss: 0.6928314232882243, grad_norm: 0.003091685846757084, ic: 0.09492691378384091
train 11, step: 2000, loss: 1.123430042902112, grad_norm: 0.05506180544038257, ic: -0.17429468696965755
Epoch 11: 2022-04-20 16:03:31.651958: train loss: 1.6276713845168114
Eval step 0: eval loss: 0.9973297520899157
Eval: 2022-04-20 16:03:34.052528: total loss: 1.08158004486308, mse:4.696442825235561, ic :0.1556391362650555, sharpe5:15.421180005669592, irr5:503.0633544921875, ndcg5:0.856822881251952, pnl5:6.696261405944824 
train 12, step: 0, loss: 1.373007329788498, grad_norm: 0.2621920414241964, ic: 0.1868263431683752
train 12, step: 500, loss: 0.8222202460598362, grad_norm: 0.4094838847272123, ic: 0.005916111447575197
train 12, step: 1000, loss: 1.1711627084535785, grad_norm: 0.28714159642608655, ic: 0.6301028617379443
train 12, step: 1500, loss: 1.0824636290197343, grad_norm: 0.2567971090518778, ic: 0.07663615899351472
train 12, step: 2000, loss: 1.1120500416845953, grad_norm: 0.059925622614546675, ic: 0.1431581368569062
Epoch 12: 2022-04-20 16:03:57.088177: train loss: 1.627746414562528
Eval step 0: eval loss: 1.0038489110222484
Eval: 2022-04-20 16:03:59.521753: total loss: 1.0845689664672709, mse:4.711148753481401, ic :0.15925531428027834, sharpe5:15.049096342921256, irr5:478.19134521484375, ndcg5:0.8686511809177312, pnl5:6.437742233276367 
train 13, step: 0, loss: 1.0786285303632293, grad_norm: 0.0531544688394711, ic: 0.4439661893595278
train 13, step: 500, loss: 1.147768256500477, grad_norm: 0.023856639728236588, ic: -0.14915205494665099
train 13, step: 1000, loss: 1.3833202779246165, grad_norm: 0.8304754292106555, ic: 0.1163932816699941
train 13, step: 1500, loss: 0.773584374554081, grad_norm: 0.010041008080746185, ic: 0.040137846597266706
train 13, step: 2000, loss: 1.0322056549119143, grad_norm: 0.036484878500184156, ic: 0.05899595845194053
Epoch 13: 2022-04-20 16:04:22.030332: train loss: 1.6277349694706664
Eval step 0: eval loss: 0.991867121675882
Eval: 2022-04-20 16:04:24.509713: total loss: 1.087596074201993, mse:4.765799956321, ic :0.11799699620617932, sharpe5:7.7165994688868516, irr5:219.2587890625, ndcg5:0.8543631268308742, pnl5:3.7451367378234863 
train 14, step: 0, loss: 1.7559523501638639, grad_norm: 0.57164536086512, ic: 0.16068821519235904
train 14, step: 500, loss: 1.2657253649373161, grad_norm: 0.1654471735035991, ic: 0.2486595259995762
train 14, step: 1000, loss: 1.0663779014398242, grad_norm: 0.2924837982419449, ic: 0.12749209345158113
train 14, step: 1500, loss: 0.9732721459415896, grad_norm: 0.1239185029724182, ic: 0.20731269546440168
train 14, step: 2000, loss: 2.300335185562806, grad_norm: 0.728830990347324, ic: -0.08798642474296997
Epoch 14: 2022-04-20 16:04:47.844834: train loss: 1.6265611272837728
Eval step 0: eval loss: 1.0059327200376842
Eval: 2022-04-20 16:04:50.321009: total loss: 1.0839275495047043, mse:4.682913685489605, ic :0.1679900986010307, sharpe5:15.315305378437042, irr5:512.2728271484375, ndcg5:0.8405823543796368, pnl5:6.030239105224609 
train 15, step: 0, loss: 0.9673768307624202, grad_norm: 0.17965612126966207, ic: 0.13160956980869026
train 15, step: 500, loss: 1.22718152424322, grad_norm: 0.026608940811906727, ic: 0.08105905606831049
train 15, step: 1000, loss: 1.7464552083333333, grad_norm: 0.04025478890600535, ic: 0.019758952114168095
train 15, step: 1500, loss: 5.37799539588167, grad_norm: 1.0199402638329282, ic: 0.007333674809040978
train 15, step: 2000, loss: 0.9284482092028308, grad_norm: 0.016523553607609973, ic: 0.039136470248095176
Epoch 15: 2022-04-20 16:05:13.143722: train loss: 1.62663562291592
Eval step 0: eval loss: 1.009307170303449
Eval: 2022-04-20 16:05:15.546243: total loss: 1.0826419252746595, mse:4.676999045786507, ic :0.16809819671672552, sharpe5:15.476821247935295, irr5:513.1661987304688, ndcg5:0.8444739724100285, pnl5:4.788181304931641 
train 16, step: 0, loss: 6.324537561830173, grad_norm: 1.338644233035749, ic: 0.16781388894274443
train 16, step: 500, loss: 1.3820136176215279, grad_norm: 0.6842554168845105, ic: -0.0011860995544482576
train 16, step: 1000, loss: 0.82815254205278, grad_norm: 0.13846687840315866, ic: -0.014057482668783606
train 16, step: 1500, loss: 1.2333973167320198, grad_norm: 0.3864369775879355, ic: 0.14177161187608817
train 16, step: 2000, loss: 0.955552364077716, grad_norm: 0.3136329354543244, ic: 0.5423973985566699
Epoch 16: 2022-04-20 16:05:38.038476: train loss: 1.624927637710871
Eval step 0: eval loss: 0.9996146974970378
Eval: 2022-04-20 16:05:40.449948: total loss: 1.0797548805809531, mse:4.694611293748496, ic :0.16805478643053004, sharpe5:15.219937148094177, irr5:505.4159851074219, ndcg5:0.8387275220433709, pnl5:4.875943183898926 
train 17, step: 0, loss: 1.1843597786558187, grad_norm: 0.009384501713358792, ic: 0.129172281129883
train 17, step: 500, loss: 1.0305529247489296, grad_norm: 0.018250131723206203, ic: -0.009014936854682559
train 17, step: 1000, loss: 3.3693432697761962, grad_norm: 2.0724650775690074, ic: -0.010847689516278129
train 17, step: 1500, loss: 0.8843445021743528, grad_norm: 0.00578089538096441, ic: 0.03857770662723844
train 17, step: 2000, loss: 1.004769754089765, grad_norm: 0.5593923709210025, ic: 0.577069020085814
Epoch 17: 2022-04-20 16:06:03.349268: train loss: 1.62799628156526
Eval step 0: eval loss: 1.0031938196295747
Eval: 2022-04-20 16:06:05.809810: total loss: 1.085089520048292, mse:4.719396614959244, ic :0.15837691727503808, sharpe5:15.53713630914688, irr5:501.0791015625, ndcg5:0.8615922441784718, pnl5:6.40861177444458 
train 18, step: 0, loss: 0.8496818144797514, grad_norm: 0.005173409419951344, ic: 0.03447191358378229
train 18, step: 500, loss: 2.523093857526191, grad_norm: 1.016922920015258, ic: 0.09666434475647753
train 18, step: 1000, loss: 1.3649042582340378, grad_norm: 0.3762797812436877, ic: 0.532162557494132
train 18, step: 1500, loss: 1.6576089545499737, grad_norm: 2.175331651767685, ic: 0.3457801344269553
train 18, step: 2000, loss: 1.2602561628935585, grad_norm: 0.3853604396563613, ic: 0.20617179499441735
Epoch 18: 2022-04-20 16:06:28.583608: train loss: 1.62501568224612
Eval step 0: eval loss: 1.0010173168855319
Eval: 2022-04-20 16:06:31.034449: total loss: 1.081000817240943, mse:4.6862630696365954, ic :0.1709139716538738, sharpe5:15.807508363723754, irr5:529.9072875976562, ndcg5:0.8524393460022361, pnl5:4.5345540046691895 
train 19, step: 0, loss: 2.2113090345854056, grad_norm: 1.1127659418923248, ic: 0.2674000432495128
train 19, step: 500, loss: 1.0214227011037427, grad_norm: 0.05829227366073045, ic: 0.052750835499241505
train 19, step: 1000, loss: 0.975247327167106, grad_norm: 0.2721063207530257, ic: 0.5650814396134596
train 19, step: 1500, loss: 1.567596435546875, grad_norm: 0.28513928569729396, ic: 0.1686717133159037
train 19, step: 2000, loss: 1.7371585429959397, grad_norm: 1.5067659838038625, ic: 0.643903861634103
Epoch 19: 2022-04-20 16:06:53.561311: train loss: 1.6244056354004583
Eval step 0: eval loss: 1.000549219984202
Eval: 2022-04-20 16:06:55.994932: total loss: 1.0808615813813522, mse:4.693374940730723, ic :0.16093096809191854, sharpe5:15.38281420469284, irr5:488.6422424316406, ndcg5:0.8416987545047526, pnl5:4.9530415534973145 
train 20, step: 0, loss: 1.247490633158315, grad_norm: 0.3329275850823484, ic: 0.4650552370439955
train 20, step: 500, loss: 1.2323534842410953, grad_norm: 0.6087807167586565, ic: 0.036728543234193695
train 20, step: 1000, loss: 1.5659086632312071, grad_norm: 0.4181370874122659, ic: 0.19122865822845708
train 20, step: 1500, loss: 0.8729614106548172, grad_norm: 0.4273024898562515, ic: 0.5659535947379633
train 20, step: 2000, loss: 1.3574971697845089, grad_norm: 0.1437652750341351, ic: -0.03605795874396179
Epoch 20: 2022-04-20 16:07:20.235358: train loss: 1.6235165306957444
Eval step 0: eval loss: 1.0064374573171735
Eval: 2022-04-20 16:07:22.647349: total loss: 1.0808891863786967, mse:4.679366086188161, ic :0.16749245271133145, sharpe5:15.229170328974723, irr5:497.53466796875, ndcg5:0.84561022401311, pnl5:6.935434818267822 
train 21, step: 0, loss: 1.39431316053207, grad_norm: 0.33215350603380533, ic: 0.26686284633795637
train 21, step: 500, loss: 1.123141579894319, grad_norm: 0.27082829575556866, ic: 0.029232312013673687
train 21, step: 1000, loss: 0.8977570357436319, grad_norm: 0.36115578034337165, ic: 0.09724304210408227
train 21, step: 1500, loss: 0.7372985881055875, grad_norm: 0.21556774283469698, ic: 0.6299198354589592
train 21, step: 2000, loss: 1.118192922001193, grad_norm: 0.15961825063239107, ic: 0.3059551343445338
Epoch 21: 2022-04-20 16:07:45.987634: train loss: 1.623066007465214
Eval step 0: eval loss: 1.0043451631615323
Eval: 2022-04-20 16:07:48.419530: total loss: 1.0832253578039173, mse:4.702127419692111, ic :0.15040316120069427, sharpe5:13.9012145447731, irr5:430.72186279296875, ndcg5:0.8569945766975737, pnl5:4.564057350158691 
train 22, step: 0, loss: 1.03042468431806, grad_norm: 0.410695283376353, ic: 0.10471102417811472
train 22, step: 500, loss: 1.0274273729699803, grad_norm: 0.0006958812735423749, ic: 0.02302409589770392
train 22, step: 1000, loss: 0.9109080985199884, grad_norm: 0.07071043842974092, ic: 0.131205840893418
train 22, step: 1500, loss: 1.0042627637631425, grad_norm: 0.06265924618493769, ic: 0.2547427576009992
train 22, step: 2000, loss: 1.0478757636491642, grad_norm: 0.12463615189642285, ic: 0.123957840139431
Epoch 22: 2022-04-20 16:08:11.329441: train loss: 1.6225759267205302
Eval step 0: eval loss: 1.0171506539214716
Eval: 2022-04-20 16:08:13.830816: total loss: 1.0840211428651416, mse:4.690587818397236, ic :0.16240601354044953, sharpe5:15.293461115956307, irr5:479.1507263183594, ndcg5:0.8495421491248221, pnl5:5.62248420715332 
train 23, step: 0, loss: 1.2777387059090464, grad_norm: 1.2374435585132701, ic: 0.012650366426568343
train 23, step: 500, loss: 0.898076906309023, grad_norm: 0.20614785750000753, ic: 0.6047848138052356
train 23, step: 1000, loss: 2.281746986739798, grad_norm: 0.8692662295468783, ic: 0.11641295311277464
train 23, step: 1500, loss: 0.7669319172752121, grad_norm: 0.31342454990334356, ic: 0.7261935652186355
train 23, step: 2000, loss: 1.4732405820401078, grad_norm: 0.4181123497161939, ic: 0.41000611302870965
Epoch 23: 2022-04-20 16:08:37.904564: train loss: 1.6225712346482204
Eval step 0: eval loss: 1.0178807616673249
Eval: 2022-04-20 16:08:40.462186: total loss: 1.0891992806602118, mse:4.7006457940249575, ic :0.1573610498165201, sharpe5:15.532226008772849, irr5:478.63885498046875, ndcg5:0.8505245663710022, pnl5:5.087136268615723 
train 24, step: 0, loss: 1.1861723781469555, grad_norm: 0.890874270049502, ic: 0.3584348876764469
train 24, step: 500, loss: 1.2477317827517163, grad_norm: 0.2755979705302054, ic: 0.030491978236450185
train 24, step: 1000, loss: 1.043751507270627, grad_norm: 0.3177595935684084, ic: 0.12137349421637511
train 24, step: 1500, loss: 1.1983425350639763, grad_norm: 0.0858874301318327, ic: 0.07069905545693606
train 24, step: 2000, loss: 1.3665680847650077, grad_norm: 0.49325453378995177, ic: 0.4585430110019645
Epoch 24: 2022-04-20 16:09:03.717963: train loss: 1.6216149499466828
Eval step 0: eval loss: 1.013792595403831
Eval: 2022-04-20 16:09:06.188161: total loss: 1.0821120654820986, mse:4.68108102885566, ic :0.17099122540860648, sharpe5:15.434880793690681, irr5:537.3272094726562, ndcg5:0.8539911032636749, pnl5:7.150266170501709 
train 25, step: 0, loss: 1.3226417184827537, grad_norm: 0.5105286305258586, ic: 0.1664099962010282
train 25, step: 500, loss: 1.4577108606115565, grad_norm: 1.37964625138382, ic: 0.10973037548933828
train 25, step: 1000, loss: 1.366874427203134, grad_norm: 0.2528280451531087, ic: 0.2575460864195365
train 25, step: 1500, loss: 2.8618440648828978, grad_norm: 1.3189593518671918, ic: 0.24531757823852463
train 25, step: 2000, loss: 1.1903999425187894, grad_norm: 0.1886724333052463, ic: 0.14494489305434108
Epoch 25: 2022-04-20 16:09:28.964275: train loss: 1.6231000172464465
Eval step 0: eval loss: 1.0045208441326026
Eval: 2022-04-20 16:09:31.385827: total loss: 1.0807287234625118, mse:4.676167546700462, ic :0.16997497101829864, sharpe5:15.770789419412612, irr5:533.5621337890625, ndcg5:0.849506053610377, pnl5:4.561827659606934 
train 26, step: 0, loss: 1.6121548295454544, grad_norm: 0.49975958005612836, ic: 0.23291584172540014
train 26, step: 500, loss: 1.0232928612238086, grad_norm: 0.3452003055549761, ic: -0.05029151174485084
train 26, step: 1000, loss: 1.8065861456598669, grad_norm: 0.6451154807199604, ic: 0.1901042474882629
train 26, step: 1500, loss: 0.9246822300723441, grad_norm: 0.033162364327593244, ic: -0.04693817708451446
train 26, step: 2000, loss: 1.0008354607529528, grad_norm: 0.13748789014184315, ic: 0.1365980407801583
Epoch 26: 2022-04-20 16:09:54.397039: train loss: 1.622448693789957
Eval step 0: eval loss: 1.0055710730771128
Eval: 2022-04-20 16:09:56.887527: total loss: 1.08264559155345, mse:4.683967996039506, ic :0.16888495212566695, sharpe5:16.04031770825386, irr5:528.8230590820312, ndcg5:0.8491850513138657, pnl5:5.531335353851318 
train 27, step: 0, loss: 1.6590006265295558, grad_norm: 0.5808894994113569, ic: 0.6254673854924823
train 27, step: 500, loss: 1.5109834804505249, grad_norm: 0.4037785624735708, ic: 0.1011427220269018
train 27, step: 1000, loss: 2.6560485413024475, grad_norm: 3.270395962146253, ic: 0.40829760229809275
train 27, step: 1500, loss: 0.837481549677958, grad_norm: 0.4096003794338913, ic: 0.5454565271334385
train 27, step: 2000, loss: 1.333925308719758, grad_norm: 1.056588308170875, ic: -0.014061721340656147
Epoch 27: 2022-04-20 16:10:19.678604: train loss: 1.6199379840459165
Eval step 0: eval loss: 1.0082430565840572
Eval: 2022-04-20 16:10:22.118799: total loss: 1.079564632227764, mse:4.679148197485781, ic :0.17013880969213416, sharpe5:15.091902319192886, irr5:513.6348266601562, ndcg5:0.8509244205113037, pnl5:4.984508991241455 
train 28, step: 0, loss: 1.1683168477329315, grad_norm: 0.11607235272941514, ic: 0.13275957708952746
train 28, step: 500, loss: 2.9422148904061984, grad_norm: 0.6023455694624615, ic: 0.13824529147555475
train 28, step: 1000, loss: 2.761546154534459, grad_norm: 1.5348080154246717, ic: -0.026709145022047565
train 28, step: 1500, loss: 1.0213202514307649, grad_norm: 0.006168085922047329, ic: 0.2051928152486137
train 28, step: 2000, loss: 1.7485819971838663, grad_norm: 0.4579127642726217, ic: 0.06742451110734243
Epoch 28: 2022-04-20 16:10:45.603514: train loss: 1.6221447148172803
Eval step 0: eval loss: 1.0063245792398958
Eval: 2022-04-20 16:10:48.113997: total loss: 1.0812605078813404, mse:4.686868516431113, ic :0.16910467707942867, sharpe5:15.97960252046585, irr5:548.08837890625, ndcg5:0.8527062926160273, pnl5:4.622745513916016 
train 29, step: 0, loss: 1.5173119580411296, grad_norm: 0.10504419659219533, ic: 0.0774953388218431
train 29, step: 500, loss: 2.5475663965969932, grad_norm: 1.2588626036508306, ic: -0.12453115384663689
train 29, step: 1000, loss: 1.705182539467993, grad_norm: 0.8606489199994745, ic: 0.47964418463441877
train 29, step: 1500, loss: 3.98555416121511, grad_norm: 1.0733727422422419, ic: 0.12373733901082597
train 29, step: 2000, loss: 0.9225315913026105, grad_norm: 0.21666123001816218, ic: 0.4726596930054263
Epoch 29: 2022-04-20 16:11:11.409528: train loss: 1.6213700856404683
Eval step 0: eval loss: 1.0041674251867758
Eval: 2022-04-20 16:11:13.900887: total loss: 1.0807811713336406, mse:4.679500505406355, ic :0.16706736899778113, sharpe5:15.086919182538985, irr5:507.2276916503906, ndcg5:0.8422381690900226, pnl5:4.0966949462890625 
train 30, step: 0, loss: 1.2583936507913038, grad_norm: 0.0424142642006269, ic: 0.9784137253990646
train 30, step: 500, loss: 1.924515543104727, grad_norm: 0.33658433885812566, ic: 0.16831045283080076
train 30, step: 1000, loss: 3.4263821618886317, grad_norm: 0.6503751653916875, ic: 0.4028543349502513
train 30, step: 1500, loss: 1.0800488196918179, grad_norm: 0.2253676076242986, ic: 0.15150436072426685
train 30, step: 2000, loss: 1.0955579083330294, grad_norm: 0.06420241630606065, ic: 0.44275842138475896
Epoch 30: 2022-04-20 16:11:37.872245: train loss: 1.6229129920501424
Eval step 0: eval loss: 1.0011169530015798
Eval: 2022-04-20 16:11:40.340479: total loss: 1.0822657220519236, mse:4.676017026852949, ic :0.17052405600229603, sharpe5:15.212442578673363, irr5:526.0838623046875, ndcg5:0.8557960988299426, pnl5:3.601079225540161 
train 31, step: 0, loss: 1.16962505346719, grad_norm: 0.23390241932102568, ic: 0.19807262479568893
train 31, step: 500, loss: 0.8239509982808829, grad_norm: 0.08768922945698171, ic: 0.2516681315852068
train 31, step: 1000, loss: 5.137933183365759, grad_norm: 1.080423490396345, ic: -0.00451312155011975
train 31, step: 1500, loss: 1.673436443440881, grad_norm: 0.38570530088796556, ic: 0.29094775279523466
train 31, step: 2000, loss: 0.8864542175526821, grad_norm: 0.5640903405234137, ic: 0.15840410554634654
Epoch 31: 2022-04-20 16:12:03.205404: train loss: 1.6232751407987887
Eval step 0: eval loss: 1.0149740868960637
Eval: 2022-04-20 16:12:05.694409: total loss: 1.0853346296700592, mse:4.685051875550717, ic :0.1647592884023535, sharpe5:15.906032202243804, irr5:512.1865844726562, ndcg5:0.8312286706425182, pnl5:5.768157482147217 
train 32, step: 0, loss: 0.8645268484351307, grad_norm: 0.5616926572877867, ic: 0.11601653531816317
train 32, step: 500, loss: 1.1084629151879288, grad_norm: 0.3041657605238913, ic: 0.17001104268722944
train 32, step: 1000, loss: 1.379184411288708, grad_norm: 0.05219166044411476, ic: 0.07326176730171922
train 32, step: 1500, loss: 2.0681023848684212, grad_norm: 0.5065185524662033, ic: 0.44311085217843227
train 32, step: 2000, loss: 1.0669156986855595, grad_norm: 0.4083175762456061, ic: 0.467974827715258
Epoch 32: 2022-04-20 16:12:28.797052: train loss: 1.6214476591233569
Eval step 0: eval loss: 1.0092662873551868
Eval: 2022-04-20 16:12:31.227783: total loss: 1.0810099437647063, mse:4.676023586609311, ic :0.17349310159507472, sharpe5:15.761109761595725, irr5:535.7572631835938, ndcg5:0.8614668300313164, pnl5:5.187961101531982 
train 33, step: 0, loss: 1.1611024114901642, grad_norm: 0.01617910800685581, ic: 0.05397618187588018
train 33, step: 500, loss: 3.153787951575711, grad_norm: 1.1079174170690793, ic: 0.5246338996201376
train 33, step: 1000, loss: 5.2678779218636205, grad_norm: 2.724038313846288, ic: 0.043230805517425974
train 33, step: 1500, loss: 1.3178466796875, grad_norm: 1.007977235835546, ic: -0.008680512866165183
train 33, step: 2000, loss: 1.8555171996124031, grad_norm: 0.27782021903273946, ic: 0.10586597688270782
Epoch 33: 2022-04-20 16:12:54.761473: train loss: 1.6217916853272356
Eval step 0: eval loss: 1.0143820555226435
Eval: 2022-04-20 16:12:57.206855: total loss: 1.088287377701372, mse:4.689297438840032, ic :0.1694642645059777, sharpe5:16.599719256162643, irr5:541.648193359375, ndcg5:0.8599911825638711, pnl5:4.120601654052734 
train 34, step: 0, loss: 0.7180398738516492, grad_norm: 0.3260651038780681, ic: 0.15120442997476616
train 34, step: 500, loss: 1.8093161286929693, grad_norm: 0.32040014076363904, ic: 0.8416240893120966
train 34, step: 1000, loss: 0.6886773050242456, grad_norm: 0.04554484068340822, ic: 0.48057738478110235
train 34, step: 1500, loss: 1.6526371882512019, grad_norm: 1.1275694679980723, ic: 0.6440832424882056
train 34, step: 2000, loss: 2.994821765277492, grad_norm: 0.48847891769956797, ic: 0.08891726489319149
Epoch 34: 2022-04-20 16:13:19.232377: train loss: 1.6215774028473173
Eval step 0: eval loss: 1.0085580995548644
Eval: 2022-04-20 16:13:21.598757: total loss: 1.081924629278219, mse:4.680262823846754, ic :0.1673643967124, sharpe5:16.172836225032807, irr5:535.9179077148438, ndcg5:0.8516244078867637, pnl5:4.121073246002197 
train 35, step: 0, loss: 1.0414753201641613, grad_norm: 0.5274604022017213, ic: -0.01203863144607257
train 35, step: 500, loss: 3.308699544270833, grad_norm: 1.5803229753527326, ic: -0.07464364269391159
train 35, step: 1000, loss: 1.3403391105627938, grad_norm: 0.08498379655910551, ic: 0.5099692285397729
train 35, step: 1500, loss: 1.6335967092803032, grad_norm: 0.3765235706813255, ic: 0.09478694182770013
train 35, step: 2000, loss: 1.306489893066782, grad_norm: 0.1725741724284195, ic: -0.08638595415227035
Epoch 35: 2022-04-20 16:13:44.893685: train loss: 1.6234151236900307
Eval step 0: eval loss: 1.003380171307267
Eval: 2022-04-20 16:13:47.382665: total loss: 1.0819448094509927, mse:4.679859791188057, ic :0.16971968919125674, sharpe5:16.027962026596068, irr5:524.5877685546875, ndcg5:0.831270581235899, pnl5:5.707396030426025 
train 36, step: 0, loss: 8.964436784727702, grad_norm: 1.048574022057537, ic: -0.17424538979755333
train 36, step: 500, loss: 0.8602370696028103, grad_norm: 0.008941588675383536, ic: 0.09080145630584036
train 36, step: 1000, loss: 1.967502396882124, grad_norm: 1.431741541487867, ic: 0.07276395558695005
train 36, step: 1500, loss: 1.0552798875651797, grad_norm: 0.11586694232445084, ic: 0.11183002295619601
train 36, step: 2000, loss: 2.1500091103682313, grad_norm: 1.3275990605267025, ic: 0.39018173499324965
Epoch 36: 2022-04-20 16:14:10.662284: train loss: 1.6227159628973162
Eval step 0: eval loss: 1.0170576387860386
Eval: 2022-04-20 16:14:13.074191: total loss: 1.0859730204607518, mse:4.683754920527035, ic :0.17064656002799916, sharpe5:16.33279793858528, irr5:545.8887329101562, ndcg5:0.8603618381247632, pnl5:4.675304889678955 
train 37, step: 0, loss: 1.19547512058813, grad_norm: 0.2126623149128921, ic: 0.14736547692245933
train 37, step: 500, loss: 2.3325444518283196, grad_norm: 0.04386086438277634, ic: 0.20435744082432228
train 37, step: 1000, loss: 0.7687817073283975, grad_norm: 0.3198075888031274, ic: 0.16745946558635008
train 37, step: 1500, loss: 3.1355411122898156, grad_norm: 0.7093854272593029, ic: 0.18627656352365096
train 37, step: 2000, loss: 3.168998782081749, grad_norm: 1.3688066201261484, ic: -0.01700461617767976
Epoch 37: 2022-04-20 16:14:36.342290: train loss: 1.6221994878751966
Eval step 0: eval loss: 1.0080790105400868
Eval: 2022-04-20 16:14:38.759520: total loss: 1.080203873831593, mse:4.6735620791855705, ic :0.17437281074030797, sharpe5:16.602625139951705, irr5:554.0745849609375, ndcg5:0.8469603521865607, pnl5:4.116668701171875 
train 38, step: 0, loss: 1.3448813698508524, grad_norm: 0.3170078649847962, ic: -0.2761924598253507
train 38, step: 500, loss: 1.772765261627907, grad_norm: 1.231941570998438, ic: 0.22342129731280364
train 38, step: 1000, loss: 1.8107302201983504, grad_norm: 0.5172878588181098, ic: 0.1422515244574604
train 38, step: 1500, loss: 1.1113457037285615, grad_norm: 0.3567072411782494, ic: 0.470108939509544
train 38, step: 2000, loss: 0.7604254577385545, grad_norm: 0.01417049285336185, ic: 0.5522376812407882
Epoch 38: 2022-04-20 16:15:01.826603: train loss: 1.6213367536986039
Eval step 0: eval loss: 0.9999899078256648
Eval: 2022-04-20 16:15:04.388779: total loss: 1.078737699725739, mse:4.68355796667283, ic :0.17529105608510895, sharpe5:16.764350059032438, irr5:539.3132934570312, ndcg5:0.8603910958128995, pnl5:4.635553359985352 
train 39, step: 0, loss: 0.8696105860609202, grad_norm: 0.03825866635649659, ic: 0.5389821887179126
train 39, step: 500, loss: 1.2279402205919205, grad_norm: 0.5489039562032091, ic: 0.05693241497921932
train 39, step: 1000, loss: 1.377554228811553, grad_norm: 0.22148666607743484, ic: 0.08131357381566741
train 39, step: 1500, loss: 2.4380361360568936, grad_norm: 0.5345532405277452, ic: -0.07986997450344005
train 39, step: 2000, loss: 2.8957927944934942, grad_norm: 1.7197877796996257, ic: 0.21610820324994512
Epoch 39: 2022-04-20 16:15:38.018900: train loss: 1.619533999148554
Eval step 0: eval loss: 1.0045707264719919
Eval: 2022-04-20 16:15:44.802840: total loss: 1.0784823680443767, mse:4.674799988060223, ic :0.17719977184539795, sharpe5:15.918431396484374, irr5:555.919677734375, ndcg5:0.8515721461263503, pnl5:3.135862350463867 

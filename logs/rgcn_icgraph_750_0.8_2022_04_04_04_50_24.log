Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='SparseAdjSeqTimeDataset', dout=0.3, epochs=40, gnn_layers=2, gpu=0, hidden_dim=128, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=3, mask_adj=True, mask_type='soft', model_type='RGCNModel', normalize_adj=True, num_days=1, num_heads=1, print_inteval=500, relation_num=1, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_750_0.8/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
load 2305 train graphs successful!
load 126 test graphs successful!
35186
RGCNModel(
  (fc1): Linear(in_features=9, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
  (fc4): Linear(in_features=128, out_features=1, bias=True)
  (gnns): ModuleList(
    (0): RGCN(
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
    )
    (1): RGCN(
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
    )
  )
  (dropout): Dropout(p=0.3, inplace=False)
  (relu): LeakyReLU(negative_slope=0.01)
)
train 0, step: 0, loss: 2.0732570482336956, grad_norm: 0.45715671469989655, ic: 0.007691766347735416
train 0, step: 500, loss: 1.365902568825815, grad_norm: 0.8636672055016832, ic: -0.02594092011829962
train 0, step: 1000, loss: 1.5045322849005218, grad_norm: 0.032377284092080516, ic: 0.21224516795133025
train 0, step: 1500, loss: 1.188061467140661, grad_norm: 0.0968274144758385, ic: 0.06447236694894579
train 0, step: 2000, loss: 1.5621386272151296, grad_norm: 0.051578899380319114, ic: 0.04479683492762621
Epoch 0: 2022-04-04 16:51:47.895064: train loss: 1.647646492054019
Eval step 0: eval loss: 1.012343179181477
Eval: 2022-04-04 16:51:51.943131: total loss: 1.0920411203539002, mse:4.888531520463267, ic :0.02031864719799022, sharpe5:7.044610531926155, irr5:212.04200744628906, ndcg5:0.8470627859066469, pnl5:2.3817124366760254 
train 1, step: 0, loss: 0.6375387966042698, grad_norm: 0.04886353600653872, ic: 0.0673741702254888
train 1, step: 500, loss: 1.2632055860422253, grad_norm: 0.2951203830229861, ic: 0.23885895632916496
train 1, step: 1000, loss: 0.8792599634234919, grad_norm: 0.06353236180182577, ic: 0.044634577647506044
train 1, step: 1500, loss: 1.8592064089891387, grad_norm: 0.5607060269368069, ic: 0.0834525775285024
train 1, step: 2000, loss: 1.3765999997008997, grad_norm: 0.24294200844274752, ic: 0.099213832071044
Epoch 1: 2022-04-04 16:52:22.987491: train loss: 1.6459993871319802
Eval step 0: eval loss: 1.00553166860025
Eval: 2022-04-04 16:52:26.971245: total loss: 1.0889421209850387, mse:4.875954454929437, ic :0.06638571940127044, sharpe5:6.782563569545745, irr5:204.68153381347656, ndcg5:0.8516817928753592, pnl5:2.773013114929199 
train 2, step: 0, loss: 1.328836761046055, grad_norm: 0.49448080446836945, ic: 0.07081680940528556
train 2, step: 500, loss: 0.9497314823596359, grad_norm: 0.2720050293070835, ic: 0.06454803936774711
train 2, step: 1000, loss: 3.066094100669886, grad_norm: 1.3657384633619303, ic: 0.19339023974529818
train 2, step: 1500, loss: 2.290035190325139, grad_norm: 0.8754273931548702, ic: 0.07859909624284411
train 2, step: 2000, loss: 1.4627911122432031, grad_norm: 0.27577526582896533, ic: -0.10515577102459266
Epoch 2: 2022-04-04 16:52:59.308335: train loss: 1.6446307699367075
Eval step 0: eval loss: 0.9964042289938783
Eval: 2022-04-04 16:53:03.291366: total loss: 1.0886669184905424, mse:4.872629849635596, ic :0.06227502155598375, sharpe5:6.6492438536882394, irr5:201.2309112548828, ndcg5:0.8440549432099114, pnl5:2.631455659866333 
train 3, step: 0, loss: 1.8320069666937644, grad_norm: 0.0682649008111884, ic: -0.14831172847123214
train 3, step: 500, loss: 0.7800255068523609, grad_norm: 0.021171820956074106, ic: 0.12999658961814248
train 3, step: 1000, loss: 1.360405258573535, grad_norm: 0.5458915738284205, ic: 0.2591707282421136
train 3, step: 1500, loss: 2.6217578200526876, grad_norm: 0.39979396023814523, ic: -0.05896224690358348
train 3, step: 2000, loss: 1.3467803955078126, grad_norm: 0.16663887742820532, ic: 0.07967586616181788
Epoch 3: 2022-04-04 16:53:35.592337: train loss: 1.6438952471717256
Eval step 0: eval loss: 1.0011724921011058
Eval: 2022-04-04 16:53:39.716831: total loss: 1.08648433669279, mse:4.715022971337542, ic :0.12518336495886584, sharpe5:7.047233110964298, irr5:211.52151489257812, ndcg5:0.862052970077329, pnl5:3.4003896713256836 
train 4, step: 0, loss: 1.1573396215337233, grad_norm: 0.15651487948456042, ic: 0.09118336504744796
train 4, step: 500, loss: 0.9936653283472481, grad_norm: 0.004563595158562783, ic: 0.11804889597305263
train 4, step: 1000, loss: 1.3263521405415715, grad_norm: 0.06076021125298907, ic: 0.0756448711395087
train 4, step: 1500, loss: 1.0499923314803685, grad_norm: 0.13314227157955408, ic: 0.6062042466169886
train 4, step: 2000, loss: 4.182100861772226, grad_norm: 0.8992550482396047, ic: -0.013554874432021791
Epoch 4: 2022-04-04 16:54:12.726869: train loss: 1.6384611738045636
Eval step 0: eval loss: 1.0017072487781398
Eval: 2022-04-04 16:54:16.818808: total loss: 1.0892067723509045, mse:4.720532415144379, ic :0.12355552895328456, sharpe5:6.322419898509979, irr5:194.17953491210938, ndcg5:0.843338704889848, pnl5:2.894543409347534 
train 5, step: 0, loss: 0.9962909405048077, grad_norm: 0.17266834634478534, ic: -0.151573834760536
train 5, step: 500, loss: 0.7910519761120162, grad_norm: 0.025414906985581163, ic: 0.14344954848480743
train 5, step: 1000, loss: 1.0969829692200364, grad_norm: 0.061296401542591444, ic: 0.39992790790410543
train 5, step: 1500, loss: 1.7803564056148373, grad_norm: 0.429011737213568, ic: -0.03044570119983274
train 5, step: 2000, loss: 2.176589260820499, grad_norm: 0.8732008479739642, ic: 0.023134543675650706
Epoch 5: 2022-04-04 16:54:49.763438: train loss: 1.6385932072886273
Eval step 0: eval loss: 1.0062280929107423
Eval: 2022-04-04 16:54:53.843107: total loss: 1.086560509781601, mse:4.713859873728994, ic :0.12748433552828273, sharpe5:6.774838667213916, irr5:202.44735717773438, ndcg5:0.8493136924405582, pnl5:2.8999412059783936 
train 6, step: 0, loss: 0.7764128072061088, grad_norm: 0.008716869717702032, ic: -0.040895766629259006
train 6, step: 500, loss: 1.4190971865291484, grad_norm: 0.24731988803779706, ic: 0.0503616889697143
train 6, step: 1000, loss: 1.2275887214206305, grad_norm: 0.19341485696567984, ic: 0.20020662070782327
train 6, step: 1500, loss: 1.0597127432193396, grad_norm: 0.3165226615799809, ic: 0.07760566164300531
train 6, step: 2000, loss: 2.3076445584211336, grad_norm: 1.1673895719305676, ic: 0.0717580908373196
Epoch 6: 2022-04-04 16:55:26.256447: train loss: 1.637780130644624
Eval step 0: eval loss: 0.998785017916502
Eval: 2022-04-04 16:55:30.360974: total loss: 1.0851148098734722, mse:4.713577217711852, ic :0.12414536566289391, sharpe5:6.22235987663269, irr5:194.43235778808594, ndcg5:0.8480019132544353, pnl5:3.1253342628479004 
train 7, step: 0, loss: 1.4553744521918761, grad_norm: 0.5463254232314672, ic: 0.20914215653881577
train 7, step: 500, loss: 1.3428672146933867, grad_norm: 0.08524838833724876, ic: 0.1818858564833021
train 7, step: 1000, loss: 0.6386993790203407, grad_norm: 0.021149230531671476, ic: 0.29722126887713307
train 7, step: 1500, loss: 1.0015189931288373, grad_norm: 0.13115813687835948, ic: 0.11869523697050582
train 7, step: 2000, loss: 1.5768532246681854, grad_norm: 0.597785508371335, ic: 0.41948118041924587
Epoch 7: 2022-04-04 16:56:03.226667: train loss: 1.637640713131563
Eval step 0: eval loss: 0.992819257257109
Eval: 2022-04-04 16:56:07.296839: total loss: 1.0837556548317204, mse:4.721875676488112, ic :0.12352272882828086, sharpe5:6.803925409913063, irr5:200.2876739501953, ndcg5:0.8413986016232444, pnl5:3.025155544281006 
train 8, step: 0, loss: 1.2059542157262046, grad_norm: 0.08427359540781604, ic: 0.0521979317537067
train 8, step: 500, loss: 5.5413309414184955, grad_norm: 1.2204546721811196, ic: 0.14618194806874646
train 8, step: 1000, loss: 1.8862243316722311, grad_norm: 0.5793789828684102, ic: 0.06284791308806953
train 8, step: 1500, loss: 1.0626814394967432, grad_norm: 0.3617049595467944, ic: 0.6433209131073895
train 8, step: 2000, loss: 1.1216549995617988, grad_norm: 0.5100165374276369, ic: 0.013631014519205835
Epoch 8: 2022-04-04 16:56:39.739266: train loss: 1.637731986882496
Eval step 0: eval loss: 1.0006313715689177
Eval: 2022-04-04 16:56:43.915217: total loss: 1.0881696373780032, mse:4.716951401097749, ic :0.12555549696198848, sharpe5:6.301199474036693, irr5:187.2886962890625, ndcg5:0.8518524567353426, pnl5:3.0445282459259033 
train 9, step: 0, loss: 1.1222575507840342, grad_norm: 0.02329877239141564, ic: 0.43667274598049155
train 9, step: 500, loss: 3.1582153877711185, grad_norm: 1.6072021376478787, ic: 0.04659179155665545
train 9, step: 1000, loss: 0.8837037949050509, grad_norm: 0.15497373592781605, ic: 0.21745234996683174
train 9, step: 1500, loss: 2.151153910681726, grad_norm: 0.9170867526964359, ic: -0.014791553510304853
train 9, step: 2000, loss: 0.606287946483453, grad_norm: 0.008552188384600678, ic: 0.047607957943630985
Epoch 9: 2022-04-04 16:57:16.103377: train loss: 1.6377097667026002
Eval step 0: eval loss: 0.9897640282508885
Eval: 2022-04-04 16:57:20.255112: total loss: 1.0866913208587217, mse:4.7516174069191175, ic :0.12703033373363118, sharpe5:7.674113688468933, irr5:241.31451416015625, ndcg5:0.8579907049383231, pnl5:3.529463291168213 
train 10, step: 0, loss: 1.3059041623565135, grad_norm: 0.023690182028952386, ic: 0.37520790765780493
train 10, step: 500, loss: 0.8980032665608415, grad_norm: 0.006500935267595435, ic: 0.08756284348659495
train 10, step: 1000, loss: 1.533451331247398, grad_norm: 0.516258980074972, ic: 0.057358826122788226
train 10, step: 1500, loss: 3.052088583669355, grad_norm: 1.1996632709252126, ic: 0.03801279465273722
train 10, step: 2000, loss: 1.3815458813699184, grad_norm: 0.1300747785128683, ic: 0.04541593245912379
Epoch 10: 2022-04-04 16:57:51.784350: train loss: 1.6378497867082678
Eval step 0: eval loss: 1.0018861438174695
Eval: 2022-04-04 16:57:55.811835: total loss: 1.0859037604184554, mse:4.712493586492401, ic :0.12492403727426217, sharpe5:6.228610553741455, irr5:191.35977172851562, ndcg5:0.8648810961237876, pnl5:2.7054667472839355 
train 11, step: 0, loss: 4.83418900263878, grad_norm: 1.0122004922562562, ic: 0.0857608274511663
train 11, step: 500, loss: 0.9923510104646698, grad_norm: 0.0609683412739072, ic: 0.04383681829776356
train 11, step: 1000, loss: 1.0337982992467583, grad_norm: 0.3049619340845143, ic: 0.036375487555412436
train 11, step: 1500, loss: 0.6924732420345536, grad_norm: 0.0010645598188246726, ic: 0.09543137980807867
train 11, step: 2000, loss: 1.1402681104348598, grad_norm: 0.053530497418671365, ic: -0.18595064421915436
Epoch 11: 2022-04-04 16:58:27.543824: train loss: 1.636887505993802
Eval step 0: eval loss: 0.9896584139678778
Eval: 2022-04-04 16:58:31.649425: total loss: 1.083301987525075, mse:4.717878636654465, ic :0.1279655161586436, sharpe5:8.071534917354583, irr5:260.0400390625, ndcg5:0.8492994428374716, pnl5:3.1694889068603516 
train 12, step: 0, loss: 1.389370135753327, grad_norm: 0.23643968934655135, ic: 0.04544098810218104
train 12, step: 500, loss: 0.8154587839754341, grad_norm: 0.3276067763195911, ic: 0.03193804758294272
train 12, step: 1000, loss: 1.2179670107396108, grad_norm: 0.25467352635733115, ic: 0.5757139197599465
train 12, step: 1500, loss: 1.0895342812261086, grad_norm: 0.20008141674402835, ic: -0.1082581916651597
train 12, step: 2000, loss: 1.113255127093194, grad_norm: 0.05763531195782581, ic: 0.11161293455702603
Epoch 12: 2022-04-04 16:59:04.417191: train loss: 1.6374005540332839
Eval step 0: eval loss: 0.9994790638164823
Eval: 2022-04-04 16:59:08.428133: total loss: 1.0864235070092358, mse:4.716587305238143, ic :0.1276872590636328, sharpe5:6.499838198125362, irr5:201.73049926757812, ndcg5:0.8591897586476324, pnl5:3.1339566707611084 
train 13, step: 0, loss: 1.0852544635779962, grad_norm: 0.043684257195008604, ic: 0.42001739424186385
train 13, step: 500, loss: 1.1463145015803913, grad_norm: 0.007113967972776125, ic: -0.16903202499655276
train 13, step: 1000, loss: 1.383793864636605, grad_norm: 0.39530711245479877, ic: 0.056446191504698706
train 13, step: 1500, loss: 0.7764176320811929, grad_norm: 0.002347253941179114, ic: -0.060909241167823806
train 13, step: 2000, loss: 1.0377146637384793, grad_norm: 0.02835036447574515, ic: 0.05488804085936125
Epoch 13: 2022-04-04 16:59:40.393603: train loss: 1.637434632798432
Eval step 0: eval loss: 0.9876596491985913
Eval: 2022-04-04 16:59:44.548969: total loss: 1.0837385723989448, mse:4.729017293412267, ic :0.12692149226875715, sharpe5:9.21785120844841, irr5:288.6138000488281, ndcg5:0.8618737856797916, pnl5:3.069225311279297 
train 14, step: 0, loss: 1.7664422503972457, grad_norm: 0.5204115218909064, ic: 0.1594646545392275
train 14, step: 500, loss: 1.2790939925261755, grad_norm: 0.13999990296931025, ic: 0.17287706930798866
train 14, step: 1000, loss: 1.0752442415095558, grad_norm: 0.12972602773855182, ic: 0.12847335635801482
train 14, step: 1500, loss: 0.9786614703618167, grad_norm: 0.08710424929066803, ic: 0.2150759300295171
train 14, step: 2000, loss: 2.2973381901254077, grad_norm: 0.46953116718008736, ic: -0.0705918708922974
Epoch 14: 2022-04-04 17:00:17.349173: train loss: 1.6374555416222225
Eval step 0: eval loss: 1.0001309411408965
Eval: 2022-04-04 17:00:21.403344: total loss: 1.0880355339407872, mse:4.72143629380697, ic :0.12551861266673398, sharpe5:6.614370883405209, irr5:194.17222595214844, ndcg5:0.8588197655689077, pnl5:2.5396575927734375 
train 15, step: 0, loss: 0.9720583685093277, grad_norm: 0.147542692891629, ic: 0.14486713065534954
train 15, step: 500, loss: 1.226749009262796, grad_norm: 0.015555752468460908, ic: 0.07185948795010413
train 15, step: 1000, loss: 1.7651638020833333, grad_norm: 0.059278020874901895, ic: -0.1168029695016058
train 15, step: 1500, loss: 5.424118148201856, grad_norm: 0.8304618939094549, ic: -0.014338800775716733
train 15, step: 2000, loss: 0.9282624000726744, grad_norm: 0.015589046235247404, ic: -0.03487686913464314
Epoch 15: 2022-04-04 17:00:53.655526: train loss: 1.6378020048768536
Eval step 0: eval loss: 0.9980335044760399
Eval: 2022-04-04 17:00:57.629166: total loss: 1.085148423650597, mse:4.710680807747663, ic :0.1283525996405002, sharpe5:10.173283474445343, irr5:304.4118957519531, ndcg5:0.8589092651645951, pnl5:3.746786117553711 
train 16, step: 0, loss: 6.331162568270816, grad_norm: 0.9715959650547384, ic: -0.03197449780879291
train 16, step: 500, loss: 1.381851826016865, grad_norm: 0.7179860118657714, ic: -0.019779970596375384
train 16, step: 1000, loss: 0.8230121129948126, grad_norm: 0.08968288184757132, ic: -0.015151101431029846
train 16, step: 1500, loss: 1.2144372848125478, grad_norm: 0.2914233782839716, ic: 0.1056378510140129
train 16, step: 2000, loss: 0.9682239014712036, grad_norm: 0.2206042169968767, ic: 0.546974141672727
Epoch 16: 2022-04-04 17:01:30.533480: train loss: 1.6348329764641567
Eval step 0: eval loss: 0.9952268515090178
Eval: 2022-04-04 17:01:34.607910: total loss: 1.0806137795781101, mse:4.706005658418716, ic :0.1455117285936804, sharpe5:12.362852720618248, irr5:393.11248779296875, ndcg5:0.8445666945475208, pnl5:4.669600486755371 
train 17, step: 0, loss: 1.1794974672282401, grad_norm: 0.012267591382854229, ic: 0.1431245602180114
train 17, step: 500, loss: 1.0454850313519577, grad_norm: 0.01807011955937484, ic: -0.02763007293640253
train 17, step: 1000, loss: 3.379282331309303, grad_norm: 0.7064900206430247, ic: -0.021146197516469813
train 17, step: 1500, loss: 0.8859673657463593, grad_norm: 0.012106722544167357, ic: 0.034102680332739915
train 17, step: 2000, loss: 1.0194873374580535, grad_norm: 0.5613272328364143, ic: 0.5584315835370441
Epoch 17: 2022-04-04 17:02:08.130748: train loss: 1.6304358375233874
Eval step 0: eval loss: 1.0014938346457016
Eval: 2022-04-04 17:02:12.264329: total loss: 1.0826503706502815, mse:4.70340716551991, ic :0.15329121031429155, sharpe5:12.742627705335616, irr5:403.35986328125, ndcg5:0.8566279259579285, pnl5:4.7347731590271 
train 18, step: 0, loss: 0.8512722526250501, grad_norm: 0.0156387218282886, ic: 0.018804900995724433
train 18, step: 500, loss: 2.525198441993632, grad_norm: 1.0104679942415957, ic: 0.09162451978864555
train 18, step: 1000, loss: 1.3612279219593075, grad_norm: 0.3229906307326609, ic: 0.5243918307565706
train 18, step: 1500, loss: 1.7562130293942206, grad_norm: 0.8541055122869295, ic: 0.33131361785745866
train 18, step: 2000, loss: 1.2612829357127382, grad_norm: 0.3060334510939162, ic: 0.173028745189715
Epoch 18: 2022-04-04 17:02:45.587479: train loss: 1.629186567874799
Eval step 0: eval loss: 1.0030718778798051
Eval: 2022-04-04 17:02:49.586220: total loss: 1.0821225843259268, mse:4.690206732145147, ic :0.15814256636339388, sharpe5:12.722841777205467, irr5:428.5289306640625, ndcg5:0.856078391411348, pnl5:5.248915195465088 
train 19, step: 0, loss: 2.2277904881168706, grad_norm: 0.986778158029324, ic: 0.2371161509680075
train 19, step: 500, loss: 1.0191073395485102, grad_norm: 0.05035956599188782, ic: 0.07861493722984897
train 19, step: 1000, loss: 1.0061448762977916, grad_norm: 0.06601862350410362, ic: 0.5119914941168524
train 19, step: 1500, loss: 1.576428448712384, grad_norm: 0.24431012226625412, ic: 0.13812404165772282
train 19, step: 2000, loss: 1.691033902503867, grad_norm: 2.1631732192321396, ic: 0.6190004309646735
Epoch 19: 2022-04-04 17:03:22.580994: train loss: 1.6281162992781633
Eval step 0: eval loss: 1.0001761309406265
Eval: 2022-04-04 17:03:26.658808: total loss: 1.0804907622800721, mse:4.691925484120326, ic :0.15859140933190236, sharpe5:12.587162922620772, irr5:437.5067138671875, ndcg5:0.8456487233351714, pnl5:4.070559024810791 
train 20, step: 0, loss: 1.2572449187090866, grad_norm: 0.3938098414129935, ic: 0.46148393728543896
train 20, step: 500, loss: 1.2422486986140868, grad_norm: 0.5628433384651165, ic: 0.009180594680167155
train 20, step: 1000, loss: 1.5709430781415432, grad_norm: 0.31114428971646596, ic: 0.1548240426435877
train 20, step: 1500, loss: 0.8519438373702757, grad_norm: 0.4912075140237877, ic: 0.5742438310499279
train 20, step: 2000, loss: 1.3532973392027081, grad_norm: 0.10039994635854799, ic: -0.04054873235209602
Epoch 20: 2022-04-04 17:03:58.645067: train loss: 1.6276978171681273
Eval step 0: eval loss: 1.0013855205453528
Eval: 2022-04-04 17:04:02.772407: total loss: 1.0824078481738726, mse:4.690024187221848, ic :0.1539186868428559, sharpe5:11.514261817932129, irr5:371.68914794921875, ndcg5:0.8652430542189644, pnl5:3.2939090728759766 
train 21, step: 0, loss: 1.4056472644861515, grad_norm: 0.26811398530488445, ic: 0.3394966526104636
train 21, step: 500, loss: 1.1117177786677506, grad_norm: 0.08801829168148856, ic: 0.046794923937594206
train 21, step: 1000, loss: 0.8958060171335763, grad_norm: 0.2087400336235019, ic: 0.10093673372656525
train 21, step: 1500, loss: 0.7770653208874916, grad_norm: 0.12332211235126386, ic: 0.5442269932634901
train 21, step: 2000, loss: 1.1650240053689427, grad_norm: 0.05070984537186656, ic: 0.13438607680643017
Epoch 21: 2022-04-04 17:04:34.231495: train loss: 1.630629195469606
Eval step 0: eval loss: 0.9997235901296734
Eval: 2022-04-04 17:04:38.284093: total loss: 1.0806811741377178, mse:4.6902000592367195, ic :0.15584183203746316, sharpe5:11.940969852805138, irr5:404.7036437988281, ndcg5:0.8463909485065482, pnl5:4.3623552322387695 
train 22, step: 0, loss: 1.0633489970608923, grad_norm: 0.24547978731693035, ic: 0.09955206032017848
train 22, step: 500, loss: 1.0268665223609743, grad_norm: 0.002727366982660691, ic: 0.005291410213960283
train 22, step: 1000, loss: 0.9145622691217961, grad_norm: 0.040671000476097105, ic: 0.11477135597495955
train 22, step: 1500, loss: 1.01225513684044, grad_norm: 0.016732842031336057, ic: 0.20374876029956662
train 22, step: 2000, loss: 1.052994129269622, grad_norm: 0.10826054274487054, ic: 0.10690801879535203
Epoch 22: 2022-04-04 17:05:10.219863: train loss: 1.6269767380965272
Eval step 0: eval loss: 1.0073608591281595
Eval: 2022-04-04 17:05:14.247618: total loss: 1.0820690112718512, mse:4.678748691539791, ic :0.16383396333042474, sharpe5:14.326107348203658, irr5:485.57342529296875, ndcg5:0.8502910787685122, pnl5:4.71414852142334 
train 23, step: 0, loss: 1.2904709077891974, grad_norm: 0.7813997712099998, ic: -0.011463364075523765
train 23, step: 500, loss: 0.9029207334413634, grad_norm: 0.216382460490009, ic: 0.5866510383847656
train 23, step: 1000, loss: 2.2950925026000397, grad_norm: 0.8751257770950123, ic: 0.10012751086634786
train 23, step: 1500, loss: 0.7813350986251631, grad_norm: 0.30561973145879084, ic: 0.7078829341309515
train 23, step: 2000, loss: 1.4342609846673045, grad_norm: 0.4801410510219899, ic: 0.4289711202568982
Epoch 23: 2022-04-04 17:05:47.497600: train loss: 1.6257711345622865
Eval step 0: eval loss: 1.0054117195728014
Eval: 2022-04-04 17:05:51.525613: total loss: 1.0870994266717016, mse:4.6956907332250095, ic :0.15461235538842474, sharpe5:11.614284948706626, irr5:383.7740783691406, ndcg5:0.8526684064095121, pnl5:3.7733945846557617 
train 24, step: 0, loss: 1.1758611055205894, grad_norm: 0.3667751338144172, ic: 0.2813303822079861
train 24, step: 500, loss: 1.2521466124976164, grad_norm: 1.564848494512783, ic: -0.011491152536191845
train 24, step: 1000, loss: 1.0402606871069933, grad_norm: 0.30192295486705806, ic: 0.13993731060441428
train 24, step: 1500, loss: 1.1936052457554134, grad_norm: 0.12811983195721302, ic: 0.10762068351435994
train 24, step: 2000, loss: 1.363392328199052, grad_norm: 0.41986721380431774, ic: 0.44347236688557
Epoch 24: 2022-04-04 17:06:24.157400: train loss: 1.6273647263576072
Eval step 0: eval loss: 1.0129035841232226
Eval: 2022-04-04 17:06:28.209536: total loss: 1.0859993286224243, mse:4.694152307236699, ic :0.15478934633299932, sharpe5:12.894640805125237, irr5:428.857421875, ndcg5:0.8501998522720832, pnl5:4.347899913787842 
train 25, step: 0, loss: 1.3379383674369298, grad_norm: 0.4299760708712129, ic: 0.19354743451006812
train 25, step: 500, loss: 1.495535317953531, grad_norm: 0.7821275416989443, ic: 0.11820295295084898
train 25, step: 1000, loss: 1.3617480356436888, grad_norm: 0.22194200837395145, ic: 0.27241726883531814
train 25, step: 1500, loss: 2.884282662717865, grad_norm: 1.079561077633152, ic: 0.18966646590531883
train 25, step: 2000, loss: 1.1949392391156546, grad_norm: 0.1710437661589123, ic: 0.17408334235516898
Epoch 25: 2022-04-04 17:07:00.985163: train loss: 1.6271081522501465
Eval step 0: eval loss: 1.0018550959180819
Eval: 2022-04-04 17:07:05.115021: total loss: 1.0804245927125327, mse:4.681619814678712, ic :0.16317191921224644, sharpe5:12.927802122831343, irr5:433.68701171875, ndcg5:0.854113305434403, pnl5:3.7679965496063232 
train 26, step: 0, loss: 1.6206795099431817, grad_norm: 0.5493426254680109, ic: 0.18185844534596712
train 26, step: 500, loss: 1.0073353525254212, grad_norm: 0.15109681259821064, ic: -0.09307259507154078
train 26, step: 1000, loss: 1.800482020191507, grad_norm: 0.5411128542669636, ic: 0.19018633921366945
train 26, step: 1500, loss: 0.9259004169488306, grad_norm: 0.006333906542826103, ic: -0.02888353570228123
train 26, step: 2000, loss: 0.9911951740895669, grad_norm: 0.09823584995667135, ic: 0.13614008425950247
Epoch 26: 2022-04-04 17:07:37.294423: train loss: 1.6258886396317616
Eval step 0: eval loss: 1.0030443654555028
Eval: 2022-04-04 17:07:41.280700: total loss: 1.081777932653149, mse:4.685201553934375, ic :0.16141899942826973, sharpe5:13.091877667307854, irr5:445.1664123535156, ndcg5:0.8401262406941675, pnl5:3.718921184539795 
train 27, step: 0, loss: 1.630295719008848, grad_norm: 0.37646962992335653, ic: 0.6486657428139943
train 27, step: 500, loss: 1.505992741087918, grad_norm: 0.25443454703400403, ic: 0.08009538352924021
train 27, step: 1000, loss: 2.623452448159479, grad_norm: 1.185202625304366, ic: 0.39634134956208705
train 27, step: 1500, loss: 0.8684612329762318, grad_norm: 0.5939132388846731, ic: 0.541650776929106
train 27, step: 2000, loss: 1.3566138857886905, grad_norm: 1.158656858654491, ic: -0.014498494032528389
Epoch 27: 2022-04-04 17:08:12.655188: train loss: 1.6262369750707508
Eval step 0: eval loss: 1.003564208855812
Eval: 2022-04-04 17:08:16.704155: total loss: 1.0800633991416526, mse:4.683183418797232, ic :0.16655806918744642, sharpe5:12.95386899769306, irr5:452.35614013671875, ndcg5:0.8326963321229119, pnl5:3.519754648208618 
train 28, step: 0, loss: 1.164676868888027, grad_norm: 0.1183446827711314, ic: 0.1390489521089766
train 28, step: 500, loss: 2.9455715223434926, grad_norm: 0.7208379217073771, ic: 0.09732276207634863
train 28, step: 1000, loss: 2.7698074027448656, grad_norm: 1.7067139031071197, ic: -0.06533777943807717
train 28, step: 1500, loss: 1.0232857811191374, grad_norm: 0.01369497294451463, ic: 0.20240176384788566
train 28, step: 2000, loss: 1.7605755828147711, grad_norm: 0.4665915470404779, ic: 0.053126195429521586
Epoch 28: 2022-04-04 17:08:49.692148: train loss: 1.625467770183119
Eval step 0: eval loss: 1.0091215900021393
Eval: 2022-04-04 17:08:53.745821: total loss: 1.0814765334498195, mse:4.684232663968376, ic :0.1587226332736804, sharpe5:12.71937117576599, irr5:429.4384765625, ndcg5:0.8468133342407599, pnl5:3.490649938583374 
train 29, step: 0, loss: 1.5212360697320413, grad_norm: 0.14616745891669808, ic: 0.0696358625498122
train 29, step: 500, loss: 2.5233276970500413, grad_norm: 1.3879093715180022, ic: 0.029467969222570667
train 29, step: 1000, loss: 1.7038143382352942, grad_norm: 1.3276295729575343, ic: 0.48182462317058045
train 29, step: 1500, loss: 3.9859627658682233, grad_norm: 1.1449595235643537, ic: 0.1281416667039247
train 29, step: 2000, loss: 0.9283792600392914, grad_norm: 0.23912991901045744, ic: 0.4682825650110569
Epoch 29: 2022-04-04 17:09:25.443235: train loss: 1.626833647701247
Eval step 0: eval loss: 1.006793511798973
Eval: 2022-04-04 17:09:29.516282: total loss: 1.0812194043726113, mse:4.681569622442314, ic :0.16504014817714435, sharpe5:13.942837167978286, irr5:483.76837158203125, ndcg5:0.8418259358088827, pnl5:3.5028953552246094 
train 30, step: 0, loss: 1.2488714271562738, grad_norm: 0.8270535324012246, ic: 0.9767337485963298
train 30, step: 500, loss: 1.9496966011916534, grad_norm: 5.390245644945125, ic: 0.17519141134547175
train 30, step: 1000, loss: 3.45160400229263, grad_norm: 0.6576031026345084, ic: 0.3463430675114907
train 30, step: 1500, loss: 1.082159785752195, grad_norm: 0.22467303637110675, ic: 0.18775199396287043
train 30, step: 2000, loss: 1.0971750907052216, grad_norm: 0.45333155416118576, ic: 0.44137026586263367
Epoch 30: 2022-04-04 17:10:02.297695: train loss: 1.6273068242723912
Eval step 0: eval loss: 1.0071395383878028
Eval: 2022-04-04 17:10:06.415863: total loss: 1.0823943039963904, mse:4.680015391382919, ic :0.16626434096868947, sharpe5:13.745199233293533, irr5:468.19842529296875, ndcg5:0.836615725292772, pnl5:3.8052778244018555 
train 31, step: 0, loss: 1.159150398487822, grad_norm: 0.2492537653247516, ic: 0.2069740537061548
train 31, step: 500, loss: 0.8363825739036805, grad_norm: 7.969457384829489, ic: 0.18898875063254317
train 31, step: 1000, loss: 5.137492400291829, grad_norm: 1.149008715727706, ic: -0.13469193712388255
train 31, step: 1500, loss: 1.6773230716286707, grad_norm: 0.3348230914384557, ic: 0.28323428869461564
train 31, step: 2000, loss: 0.9964588384518679, grad_norm: 0.4287422702036505, ic: 0.14423953817796226
Epoch 31: 2022-04-04 17:10:39.595641: train loss: 1.6258676886031505
Eval step 0: eval loss: 1.0078719602628028
Eval: 2022-04-04 17:10:43.735786: total loss: 1.0829800858844658, mse:4.679718874354968, ic :0.16202360209065558, sharpe5:12.761886752843855, irr5:428.6021423339844, ndcg5:0.8351927565554126, pnl5:3.877361297607422 
train 32, step: 0, loss: 0.885568383067191, grad_norm: 0.3711788194194155, ic: 0.1127738293422668
train 32, step: 500, loss: 1.1151919481230945, grad_norm: 0.3525684657685418, ic: 0.16897793814767903
train 32, step: 1000, loss: 1.3735985050720767, grad_norm: 0.01810636526628883, ic: 0.08208383927580473
train 32, step: 1500, loss: 2.068239950174149, grad_norm: 0.42979224554120443, ic: 0.4309989157805122
train 32, step: 2000, loss: 1.0612280945646602, grad_norm: 0.3770392027277032, ic: 0.46687614155324253
Epoch 32: 2022-04-04 17:11:15.224544: train loss: 1.624513514598603
Eval step 0: eval loss: 1.0109563087274551
Eval: 2022-04-04 17:11:19.244796: total loss: 1.0826792181468397, mse:4.684219970364257, ic :0.16100234718499726, sharpe5:13.76581095457077, irr5:476.5893249511719, ndcg5:0.8557988978535238, pnl5:3.418177366256714 
train 33, step: 0, loss: 1.1647149094012605, grad_norm: 0.023821308572495255, ic: 0.03746197871652455
train 33, step: 500, loss: 3.163148614647387, grad_norm: 0.4306454170032385, ic: 0.5129404948525013
train 33, step: 1000, loss: 5.240671801028769, grad_norm: 1.9678114557828978, ic: 0.03596265622451182
train 33, step: 1500, loss: 1.3191162109375, grad_norm: 0.9476084687880912, ic: 0.0014079586746083145
train 33, step: 2000, loss: 1.8645585407582363, grad_norm: 0.2856622537525066, ic: 0.07258520177368881
Epoch 33: 2022-04-04 17:11:51.847435: train loss: 1.626392152293793
Eval step 0: eval loss: 1.0175509982638888
Eval: 2022-04-04 17:11:55.914072: total loss: 1.0902277815362549, mse:4.700253078322712, ic :0.16187488178450377, sharpe5:13.29260499536991, irr5:454.23773193359375, ndcg5:0.848253751439338, pnl5:3.7127604484558105 
train 34, step: 0, loss: 0.7163291967425218, grad_norm: 0.2923352766906414, ic: 0.15831456744793446
train 34, step: 500, loss: 1.8219321913565818, grad_norm: 0.4100642322103077, ic: 0.8822779929192552
train 34, step: 1000, loss: 0.7060001346982758, grad_norm: 0.11103293429155392, ic: 0.43988276445245217
train 34, step: 1500, loss: 1.6593574719551283, grad_norm: 1.350669530484849, ic: 0.6405379621476213
train 34, step: 2000, loss: 2.976366222199341, grad_norm: 0.48595360546158933, ic: 0.09091958925345611
Epoch 34: 2022-04-04 17:12:27.905397: train loss: 1.6270751326052153
Eval step 0: eval loss: 1.0117913879426672
Eval: 2022-04-04 17:12:32.032645: total loss: 1.084846775327612, mse:4.6880376869481974, ic :0.16083013883349848, sharpe5:12.918427999019622, irr5:423.8607177734375, ndcg5:0.8526949945079058, pnl5:3.60082745552063 
train 35, step: 0, loss: 1.0570078016836433, grad_norm: 0.7559255049570234, ic: -0.012070114278645981
train 35, step: 500, loss: 3.332159978693182, grad_norm: 1.203243712759207, ic: -0.10989467201045106
train 35, step: 1000, loss: 1.3538896805814067, grad_norm: 0.11811720947659553, ic: 0.49400366671865437
train 35, step: 1500, loss: 1.6285824287533273, grad_norm: 0.3838280958006809, ic: 0.09386800209222076
train 35, step: 2000, loss: 1.2913010195643282, grad_norm: 0.07680534997485204, ic: -0.10596148171633941
Epoch 35: 2022-04-04 17:13:03.820007: train loss: 1.6256211176273814
Eval step 0: eval loss: 1.0034909923808584
Eval: 2022-04-04 17:13:07.918244: total loss: 1.0847392064497523, mse:4.696768085862388, ic :0.1622436870492469, sharpe5:13.607201914787291, irr5:436.9847106933594, ndcg5:0.8457237402854427, pnl5:4.331683158874512 
train 36, step: 0, loss: 8.973644374013418, grad_norm: 1.0547957190790689, ic: -0.19637061264351405
train 36, step: 500, loss: 0.8579465648064913, grad_norm: 0.021578999944369022, ic: 0.149632069678318
train 36, step: 1000, loss: 1.9799181349734043, grad_norm: 1.2605836675531499, ic: 0.09612980302537145
train 36, step: 1500, loss: 1.0496866484782372, grad_norm: 0.12172270418989836, ic: 0.10906855882179252
train 36, step: 2000, loss: 2.1591089887433785, grad_norm: 1.1934368029919606, ic: 0.3887477804266648
Epoch 36: 2022-04-04 17:13:39.430325: train loss: 1.6259112015713837
Eval step 0: eval loss: 1.0110367247153107
Eval: 2022-04-04 17:13:43.562027: total loss: 1.0867081997112078, mse:4.6902997333212415, ic :0.1639160368724151, sharpe5:13.494411624670027, irr5:451.260009765625, ndcg5:0.8455642466220621, pnl5:3.909899950027466 
train 37, step: 0, loss: 1.179948280220862, grad_norm: 0.16993958056503083, ic: 0.18813284904662664
train 37, step: 500, loss: 2.3360260389652487, grad_norm: 0.038304378691386136, ic: 0.14946860907616094
train 37, step: 1000, loss: 0.767276141231676, grad_norm: 0.3684559659947709, ic: 0.15399453488308487
train 37, step: 1500, loss: 3.133263602474619, grad_norm: 0.6698218614416537, ic: 0.19737926135753464
train 37, step: 2000, loss: 3.1320958590779466, grad_norm: 1.7849934545292028, ic: 0.031140575291331574
Epoch 37: 2022-04-04 17:14:16.447375: train loss: 1.6242014529197562
Eval step 0: eval loss: 1.007773416929963
Eval: 2022-04-04 17:14:20.507473: total loss: 1.0808701908489067, mse:4.680008377137069, ic :0.1632646459045445, sharpe5:13.33605893075466, irr5:461.66949462890625, ndcg5:0.838003191599529, pnl5:3.7790677547454834 
train 38, step: 0, loss: 1.3421717788233902, grad_norm: 0.4062900631026119, ic: -0.2355629896093138
train 38, step: 500, loss: 1.7081404811652132, grad_norm: 0.8037189370565048, ic: 0.21321029199199135
train 38, step: 1000, loss: 1.8152528629467795, grad_norm: 0.5927781956537309, ic: 0.16873574304067604
train 38, step: 1500, loss: 1.0933885421092784, grad_norm: 0.38237382370499307, ic: 0.47400183149182407
train 38, step: 2000, loss: 0.7605447651427468, grad_norm: 0.01469736729339247, ic: 0.557086398657819
Epoch 38: 2022-04-04 17:14:52.553224: train loss: 1.6251584227473947
Eval step 0: eval loss: 0.9969990244660017
Eval: 2022-04-04 17:14:56.628547: total loss: 1.079465971374575, mse:4.685898556637359, ic :0.1670596033551893, sharpe5:13.392717989087105, irr5:460.9847412109375, ndcg5:0.841782019298062, pnl5:3.8272268772125244 
train 39, step: 0, loss: 0.8644452569609005, grad_norm: 0.022653315396992817, ic: 0.5419382983678243
train 39, step: 500, loss: 1.2456052729676224, grad_norm: 0.320840959598786, ic: 0.018002415035095008
train 39, step: 1000, loss: 1.3962002840909091, grad_norm: 0.32391047414345886, ic: 0.07059659601391734
train 39, step: 1500, loss: 2.4261774715791113, grad_norm: 0.44702972835812715, ic: -0.07212840958667172
train 39, step: 2000, loss: 2.880699639869888, grad_norm: 1.4031355927444995, ic: 0.21838926014936738
Epoch 39: 2022-04-04 17:15:28.902604: train loss: 1.6234935990547965
Eval step 0: eval loss: 1.002541749461065
Eval: 2022-04-04 17:15:33.019202: total loss: 1.0796491838014268, mse:4.6751512082366276, ic :0.16821446580130978, sharpe5:13.150790866613388, irr5:470.3351135253906, ndcg5:0.845551704035589, pnl5:3.289289712905884 

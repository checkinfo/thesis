Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='AdjSeqTimeDataset', dout=0.3, epochs=40, glstm_layers=1, gnn_layers=2, gpu=0, graph_attn=True, hidden_dim=128, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=3, mask_adj=True, mask_type='soft', model_type='RGCNModel', normalize_adj=True, num_days=1, num_heads=1, print_inteval=500, relation_num=1, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_250_0.8/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
26928
RGCNModel(
  (fc1): Linear(in_features=9, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
  (fc4): Linear(in_features=128, out_features=1, bias=True)
  (gnns): ModuleList(
    (0): RGCN(
      (attention): ModuleList(
        (0): GraphAttentionLayer (128 -> 128)
      )
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
    )
    (1): RGCN(
      (attention): ModuleList(
        (0): GraphAttentionLayer (128 -> 128)
      )
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
    )
  )
  (dropout): Dropout(p=0.3, inplace=False)
  (relu): LeakyReLU(negative_slope=0.01)
)
train 0, step: 0, loss: 2.0745534060029645, grad_norm: 0.48186794193141197, ic: 0.12071292676498108
train 0, step: 500, loss: 1.3669655708041129, grad_norm: 0.8513339048492476, ic: -0.036555187547482104
train 0, step: 1000, loss: 1.5061447717944456, grad_norm: 0.032533067828839655, ic: 0.11826507921720497
train 0, step: 1500, loss: 1.1943385646858187, grad_norm: 0.11340289963868665, ic: 0.016418789408448136
train 0, step: 2000, loss: 1.556239895704316, grad_norm: 0.04624766437210144, ic: -0.006408728018303049
Epoch 0: 2022-04-20 15:05:46.550310: train loss: 1.6475261889187305
Eval step 0: eval loss: 1.0137139150128356
Eval: 2022-04-20 15:05:48.577794: total loss: 1.091985532913966, mse:4.889637212095495, ic :0.027783002053323652, sharpe5:1.1355271806567906, irr5:11.036502838134766, ndcg5:0.853414229263011, pnl5:0.8995426893234253 
train 1, step: 0, loss: 0.6389227385568147, grad_norm: 0.048542820565349684, ic: 0.03340864959150834
train 1, step: 500, loss: 1.2610987768096515, grad_norm: 0.28957125898641217, ic: 0.16787469272401992
train 1, step: 1000, loss: 0.8805858483285487, grad_norm: 0.06388867118473389, ic: -0.0032734631870658523
train 1, step: 1500, loss: 1.8467396061594894, grad_norm: 0.5394616142929687, ic: -0.0174594339934573
train 1, step: 2000, loss: 1.380866198225737, grad_norm: 0.22801114483314316, ic: 0.03422261416912157
Epoch 1: 2022-04-20 15:06:15.640703: train loss: 1.646993043634722
Eval step 0: eval loss: 1.0130718084559307
Eval: 2022-04-20 15:06:17.716608: total loss: 1.0904265148903851, mse:4.8883048454699995, ic :0.027523652713557445, sharpe5:0.6023392443358898, irr5:6.249181747436523, ndcg5:0.849315736981842, pnl5:0.97188800573349 
train 2, step: 0, loss: 1.3306123292278733, grad_norm: 0.49036140560148705, ic: 0.03444859156206636
train 2, step: 500, loss: 0.9490073960901935, grad_norm: 0.25291431109609935, ic: 0.03654441847044569
train 2, step: 1000, loss: 2.986541980498504, grad_norm: 0.8985167820583082, ic: 0.09168708762448471
train 2, step: 1500, loss: 2.2908936514918716, grad_norm: 0.8422650816353863, ic: 0.04706720651199102
train 2, step: 2000, loss: 1.4621569055664863, grad_norm: 0.27373468627254705, ic: -0.11643250477988834
Epoch 2: 2022-04-20 15:06:44.430390: train loss: 1.6464686623719575
Eval step 0: eval loss: 0.998540877291502
Eval: 2022-04-20 15:06:46.494418: total loss: 1.0890437822086891, mse:4.877889765935876, ic :0.052276809120507466, sharpe5:2.031963597089052, irr5:21.879940032958984, ndcg5:0.8658414769073067, pnl5:1.233722448348999 
train 3, step: 0, loss: 1.8262411758201031, grad_norm: 0.06310806012266477, ic: -0.15142000162543945
train 3, step: 500, loss: 0.7808725769121928, grad_norm: 0.024691500618042664, ic: 0.08988564889890564
train 3, step: 1000, loss: 1.4114670659127664, grad_norm: 0.40668994290071664, ic: 0.10772279592552907
train 3, step: 1500, loss: 2.646955285068639, grad_norm: 0.3567849118043782, ic: -0.051022520595354066
train 3, step: 2000, loss: 1.356886707652699, grad_norm: 0.15738447843068984, ic: 0.06333926982040405
Epoch 3: 2022-04-20 15:07:14.333699: train loss: 1.6459750747564308
Eval step 0: eval loss: 1.0045480351500788
Eval: 2022-04-20 15:07:16.665351: total loss: 1.0903325411003328, mse:4.877824493882074, ic :0.05174214119567202, sharpe5:1.4075752973556517, irr5:14.722221374511719, ndcg5:0.8411740905533117, pnl5:1.2735607624053955 
train 4, step: 0, loss: 1.1666630435751997, grad_norm: 0.15006872698373236, ic: 0.08359065312014514
train 4, step: 500, loss: 0.9966131338899197, grad_norm: 0.002742029088119309, ic: 0.1338405353487881
train 4, step: 1000, loss: 1.334535320872664, grad_norm: 0.06287409796617661, ic: 0.07204031984927574
train 4, step: 1500, loss: 1.07649903908754, grad_norm: 0.09347645719496668, ic: 0.17232240486606262
train 4, step: 2000, loss: 4.184204581776161, grad_norm: 0.8828793136159104, ic: -0.023172095042687253
Epoch 4: 2022-04-20 15:07:45.969286: train loss: 1.6455074064806892
Eval step 0: eval loss: 1.0550922797566151
Eval: 2022-04-20 15:07:48.374454: total loss: 1.1429852586345657, mse:5.0436548088974895, ic :0.049383591532280856, sharpe5:1.6445140805840492, irr5:16.669076919555664, ndcg5:0.8429219137163685, pnl5:1.146920084953308 
train 5, step: 0, loss: 1.1112135853008378, grad_norm: 2.9907355314544195, ic: -0.07181226795687203
train 5, step: 500, loss: 0.7915912646252962, grad_norm: 0.030715903799090494, ic: 0.15097370821499692
train 5, step: 1000, loss: 1.117808442843572, grad_norm: 0.036334489466837566, ic: -0.1121022749516343
train 5, step: 1500, loss: 1.7503608517530487, grad_norm: 0.31711233088977, ic: -0.10544900923348322
train 5, step: 2000, loss: 2.1771216248174454, grad_norm: 0.8160772823398812, ic: 0.01865168832359315
Epoch 5: 2022-04-20 15:08:21.501625: train loss: 1.6456443750910617
Eval step 0: eval loss: 0.9950263579309834
Eval: 2022-04-20 15:08:24.307948: total loss: 1.0889759768724103, mse:4.887447600456148, ic :0.048560578681334794, sharpe5:1.3458931370079517, irr5:12.769519805908203, ndcg5:0.8406507767473544, pnl5:1.0682908296585083 
train 6, step: 0, loss: 0.7867594568146817, grad_norm: 0.015971720305576767, ic: -0.09314563966681527
train 6, step: 500, loss: 1.4379327785201936, grad_norm: 0.21916121987690151, ic: 0.053465653227626045
train 6, step: 1000, loss: 1.2351759625145011, grad_norm: 0.17188361624282644, ic: 0.13685213750411415
train 6, step: 1500, loss: 1.0634282871462264, grad_norm: 0.35619909178708425, ic: 0.06514998199202615
train 6, step: 2000, loss: 2.2822749111344107, grad_norm: 1.0676636642441182, ic: 0.10523261916570036
Epoch 6: 2022-04-20 15:09:01.864959: train loss: 1.6461101841281283
Eval step 0: eval loss: 1.0020158636124274
Eval: 2022-04-20 15:09:04.985288: total loss: 1.0896720873074808, mse:4.87927843958193, ic :0.04850757759951149, sharpe5:2.0338270707428454, irr5:20.415056228637695, ndcg5:0.850176716343296, pnl5:1.1990901231765747 
train 7, step: 0, loss: 1.4521654308136842, grad_norm: 0.5222454579837925, ic: 0.18676485142775376
train 7, step: 500, loss: 1.3232293906122032, grad_norm: 0.024590156504576077, ic: 0.10498362913018447
train 7, step: 1000, loss: 0.6435818095200582, grad_norm: 0.012096144462987294, ic: 0.27612492226197627
train 7, step: 1500, loss: 1.0009438667677955, grad_norm: 0.12320951646120915, ic: 0.07393907632932302
train 7, step: 2000, loss: 1.5879827097365293, grad_norm: 0.5288375693433467, ic: 0.11443937714275458
Epoch 7: 2022-04-20 15:09:43.881156: train loss: 1.6450669454591391
Eval step 0: eval loss: 0.9938034049582016
Eval: 2022-04-20 15:09:47.014067: total loss: 1.0895948077007978, mse:4.884457953557649, ic :0.0523595022284173, sharpe5:0.9851156513392925, irr5:10.159858703613281, ndcg5:0.8566314459972924, pnl5:1.1095911264419556 
train 8, step: 0, loss: 1.2122280126875986, grad_norm: 0.08397297156085619, ic: 0.049556410272155994
train 8, step: 500, loss: 5.538438372477469, grad_norm: 1.0673524024435874, ic: 0.12951964476859826
train 8, step: 1000, loss: 1.8780397713324823, grad_norm: 0.5247514560273927, ic: 0.05092883939359486
train 8, step: 1500, loss: 1.1203679920130274, grad_norm: 0.3292490947517667, ic: 0.09857353032902319
train 8, step: 2000, loss: 1.1341738578600762, grad_norm: 0.5484791013240082, ic: -0.01656092383952572
Epoch 8: 2022-04-20 15:10:26.136801: train loss: 1.644678584053704
Eval step 0: eval loss: 1.0060027224443786
Eval: 2022-04-20 15:10:29.008588: total loss: 1.0923722740704342, mse:4.882553952936115, ic :0.05206231313014627, sharpe5:2.846320738792419, irr5:27.206857681274414, ndcg5:0.8507221427247761, pnl5:1.038146734237671 
train 9, step: 0, loss: 1.1478470729575019, grad_norm: 0.009943554320928144, ic: 0.04337795212079765
train 9, step: 500, loss: 3.1914482407011033, grad_norm: 0.7427316512118056, ic: 0.11004695246648664
train 9, step: 1000, loss: 0.8639353824576644, grad_norm: 0.07454721992338549, ic: 0.2702642169967132
train 9, step: 1500, loss: 2.1833418934233184, grad_norm: 1.1466323413675765, ic: -0.03249448843115212
train 9, step: 2000, loss: 0.6052324848790323, grad_norm: 0.0056931075329500706, ic: 0.08730167832274166
Epoch 9: 2022-04-20 15:11:10.267580: train loss: 1.6442888588573104
Eval step 0: eval loss: 0.9993760850694443
Eval: 2022-04-20 15:11:13.493221: total loss: 1.089822143987628, mse:4.895311927030095, ic :0.03813027489279117, sharpe5:1.5492225884646176, irr5:14.856679916381836, ndcg5:0.8336052901633937, pnl5:1.035071849822998 
train 10, step: 0, loss: 1.3144022895254939, grad_norm: 0.0337910611075324, ic: 0.2084251686251134
train 10, step: 500, loss: 0.8989895465610784, grad_norm: 0.00490075352501377, ic: 0.09171879031158411
train 10, step: 1000, loss: 1.5391257204282889, grad_norm: 0.5338858476871088, ic: 0.040494631690572595
train 10, step: 1500, loss: 3.128380127913552, grad_norm: 0.813104956393081, ic: 0.014557582954992255
train 10, step: 2000, loss: 1.3827663989777261, grad_norm: 0.12826613707490597, ic: 0.029820542644905492
Epoch 10: 2022-04-20 15:11:53.918560: train loss: 1.6445335217940624
Eval step 0: eval loss: 1.0066031103952737
Eval: 2022-04-20 15:11:57.142310: total loss: 1.0907620000222003, mse:4.881427542670927, ic :0.0469814909409893, sharpe5:2.0521004636585713, irr5:20.71503448486328, ndcg5:0.8391264000306857, pnl5:1.121451497077942 
train 11, step: 0, loss: 4.859426156909695, grad_norm: 0.6149902963289895, ic: 0.06527841277789216
train 11, step: 500, loss: 0.9886645245295699, grad_norm: 0.06237265930090795, ic: 0.04372575409450071
train 11, step: 1000, loss: 1.0344126546410184, grad_norm: 0.31230609786259184, ic: 0.03816213110727189
train 11, step: 1500, loss: 0.6939341665341131, grad_norm: 0.0029865036349941837, ic: 0.10971314719121911
train 11, step: 2000, loss: 1.0941242431838951, grad_norm: 0.03685006221694054, ic: 0.014968274381662858
Epoch 11: 2022-04-20 15:12:38.675672: train loss: 1.6436622998106494
Eval step 0: eval loss: 0.994804522939705
Eval: 2022-04-20 15:12:42.160638: total loss: 1.0887547859157358, mse:4.890098801457501, ic :0.04584922637942955, sharpe5:1.2725700601190328, irr5:12.108602523803711, ndcg5:0.8450029826664696, pnl5:0.9278477430343628 
train 12, step: 0, loss: 1.3852032215423002, grad_norm: 0.2746596481958357, ic: 0.057362955278818524
train 12, step: 500, loss: 0.8048986903117601, grad_norm: 0.3563264537238477, ic: 0.021462806190642517
train 12, step: 1000, loss: 1.2823894571188572, grad_norm: 0.24840789331323287, ic: -0.06205777739037158
train 12, step: 1500, loss: 1.0886876284164755, grad_norm: 0.1871217364740828, ic: -0.08660497516745924
train 12, step: 2000, loss: 1.1175102194492255, grad_norm: 0.0569967050329193, ic: 0.0867245495870376
Epoch 12: 2022-04-20 15:13:24.160875: train loss: 1.6441193569696282
Eval step 0: eval loss: 1.0010071604298314
Eval: 2022-04-20 15:13:27.719079: total loss: 1.0905937161785073, mse:4.88015838689273, ic :0.05005673207369188, sharpe5:1.7021667156368494, irr5:15.774816513061523, ndcg5:0.8386501903219794, pnl5:1.1360944509506226 
train 13, step: 0, loss: 1.1068075756975269, grad_norm: 0.0270227383348664, ic: -0.1577932852690456
train 13, step: 500, loss: 1.1469187030355439, grad_norm: 0.005060436448742287, ic: -0.182150274690835
train 13, step: 1000, loss: 1.3916029070982494, grad_norm: 0.3983155223451906, ic: 0.07052380117191975
train 13, step: 1500, loss: 0.7764648251700437, grad_norm: 0.0025159739581572787, ic: -0.049653603791998055
train 13, step: 2000, loss: 1.044250019501248, grad_norm: 0.024456480679499737, ic: 0.05488598034252938
Epoch 13: 2022-04-20 15:14:09.213111: train loss: 1.6450640390061189
Eval step 0: eval loss: 0.9955818774889744
Eval: 2022-04-20 15:14:12.622551: total loss: 1.0890816159432508, mse:4.894818838058927, ic :0.04244985156177517, sharpe5:7.77656595647335, irr5:216.31533813476562, ndcg5:0.8612369355623583, pnl5:3.2902588844299316 
train 14, step: 0, loss: 1.7678156707246424, grad_norm: 0.5361949030017286, ic: 0.16790246001708437
train 14, step: 500, loss: 1.2812476680175422, grad_norm: 0.14357051268102033, ic: 0.18231145271703042
train 14, step: 1000, loss: 1.0705234496061466, grad_norm: 0.12315961026274685, ic: 0.14662085402275638
train 14, step: 1500, loss: 0.9805817049773864, grad_norm: 0.07061421933896285, ic: 0.16689790864646367
train 14, step: 2000, loss: 2.284574374872553, grad_norm: 0.46189485351714155, ic: -0.03996030508785475
Epoch 14: 2022-04-20 15:14:53.666532: train loss: 1.6417180152224018
Eval step 0: eval loss: 1.0011234454194642
Eval: 2022-04-20 15:14:57.159943: total loss: 1.0904299750551936, mse:4.8345700862961944, ic :0.09611583482076852, sharpe5:7.538726179003715, irr5:216.6732940673828, ndcg5:0.8473305447603311, pnl5:3.104048252105713 
train 15, step: 0, loss: 0.9653809373129489, grad_norm: 0.1395899482409812, ic: 0.14022946531658165
train 15, step: 500, loss: 1.2222431319829068, grad_norm: 0.006839214820556324, ic: 0.09423194540456424
train 15, step: 1000, loss: 1.7619119791666666, grad_norm: 0.05001821365596254, ic: -0.11592685448449258
train 15, step: 1500, loss: 5.419779129205336, grad_norm: 0.8698679179160017, ic: 0.03265723052226425
train 15, step: 2000, loss: 0.9327898162808, grad_norm: 0.013202252453789531, ic: -0.11701008534293657
Epoch 15: 2022-04-20 15:15:37.735213: train loss: 1.6378030742253977
Eval step 0: eval loss: 0.9976490376308254
Eval: 2022-04-20 15:15:40.860908: total loss: 1.0867822907830016, mse:4.727436807279514, ic :0.11756791205993372, sharpe5:8.412958289980889, irr5:233.62939453125, ndcg5:0.848119470449983, pnl5:2.9819278717041016 
train 16, step: 0, loss: 6.307526213417148, grad_norm: 1.1575126469824955, ic: -0.04202176384088992
train 16, step: 500, loss: 1.39688962906126, grad_norm: 0.6183772424727809, ic: -0.01249760924577344
train 16, step: 1000, loss: 0.8205096224063255, grad_norm: 0.1073323714855913, ic: 0.03719010298489754
train 16, step: 1500, loss: 1.21606557389298, grad_norm: 0.26065992706477864, ic: 0.13862845612528757
train 16, step: 2000, loss: 0.9730494308239501, grad_norm: 0.238372559628571, ic: 0.518810411860519
Epoch 16: 2022-04-20 15:16:22.321721: train loss: 1.636386482979669
Eval step 0: eval loss: 0.9960943928136519
Eval: 2022-04-20 15:16:26.034324: total loss: 1.0859061700969992, mse:4.749388071931343, ic :0.11606070514998006, sharpe5:8.314407019615173, irr5:225.77093505859375, ndcg5:0.8641240864564792, pnl5:3.495065450668335 
train 17, step: 0, loss: 1.1813455593366564, grad_norm: 0.01623845350305711, ic: 0.157010362321803
train 17, step: 500, loss: 1.0335137770187603, grad_norm: 0.0217622471686962, ic: -0.016682703876177107
train 17, step: 1000, loss: 3.356617540416151, grad_norm: 0.760205667521334, ic: -0.025202855383055625
train 17, step: 1500, loss: 0.8874224320198726, grad_norm: 0.0035821420715201474, ic: 0.027940850724393482
train 17, step: 2000, loss: 1.0202495805369127, grad_norm: 0.4734845348712306, ic: 0.5214633453532469
Epoch 17: 2022-04-20 15:17:07.976902: train loss: 1.636255196898626
Eval step 0: eval loss: 1.0078441264316744
Eval: 2022-04-20 15:17:11.399846: total loss: 1.0923983207828032, mse:4.7463690371475, ic :0.14257752399211196, sharpe5:14.277911487221717, irr5:467.5854797363281, ndcg5:0.8446023426760498, pnl5:8.024611473083496 
train 18, step: 0, loss: 0.8602390855240076, grad_norm: 1.1007988486263323, ic: 0.038994812109497436
train 18, step: 500, loss: 2.534343183481409, grad_norm: 1.1283815416045186, ic: 0.07193158701339325
train 18, step: 1000, loss: 1.3585951551258992, grad_norm: 0.4084080141200622, ic: 0.5333910913141648
train 18, step: 1500, loss: 1.7574377454351142, grad_norm: 0.6964222458221161, ic: 0.3369888736292904
train 18, step: 2000, loss: 1.2561327109510398, grad_norm: 0.3529790163867708, ic: 0.19622130951387096
Epoch 18: 2022-04-20 15:17:52.787348: train loss: 1.6294575380970842
Eval step 0: eval loss: 1.0006104158438651
Eval: 2022-04-20 15:17:56.079063: total loss: 1.083201764873694, mse:4.692511905248375, ic :0.1595811686332984, sharpe5:14.855592103600502, irr5:498.45648193359375, ndcg5:0.8533152636163546, pnl5:6.511608123779297 
train 19, step: 0, loss: 2.1940533171743497, grad_norm: 0.82930826692036, ic: 0.25800252708940635
train 19, step: 500, loss: 1.0265055101971294, grad_norm: 0.07364869903484252, ic: 0.03148773093417026
train 19, step: 1000, loss: 0.987331161549316, grad_norm: 0.6412563398182461, ic: 0.5539128525224437
train 19, step: 1500, loss: 1.582424776053723, grad_norm: 0.1815363602994943, ic: 0.1366157157382469
train 19, step: 2000, loss: 1.8593761329031324, grad_norm: 1.7369377739488083, ic: 0.6471154618061945
Epoch 19: 2022-04-20 15:18:38.704090: train loss: 1.6259883978114529
Eval step 0: eval loss: 0.9984985801532056
Eval: 2022-04-20 15:18:42.267226: total loss: 1.0826758208234277, mse:4.699867588462415, ic :0.1532266687137752, sharpe5:14.078727909922598, irr5:449.4639587402344, ndcg5:0.8363270251847462, pnl5:6.102262496948242 
train 20, step: 0, loss: 1.227633735485505, grad_norm: 0.33024882486542745, ic: 0.46237674082677066
train 20, step: 500, loss: 1.2208359835297269, grad_norm: 0.48280550957944707, ic: 0.01818991186709521
train 20, step: 1000, loss: 1.5543155377349127, grad_norm: 0.5264131201851414, ic: 0.16751548728321586
train 20, step: 1500, loss: 0.8350503347177045, grad_norm: 0.5274269755533154, ic: 0.5772933258676107
train 20, step: 2000, loss: 1.346133874324222, grad_norm: 0.13064735310146047, ic: -0.0387949727664846
Epoch 20: 2022-04-20 15:19:24.451248: train loss: 1.6250693697794347
Eval step 0: eval loss: 1.000923401810986
Eval: 2022-04-20 15:19:27.690872: total loss: 1.0822463805997098, mse:4.681715695687474, ic :0.1637003494446457, sharpe5:14.975095628499984, irr5:497.7441101074219, ndcg5:0.8501236526758372, pnl5:4.611820697784424 
train 21, step: 0, loss: 1.415302136479592, grad_norm: 0.2696512868900817, ic: 0.3042027297441862
train 21, step: 500, loss: 1.098263145861228, grad_norm: 0.13103091518944465, ic: 0.059526134002283494
train 21, step: 1000, loss: 0.9103750136413824, grad_norm: 0.18224907762460965, ic: 0.08081436171667988
train 21, step: 1500, loss: 0.7265844248501857, grad_norm: 0.11204268181693654, ic: 0.6257998545870842
train 21, step: 2000, loss: 1.1145075099233663, grad_norm: 0.027071200054473946, ic: 0.29715167043768353
Epoch 21: 2022-04-20 15:20:09.658901: train loss: 1.6244191075024594
Eval step 0: eval loss: 0.9984337845370919
Eval: 2022-04-20 15:20:13.122376: total loss: 1.083309908591877, mse:4.715265761756152, ic :0.14542891432462082, sharpe5:13.196779882907867, irr5:389.4519348144531, ndcg5:0.8397429082722404, pnl5:4.507188320159912 
train 22, step: 0, loss: 1.0737671029273848, grad_norm: 0.29569092199666286, ic: 0.09375647967440585
train 22, step: 500, loss: 1.027445539339321, grad_norm: 0.0013817575625113348, ic: 0.018050466613414133
train 22, step: 1000, loss: 0.9183940814484506, grad_norm: 0.014202680401094733, ic: 0.11647668420578933
train 22, step: 1500, loss: 0.999896753614194, grad_norm: 0.44461105536670714, ic: 0.27525576632269844
train 22, step: 2000, loss: 1.0495415975881177, grad_norm: 0.13798280219242115, ic: 0.1619105071275629
Epoch 22: 2022-04-20 15:20:54.128020: train loss: 1.624246188523271
Eval step 0: eval loss: 1.004074795739534
Eval: 2022-04-20 15:20:57.158499: total loss: 1.0823274725895002, mse:4.693929707263179, ic :0.15566135099735648, sharpe5:14.4894488543272, irr5:448.4320983886719, ndcg5:0.8434477119069871, pnl5:5.666057586669922 
train 23, step: 0, loss: 1.3039726125576434, grad_norm: 0.8388142149556627, ic: -0.026057103282600684
train 23, step: 500, loss: 0.902479989188058, grad_norm: 0.23866946005442274, ic: 0.6071932561116089
train 23, step: 1000, loss: 2.2743602819185815, grad_norm: 0.8537147707916102, ic: 0.09958783002694029
train 23, step: 1500, loss: 0.7387390933522356, grad_norm: 0.4188563298248303, ic: 0.7387615804506494
train 23, step: 2000, loss: 1.5119894637542517, grad_norm: 0.3609723321449368, ic: 0.41252845441336866
Epoch 23: 2022-04-20 15:21:38.759816: train loss: 1.6221955890162272
Eval step 0: eval loss: 0.999053906867101
Eval: 2022-04-20 15:21:41.994139: total loss: 1.0843153604048448, mse:4.697508396862567, ic :0.14837495950193302, sharpe5:13.592898572087288, irr5:399.5356750488281, ndcg5:0.848085504647311, pnl5:4.818166732788086 
train 24, step: 0, loss: 1.1670287800058547, grad_norm: 0.833357196181051, ic: 0.35897936508358885
train 24, step: 500, loss: 1.252877172125286, grad_norm: 0.2288435258343646, ic: 0.043573673004195373
train 24, step: 1000, loss: 1.0460311145317265, grad_norm: 0.2971793011023554, ic: 0.10149716001732126
train 24, step: 1500, loss: 1.1989226093442422, grad_norm: 0.09233183161583637, ic: 0.08950129522524773
train 24, step: 2000, loss: 1.3703057890254737, grad_norm: 0.40059895636840553, ic: 0.44418367156534494
Epoch 24: 2022-04-20 15:22:24.442260: train loss: 1.625016972450331
Eval step 0: eval loss: 1.005714870491048
Eval: 2022-04-20 15:22:27.791810: total loss: 1.084027636135926, mse:4.695391054570277, ic :0.15578585463544142, sharpe5:14.333986909389495, irr5:467.9708557128906, ndcg5:0.8489847142480047, pnl5:6.253518581390381 
train 25, step: 0, loss: 1.3339047578748575, grad_norm: 0.3933431428144138, ic: 0.17151819118833514
train 25, step: 500, loss: 1.504398197322697, grad_norm: 0.5112156505271519, ic: 0.1144291125063696
train 25, step: 1000, loss: 1.3675330032076625, grad_norm: 0.2094434993478802, ic: 0.27538653124678075
train 25, step: 1500, loss: 2.876782563430465, grad_norm: 1.1579679166850176, ic: 0.27353292671138163
train 25, step: 2000, loss: 1.2056701273857793, grad_norm: 0.14402816238558275, ic: 0.11157967703355703
Epoch 25: 2022-04-20 15:23:10.597363: train loss: 1.6228304088949355
Eval step 0: eval loss: 0.9985808603006516
Eval: 2022-04-20 15:23:14.110008: total loss: 1.0807995769634469, mse:4.678593630591073, ic :0.16810058432140168, sharpe5:15.039197230339049, irr5:492.3703918457031, ndcg5:0.8420711438831834, pnl5:5.157016754150391 
train 26, step: 0, loss: 1.6081168323863635, grad_norm: 0.25482717234100466, ic: 0.22996188225432407
train 26, step: 500, loss: 1.0522605375667624, grad_norm: 0.2716255092042219, ic: -0.04871625725545179
train 26, step: 1000, loss: 1.7869044676311407, grad_norm: 0.6784772700973265, ic: 0.18435982116538827
train 26, step: 1500, loss: 0.9207219129889007, grad_norm: 0.004789050354895163, ic: 0.054236122527900506
train 26, step: 2000, loss: 1.010241410863681, grad_norm: 0.11550507609169217, ic: 0.11498899491744106
Epoch 26: 2022-04-20 15:23:56.491462: train loss: 1.6278420845186667
Eval step 0: eval loss: 0.9993954337603672
Eval: 2022-04-20 15:24:00.025361: total loss: 1.0838341430773755, mse:4.7013762829958585, ic :0.15829660267651977, sharpe5:15.00485728919506, irr5:484.28521728515625, ndcg5:0.8552873582285911, pnl5:5.947143077850342 
train 27, step: 0, loss: 1.694833410791604, grad_norm: 0.5236458651441895, ic: 0.6356315353636091
train 27, step: 500, loss: 1.5025008277240475, grad_norm: 0.28460618168130786, ic: 0.057316530725910954
train 27, step: 1000, loss: 2.5567354737276613, grad_norm: 2.5282814570772048, ic: 0.3996074454633382
train 27, step: 1500, loss: 0.826218212585661, grad_norm: 0.6475236939117613, ic: 0.5564970286077228
train 27, step: 2000, loss: 1.356304209719422, grad_norm: 0.7460392454966478, ic: -0.014096545683261689
Epoch 27: 2022-04-20 15:24:42.523803: train loss: 1.6198369320456993
Eval step 0: eval loss: 1.0029548857951553
Eval: 2022-04-20 15:24:46.173185: total loss: 1.0816943532592265, mse:4.685946292934258, ic :0.1657672833896731, sharpe5:15.388261790871619, irr5:506.9575500488281, ndcg5:0.8452613986513313, pnl5:4.3329620361328125 
train 28, step: 0, loss: 1.1703452447270135, grad_norm: 0.27684497198970265, ic: 0.11600302626597501
train 28, step: 500, loss: 2.9315638031558895, grad_norm: 0.6910447863476477, ic: 0.13612484326329544
train 28, step: 1000, loss: 2.8015319920640795, grad_norm: 2.2451234960721713, ic: -0.04615563718215902
train 28, step: 1500, loss: 1.023853057060476, grad_norm: 0.040185792459515875, ic: 0.20291101021412322
train 28, step: 2000, loss: 1.7636078235714934, grad_norm: 0.3292740935633825, ic: 0.10615126700592759
Epoch 28: 2022-04-20 15:25:28.880226: train loss: 1.6214222610768354
Eval step 0: eval loss: 1.004097937031003
Eval: 2022-04-20 15:25:32.003239: total loss: 1.0819180686100844, mse:4.694482601738422, ic :0.15820454663363964, sharpe5:14.777350804209709, irr5:475.7122497558594, ndcg5:0.8368265797905061, pnl5:5.183906555175781 
train 29, step: 0, loss: 1.5026305735879455, grad_norm: 0.18654349915476554, ic: 0.09669336667646969
train 29, step: 500, loss: 2.4724225667988056, grad_norm: 1.5302382280642453, ic: -0.1165254024194659
train 29, step: 1000, loss: 1.6836577841154843, grad_norm: 0.9713535128356201, ic: 0.4833805608658521
train 29, step: 1500, loss: 3.950104365858159, grad_norm: 1.2731365265227799, ic: 0.12480703098953615
train 29, step: 2000, loss: 0.9431940565480154, grad_norm: 0.18064510740385842, ic: 0.46836956020318654
Epoch 29: 2022-04-20 15:26:14.415327: train loss: 1.6199426235856529
Eval step 0: eval loss: 0.999487677519418
Eval: 2022-04-20 15:26:17.536242: total loss: 1.0817403291685077, mse:4.685722534947089, ic :0.1648734287889181, sharpe5:15.76199325621128, irr5:504.8803405761719, ndcg5:0.8464110336028848, pnl5:5.612581729888916 
train 30, step: 0, loss: 1.262435739821868, grad_norm: 0.09648116401810379, ic: 0.9708445957465247
train 30, step: 500, loss: 1.9434659933742089, grad_norm: 0.3553695322908241, ic: 0.15352353285572318
train 30, step: 1000, loss: 3.436307212491738, grad_norm: 0.6492946374641992, ic: 0.43449426229021104
train 30, step: 1500, loss: 1.0872354370187465, grad_norm: 0.25868092251615976, ic: 0.12420089624528093
train 30, step: 2000, loss: 1.0976637992725349, grad_norm: 0.24369078763336965, ic: 0.44214240097234375
Epoch 30: 2022-04-20 15:26:59.407335: train loss: 1.6229297618048384
Eval step 0: eval loss: 0.9972045319905213
Eval: 2022-04-20 15:27:02.559846: total loss: 1.0837144231754707, mse:4.68823509015644, ic :0.1623200455967672, sharpe5:14.226357589960097, irr5:454.77215576171875, ndcg5:0.8589746236436088, pnl5:3.878955841064453 
train 31, step: 0, loss: 1.1823494584088163, grad_norm: 0.31326048095767434, ic: 0.17608013967559766
train 31, step: 500, loss: 0.82785304225602, grad_norm: 0.0928606741423088, ic: 0.26311240343720566
train 31, step: 1000, loss: 5.081423273346304, grad_norm: 0.6234277967019408, ic: -0.08375707786254655
train 31, step: 1500, loss: 1.6689028614639683, grad_norm: 0.354898639734423, ic: 0.27119582650873697
train 31, step: 2000, loss: 0.9210093764966475, grad_norm: 0.7946594525972079, ic: 0.22072081091908405
Epoch 31: 2022-04-20 15:27:44.181986: train loss: 1.623042007244952
Eval step 0: eval loss: 1.0032502586682135
Eval: 2022-04-20 15:27:47.210031: total loss: 1.0827350517772762, mse:4.681322962642657, ic :0.1679589887806546, sharpe5:15.452615008950232, irr5:492.1499328613281, ndcg5:0.834498683601597, pnl5:5.2168474197387695 
train 32, step: 0, loss: 0.8770500223595052, grad_norm: 0.3857705053997554, ic: 0.11155722693127113
train 32, step: 500, loss: 1.110275082471894, grad_norm: 0.32460846134729554, ic: 0.08867643781016485
train 32, step: 1000, loss: 1.3983332221035771, grad_norm: 0.15962525476646164, ic: 0.040124417183259466
train 32, step: 1500, loss: 2.059170088162732, grad_norm: 0.436673061766104, ic: 0.45583903477223214
train 32, step: 2000, loss: 1.0687832958040422, grad_norm: 0.32366983128425947, ic: 0.4614975881211786
Epoch 32: 2022-04-20 15:28:29.094344: train loss: 1.6213005907551619
Eval step 0: eval loss: 1.0007523490982095
Eval: 2022-04-20 15:28:32.422456: total loss: 1.0820777884656445, mse:4.677045462587491, ic :0.17214903267900103, sharpe5:17.190650399923324, irr5:563.0473022460938, ndcg5:0.8385922316589554, pnl5:9.987558364868164 
train 33, step: 0, loss: 1.1675037824078496, grad_norm: 0.012182208860249163, ic: -0.005139940306156509
train 33, step: 500, loss: 3.1731983510280553, grad_norm: 0.9090389866348871, ic: 0.5166121735134848
train 33, step: 1000, loss: 5.314421118217408, grad_norm: 2.450393630615352, ic: 0.04371911962612447
train 33, step: 1500, loss: 1.2893740770293445, grad_norm: 1.1454672707980758, ic: 0.03334631155827901
train 33, step: 2000, loss: 1.8695558533187984, grad_norm: 0.23761443648131636, ic: 0.09522454690570187
Epoch 33: 2022-04-20 15:29:14.025669: train loss: 1.6203981476834057
Eval step 0: eval loss: 1.0069948410347551
Eval: 2022-04-20 15:29:17.469903: total loss: 1.0859009440051284, mse:4.681524580057931, ic :0.17080355230833855, sharpe5:16.496023095846176, irr5:548.3115234375, ndcg5:0.8335518388006559, pnl5:8.252885818481445 
train 34, step: 0, loss: 0.7326219561738561, grad_norm: 0.2498522812590369, ic: 0.1751580055405651
train 34, step: 500, loss: 1.797205877197083, grad_norm: 0.20038996972064538, ic: 0.8680177385435112
train 34, step: 1000, loss: 0.6827060041756465, grad_norm: 0.06391630165558525, ic: 0.4973203769236536
train 34, step: 1500, loss: 1.6525191869491185, grad_norm: 1.5223833183276243, ic: 0.6588564071161126
train 34, step: 2000, loss: 2.9910957047338345, grad_norm: 0.40827184784453086, ic: 0.12396044785407556
Epoch 34: 2022-04-20 15:30:00.203788: train loss: 1.621185857476041
Eval step 0: eval loss: 1.0048128743746707
Eval: 2022-04-20 15:30:03.488607: total loss: 1.0835929747124144, mse:4.6878426342775406, ic :0.16582497980543254, sharpe5:17.179689012765884, irr5:563.9037475585938, ndcg5:0.8477909670680739, pnl5:8.1065673828125 
train 35, step: 0, loss: 1.0432940133010284, grad_norm: 0.41743680613724965, ic: -0.006357776927305827
train 35, step: 500, loss: 3.2991129557291665, grad_norm: 0.9872071594376214, ic: -0.07549577291705374
train 35, step: 1000, loss: 1.3354679693622649, grad_norm: 0.2122680089343027, ic: 0.5189347057005016
train 35, step: 1500, loss: 1.6388741258126025, grad_norm: 0.4897603666761556, ic: 0.08868762292448817
train 35, step: 2000, loss: 1.2678549680643763, grad_norm: 0.08323253420007432, ic: -0.03270201971093592
Epoch 35: 2022-04-20 15:30:45.116530: train loss: 1.6203972962550457
Eval step 0: eval loss: 1.000056181913178
Eval: 2022-04-20 15:30:48.878939: total loss: 1.0833253617300644, mse:4.693310647980023, ic :0.16069107676004474, sharpe5:15.863067310452461, irr5:506.0108337402344, ndcg5:0.8396536580803204, pnl5:3.9683854579925537 
train 36, step: 0, loss: 9.051851075374902, grad_norm: 1.2950163268876773, ic: -0.12820746026957977
train 36, step: 500, loss: 0.8620173001632286, grad_norm: 0.03810551783936606, ic: 0.10372399839329441
train 36, step: 1000, loss: 1.9925804254131838, grad_norm: 1.4839601782196412, ic: 0.0454563628634592
train 36, step: 1500, loss: 1.0487162390009415, grad_norm: 0.09183177714742777, ic: 0.08901396459116939
train 36, step: 2000, loss: 2.185730519331224, grad_norm: 0.8927317830337347, ic: 0.3839522449725696
Epoch 36: 2022-04-20 15:31:31.111239: train loss: 1.6207341664174508
Eval step 0: eval loss: 1.0096685601385598
Eval: 2022-04-20 15:31:34.633287: total loss: 1.0879832562516163, mse:4.7033754545148945, ic :0.15393017876657883, sharpe5:15.53709563434124, irr5:499.12353515625, ndcg5:0.8402609985041508, pnl5:5.3176116943359375 
train 37, step: 0, loss: 1.1899096651721792, grad_norm: 0.1485010199213035, ic: 0.18646876091852704
train 37, step: 500, loss: 2.325961367025415, grad_norm: 0.07103727998021751, ic: 0.25499220897282693
train 37, step: 1000, loss: 0.7418190643262184, grad_norm: 0.31132785440791433, ic: 0.17102995149355296
train 37, step: 1500, loss: 3.1457466861318206, grad_norm: 1.0577838140633924, ic: 0.2065519721829433
train 37, step: 2000, loss: 3.1635311460313686, grad_norm: 1.466683619964447, ic: 0.0007072275391362421
Epoch 37: 2022-04-20 15:32:16.400603: train loss: 1.619438233601743
Eval step 0: eval loss: 1.0024043801836493
Eval: 2022-04-20 15:32:19.366013: total loss: 1.0800930931928303, mse:4.675069317493315, ic :0.17699991802468956, sharpe5:17.328299617767332, irr5:579.51025390625, ndcg5:0.8444627098154466, pnl5:5.602197647094727 
train 38, step: 0, loss: 1.3428835782137785, grad_norm: 0.41503238925628927, ic: -0.2747203110235107
train 38, step: 500, loss: 1.6992796905281007, grad_norm: 0.8534009172532553, ic: 0.24310786085768804
train 38, step: 1000, loss: 1.813908459347997, grad_norm: 0.6273317346729643, ic: 0.19446900092425684
train 38, step: 1500, loss: 1.1019412348385351, grad_norm: 0.3331050729277926, ic: 0.47034728770112455
train 38, step: 2000, loss: 0.7500036001532493, grad_norm: 0.44159165383790056, ic: 0.5780753664966684
Epoch 38: 2022-04-20 15:33:03.481669: train loss: 1.6214222562671297
Eval step 0: eval loss: 0.9945228419974328
Eval: 2022-04-20 15:33:07.043067: total loss: 1.079452240703249, mse:4.68711847393645, ic :0.17473173649029292, sharpe5:16.72710896372795, irr5:568.7052612304688, ndcg5:0.8474147658591226, pnl5:3.4078426361083984 
train 39, step: 0, loss: 0.8746455525523301, grad_norm: 0.04565223947317565, ic: 0.537506110720808
train 39, step: 500, loss: 1.2348302919193563, grad_norm: 0.650636885185068, ic: 0.06205860165897178
train 39, step: 1000, loss: 1.3771761807528409, grad_norm: 0.26832017718669554, ic: 0.08286762007736276
train 39, step: 1500, loss: 2.441493037531146, grad_norm: 0.37046294305071625, ic: -0.0969283074308071
train 39, step: 2000, loss: 2.836844048725438, grad_norm: 0.8072083966363413, ic: 0.22562970442049457
Epoch 39: 2022-04-20 15:33:49.699499: train loss: 1.6186608523375874
Eval step 0: eval loss: 1.0016950353187533
Eval: 2022-04-20 15:33:52.289389: total loss: 1.0800850368236183, mse:4.689180672282016, ic :0.16885769475611792, sharpe5:16.679606466293333, irr5:557.6209716796875, ndcg5:0.8454077275613966, pnl5:3.993459939956665 

Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='AdjTimeDataset', dout=0.3, epochs=20, glstm_layers=1, gnn_layers=1, gpu=0, hidden_dim=128, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=1, mask_adj=True, mask_type='soft', model_type='BiGLSTM', normalize_adj=True, num_days=8, num_heads=1, print_inteval=500, relation_num=1, seed=10086, shuffle=True, side_info=False, sparse_adj_path=None, stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
64649
BiGLSTM(
  (input_to_hidden): Linear(in_features=9, out_features=128, bias=True)
  (forward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
  )
  (backward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
  )
  (fc0): ModuleList(
    (0): Linear(in_features=256, out_features=128, bias=True)
  )
  (w_out): Linear(in_features=128, out_features=1, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
)
train 0, step: 0, loss: 4.812226272356333, grad_norm: 4.549448262213707, ic: 0.032209013656201824
train 0, step: 500, loss: 0.8654711564501696, grad_norm: 0.02532535229466532, ic: 0.01999482025725361
train 0, step: 1000, loss: 1.948317912170812, grad_norm: 0.4443499038093347, ic: -0.019702006049628417
train 0, step: 1500, loss: 0.9530059211338933, grad_norm: 0.04499272215545407, ic: 0.05120552631143287
train 0, step: 2000, loss: 1.0006699366394438, grad_norm: 0.1309506477387247, ic: 0.04524766674258038
Epoch 0: 2022-04-04 23:35:24.500519: train loss: 1.649148171060271
Eval step 0: eval loss: 0.836215599068098
Eval: 2022-04-04 23:35:28.314349: total loss: 1.0792882134286272, mse:4.823189844497148, ic :0.007579534812167715, sharpe5:8.010155689716338, irr5:224.1614990234375, ndcg5:0.8487788809022078, pnl5:2.9725594520568848 
train 1, step: 0, loss: 2.767455070249496, grad_norm: 0.7407492902065619, ic: 0.045415074437528326
train 1, step: 500, loss: 1.748753331006136, grad_norm: 0.6574543296683202, ic: 0.1242710350975063
train 1, step: 1000, loss: 0.8749060740476109, grad_norm: 0.14986802933403384, ic: 0.05950170474010899
train 1, step: 1500, loss: 1.7077465539691092, grad_norm: 0.1797688070123732, ic: -0.00800401354796065
train 1, step: 2000, loss: 2.1725787109375, grad_norm: 0.840864837651709, ic: 0.012132510351795054
Epoch 1: 2022-04-04 23:37:02.045417: train loss: 1.6468394902591361
Eval step 0: eval loss: 0.836258304382903
Eval: 2022-04-04 23:37:06.094491: total loss: 1.079298135078924, mse:4.823102312849023, ic :0.011870660537467407, sharpe5:8.23420481622219, irr5:230.510986328125, ndcg5:0.8488288646880469, pnl5:2.6126394271850586 
train 2, step: 0, loss: 2.1404783380681818, grad_norm: 0.0065314504860351326, ic: 0.10149670350884574
train 2, step: 500, loss: 3.2898675145491003, grad_norm: 0.25536724802318667, ic: 0.015604773454548533
train 2, step: 1000, loss: 2.0740297982519156, grad_norm: 2.3297675581817218e-05, ic: 0.2522205585780917
train 2, step: 1500, loss: 1.4807035722805344, grad_norm: 0.05128086414903652, ic: -0.02231494458693043
train 2, step: 2000, loss: 3.2155968299278848, grad_norm: 0.7282780297611381, ic: 0.14084638455674672
Epoch 2: 2022-04-04 23:38:45.758766: train loss: 1.6466233236330623
Eval step 0: eval loss: 0.83667545298505
Eval: 2022-04-04 23:38:49.805134: total loss: 1.0794279121032913, mse:4.822853874273605, ic :0.016861164349388457, sharpe5:10.245851111412048, irr5:295.84100341796875, ndcg5:0.8538047986341215, pnl5:2.4435713291168213 
train 3, step: 0, loss: 1.5233125516069614, grad_norm: 0.4929369964987043, ic: -0.012636233963847996
train 3, step: 500, loss: 1.4921961032326743, grad_norm: 0.326091012560543, ic: 0.021801655685159623
train 3, step: 1000, loss: 3.686895621941566, grad_norm: 0.6792168203157014, ic: -0.04140500280194419
train 3, step: 1500, loss: 1.9548733425608635, grad_norm: 0.9374986556220674, ic: 0.007599276582799018
train 3, step: 2000, loss: 0.9003932643581081, grad_norm: 0.0009777618516652194, ic: -0.000513979832090148
Epoch 3: 2022-04-04 23:40:31.129914: train loss: 1.6471679070883982
Eval step 0: eval loss: 0.8359836140221615
Eval: 2022-04-04 23:40:35.286307: total loss: 1.0792064136073702, mse:4.822986306929022, ic :0.026474832267753066, sharpe5:11.613914145827293, irr5:401.0364685058594, ndcg5:0.8414327570802965, pnl5:3.5284817218780518 
train 4, step: 0, loss: 1.4382275390625001, grad_norm: 0.04170582390752245, ic: 0.13216063465673578
train 4, step: 500, loss: 1.6418176365649606, grad_norm: 0.5424261241568832, ic: -0.04829947386358434
train 4, step: 1000, loss: 2.969258750357279, grad_norm: 0.6673708050114637, ic: 0.03819113434009156
train 4, step: 1500, loss: 2.1526791600738395, grad_norm: 0.4550612386483914, ic: -0.06117497225466346
train 4, step: 2000, loss: 1.0889652424244265, grad_norm: 0.39100439095422174, ic: 0.19241398731022258
Epoch 4: 2022-04-04 23:42:14.708563: train loss: 1.6446080996384176
Eval step 0: eval loss: 0.8461788004643045
Eval: 2022-04-04 23:42:18.947810: total loss: 1.0840713475334391, mse:4.748281589502131, ic :0.12261678626962685, sharpe5:11.363525717854499, irr5:390.71917724609375, ndcg5:0.8527496661017226, pnl5:3.4542198181152344 
train 5, step: 0, loss: 1.3209227696361157, grad_norm: 0.1647309794839275, ic: 0.3576615887221288
train 5, step: 500, loss: 0.8899107773468478, grad_norm: 0.010329790473871218, ic: 0.7960106015634124
train 5, step: 1000, loss: 0.9956434461805556, grad_norm: 0.1537260074812919, ic: 0.023412488961159397
train 5, step: 1500, loss: 1.5282174967697169, grad_norm: 0.15192439278910938, ic: 0.01211008990027563
train 5, step: 2000, loss: 1.1386188409721214, grad_norm: 0.12025403158082339, ic: 0.1593298650432382
Epoch 5: 2022-04-04 23:43:58.796551: train loss: 1.639725150786656
Eval step 0: eval loss: 0.8365656025668466
Eval: 2022-04-04 23:44:02.994432: total loss: 1.075320618245692, mse:4.633124432571734, ic :0.14006235503184875, sharpe5:11.543808753490447, irr5:401.5251770019531, ndcg5:0.840583376400644, pnl5:3.24233341217041 
train 6, step: 0, loss: 1.338291685356858, grad_norm: 0.46107382113723394, ic: 0.05641077359550757
train 6, step: 500, loss: 1.0087496186471094, grad_norm: 0.04223395383532711, ic: 0.047568853687680206
train 6, step: 1000, loss: 1.0940482600106938, grad_norm: 0.09192191898149607, ic: 0.8027108090632368
train 6, step: 1500, loss: 1.575982212035124, grad_norm: 0.723909007948687, ic: 0.0070896574384996195
train 6, step: 2000, loss: 0.7989018656331315, grad_norm: 0.07268834061187404, ic: 0.3554088879461711
Epoch 6: 2022-04-04 23:45:44.782070: train loss: 1.6351740963152566
Eval step 0: eval loss: 0.8300590233757573
Eval: 2022-04-04 23:45:49.167998: total loss: 1.0718889202036233, mse:4.626640231386856, ic :0.13599696859164087, sharpe5:11.547151654958725, irr5:397.3142395019531, ndcg5:0.8482147890936254, pnl5:3.448469638824463 
train 7, step: 0, loss: 0.9958294868469239, grad_norm: 0.04631766089279483, ic: 0.02972044420435163
train 7, step: 500, loss: 0.6557075013505651, grad_norm: 0.013168070789073713, ic: -0.016511928609289794
train 7, step: 1000, loss: 1.036949279738671, grad_norm: 0.25720423279442683, ic: -0.013887887150862761
train 7, step: 1500, loss: 2.2888060607583065, grad_norm: 0.929193817412556, ic: 0.4138316175576954
train 7, step: 2000, loss: 0.9086764186187399, grad_norm: 0.0891532702438565, ic: -0.01939145411735028
Epoch 7: 2022-04-04 23:47:29.598183: train loss: 1.633380982686821
Eval step 0: eval loss: 0.8286155322831599
Eval: 2022-04-04 23:47:34.033506: total loss: 1.071432392445918, mse:4.601130738486127, ic :0.16692036786437878, sharpe5:16.181220910549165, irr5:521.597900390625, ndcg5:0.8423992749005883, pnl5:5.393573760986328 
train 8, step: 0, loss: 3.614741493999094, grad_norm: 1.158893913364682, ic: 0.16988694212906125
train 8, step: 500, loss: 2.757625869704597, grad_norm: 0.9652775133064445, ic: -0.09814140253032094
train 8, step: 1000, loss: 3.076117031816123, grad_norm: 0.9407115955711352, ic: 0.10096948303127858
train 8, step: 1500, loss: 0.69905844804832, grad_norm: 0.10948502237405472, ic: 0.5937165025514437
train 8, step: 2000, loss: 1.0740788083514268, grad_norm: 0.5189879452407085, ic: 0.6560770420730835
Epoch 8: 2022-04-04 23:49:14.529684: train loss: 1.6304499926200504
Eval step 0: eval loss: 0.823559325914614
Eval: 2022-04-04 23:49:18.819127: total loss: 1.0689995986201835, mse:4.598321611262676, ic :0.17059912597659865, sharpe5:16.79884418606758, irr5:546.1409912109375, ndcg5:0.848250931083731, pnl5:8.489978790283203 
train 9, step: 0, loss: 5.434456613835725, grad_norm: 0.9474040591652599, ic: -0.048889087506409856
train 9, step: 500, loss: 1.3339234650012817, grad_norm: 1.113713037209092, ic: 0.3031467012181789
train 9, step: 1000, loss: 0.9245280749692117, grad_norm: 1.812401718191639, ic: 0.11226599429608997
train 9, step: 1500, loss: 1.0767095956254602, grad_norm: 0.015410252892493825, ic: 0.49188435170964034
train 9, step: 2000, loss: 1.0682876514695319, grad_norm: 0.30949258401267377, ic: 0.2970567307605461
Epoch 9: 2022-04-04 23:50:59.516470: train loss: 1.6283049389941233
Eval step 0: eval loss: 0.8245019942867492
Eval: 2022-04-04 23:51:03.758430: total loss: 1.0707750117905777, mse:4.606702890141744, ic :0.1612722276734361, sharpe5:16.163030759096145, irr5:515.028564453125, ndcg5:0.8453753508112947, pnl5:6.450768947601318 
train 10, step: 0, loss: 7.128523312226676, grad_norm: 1.4404101375073857, ic: 0.28116606077226347
train 10, step: 500, loss: 1.1202910945778553, grad_norm: 0.19974950441051506, ic: 0.0838109517835371
train 10, step: 1000, loss: 2.3833752965634587, grad_norm: 0.7095453567369804, ic: 0.002836083697971812
train 10, step: 1500, loss: 1.1011714192179891, grad_norm: 0.25562007919029694, ic: 0.01601303082657119
train 10, step: 2000, loss: 2.716637515731858, grad_norm: 1.0446025251158522, ic: 0.5390007268019462
Epoch 10: 2022-04-04 23:52:44.369988: train loss: 1.6280847440010573
Eval step 0: eval loss: 0.8249701448687763
Eval: 2022-04-04 23:52:49.051249: total loss: 1.0698504561894369, mse:4.609227233649201, ic :0.16565812024949378, sharpe5:16.0772996199131, irr5:527.0060424804688, ndcg5:0.8582896186077346, pnl5:5.337259769439697 
train 11, step: 0, loss: 1.2569701865211718, grad_norm: 0.17094099572170368, ic: 0.1796741560447096
train 11, step: 500, loss: 0.6424787575631072, grad_norm: 0.03620829217088829, ic: 0.6487867914738843
train 11, step: 1000, loss: 0.9459408652359852, grad_norm: 0.13622580172967588, ic: 0.12433584514681865
train 11, step: 1500, loss: 1.059148955763432, grad_norm: 0.06449095359019887, ic: 0.18319826163267003
train 11, step: 2000, loss: 0.7950359422825336, grad_norm: 0.0002543828974820555, ic: 0.027811593222895576
Epoch 11: 2022-04-04 23:54:32.323352: train loss: 1.6272813406674267
Eval step 0: eval loss: 0.8283224477657402
Eval: 2022-04-04 23:54:36.648999: total loss: 1.071082395663976, mse:4.6024653887272615, ic :0.16610721197385336, sharpe5:15.348259538412094, irr5:497.8135070800781, ndcg5:0.8487371268765157, pnl5:3.575395107269287 
train 12, step: 0, loss: 0.9696706930796305, grad_norm: 0.09415507317771915, ic: 0.39600193608567696
train 12, step: 500, loss: 0.9504407528089169, grad_norm: 0.07275685556650247, ic: 0.022243404918358245
train 12, step: 1000, loss: 3.011027147815486, grad_norm: 0.23389927194450078, ic: 0.051123251502472905
train 12, step: 1500, loss: 0.9361498818902323, grad_norm: 0.11226608039636385, ic: -0.011906323135914146
train 12, step: 2000, loss: 0.8789748454021903, grad_norm: 0.0044119246910306964, ic: 0.018818789228360583
Epoch 12: 2022-04-04 23:56:18.731567: train loss: 1.6269649571343603
Eval step 0: eval loss: 0.8262289869270284
Eval: 2022-04-04 23:56:23.042109: total loss: 1.0706832863754037, mse:4.603935206917663, ic :0.16369626738650336, sharpe5:16.095149238109588, irr5:519.2326049804688, ndcg5:0.8425639028558078, pnl5:7.574531555175781 
train 13, step: 0, loss: 2.0581018594904963, grad_norm: 0.6992574930781319, ic: 0.421577473649458
train 13, step: 500, loss: 0.8308015539733971, grad_norm: 0.04271399879387859, ic: 0.5749265722742147
train 13, step: 1000, loss: 0.9542179798919882, grad_norm: 0.36422253040865543, ic: 0.5843808292785866
train 13, step: 1500, loss: 2.3516964819354995, grad_norm: 0.21128592619456155, ic: 0.07588981294852366
train 13, step: 2000, loss: 1.4607569787757408, grad_norm: 0.04554269382259378, ic: 0.19805775143823284
Epoch 13: 2022-04-04 23:58:05.281633: train loss: 1.626496897094668
Eval step 0: eval loss: 0.8220451523807956
Eval: 2022-04-04 23:58:09.613710: total loss: 1.0702896092930783, mse:4.618058562030491, ic :0.16664935247635684, sharpe5:16.785111236572266, irr5:555.1010131835938, ndcg5:0.8534587751746449, pnl5:8.674749374389648 
train 14, step: 0, loss: 4.53076324224844, grad_norm: 1.5392328189345745, ic: 0.10817031217107295
train 14, step: 500, loss: 0.8304387363818807, grad_norm: 0.017536239968942824, ic: 0.02327928894421738
train 14, step: 1000, loss: 1.8413680995515376, grad_norm: 0.6420409543128476, ic: 0.4508043922858569
train 14, step: 1500, loss: 1.1204688343185834, grad_norm: 0.06323618731374994, ic: 0.08119457832576377
train 14, step: 2000, loss: 1.1375020109030598, grad_norm: 0.2473485019237872, ic: 0.11017093843330564
Epoch 14: 2022-04-04 23:59:50.437542: train loss: 1.6268206710828133
Eval step 0: eval loss: 0.8313132347372233
Eval: 2022-04-04 23:59:54.661871: total loss: 1.0707865554915836, mse:4.6010420612103164, ic :0.17692843537730035, sharpe5:16.85719645142555, irr5:564.6187133789062, ndcg5:0.8462457456279546, pnl5:6.055577754974365 
train 15, step: 0, loss: 3.325701073078794, grad_norm: 0.6775317831131582, ic: 0.09310375995559722
train 15, step: 500, loss: 1.256298544004572, grad_norm: 0.09459521201492775, ic: 0.04604589287008893
train 15, step: 1000, loss: 1.3259559197154471, grad_norm: 0.20895863997839143, ic: 0.08179325905224602
train 15, step: 1500, loss: 0.8630113496555119, grad_norm: 0.4996725928249542, ic: 0.017978466641264908
train 15, step: 2000, loss: 1.4626203404916465, grad_norm: 0.7327809859581157, ic: 0.02949309550093454
Epoch 15: 2022-04-05 00:01:35.214190: train loss: 1.625789430084536
Eval step 0: eval loss: 0.8329042649746443
Eval: 2022-04-05 00:01:39.464509: total loss: 1.0735952979348318, mse:4.613517933868086, ic :0.17259074260917162, sharpe5:16.23906994342804, irr5:530.5979614257812, ndcg5:0.8589527277677348, pnl5:5.478875637054443 
train 16, step: 0, loss: 0.7019878034070665, grad_norm: 0.21670255079126036, ic: 0.02721751704244181
train 16, step: 500, loss: 1.5882305349225783, grad_norm: 0.4251621573926294, ic: 0.14587303728839135
train 16, step: 1000, loss: 0.8729101007634943, grad_norm: 0.0016700948256755542, ic: 0.0002574674906646521
train 16, step: 1500, loss: 0.8590871872537431, grad_norm: 0.25827582418310996, ic: 0.1420276704884824
train 16, step: 2000, loss: 3.3692678361761974, grad_norm: 0.8852927567047626, ic: 0.07402928207740717
Epoch 16: 2022-04-05 00:03:20.077003: train loss: 1.626654382288657
Eval step 0: eval loss: 0.8249103960171891
Eval: 2022-04-05 00:03:24.005858: total loss: 1.068055828858314, mse:4.592971473288733, ic :0.18209338639000902, sharpe5:16.27124087691307, irr5:534.5510864257812, ndcg5:0.8358304876373329, pnl5:6.588736534118652 
train 17, step: 0, loss: 1.2746531519396551, grad_norm: 0.22827311983348683, ic: -0.10914507947786001
train 17, step: 500, loss: 1.7789745299796749, grad_norm: 0.465326451737673, ic: 0.14692111138950373
train 17, step: 1000, loss: 1.282842480365191, grad_norm: 0.10104742404498669, ic: 0.1367227964827251
train 17, step: 1500, loss: 4.517515340856907, grad_norm: 1.2934957882804394, ic: 0.2361966636546639
train 17, step: 2000, loss: 1.2621007902620327, grad_norm: 0.5429316262260726, ic: 0.04190929352057324
Epoch 17: 2022-04-05 00:05:06.937951: train loss: 1.6252674305944494
Eval step 0: eval loss: 0.8319089224265673
Eval: 2022-04-05 00:05:11.249715: total loss: 1.070762670345734, mse:4.592386722206777, ic :0.1833596941561049, sharpe5:16.81287604808807, irr5:550.3162841796875, ndcg5:0.8508327284535301, pnl5:4.0787529945373535 
train 18, step: 0, loss: 1.4197170158524293, grad_norm: 0.5070309040542914, ic: 0.07205168938834135
train 18, step: 500, loss: 1.4458291559473364, grad_norm: 0.881434092941294, ic: 0.010938325998754222
train 18, step: 1000, loss: 0.6612932095462328, grad_norm: 0.047941120145131425, ic: 0.569725829778921
train 18, step: 1500, loss: 1.4405970467982188, grad_norm: 0.045457729592785066, ic: 0.1279182910505754
train 18, step: 2000, loss: 0.910705955165207, grad_norm: 0.006838111054657062, ic: -0.012922561764724104
Epoch 18: 2022-04-05 00:06:53.656154: train loss: 1.625560179138859
Eval step 0: eval loss: 0.823679080878721
Eval: 2022-04-05 00:06:58.001686: total loss: 1.0662652786670688, mse:4.601356322535937, ic :0.18787242565416398, sharpe5:16.593911272287368, irr5:571.66748046875, ndcg5:0.8397453410075792, pnl5:4.248471260070801 
train 19, step: 0, loss: 1.4865930950830852, grad_norm: 0.6730191185289386, ic: 0.028310456376215792
train 19, step: 500, loss: 0.8615810253002025, grad_norm: 0.0432879019552813, ic: 0.23015546552012967
train 19, step: 1000, loss: 0.9660584283943148, grad_norm: 0.006313491290209862, ic: 0.1609006889971317
train 19, step: 1500, loss: 3.9611694593288824, grad_norm: 0.9692610934657723, ic: 0.15400206645523434
train 19, step: 2000, loss: 1.0013858736478365, grad_norm: 0.10637387570969126, ic: 0.17827898269639397
Epoch 19: 2022-04-05 00:08:41.225914: train loss: 1.6247798596668055
Eval step 0: eval loss: 0.8275516940117886
Eval: 2022-04-05 00:08:45.433899: total loss: 1.0689209445369836, mse:4.5953041422440615, ic :0.18692733179185592, sharpe5:17.06819464087486, irr5:578.3008422851562, ndcg5:0.8378771980677904, pnl5:5.557066917419434 

Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='AdjSeqTimeDataset', dout=0.3, epochs=40, glstm_layers=1, gnn_layers=2, gpu=0, graph_attn=True, hidden_dim=128, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=3, mask_adj=True, mask_type='soft', model_type='RGCNModel', normalize_adj=True, num_days=1, num_heads=1, print_inteval=500, relation_num=1, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_250_0.8/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
64562
RGCNModel(
  (fc1): Linear(in_features=9, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
  (fc4): Linear(in_features=128, out_features=1, bias=True)
  (gnns): ModuleList(
    (0): RGCN(
      (attention): ModuleList(
        (0): GraphAttentionLayer (128 -> 128)
      )
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
    )
    (1): RGCN(
      (attention): ModuleList(
        (0): GraphAttentionLayer (128 -> 128)
      )
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
    )
  )
  (dropout): Dropout(p=0.3, inplace=False)
  (relu): LeakyReLU(negative_slope=0.01)
)
train 0, step: 0, loss: 2.073096089118083, grad_norm: 0.4556558162055587, ic: -0.09656168670016507
train 0, step: 500, loss: 1.3607694150101877, grad_norm: 0.864072437966924, ic: 4.8185235570818996e-05
train 0, step: 1000, loss: 1.5063126933945377, grad_norm: 0.03271888816372366, ic: 0.06654772439525812
train 0, step: 1500, loss: 1.194831724995196, grad_norm: 0.11137429554811373, ic: 0.030012954597507007
train 0, step: 2000, loss: 1.563449394412157, grad_norm: 0.05373126769118076, ic: 0.004609143156515125
Epoch 0: 2022-04-20 15:35:27.752942: train loss: 1.6480820427280167
Eval step 0: eval loss: 1.0137442558172063
Eval: 2022-04-20 15:35:30.228970: total loss: 1.092286778550136, mse:4.890274192179027, ic :0.006917899529109054, sharpe5:7.141587308943271, irr5:202.57723999023438, ndcg5:0.8520132036689891, pnl5:3.0896050930023193 
train 1, step: 0, loss: 0.6368309247611773, grad_norm: 0.04861418751213216, ic: 0.07579865173566791
train 1, step: 500, loss: 1.272580847855228, grad_norm: 0.2859386570191188, ic: 0.22837589142621956
train 1, step: 1000, loss: 0.883059883223229, grad_norm: 0.0666321032112671, ic: 0.07217240900473439
train 1, step: 1500, loss: 1.8439982344464558, grad_norm: 0.5258914268078195, ic: 0.07623285795531305
train 1, step: 2000, loss: 1.377154456893664, grad_norm: 0.22295749797759418, ic: 0.04105105969111189
Epoch 1: 2022-04-20 15:36:01.781957: train loss: 1.6480543961974174
Eval step 0: eval loss: 1.0064823257100777
Eval: 2022-04-20 15:36:04.274932: total loss: 1.0896632825620933, mse:4.879380506329503, ic :0.050005911695571045, sharpe5:-0.05652985079213976, irr5:-1.5731213092803955, ndcg5:0.8538407880858283, pnl5:1.02283775806427 
train 2, step: 0, loss: 1.3187554494064118, grad_norm: 0.4943694011782025, ic: 0.0866094924743665
train 2, step: 500, loss: 0.939227878414264, grad_norm: 0.24374614976461, ic: 0.051169984614374546
train 2, step: 1000, loss: 2.981856552638738, grad_norm: 0.9085533276076591, ic: 0.06924131712411884
train 2, step: 1500, loss: 2.347603007595658, grad_norm: 2.1845932080851953, ic: 0.08684910681791937
train 2, step: 2000, loss: 1.466206885124949, grad_norm: 0.2798986650626781, ic: -0.1146638389121147
Epoch 2: 2022-04-20 15:36:35.196736: train loss: 1.6455740103016394
Eval step 0: eval loss: 0.9972414937755067
Eval: 2022-04-20 15:36:37.746519: total loss: 1.0889921571462922, mse:4.880666139676514, ic :0.04957815332305278, sharpe5:2.247918200790882, irr5:24.823793411254883, ndcg5:0.8337873037007082, pnl5:1.1207780838012695 
train 3, step: 0, loss: 1.8264658898001147, grad_norm: 0.06384714793033633, ic: -0.12427774226844832
train 3, step: 500, loss: 0.7811269821818403, grad_norm: 0.026186112261180002, ic: 0.07834470366505786
train 3, step: 1000, loss: 1.412132414145738, grad_norm: 0.37385043598681444, ic: 0.1707554340397382
train 3, step: 1500, loss: 2.6445539080626452, grad_norm: 0.4080166466827042, ic: -0.0720934819164694
train 3, step: 2000, loss: 1.3602426239938448, grad_norm: 0.1650482345274362, ic: 0.07292949783878622
Epoch 3: 2022-04-20 15:37:08.181516: train loss: 1.645694184213077
Eval step 0: eval loss: 1.002891954338632
Eval: 2022-04-20 15:37:10.628406: total loss: 1.0902768052576748, mse:4.878350023575745, ic :0.05199730201580623, sharpe5:2.4040127335488797, irr5:26.354595184326172, ndcg5:0.8522597283218366, pnl5:1.1786913871765137 
train 4, step: 0, loss: 1.164850104345034, grad_norm: 0.14801878677303182, ic: 0.08549817900752403
train 4, step: 500, loss: 0.9925620905322357, grad_norm: 0.00540493414919259, ic: 0.16500316976004237
train 4, step: 1000, loss: 1.3356721297554348, grad_norm: 0.06475560041966856, ic: 0.0632013703249795
train 4, step: 1500, loss: 1.0829639141376202, grad_norm: 0.1111163915430634, ic: 0.1729567438025566
train 4, step: 2000, loss: 4.175803147742919, grad_norm: 0.903623969855349, ic: -0.04321672540423568
Epoch 4: 2022-04-20 15:37:40.825863: train loss: 1.6449562448169543
Eval step 0: eval loss: 1.0101543344153172
Eval: 2022-04-20 15:37:43.283135: total loss: 1.0970341950818925, mse:4.892867930945611, ic :0.05444410739760942, sharpe5:1.7905445549637078, irr5:19.52205467224121, ndcg5:0.839522079309765, pnl5:1.2199617624282837 
train 5, step: 0, loss: 0.9996196575411748, grad_norm: 0.18898891223550687, ic: -0.09414360941206523
train 5, step: 500, loss: 0.787734286291716, grad_norm: 0.005210903754545482, ic: 0.13520084099437424
train 5, step: 1000, loss: 1.113349358895068, grad_norm: 0.032689801943432344, ic: -0.12592048058200697
train 5, step: 1500, loss: 1.7488132383765245, grad_norm: 0.3124125660738791, ic: -0.10977943343348309
train 5, step: 2000, loss: 2.1728829390434146, grad_norm: 0.8169939193908172, ic: 0.04617447553692656
Epoch 5: 2022-04-20 15:38:13.175534: train loss: 1.6450623066608943
Eval step 0: eval loss: 0.9995715004196287
Eval: 2022-04-20 15:38:15.659842: total loss: 1.0891495809500775, mse:4.87616804114288, ic :0.054097671350133346, sharpe5:1.9796442094445228, irr5:22.698877334594727, ndcg5:0.827997448312393, pnl5:1.1486221551895142 
train 6, step: 0, loss: 0.7837355220097536, grad_norm: 0.01985657207435798, ic: -0.08335143783999704
train 6, step: 500, loss: 1.4263289602179277, grad_norm: 0.22815426277481687, ic: 0.0549718271430579
train 6, step: 1000, loss: 1.2241002294506478, grad_norm: 0.18407471759330957, ic: 0.17072709082447518
train 6, step: 1500, loss: 1.068726599351415, grad_norm: 0.3231444274979044, ic: 0.05847864027487401
train 6, step: 2000, loss: 2.2796417086487315, grad_norm: 1.0125103518860825, ic: 0.10784912759660904
Epoch 6: 2022-04-20 15:38:46.045959: train loss: 1.645105404444435
Eval step 0: eval loss: 0.9994914058385992
Eval: 2022-04-20 15:38:48.538790: total loss: 1.0895122004068873, mse:4.881853419668863, ic :0.04703136343560194, sharpe5:1.4905264791101216, irr5:14.493175506591797, ndcg5:0.8504839062953721, pnl5:1.161889672279358 
train 7, step: 0, loss: 1.45083210927847, grad_norm: 0.5534353656802391, ic: 0.18979964763988663
train 7, step: 500, loss: 1.32168536611896, grad_norm: 0.023779655027250563, ic: 0.09703943946901854
train 7, step: 1000, loss: 0.6445067170929676, grad_norm: 0.01830589833043102, ic: 0.27785747944000255
train 7, step: 1500, loss: 1.0037914870431217, grad_norm: 0.12463807928850404, ic: 0.07556344279113639
train 7, step: 2000, loss: 1.6010039299805203, grad_norm: 0.5476135845876732, ic: 0.1080413620628386
Epoch 7: 2022-04-20 15:39:19.604451: train loss: 1.6452059261668714
Eval step 0: eval loss: 0.997802091561348
Eval: 2022-04-20 15:39:22.134670: total loss: 1.0892755129310219, mse:4.87873802246838, ic :0.05273958362953808, sharpe5:1.6280615946650505, irr5:19.59838104248047, ndcg5:0.8634033724355892, pnl5:1.144958734512329 
train 8, step: 0, loss: 1.2126854388823065, grad_norm: 0.08359892655002497, ic: 0.04990812965823375
train 8, step: 500, loss: 5.524661264449451, grad_norm: 1.0763827508237136, ic: 0.11798091022415494
train 8, step: 1000, loss: 1.8725083464257661, grad_norm: 0.5228073191772111, ic: 0.03827399117184279
train 8, step: 1500, loss: 1.1304605261563663, grad_norm: 0.3795469331688951, ic: 0.0966941139695074
train 8, step: 2000, loss: 1.1189729739458132, grad_norm: 0.4759210188944936, ic: 0.047653403890061
Epoch 8: 2022-04-20 15:39:52.551485: train loss: 1.6469522232965954
Eval step 0: eval loss: 1.0079933877616507
Eval: 2022-04-20 15:39:55.048533: total loss: 1.0925987397696098, mse:4.882559528487167, ic :0.05132703466936244, sharpe5:1.2376536954939366, irr5:11.60908031463623, ndcg5:0.863638282858374, pnl5:0.9612126350402832 
train 9, step: 0, loss: 1.152730059470777, grad_norm: 0.01147882535242378, ic: 0.024256346782804812
train 9, step: 500, loss: 3.187944432553272, grad_norm: 0.6538771347666601, ic: 0.02162179045492895
train 9, step: 1000, loss: 0.8654156164350039, grad_norm: 0.06886508402665127, ic: 0.2271947863868423
train 9, step: 1500, loss: 2.1507338859273704, grad_norm: 0.9720393091802892, ic: -0.004182258725653452
train 9, step: 2000, loss: 0.6070397209689713, grad_norm: 0.008561757139822853, ic: 0.09588450554301964
Epoch 9: 2022-04-20 15:40:25.097308: train loss: 1.6452532056179592
Eval step 0: eval loss: 1.0038024998765798
Eval: 2022-04-20 15:40:27.998260: total loss: 1.0874571172330678, mse:4.880601993790708, ic :0.05199058845520393, sharpe5:2.101002221703529, irr5:23.489896774291992, ndcg5:0.8393581267854714, pnl5:1.0162557363510132 
train 10, step: 0, loss: 1.3177821968432994, grad_norm: 0.03329884882445085, ic: 0.15882874733017321
train 10, step: 500, loss: 0.9015798619337566, grad_norm: 0.006153690964560771, ic: 0.09161055813205315
train 10, step: 1000, loss: 1.5486909102440676, grad_norm: 0.4763730859265613, ic: 0.03916534009379583
train 10, step: 1500, loss: 3.105630101789929, grad_norm: 0.7502843984757612, ic: 0.05260767314886086
train 10, step: 2000, loss: 1.3873771505152925, grad_norm: 0.13228474464663767, ic: 0.02909348889338819
Epoch 10: 2022-04-20 15:40:57.800646: train loss: 1.6452673595627898
Eval step 0: eval loss: 1.0075100561767705
Eval: 2022-04-20 15:41:00.348952: total loss: 1.0910095379524223, mse:4.880807265251205, ic :0.05320029128670247, sharpe5:1.8135005166381597, irr5:20.485797882080078, ndcg5:0.8384153604926657, pnl5:1.1174529790878296 
train 11, step: 0, loss: 4.875720014415559, grad_norm: 0.553207990861128, ic: 0.04036631912863729
train 11, step: 500, loss: 0.9875625165010561, grad_norm: 0.06174903938624918, ic: 0.043716251525212656
train 11, step: 1000, loss: 1.0298287328375286, grad_norm: 0.2739139986241484, ic: 0.04252867670848585
train 11, step: 1500, loss: 0.6940248350473522, grad_norm: 0.00044329668120610366, ic: 0.10176991755796899
train 11, step: 2000, loss: 1.0954002795618398, grad_norm: 0.03344713716173897, ic: -0.018356314827097674
Epoch 11: 2022-04-20 15:41:30.065698: train loss: 1.6446317360088405
Eval step 0: eval loss: 0.9996960777053712
Eval: 2022-04-20 15:41:32.711933: total loss: 1.0890823798192346, mse:4.880635359844038, ic :0.04757700122563028, sharpe5:0.7441672663763165, irr5:6.87980318069458, ndcg5:0.8423975563660666, pnl5:0.9068503975868225 
train 12, step: 0, loss: 1.4009389667003327, grad_norm: 0.24659574935444975, ic: 0.05527974589856939
train 12, step: 500, loss: 0.8032484769632992, grad_norm: 0.30553700025340996, ic: 0.04512963196306368
train 12, step: 1000, loss: 1.2687817576063654, grad_norm: 0.26565498971939555, ic: -0.06982207588921865
train 12, step: 1500, loss: 1.0914873129001816, grad_norm: 0.18642676176176093, ic: -0.10652675949946813
train 12, step: 2000, loss: 1.1158630756284065, grad_norm: 0.057534320137664054, ic: 0.08922873486878773
Epoch 12: 2022-04-20 15:42:02.705621: train loss: 1.644680165692219
Eval step 0: eval loss: 1.002529728845774
Eval: 2022-04-20 15:42:05.183592: total loss: 1.0902686915570265, mse:4.878269106400468, ic :0.05220161472168121, sharpe5:1.2498594479262828, irr5:12.944597244262695, ndcg5:0.8484907785646024, pnl5:1.225889801979065 
train 13, step: 0, loss: 1.1052729885413364, grad_norm: 0.03304118850796566, ic: -0.14230986652590866
train 13, step: 500, loss: 1.1431573532919848, grad_norm: 0.008075132864669583, ic: -0.20533774896626938
train 13, step: 1000, loss: 1.3860776647632278, grad_norm: 0.4067190497531526, ic: 0.07596181882858301
train 13, step: 1500, loss: 0.7766378974624238, grad_norm: 0.004120976748547055, ic: -0.04581578637301792
train 13, step: 2000, loss: 1.0453835295458909, grad_norm: 0.026330993414232125, ic: 0.04884003446003692
Epoch 13: 2022-04-20 15:42:34.897053: train loss: 1.6443284369294957
Eval step 0: eval loss: 0.992834684784755
Eval: 2022-04-20 15:42:37.402090: total loss: 1.088774689380524, mse:4.8906606780381585, ic :0.04872461778335768, sharpe5:2.6749135605990886, irr5:26.556793212890625, ndcg5:0.8464359111671309, pnl5:1.0842669010162354 
train 14, step: 0, loss: 1.7825607041181144, grad_norm: 0.5398004241027613, ic: 0.17199410717207114
train 14, step: 500, loss: 1.28183156054831, grad_norm: 0.15386252665943048, ic: 0.17812073492143912
train 14, step: 1000, loss: 1.0729337834129649, grad_norm: 0.12106943246295093, ic: 0.13745426385835047
train 14, step: 1500, loss: 0.9895893475750577, grad_norm: 0.06876322550191633, ic: 0.1551894319406149
train 14, step: 2000, loss: 2.3175931000203915, grad_norm: 0.45747760935905335, ic: -0.10100187564968595
Epoch 14: 2022-04-20 15:43:07.497982: train loss: 1.6444877447303556
Eval step 0: eval loss: 1.0024429490027644
Eval: 2022-04-20 15:43:09.973631: total loss: 1.0933496822971935, mse:4.895122042919665, ic :0.04347646110362016, sharpe5:2.7922993943095205, irr5:27.973604202270508, ndcg5:0.8508029539865047, pnl5:1.1061848402023315 
train 15, step: 0, loss: 0.9713509842004191, grad_norm: 0.16199174794507776, ic: 0.13290626320311863
train 15, step: 500, loss: 1.2274956058417685, grad_norm: 0.005395509264518845, ic: 0.05962205123057482
train 15, step: 1000, loss: 1.7558252604166666, grad_norm: 0.0392584225351571, ic: -0.10899653646182558
train 15, step: 1500, loss: 5.434871664733178, grad_norm: 0.8410079606780909, ic: 0.02693971163389578
train 15, step: 2000, loss: 0.9342497258487333, grad_norm: 0.02173098489739537, ic: -0.06899802647131689
Epoch 15: 2022-04-20 15:43:39.988455: train loss: 1.6455207811276684
Eval step 0: eval loss: 0.9991113744075829
Eval: 2022-04-20 15:43:42.480447: total loss: 1.0898658255050597, mse:4.878101940357166, ic :0.054006552057224946, sharpe5:5.260667474269867, irr5:53.96497344970703, ndcg5:0.8653801717156855, pnl5:1.4324567317962646 
train 16, step: 0, loss: 6.318820283517106, grad_norm: 1.0983971515765356, ic: -0.0832245313688319
train 16, step: 500, loss: 1.387408447265625, grad_norm: 0.6312879458100709, ic: 0.0011965193951993837
train 16, step: 1000, loss: 0.820504359906955, grad_norm: 0.09718746105218352, ic: -0.009756111593356251
train 16, step: 1500, loss: 1.2171847541184486, grad_norm: 0.25807145751675564, ic: 0.11313823996272382
train 16, step: 2000, loss: 0.9999103975673311, grad_norm: 0.21575718481241635, ic: 0.1310874999688728
Epoch 16: 2022-04-20 15:44:12.749338: train loss: 1.6438536630286682
Eval step 0: eval loss: 0.9992563931674565
Eval: 2022-04-20 15:44:15.214166: total loss: 1.0869452970512765, mse:4.878605906920962, ic :0.052022590967600285, sharpe5:1.8320211508870123, irr5:17.768280029296875, ndcg5:0.8391075387497202, pnl5:1.1787561178207397 
train 17, step: 0, loss: 1.1901992142566142, grad_norm: 0.0170317232650435, ic: 0.11691453417179927
train 17, step: 500, loss: 1.0138835564717579, grad_norm: 0.007418838019651883, ic: 0.19058276838629845
train 17, step: 1000, loss: 3.362611474770524, grad_norm: 0.7025317638263745, ic: -0.03661341369799834
train 17, step: 1500, loss: 0.8887050591626214, grad_norm: 0.005481997506058918, ic: 0.006344068639780223
train 17, step: 2000, loss: 1.0431335039586829, grad_norm: 0.49068800692518905, ic: 0.12129893300136049
Epoch 17: 2022-04-20 15:44:45.545600: train loss: 1.6446356908677726
Eval step 0: eval loss: 1.0003054650473933
Eval: 2022-04-20 15:44:48.067563: total loss: 1.0899655665725045, mse:4.894930097342634, ic :0.03952986227923825, sharpe5:2.471844593435526, irr5:25.014997482299805, ndcg5:0.848448359044055, pnl5:1.0627306699752808 
train 18, step: 0, loss: 0.8528462450506215, grad_norm: 0.006710727704040572, ic: 0.022560765156349468
train 18, step: 500, loss: 2.518238127182621, grad_norm: 1.1827359501153267, ic: 0.11023283316682989
train 18, step: 1000, loss: 1.3996506505732913, grad_norm: 0.318511338634157, ic: 0.1004989084858448
train 18, step: 1500, loss: 1.779148656009743, grad_norm: 0.6391451309056874, ic: -0.052727881615892355
train 18, step: 2000, loss: 1.2868391419338532, grad_norm: 0.29719163119826514, ic: 0.09787744271910434
Epoch 18: 2022-04-20 15:45:19.518412: train loss: 1.6443766010260192
Eval step 0: eval loss: 1.0006435850283042
Eval: 2022-04-20 15:45:22.053704: total loss: 1.0903129867829915, mse:4.879392912814017, ic :0.05199925881376835, sharpe5:5.506486608088016, irr5:63.35314178466797, ndcg5:0.8467140113498705, pnl5:1.5075342655181885 
train 19, step: 0, loss: 2.253509871724369, grad_norm: 0.7979288698271174, ic: 0.053102057192276536
train 19, step: 500, loss: 1.0159086715343386, grad_norm: 0.03000065006461943, ic: -0.07211066025138407
train 19, step: 1000, loss: 1.0697098733880603, grad_norm: 0.022783199829586837, ic: 0.10885276128226748
train 19, step: 1500, loss: 1.5803804750795716, grad_norm: 0.003546848520887295, ic: 0.0988017347645611
train 19, step: 2000, loss: 1.6906500371592228, grad_norm: 4.351623327960133, ic: 0.1002040057489622
Epoch 19: 2022-04-20 15:45:52.672248: train loss: 1.6442049561365923
Eval step 0: eval loss: 1.0055611094655081
Eval: 2022-04-20 15:45:55.152436: total loss: 1.0914843952815767, mse:4.883289889805699, ic :0.0431816469272392, sharpe5:-0.16381352305412292, irr5:-2.6533010005950928, ndcg5:0.8556253512643528, pnl5:0.856419026851654 
train 20, step: 0, loss: 1.2412109375, grad_norm: 0.3742961689767412, ic: 0.07674934134358286
train 20, step: 500, loss: 1.2380831391018345, grad_norm: 0.533221482199354, ic: 0.038816856729630485
train 20, step: 1000, loss: 1.6176015955862892, grad_norm: 0.48392447859911236, ic: 0.08062691002605146
train 20, step: 1500, loss: 0.9383932914875697, grad_norm: 1.0331144324995145, ic: 0.15017808582906195
train 20, step: 2000, loss: 1.3245150936931587, grad_norm: 0.10959328481841395, ic: 0.23550697045829866
Epoch 20: 2022-04-20 15:46:25.304378: train loss: 1.6414336451945886
Eval step 0: eval loss: 1.0339027633787519
Eval: 2022-04-20 15:46:27.864031: total loss: 1.1107619224883907, mse:4.938082256029064, ic :0.10113470426610863, sharpe5:12.714026695489883, irr5:379.4703674316406, ndcg5:0.8460941476618052, pnl5:4.6809773445129395 
train 21, step: 0, loss: 1.292780555302478, grad_norm: 0.6364747212722125, ic: 0.26310181795515275
train 21, step: 500, loss: 1.1130182431140014, grad_norm: 0.0754268433217495, ic: -0.0828615118038956
train 21, step: 1000, loss: 0.9337697840167933, grad_norm: 0.17678733501909905, ic: 0.11058174828404577
train 21, step: 1500, loss: 0.7374987141817185, grad_norm: 0.1492632409058468, ic: 0.6226193887071595
train 21, step: 2000, loss: 1.1364604485017438, grad_norm: 0.6716099578068095, ic: 0.2783074767947796
Epoch 21: 2022-04-20 15:46:58.179283: train loss: 1.631730962633378
Eval step 0: eval loss: 1.0001900157155081
Eval: 2022-04-20 15:47:00.688054: total loss: 1.0813490753920072, mse:4.694082581665609, ic :0.1542177411404651, sharpe5:13.793083884716033, irr5:421.14801025390625, ndcg5:0.8509942343150693, pnl5:7.645765781402588 
train 22, step: 0, loss: 1.0659356970751273, grad_norm: 0.2881834439186084, ic: 0.05651427525590192
train 22, step: 500, loss: 1.0292751522514763, grad_norm: 0.0014689921516331886, ic: -0.03791924622127206
train 22, step: 1000, loss: 0.9158009979318095, grad_norm: 0.03158429804278762, ic: 0.12291660555921197
train 22, step: 1500, loss: 1.013384192160728, grad_norm: 0.06725949944893315, ic: 0.21781372907862434
train 22, step: 2000, loss: 1.0509458320085392, grad_norm: 0.11762714825979012, ic: 0.1466909885466184
Epoch 22: 2022-04-20 15:47:31.078637: train loss: 1.62901195297378
Eval step 0: eval loss: 1.0071624868351763
Eval: 2022-04-20 15:47:33.619683: total loss: 1.0832838385581562, mse:4.693232609335703, ic :0.1529362394654458, sharpe5:13.071789042949677, irr5:397.4571838378906, ndcg5:0.8424637952599789, pnl5:4.972900390625 
train 23, step: 0, loss: 1.2950470114427983, grad_norm: 0.7780183014858965, ic: -0.03433909386761996
train 23, step: 500, loss: 0.9260404817350619, grad_norm: 0.3914940046734157, ic: 0.5633894149602915
train 23, step: 1000, loss: 2.271347795537837, grad_norm: 0.8786455277103175, ic: 0.11980056048970823
train 23, step: 1500, loss: 0.7578424598156005, grad_norm: 0.5055835221196963, ic: 0.7272597469927443
train 23, step: 2000, loss: 1.5085958537060657, grad_norm: 0.399168992167406, ic: 0.36291496115225463
Epoch 23: 2022-04-20 15:48:03.971918: train loss: 1.629649331193652
Eval step 0: eval loss: 1.0047860690453856
Eval: 2022-04-20 15:48:06.503036: total loss: 1.0897840488852737, mse:4.726676053306127, ic :0.11739657201836909, sharpe5:8.195372673869132, irr5:234.82586669921875, ndcg5:0.8504204563713053, pnl5:4.261486053466797 
train 24, step: 0, loss: 1.2087329921082162, grad_norm: 0.14546827831731804, ic: 0.10933824687635237
train 24, step: 500, loss: 1.2507342841223303, grad_norm: 0.2089485166816341, ic: 0.03501180608247363
train 24, step: 1000, loss: 1.0575881585842226, grad_norm: 0.27337803222682844, ic: 0.11540686268950859
train 24, step: 1500, loss: 1.2009561854084645, grad_norm: 0.08134924386403494, ic: 0.09823439580006357
train 24, step: 2000, loss: 1.3662779186825302, grad_norm: 0.4773180656305276, ic: 0.4474295913706991
Epoch 24: 2022-04-20 15:48:36.447066: train loss: 1.6326773115417221
Eval step 0: eval loss: 1.0076076995704975
Eval: 2022-04-20 15:48:38.974667: total loss: 1.0843500665769215, mse:4.693063850313821, ic :0.15454278883284212, sharpe5:15.020303310155867, irr5:491.377685546875, ndcg5:0.8346896651585847, pnl5:6.259068012237549 
train 25, step: 0, loss: 1.3184545814923034, grad_norm: 1.2098709121965716, ic: 0.17949203790197094
train 25, step: 500, loss: 1.5033147242162135, grad_norm: 0.8663921204223815, ic: 0.08566457503234207
train 25, step: 1000, loss: 1.3657855515921506, grad_norm: 0.3418380063774222, ic: 0.2317217510512039
train 25, step: 1500, loss: 2.896960954520697, grad_norm: 0.9436654548335384, ic: 0.21998785554796796
train 25, step: 2000, loss: 1.1969569725326346, grad_norm: 0.16627288877269902, ic: 0.16554997093213236
Epoch 25: 2022-04-20 15:49:09.346000: train loss: 1.6282251342275997
Eval step 0: eval loss: 1.0037911863563058
Eval: 2022-04-20 15:49:11.863264: total loss: 1.0825198440675587, mse:4.685313524065294, ic :0.1605892613176675, sharpe5:14.239051913022994, irr5:467.69659423828125, ndcg5:0.8398368688953938, pnl5:6.743846416473389 
train 26, step: 0, loss: 1.6095181107954544, grad_norm: 0.23141416719580138, ic: 0.18053626814019255
train 26, step: 500, loss: 1.0186710404683648, grad_norm: 0.15762675824593064, ic: -0.0741003084252772
train 26, step: 1000, loss: 1.8231196089847004, grad_norm: 0.9902162632907262, ic: 0.17003181251662566
train 26, step: 1500, loss: 0.9224080575697015, grad_norm: 0.02585509624721389, ic: 0.000498924873395255
train 26, step: 2000, loss: 1.0009708915169784, grad_norm: 0.09906768925640118, ic: 0.10635626747216706
Epoch 26: 2022-04-20 15:49:41.971155: train loss: 1.6280024839295935
Eval step 0: eval loss: 0.9964946085933385
Eval: 2022-04-20 15:49:44.502957: total loss: 1.0855570937879435, mse:4.7259897543716605, ic :0.12157476499914588, sharpe5:7.7846952420473094, irr5:224.12277221679688, ndcg5:0.8688122938637152, pnl5:3.2643256187438965 
train 27, step: 0, loss: 1.675548507506589, grad_norm: 0.7654897012651869, ic: 0.6390640194343888
train 27, step: 500, loss: 1.5573956384258358, grad_norm: 0.9795838631438061, ic: 0.08271542892075401
train 27, step: 1000, loss: 2.5898657549048174, grad_norm: 0.6923139540661243, ic: 0.38464412219376637
train 27, step: 1500, loss: 0.7951207792982303, grad_norm: 0.2504218459076504, ic: 0.5539406438608377
train 27, step: 2000, loss: 1.3418077506960446, grad_norm: 1.11395596431499, ic: -0.02259432290505065
Epoch 27: 2022-04-20 15:50:14.756554: train loss: 1.628927416971655
Eval step 0: eval loss: 1.0058260129714651
Eval: 2022-04-20 15:50:17.311736: total loss: 1.0818478312237851, mse:4.690132341720724, ic :0.15571132617355307, sharpe5:13.951877380013466, irr5:420.3868713378906, ndcg5:0.8493704429275539, pnl5:6.833759307861328 
train 28, step: 0, loss: 1.1710272738344398, grad_norm: 0.13163701303227135, ic: 0.13234595840017818
train 28, step: 500, loss: 2.943855700422158, grad_norm: 0.6152428761571453, ic: 0.12716329147753092
train 28, step: 1000, loss: 2.7893182112707344, grad_norm: 1.616737550177581, ic: -0.03724731362013709
train 28, step: 1500, loss: 1.0226652740700028, grad_norm: 0.004890050087747391, ic: 0.2044990474354919
train 28, step: 2000, loss: 1.7607615271279977, grad_norm: 0.3760078076223085, ic: 0.09740800426204943
Epoch 28: 2022-04-20 15:50:47.293845: train loss: 1.6253255716532693
Eval step 0: eval loss: 1.0041921735123749
Eval: 2022-04-20 15:50:49.786415: total loss: 1.0820549022617285, mse:4.694857682911586, ic :0.15866045343276233, sharpe5:14.839574743509292, irr5:478.30743408203125, ndcg5:0.8521871919101122, pnl5:5.591465950012207 
train 29, step: 0, loss: 1.515934571793262, grad_norm: 0.14063575619965166, ic: 0.08710742939015982
train 29, step: 500, loss: 2.531303694849156, grad_norm: 1.1076525640022803, ic: -0.14758150261719774
train 29, step: 1000, loss: 1.6502835072448097, grad_norm: 0.9200654317205513, ic: 0.47910115132376485
train 29, step: 1500, loss: 3.9483790006038646, grad_norm: 1.1447721258879786, ic: 0.12167180034956836
train 29, step: 2000, loss: 0.9443345067344832, grad_norm: 0.2118638151047946, ic: 0.46767878766944393
Epoch 29: 2022-04-20 15:51:20.188025: train loss: 1.6258369056068926
Eval step 0: eval loss: 1.0013135254163374
Eval: 2022-04-20 15:51:22.757193: total loss: 1.081685610395389, mse:4.684183739201374, ic :0.16105680296243408, sharpe5:15.012469153404234, irr5:471.7220764160156, ndcg5:0.8373884426660408, pnl5:6.947291374206543 
train 30, step: 0, loss: 1.2559057635669, grad_norm: 0.05410815288654339, ic: 0.9921723893969545
train 30, step: 500, loss: 1.9228778307950949, grad_norm: 0.41057367226559816, ic: 0.1574685222413617
train 30, step: 1000, loss: 3.4431283046926633, grad_norm: 0.6983670911922988, ic: 0.4379518656701736
train 30, step: 1500, loss: 1.0975535057300663, grad_norm: 0.3385003318208025, ic: 0.11465840801381683
train 30, step: 2000, loss: 1.0962274433434218, grad_norm: 0.08837876785908455, ic: 0.439248861720143
Epoch 30: 2022-04-20 15:51:53.496133: train loss: 1.62625508991971
Eval step 0: eval loss: 1.0019609673265533
Eval: 2022-04-20 15:51:55.998742: total loss: 1.083238739926726, mse:4.682632433016305, ic :0.16767508231891687, sharpe5:15.120733188986778, irr5:499.13702392578125, ndcg5:0.8583226515976488, pnl5:5.505092144012451 
train 31, step: 0, loss: 1.171160564330465, grad_norm: 0.22716904598075632, ic: 0.1768815830709245
train 31, step: 500, loss: 0.8290543403117658, grad_norm: 0.08155509323013765, ic: 0.262739598778344
train 31, step: 1000, loss: 5.0382067728599225, grad_norm: 0.36883279316637213, ic: -0.046803735200422
train 31, step: 1500, loss: 1.6691083244783615, grad_norm: 0.3489135513450458, ic: 0.27503242568053754
train 31, step: 2000, loss: 0.9745978695222701, grad_norm: 0.4762780449612356, ic: 0.22805991302091955
Epoch 31: 2022-04-20 15:52:26.128894: train loss: 1.625576961645283
Eval step 0: eval loss: 1.0017306471950698
Eval: 2022-04-20 15:52:28.730316: total loss: 1.0852226023379001, mse:4.696003265257223, ic :0.14939939472866537, sharpe5:12.895721052289009, irr5:404.7786560058594, ndcg5:0.8413724275985953, pnl5:6.142324447631836 
train 32, step: 0, loss: 0.8660091836855572, grad_norm: 0.4038394283460471, ic: 0.10992741010129826
train 32, step: 500, loss: 1.1174233599406918, grad_norm: 0.3224088302678303, ic: 0.13680376487161522
train 32, step: 1000, loss: 1.38019603723138, grad_norm: 0.06627818342751576, ic: 0.0752000622103682
train 32, step: 1500, loss: 2.1047370839783284, grad_norm: 1.4360500536435623, ic: 0.4340535869979047
train 32, step: 2000, loss: 1.0929452798907073, grad_norm: 0.39679259701583025, ic: 0.46403279216168175
Epoch 32: 2022-04-20 15:52:58.888866: train loss: 1.6248404962366354
Eval step 0: eval loss: 1.0061731966248684
Eval: 2022-04-20 15:53:01.403563: total loss: 1.0812559958743335, mse:4.682628313998405, ic :0.1641331745694948, sharpe5:14.237856262922286, irr5:474.51837158203125, ndcg5:0.8458320590457711, pnl5:6.577505111694336 
train 33, step: 0, loss: 1.1658522428857907, grad_norm: 0.013950922830202977, ic: -0.0021807400343856267
train 33, step: 500, loss: 3.21835554681495, grad_norm: 1.6978396456398293, ic: 0.5152782953852713
train 33, step: 1000, loss: 5.294126684268027, grad_norm: 1.6692081484430898, ic: 0.007496510882791101
train 33, step: 1500, loss: 1.277949784441692, grad_norm: 1.1235789442367596, ic: 0.06769971060882327
train 33, step: 2000, loss: 1.865887309229651, grad_norm: 0.30182738427835737, ic: 0.09034464201526504
Epoch 33: 2022-04-20 15:53:31.986615: train loss: 1.6262749624951949
Eval step 0: eval loss: 1.010627573825862
Eval: 2022-04-20 15:53:34.502615: total loss: 1.0877294096103225, mse:4.694828638379452, ic :0.16099500009294815, sharpe5:14.403467990756035, irr5:461.01202392578125, ndcg5:0.8449471885938129, pnl5:6.4758524894714355 
train 34, step: 0, loss: 0.7177739211383222, grad_norm: 0.2965920867954983, ic: 0.13949550585488316
train 34, step: 500, loss: 1.8391602658119857, grad_norm: 0.8562417587562892, ic: 0.8492885265762052
train 34, step: 1000, loss: 0.690647183122306, grad_norm: 0.1139330458337185, ic: 0.48933409802940386
train 34, step: 1500, loss: 1.6592914287860576, grad_norm: 1.040885514791316, ic: 0.6510334945415805
train 34, step: 2000, loss: 2.9837101491711286, grad_norm: 0.4379936560572839, ic: 0.10257420256678038
Epoch 34: 2022-04-20 15:54:04.430563: train loss: 1.6244702040352468
Eval step 0: eval loss: 1.0072540877805751
Eval: 2022-04-20 15:54:06.906830: total loss: 1.086952018409822, mse:4.706908085882498, ic :0.14988251651439602, sharpe5:14.061787326335907, irr5:423.11614990234375, ndcg5:0.863209854644688, pnl5:7.323317527770996 
train 35, step: 0, loss: 1.0846718896793413, grad_norm: 0.6371771420995481, ic: 0.0067013901499140376
train 35, step: 500, loss: 3.271613843513258, grad_norm: 1.7883383734576912, ic: -0.06135375705066184
train 35, step: 1000, loss: 1.3332531011216693, grad_norm: 0.21443381709848452, ic: 0.5197681784398428
train 35, step: 1500, loss: 1.6448252784922708, grad_norm: 0.37967209424546083, ic: 0.09250301706956132
train 35, step: 2000, loss: 1.298299717480995, grad_norm: 0.1443230162683831, ic: -0.047124612320225794
Epoch 35: 2022-04-20 15:54:36.585906: train loss: 1.625001160839086
Eval step 0: eval loss: 1.0018009067272247
Eval: 2022-04-20 15:54:39.131985: total loss: 1.0816691634492994, mse:4.687341945464513, ic :0.15578001817262913, sharpe5:13.545064054727554, irr5:408.77740478515625, ndcg5:0.8356327546827572, pnl5:5.10786771774292 
train 36, step: 0, loss: 8.984015822316495, grad_norm: 1.2012634695070301, ic: -0.11082298110921639
train 36, step: 500, loss: 0.8602170171744891, grad_norm: 0.02215706505103456, ic: 0.07939347622512231
train 36, step: 1000, loss: 1.9861888015886209, grad_norm: 2.0296964191649653, ic: 0.05494946476897135
train 36, step: 1500, loss: 1.059231401180475, grad_norm: 0.16734977595066441, ic: 0.09751562327358551
train 36, step: 2000, loss: 2.184800658245659, grad_norm: 1.1014705508463611, ic: 0.3839698776521208
Epoch 36: 2022-04-20 15:55:09.150539: train loss: 1.6239064588791357
Eval step 0: eval loss: 1.007721220461427
Eval: 2022-04-20 15:55:11.601252: total loss: 1.084831225763846, mse:4.686047852452769, ic :0.16292163749666944, sharpe5:15.204318022727966, irr5:489.70721435546875, ndcg5:0.8528630476116209, pnl5:6.2255964279174805 
train 37, step: 0, loss: 1.1966770866892182, grad_norm: 0.16138813660770165, ic: 0.17701453327389494
train 37, step: 500, loss: 2.333900901192946, grad_norm: 0.05325783095490366, ic: 0.205624794250043
train 37, step: 1000, loss: 0.7518785479707311, grad_norm: 0.32640991251157225, ic: 0.16542003587827775
train 37, step: 1500, loss: 3.1517126402879123, grad_norm: 0.6574591032154851, ic: 0.23134820842123668
train 37, step: 2000, loss: 3.168511243464829, grad_norm: 1.3640909721540266, ic: 0.013358445572194049
Epoch 37: 2022-04-20 15:55:41.644770: train loss: 1.624073000159717
Eval step 0: eval loss: 0.9990630348209583
Eval: 2022-04-20 15:55:44.171356: total loss: 1.081318707250487, mse:4.684389578453304, ic :0.17027424263952587, sharpe5:15.145525901913642, irr5:506.0518493652344, ndcg5:0.8296602110125537, pnl5:5.956124782562256 
train 38, step: 0, loss: 1.3416220925071023, grad_norm: 0.44400616292451345, ic: -0.28551137996996745
train 38, step: 500, loss: 1.703005011506783, grad_norm: 0.9375428206254882, ic: 0.24157201063418274
train 38, step: 1000, loss: 1.8327024928809899, grad_norm: 0.5804912152360484, ic: 0.13366072153899552
train 38, step: 1500, loss: 1.0801823902483776, grad_norm: 0.18187943864014694, ic: 0.4834891397846706
train 38, step: 2000, loss: 0.7597008222415123, grad_norm: 0.12403001286034583, ic: 0.5610804048397346
Epoch 38: 2022-04-20 15:56:15.832893: train loss: 1.623848764980627
Eval step 0: eval loss: 0.9959910926597879
Eval: 2022-04-20 15:56:18.357297: total loss: 1.0788693193586403, mse:4.682339765797929, ic :0.1705369904890975, sharpe5:15.257540532946585, irr5:506.58258056640625, ndcg5:0.8457200171748303, pnl5:5.767838001251221 
train 39, step: 0, loss: 0.8818936943066252, grad_norm: 0.062287417316570975, ic: 0.529624146170516
train 39, step: 500, loss: 1.2402905645424018, grad_norm: 0.5242394340620764, ic: 0.046265237038335565
train 39, step: 1000, loss: 1.380228955817945, grad_norm: 0.3082829624741272, ic: 0.05468701332290206
train 39, step: 1500, loss: 2.4429116486710964, grad_norm: 0.43395549760811203, ic: -0.07048903962410794
train 39, step: 2000, loss: 2.8367270997908918, grad_norm: 0.7621834457364369, ic: 0.2139070521136855
Epoch 39: 2022-04-20 15:56:46.803209: train loss: 1.6218683706675852
Eval step 0: eval loss: 1.0065271298216165
Eval: 2022-04-20 15:56:49.232249: total loss: 1.0803107467596624, mse:4.67585824477066, ic :0.1679668868574105, sharpe5:16.174932396411894, irr5:535.5259399414062, ndcg5:0.8429333957907388, pnl5:5.69102144241333 

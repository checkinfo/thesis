Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='RGCNSeqTimeDataset', dout=0.3, epochs=60, glstm_layers=1, gnn_layers=1, gpu=0, graph_attn=True, hidden_dim=128, inner_prod=False, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=1, mask_adj=True, mask_type='soft', model_type='BiGLSTM', normalize_adj=True, num_days=8, num_heads=1, print_inteval=500, relation_num=2, seed=10086, shuffle=True, side_info=False, sparse_adj_path='../data/icgraph_window_250_0.8/', stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
load 2305 train graphs successful!
load 126 test graphs successful!
13465
BiGLSTM(
  (input_to_hidden): Linear(in_features=9, out_features=128, bias=True)
  (forward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (attention): ModuleList(
            (0): GraphAttentionLayer (128 -> 128)
            (1): GraphAttentionLayer (128 -> 128)
          )
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
            (1): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
  )
  (backward_cells): ModuleList(
    (0): GLSTMCell(
      (dropout): Dropout(p=0.3, inplace=False)
      (Wh): Linear(in_features=128, out_features=640, bias=False)
      (Wn): Linear(in_features=128, out_features=640, bias=False)
      (Wt): Linear(in_features=128, out_features=640, bias=False)
      (U): Linear(in_features=128, out_features=640, bias=False)
      (V): Linear(in_features=128, out_features=640, bias=True)
      (relu): LeakyReLU(negative_slope=0.01)
      (gnn): ModuleList(
        (0): RGCN(
          (attention): ModuleList(
            (0): GraphAttentionLayer (128 -> 128)
            (1): GraphAttentionLayer (128 -> 128)
          )
          (lin_rel): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): Linear(in_features=128, out_features=128, bias=True)
          )
          (lin_root): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=False)
            (1): Linear(in_features=128, out_features=128, bias=False)
          )
        )
      )
    )
  )
  (fc0): ModuleList(
    (0): Linear(in_features=256, out_features=128, bias=True)
  )
  (w_out): Linear(in_features=128, out_features=1, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
)
train 0, step: 0, loss: 4.931181358116692, grad_norm: 4.941579925469582, ic: -0.03934702255174804
train 0, step: 500, loss: 0.8657118934568104, grad_norm: 0.024000769149039373, ic: 0.015931687211995574
train 0, step: 1000, loss: 1.9383547600813826, grad_norm: 0.42031877271386947, ic: -0.00220310571150094
train 0, step: 1500, loss: 0.9412842761857707, grad_norm: 0.017509979703034584, ic: -0.008647609169830914
train 0, step: 2000, loss: 1.0000299683056606, grad_norm: 0.13050816388117709, ic: -0.034315289829609845
Epoch 0: 2022-04-20 20:27:39.108506: train loss: 1.6491399209985251
Eval step 0: eval loss: 0.8360690889670047
Eval: 2022-04-20 20:28:00.707314: total loss: 1.0792398823542981, mse:4.823304327707958, ic :0.010017821195492481, sharpe5:7.964485450387, irr5:222.44126892089844, ndcg5:0.8557820660523122, pnl5:2.7981982231140137 
train 1, step: 0, loss: 2.7647352649319554, grad_norm: 0.7380803627849992, ic: 0.06464270585978596
train 1, step: 500, loss: 1.7499609743746067, grad_norm: 0.6531415105625038, ic: 0.16684969202754596
train 1, step: 1000, loss: 0.8748312675417579, grad_norm: 0.1502927065375155, ic: 0.054248921417271105
train 1, step: 1500, loss: 1.7073882004310346, grad_norm: 0.179880772525779, ic: 0.004105263718491445
train 1, step: 2000, loss: 2.1732308593750003, grad_norm: 0.8096639496449339, ic: 0.02833958832201782
Epoch 1: 2022-04-20 20:33:36.207583: train loss: 1.6467313332040987
Eval step 0: eval loss: 0.835589683219178
Eval: 2022-04-20 20:33:57.845040: total loss: 1.07909740991294, mse:4.823344878354672, ic :0.01994235962036176, sharpe5:9.489228782057761, irr5:264.4228820800781, ndcg5:0.8548481462866093, pnl5:2.108813762664795 
train 2, step: 0, loss: 2.141236505681818, grad_norm: 0.0069661169242969095, ic: 0.08331588280441336
train 2, step: 500, loss: 3.293003518070227, grad_norm: 0.2559359049376438, ic: -0.00719491257469103
train 2, step: 1000, loss: 2.0740399006226053, grad_norm: 1.7160941469057538e-05, ic: 0.32581885537653116
train 2, step: 1500, loss: 1.4799523273497137, grad_norm: 0.050741728714936256, ic: -0.02281483301330753
train 2, step: 2000, loss: 3.2174312650240386, grad_norm: 0.7280356548525804, ic: 0.13236151145820207
Epoch 2: 2022-04-20 20:39:34.937549: train loss: 1.6466340131912378
Eval step 0: eval loss: 0.8365393619517254
Eval: 2022-04-20 20:39:56.242900: total loss: 1.079365354354336, mse:4.822311154916883, ic :0.029083802306891702, sharpe5:11.492695657610893, irr5:379.8939208984375, ndcg5:0.8481449225697667, pnl5:2.5716359615325928 
train 3, step: 0, loss: 1.5227575782837905, grad_norm: 0.4937370274586311, ic: -0.012617778000457236
train 3, step: 500, loss: 1.4923865214491974, grad_norm: 0.32422954766652395, ic: 0.046313047744593806
train 3, step: 1000, loss: 3.684754436978267, grad_norm: 0.6792017764576842, ic: -0.014297092529283377
train 3, step: 1500, loss: 1.9628195005626023, grad_norm: 0.9523318463210616, ic: 0.034705466206637954
train 3, step: 2000, loss: 0.9024455632390203, grad_norm: 0.007209227341516935, ic: 0.023090073524967718
Epoch 3: 2022-04-20 20:45:29.822025: train loss: 1.6476220291357544
Eval step 0: eval loss: 0.8358008301295772
Eval: 2022-04-20 20:45:51.274119: total loss: 1.079148669957412, mse:4.822873415498642, ic :0.07315941378790189, sharpe5:11.552017496824265, irr5:401.4085693359375, ndcg5:0.8480342173065066, pnl5:3.39528226852417 
train 4, step: 0, loss: 1.4389546795280612, grad_norm: 0.042316599147398826, ic: 0.15407220761427898
train 4, step: 500, loss: 1.644894577386811, grad_norm: 0.5494062682333668, ic: -0.10956361169086391
train 4, step: 1000, loss: 2.928001031643007, grad_norm: 0.724898847421637, ic: -0.026607001898798915
train 4, step: 1500, loss: 2.166221650843882, grad_norm: 0.46839169779317874, ic: -0.052890316249144594
train 4, step: 2000, loss: 1.0890918690160867, grad_norm: 0.39494290907325474, ic: 0.19472402617177498
Epoch 4: 2022-04-20 20:51:26.322249: train loss: 1.6425342165479395
Eval step 0: eval loss: 0.8438476948391398
Eval: 2022-04-20 20:51:48.085155: total loss: 1.0823735966099206, mse:4.6958647903461035, ic :0.1309291738465533, sharpe5:11.691813966035843, irr5:404.6680908203125, ndcg5:0.8322972485221346, pnl5:3.371065855026245 
train 5, step: 0, loss: 1.3115657115142616, grad_norm: 0.13585107040463512, ic: 0.42523283111668303
train 5, step: 500, loss: 0.8663471412507434, grad_norm: 0.02264690999246451, ic: 0.9446005971064781
train 5, step: 1000, loss: 0.9874896170079024, grad_norm: 0.15830306765621113, ic: -0.010606464225876515
train 5, step: 1500, loss: 1.5279439134583175, grad_norm: 0.15126129215629133, ic: 0.005573127226570489
train 5, step: 2000, loss: 1.1076330198212732, grad_norm: 0.028228720401884917, ic: 0.1533777950320354
Epoch 5: 2022-04-20 20:57:24.853568: train loss: 1.6356041603137164
Eval step 0: eval loss: 0.8365144719565002
Eval: 2022-04-20 20:57:46.275873: total loss: 1.0800351374060142, mse:4.752194522265171, ic :0.12636262926308464, sharpe5:11.426718285083771, irr5:395.7353515625, ndcg5:0.8525521392307881, pnl5:3.2161903381347656 
train 6, step: 0, loss: 1.3361547734748804, grad_norm: 0.4188019465028514, ic: 0.052690186648603234
train 6, step: 500, loss: 1.01349596663237, grad_norm: 0.041542884324413956, ic: -0.032695412576949134
train 6, step: 1000, loss: 1.097660520140209, grad_norm: 0.07959888826629771, ic: 0.8017143675455511
train 6, step: 1500, loss: 1.5790753325154958, grad_norm: 0.6903369486674737, ic: 0.000979392105154752
train 6, step: 2000, loss: 0.7882831167277572, grad_norm: 0.03859751794012489, ic: 0.35698722196006627
Epoch 6: 2022-04-20 21:03:18.585185: train loss: 1.6340907290953546
Eval step 0: eval loss: 0.8291554586653714
Eval: 2022-04-20 21:03:40.131316: total loss: 1.0724025752421824, mse:4.635812228851341, ic :0.13963485986297175, sharpe5:11.126358493566512, irr5:385.2162780761719, ndcg5:0.8449581832892485, pnl5:3.171865940093994 
train 7, step: 0, loss: 0.9976425170898438, grad_norm: 0.05491826233657241, ic: 0.014374944004196614
train 7, step: 500, loss: 0.6529986720679378, grad_norm: 0.002663689188924537, ic: 0.05010899489948829
train 7, step: 1000, loss: 1.0315318866622238, grad_norm: 0.20069077342280556, ic: 0.0069937765063615015
train 7, step: 1500, loss: 2.2420006656953375, grad_norm: 0.6853808429156104, ic: 0.4239584675274819
train 7, step: 2000, loss: 0.907462814898021, grad_norm: 0.03467677248445042, ic: -0.0025508080765625427
Epoch 7: 2022-04-20 21:09:17.793813: train loss: 1.6334858126976315
Eval step 0: eval loss: 0.8336709025536748
Eval: 2022-04-20 21:09:39.205281: total loss: 1.0777940062314624, mse:4.712330414686822, ic :0.12836026764261868, sharpe5:11.633116437792777, irr5:404.2041320800781, ndcg5:0.8505730186873981, pnl5:3.181657314300537 
train 8, step: 0, loss: 3.565621815557065, grad_norm: 1.1409543263528263, ic: 0.1636020620649874
train 8, step: 500, loss: 2.7490008044025456, grad_norm: 0.8528981952172539, ic: -0.00846168767881459
train 8, step: 1000, loss: 3.0646841740262682, grad_norm: 0.8502124539981732, ic: 0.12216880602530757
train 8, step: 1500, loss: 0.718300552462238, grad_norm: 0.04045753004862172, ic: 0.563575893169338
train 8, step: 2000, loss: 1.0574587687073511, grad_norm: 0.318661829806459, ic: 0.6607770033430426
Epoch 8: 2022-04-20 21:15:57.769214: train loss: 1.6348748657533363
Eval step 0: eval loss: 0.8280906556655031
Eval: 2022-04-20 21:16:22.634284: total loss: 1.0729106773588362, mse:4.649472432841773, ic :0.13570998571448717, sharpe5:11.730767186880112, irr5:398.5128173828125, ndcg5:0.839734422356846, pnl5:4.182306289672852 
train 9, step: 0, loss: 5.425144225976874, grad_norm: 0.747010611019461, ic: -0.0985480592798117
train 9, step: 500, loss: 1.3411910291086382, grad_norm: 0.982364238279797, ic: 0.2938312537913523
train 9, step: 1000, loss: 0.9353515424556137, grad_norm: 0.012102364687951806, ic: -0.043439467227574705
train 9, step: 1500, loss: 1.0792049357395987, grad_norm: 0.06591181929346918, ic: 0.4928974114352888
train 9, step: 2000, loss: 1.0645610817063895, grad_norm: 0.22481286293045252, ic: 0.2975149888585582
Epoch 9: 2022-04-20 21:23:04.208183: train loss: 1.630372043839413
Eval step 0: eval loss: 0.8261485928856032
Eval: 2022-04-20 21:23:29.396300: total loss: 1.075479058159149, mse:4.679545701695049, ic :0.14003455705947737, sharpe5:14.186506685614585, irr5:476.1114807128906, ndcg5:0.8567610059988067, pnl5:5.223901748657227 
train 10, step: 0, loss: 7.136986379373178, grad_norm: 1.3412971957392008, ic: 0.2755683002445089
train 10, step: 500, loss: 1.1254454512423961, grad_norm: 0.06041937162973904, ic: 0.06422105127225047
train 10, step: 1000, loss: 2.4019254906777223, grad_norm: 0.6695356529520249, ic: 0.07011335099141043
train 10, step: 1500, loss: 1.1085604382799819, grad_norm: 0.25984639596100984, ic: 0.011447451608382828
train 10, step: 2000, loss: 2.715316447805851, grad_norm: 0.7622855075465003, ic: 0.5348818664010541
Epoch 10: 2022-04-20 21:29:59.606258: train loss: 1.6286726964669873
Eval step 0: eval loss: 0.826857089493875
Eval: 2022-04-20 21:30:25.753750: total loss: 1.0720807816099283, mse:4.634936611936865, ic :0.14629414489135523, sharpe5:14.009036833047865, irr5:471.2412109375, ndcg5:0.8503145667264287, pnl5:4.937263011932373 
train 11, step: 0, loss: 1.2669374682787125, grad_norm: 0.048193454039269834, ic: 0.12405460995083381
train 11, step: 500, loss: 0.6445667867773031, grad_norm: 0.13851812376238512, ic: 0.6510633529433186
train 11, step: 1000, loss: 0.9493240142595837, grad_norm: 0.1397677580689871, ic: 0.047346600209220026
train 11, step: 1500, loss: 1.0536741290176124, grad_norm: 0.04218186943720767, ic: 0.1902360856532256
train 11, step: 2000, loss: 0.7943276741305045, grad_norm: 0.00024812849499157477, ic: 0.06503735969011087
Epoch 11: 2022-04-20 21:36:52.868992: train loss: 1.6267048822865493
Eval step 0: eval loss: 0.8280992739067439
Eval: 2022-04-20 21:37:17.505012: total loss: 1.0720204717329413, mse:4.620815972125885, ic :0.1597060618765593, sharpe5:15.342738170027731, irr5:506.35723876953125, ndcg5:0.8341947324096494, pnl5:4.417551040649414 
train 12, step: 0, loss: 0.9724543889363606, grad_norm: 0.06793834077899781, ic: 0.39788983666490485
train 12, step: 500, loss: 0.9439842230369575, grad_norm: 0.06616936033754915, ic: 0.12873778572681968
train 12, step: 1000, loss: 3.003320195872313, grad_norm: 0.3150885277290245, ic: 0.019857920001771435
train 12, step: 1500, loss: 0.9320046046446592, grad_norm: 0.10354947757385817, ic: -0.02611612570323115
train 12, step: 2000, loss: 0.8792294966130099, grad_norm: 0.006487081847247236, ic: 0.05345569627804374
Epoch 12: 2022-04-20 21:43:49.259208: train loss: 1.6267348805484858
Eval step 0: eval loss: 0.8289785917742359
Eval: 2022-04-20 21:44:14.717939: total loss: 1.0739939408369927, mse:4.663143046366623, ic :0.14396182852280479, sharpe5:14.27028448820114, irr5:482.31005859375, ndcg5:0.8558118202922456, pnl5:3.4952900409698486 
train 13, step: 0, loss: 2.05763678062302, grad_norm: 0.7149495269960632, ic: 0.4216542672331809
train 13, step: 500, loss: 0.8316201578220924, grad_norm: 0.09091063099816044, ic: 0.579633750321437
train 13, step: 1000, loss: 0.9407210177223154, grad_norm: 0.3272291980707207, ic: 0.5936570639337091
train 13, step: 1500, loss: 2.3551836333918814, grad_norm: 0.1445992030913608, ic: -0.017975423841620597
train 13, step: 2000, loss: 1.4637731210005291, grad_norm: 0.05599159168268836, ic: 0.19555414984978456
Epoch 13: 2022-04-20 21:50:43.737523: train loss: 1.6261316199362579
Eval step 0: eval loss: 0.8237308546413988
Eval: 2022-04-20 21:51:08.050134: total loss: 1.0699131250473661, mse:4.610000353368627, ic :0.16542706627154136, sharpe5:15.690952343344687, irr5:513.4114379882812, ndcg5:0.8366514542877929, pnl5:5.526617527008057 
train 14, step: 0, loss: 4.536610429260921, grad_norm: 1.2725378545286354, ic: 0.05444110609602331
train 14, step: 500, loss: 0.8280919626218464, grad_norm: 0.0028993930805589646, ic: 0.058901550034423156
train 14, step: 1000, loss: 1.8238083268080867, grad_norm: 0.2784596630999644, ic: 0.46285122581704585
train 14, step: 1500, loss: 1.121690687242445, grad_norm: 0.06083584644579834, ic: 0.053146235260505596
train 14, step: 2000, loss: 1.1361641939167633, grad_norm: 0.14700285915389447, ic: 0.13051563406005373
Epoch 14: 2022-04-20 21:57:36.887610: train loss: 1.6260664081331788
Eval step 0: eval loss: 0.8334945501844045
Eval: 2022-04-20 21:58:02.225290: total loss: 1.0762911473059058, mse:4.680174706464207, ic :0.15401556768018004, sharpe5:15.282918773889541, irr5:504.0306701660156, ndcg5:0.8441926885761727, pnl5:3.8673312664031982 
train 15, step: 0, loss: 3.339361168531129, grad_norm: 0.5278263271300954, ic: 0.10187044679958929
train 15, step: 500, loss: 1.259151316045823, grad_norm: 0.009776612159848812, ic: 0.006046124814133188
train 15, step: 1000, loss: 1.3140420557037602, grad_norm: 0.1248090573135879, ic: 0.06406286196225543
train 15, step: 1500, loss: 0.851535202386811, grad_norm: 0.17411407171965398, ic: 0.04431116129300344
train 15, step: 2000, loss: 1.4647533275462963, grad_norm: 0.5140051752307604, ic: 0.05106216749919916
Epoch 15: 2022-04-20 22:04:26.860820: train loss: 1.6250594896564463
Eval step 0: eval loss: 0.8335710209966082
Eval: 2022-04-20 22:04:52.319071: total loss: 1.0750981789981375, mse:4.6441804856653865, ic :0.16026457386684997, sharpe5:15.948055897951125, irr5:523.756103515625, ndcg5:0.8444722486314425, pnl5:4.745820999145508 
train 16, step: 0, loss: 0.6927756991352434, grad_norm: 0.17896377068511246, ic: 0.05772258571095107
train 16, step: 500, loss: 1.5521486442893067, grad_norm: 3.3133241715528836, ic: 0.20796387226404306
train 16, step: 1000, loss: 0.873880097360322, grad_norm: 0.005882232305668666, ic: 0.022852427709375577
train 16, step: 1500, loss: 0.8412118224857171, grad_norm: 0.22595278834824428, ic: 0.15608028593290668
train 16, step: 2000, loss: 3.3540835392366843, grad_norm: 0.8787750997287628, ic: -0.041327184838748914
Epoch 16: 2022-04-20 22:10:49.057276: train loss: 1.6252111857656206
Eval step 0: eval loss: 0.8263148477632705
Eval: 2022-04-20 22:11:10.584859: total loss: 1.0686158664634056, mse:4.596830179796561, ic :0.17472009905924207, sharpe5:16.327824261188507, irr5:528.8993530273438, ndcg5:0.865308747373522, pnl5:7.410672664642334 
train 17, step: 0, loss: 1.2743691199021883, grad_norm: 0.22728378768021934, ic: -0.08400596462018889
train 17, step: 500, loss: 1.7815006245765583, grad_norm: 0.3993377664243382, ic: 0.13981877840570603
train 17, step: 1000, loss: 1.2790933813295335, grad_norm: 0.06871265848128061, ic: 0.13908282495650606
train 17, step: 1500, loss: 4.523128960782513, grad_norm: 1.0264979815603956, ic: 0.23819987498522827
train 17, step: 2000, loss: 1.2758213185846758, grad_norm: 0.5985883755117167, ic: 0.038551946172732776
Epoch 17: 2022-04-20 22:16:45.746031: train loss: 1.623878907824861
Eval step 0: eval loss: 0.8321205838588316
Eval: 2022-04-20 22:17:07.519457: total loss: 1.0718315744586082, mse:4.617542062485405, ic :0.17356921242698228, sharpe5:17.203533908128737, irr5:563.15869140625, ndcg5:0.8480645334615006, pnl5:5.490445613861084 
train 18, step: 0, loss: 1.4058506543199252, grad_norm: 0.43675808937361577, ic: 0.24089464929292337
train 18, step: 500, loss: 1.4749387382402643, grad_norm: 0.6637716055798781, ic: 0.0626039647899957
train 18, step: 1000, loss: 0.6569828232020547, grad_norm: 0.020046451209943573, ic: 0.5709898736513619
train 18, step: 1500, loss: 1.4282326538185914, grad_norm: 0.03238703025523361, ic: 0.2132227902358017
train 18, step: 2000, loss: 0.9102194233305135, grad_norm: 0.007145521076786889, ic: 0.02550616690471153
Epoch 18: 2022-04-20 22:22:43.560149: train loss: 1.6238384529355345
Eval step 0: eval loss: 0.8223758613096022
Eval: 2022-04-20 22:23:05.034993: total loss: 1.0665472785530055, mse:4.602219681396314, ic :0.17969021581880643, sharpe5:17.35488580584526, irr5:559.6675415039062, ndcg5:0.8614089022830914, pnl5:6.804329872131348 
train 19, step: 0, loss: 1.4756401909722223, grad_norm: 0.7020741031688199, ic: 0.05840187081652021
train 19, step: 500, loss: 0.8587126555266203, grad_norm: 0.05695596503307947, ic: 0.2730270735892453
train 19, step: 1000, loss: 0.9626794813615225, grad_norm: 0.015873940013294948, ic: 0.1784572940124858
train 19, step: 1500, loss: 3.9631692507027405, grad_norm: 0.8143751944031306, ic: 0.17124124113656003
train 19, step: 2000, loss: 1.011238544170673, grad_norm: 0.079295191043488, ic: 0.20567415917258347
Epoch 19: 2022-04-20 22:28:44.439673: train loss: 1.623334760225219
Eval step 0: eval loss: 0.8289954423653187
Eval: 2022-04-20 22:29:07.121297: total loss: 1.0681661903201833, mse:4.594437467291465, ic :0.1789979311542673, sharpe5:17.382260895967484, irr5:565.4945068359375, ndcg5:0.8538747320483087, pnl5:7.7203192710876465 
train 20, step: 0, loss: 2.301376065340909, grad_norm: 0.5908047578720835, ic: 0.03729653291786052
train 20, step: 500, loss: 3.197511008522727, grad_norm: 0.40803785297834405, ic: 0.11956771162593792
train 20, step: 1000, loss: 0.9732779502868653, grad_norm: 0.05547652048573121, ic: 0.14725074512479608
train 20, step: 1500, loss: 1.895835701210758, grad_norm: 0.40361912862663474, ic: 0.23686814836919737
train 20, step: 2000, loss: 1.032363767141619, grad_norm: 0.031338808675106716, ic: 0.01605480717324459
Epoch 20: 2022-04-20 22:34:50.652811: train loss: 1.6231982617907916
Eval step 0: eval loss: 0.8346453426509812
Eval: 2022-04-20 22:35:12.860153: total loss: 1.0697175363303841, mse:4.611250492199668, ic :0.16877768329744613, sharpe5:15.752654131650925, irr5:526.6238403320312, ndcg5:0.8373075390601322, pnl5:5.63352108001709 
train 21, step: 0, loss: 1.0124865545742754, grad_norm: 0.2620998562273048, ic: 0.05748826590485874
train 21, step: 500, loss: 0.7732774177483752, grad_norm: 0.010770503334473524, ic: 0.1865198934967819
train 21, step: 1000, loss: 0.9238199602093612, grad_norm: 0.39708205514786926, ic: 0.16549690160693484
train 21, step: 1500, loss: 0.9913773011440334, grad_norm: 0.19103601545497953, ic: 0.3050512906309596
train 21, step: 2000, loss: 0.9410903271646595, grad_norm: 0.03923478841258164, ic: 0.08470330118080799
Epoch 21: 2022-04-20 22:40:57.786455: train loss: 1.6232099799450217
Eval step 0: eval loss: 0.8314895227912604
Eval: 2022-04-20 22:41:20.457979: total loss: 1.0674421026419296, mse:4.603618594389129, ic :0.1782519829177687, sharpe5:16.163136702775954, irr5:521.6197509765625, ndcg5:0.8579783462315739, pnl5:6.017642498016357 
train 22, step: 0, loss: 1.0406523451293255, grad_norm: 0.019973431143717652, ic: 0.21696827351416567
train 22, step: 500, loss: 3.242551130589431, grad_norm: 1.018233956057843, ic: -0.11673140148235467
train 22, step: 1000, loss: 1.195588393018425, grad_norm: 0.015657530414175905, ic: 0.4590963295552733
train 22, step: 1500, loss: 0.9760137361754115, grad_norm: 0.05463357276052137, ic: 0.10814049062978756
train 22, step: 2000, loss: 1.753589863679847, grad_norm: 0.5216675261266147, ic: 0.20562172994378258
Epoch 22: 2022-04-20 22:47:03.890744: train loss: 1.6227087847896138
Eval step 0: eval loss: 0.8281441659394757
Eval: 2022-04-20 22:47:26.384779: total loss: 1.0666536334724415, mse:4.595534491860082, ic :0.1797721394282773, sharpe5:17.918850499391556, irr5:579.6834716796875, ndcg5:0.843631200700386, pnl5:4.6131815910339355 
train 23, step: 0, loss: 0.9881046526026658, grad_norm: 0.05661500585380434, ic: 0.17337663724202323
train 23, step: 500, loss: 1.4285652004942604, grad_norm: 0.07996175850024877, ic: 0.042187502735800186
train 23, step: 1000, loss: 1.6405345662434896, grad_norm: 0.04849227464076998, ic: 0.25695845753283425
train 23, step: 1500, loss: 1.1226155536502302, grad_norm: 0.18431509648915928, ic: 0.06656891626353544
train 23, step: 2000, loss: 1.895614753235662, grad_norm: 0.6411447334081937, ic: 0.4531188487559811
Epoch 23: 2022-04-20 22:53:14.117275: train loss: 1.6227893038318637
Eval step 0: eval loss: 0.8340661839765542
Eval: 2022-04-20 22:53:36.506196: total loss: 1.0685360148676115, mse:4.592740991396558, ic :0.1810943249424307, sharpe5:16.00446334004402, irr5:519.30322265625, ndcg5:0.8412835243972504, pnl5:4.0737833976745605 
train 24, step: 0, loss: 2.2073956307978824, grad_norm: 0.02520065477439859, ic: 0.1057073575315752
train 24, step: 500, loss: 1.220863098857004, grad_norm: 0.0682120648055261, ic: 0.10136233711426976
train 24, step: 1000, loss: 0.9034402397820308, grad_norm: 0.04660863709831925, ic: 0.5402152067191958
train 24, step: 1500, loss: 2.602386097227947, grad_norm: 0.8006577627557563, ic: 0.03769704783616032
train 24, step: 2000, loss: 0.930996149462612, grad_norm: 0.061424981469272444, ic: 0.09026706270902479
Epoch 24: 2022-04-20 22:59:23.969791: train loss: 1.6222752305680816
Eval step 0: eval loss: 0.826572044380598
Eval: 2022-04-20 22:59:46.172545: total loss: 1.0662069697574206, mse:4.596470809665405, ic :0.1848268555524884, sharpe5:17.70276512145996, irr5:577.4503784179688, ndcg5:0.8492724901814867, pnl5:7.592443943023682 
train 25, step: 0, loss: 0.8554642960831926, grad_norm: 0.057818337271266874, ic: 0.5973245545937855
train 25, step: 500, loss: 0.8726774371282572, grad_norm: 0.0033725981963304355, ic: 0.1862057664235795
train 25, step: 1000, loss: 2.080505789461158, grad_norm: 0.1260738146324784, ic: 0.28378788984701664
train 25, step: 1500, loss: 1.1400273675363668, grad_norm: 0.30762105127750045, ic: 0.535420216879185
train 25, step: 2000, loss: 1.014669869692271, grad_norm: 0.3759833540408615, ic: 0.6007352613361736
Epoch 25: 2022-04-20 23:05:34.094103: train loss: 1.6216621577545547
Eval step 0: eval loss: 0.8306397899310128
Eval: 2022-04-20 23:05:56.364954: total loss: 1.0676558750070793, mse:4.5919782554545066, ic :0.18203462742776946, sharpe5:15.362137214541434, irr5:498.33740234375, ndcg5:0.85166866878902, pnl5:5.819869518280029 
train 26, step: 0, loss: 6.676363911491613, grad_norm: 0.27660956488244043, ic: 0.12610060992600441
train 26, step: 500, loss: 3.842752440260946, grad_norm: 0.5512590410929312, ic: 0.3918196681432467
train 26, step: 1000, loss: 1.2579136822998431, grad_norm: 0.7688492185009874, ic: 0.04001344507709359
train 26, step: 1500, loss: 0.8376275956932393, grad_norm: 0.12765829968234954, ic: 0.2872730861123233
train 26, step: 2000, loss: 0.9666093995869394, grad_norm: 0.143197919411907, ic: 0.07282115030645535
Epoch 26: 2022-04-20 23:11:38.489863: train loss: 1.6222618195259868
Eval step 0: eval loss: 0.830090087633364
Eval: 2022-04-20 23:12:00.869205: total loss: 1.0671219105871925, mse:4.590489578902264, ic :0.18114460464694532, sharpe5:16.95543083667755, irr5:547.6629638671875, ndcg5:0.8391096301781884, pnl5:4.620486736297607 
train 27, step: 0, loss: 0.8296059283088235, grad_norm: 0.018041293986666623, ic: 0.08340220003371307
train 27, step: 500, loss: 0.8935186193954953, grad_norm: 0.41249967517083597, ic: 0.30209253745893144
train 27, step: 1000, loss: 0.7515648696557183, grad_norm: 0.14164488787983365, ic: 0.1850330713276437
train 27, step: 1500, loss: 0.6297444041587323, grad_norm: 0.02796370774363416, ic: 0.5263597776317546
train 27, step: 2000, loss: 1.3874153015553816, grad_norm: 0.010747114006507854, ic: -0.047288914829382
Epoch 27: 2022-04-20 23:17:53.101766: train loss: 1.6225008166316308
Eval step 0: eval loss: 0.8328517837444019
Eval: 2022-04-20 23:18:17.204605: total loss: 1.068027114968989, mse:4.602881067704707, ic :0.18332038744826132, sharpe5:17.075934205055237, irr5:554.7769165039062, ndcg5:0.8499616211616102, pnl5:6.292525291442871 
train 28, step: 0, loss: 1.5440846329029922, grad_norm: 0.23576824508123406, ic: 0.23922525517734358
train 28, step: 500, loss: 1.3652305539058134, grad_norm: 0.256061371836628, ic: 0.17097125905997956
train 28, step: 1000, loss: 0.9123610416402016, grad_norm: 0.2172563613821233, ic: 0.583584619514221
train 28, step: 1500, loss: 1.032750412022873, grad_norm: 0.01573900560027504, ic: 0.0275391067722177
train 28, step: 2000, loss: 1.0466630619727761, grad_norm: 0.12210761088367042, ic: 0.03628463160794512
Epoch 28: 2022-04-20 23:24:37.216078: train loss: 1.6224931482056018
Eval step 0: eval loss: 0.8272082506668202
Eval: 2022-04-20 23:25:01.188190: total loss: 1.0687934244204595, mse:4.640400765270766, ic :0.16848909232336123, sharpe5:16.25031321644783, irr5:534.3653564453125, ndcg5:0.850912331803994, pnl5:5.737865447998047 
train 29, step: 0, loss: 0.907630810509856, grad_norm: 0.01913634717150044, ic: 0.07658929351101419
train 29, step: 500, loss: 1.1293131749348575, grad_norm: 0.1653307372683002, ic: 0.6083137419807505
train 29, step: 1000, loss: 1.0624766726724386, grad_norm: 0.270596548065728, ic: 0.07895122785467391
train 29, step: 1500, loss: 2.372521429486241, grad_norm: 0.3362724992753268, ic: -0.028351916400293664
train 29, step: 2000, loss: 4.542787905092593, grad_norm: 1.3029366197042676, ic: 0.23097809236071962
Epoch 29: 2022-04-20 23:30:58.978753: train loss: 1.6224811857071622
Eval step 0: eval loss: 0.8348653650635537
Eval: 2022-04-20 23:31:22.893335: total loss: 1.0684053517247483, mse:4.59809360597679, ic :0.17840432676471785, sharpe5:15.231296769976614, irr5:507.4242858886719, ndcg5:0.8486240849053163, pnl5:5.171754837036133 
train 30, step: 0, loss: 1.0125835871292375, grad_norm: 0.049235768902390925, ic: 0.5131061541009873
train 30, step: 500, loss: 1.4060814648597724, grad_norm: 0.8828616749264973, ic: 0.13708011743493032
train 30, step: 1000, loss: 0.9738561456853693, grad_norm: 0.0213651620489877, ic: -0.026874799050459336
train 30, step: 1500, loss: 1.5267868164585565, grad_norm: 0.6142177766696479, ic: 0.17956926576365567
train 30, step: 2000, loss: 1.8432200635400726, grad_norm: 0.13796899871167403, ic: 0.03181336768131091
Epoch 30: 2022-04-20 23:37:38.405665: train loss: 1.6218891534284652
Eval step 0: eval loss: 0.833686145263929
Eval: 2022-04-20 23:38:02.570056: total loss: 1.0683915072626213, mse:4.595043245057718, ic :0.183550122763307, sharpe5:16.64940305829048, irr5:544.8584594726562, ndcg5:0.8605521287214306, pnl5:5.391319274902344 
train 31, step: 0, loss: 1.0418428152617267, grad_norm: 0.08528056624427428, ic: 0.34359688077204076
train 31, step: 500, loss: 1.4638906973379628, grad_norm: 0.5519736142066654, ic: 0.00750656883698546
train 31, step: 1000, loss: 4.342130400443989, grad_norm: 0.8593849170458535, ic: 0.46086685287374163
train 31, step: 1500, loss: 0.7739568270951233, grad_norm: 0.18490539048209378, ic: 0.707536487057492
train 31, step: 2000, loss: 1.2271037464083872, grad_norm: 0.4306220665924758, ic: 0.12827820828385533
Epoch 31: 2022-04-20 23:44:07.061250: train loss: 1.62023523984076
Eval step 0: eval loss: 0.8456976582051831
Eval: 2022-04-20 23:44:30.033340: total loss: 1.0857251413562072, mse:4.716202725487322, ic :0.1409156123320654, sharpe5:16.388371074199675, irr5:516.9270629882812, ndcg5:0.8522752432293215, pnl5:5.943297863006592 
train 32, step: 0, loss: 1.135870727634207, grad_norm: 0.02236942109889634, ic: 0.18175424103021395
train 32, step: 500, loss: 1.493123885027067, grad_norm: 0.4769733732574855, ic: 0.12041463138116203
train 32, step: 1000, loss: 1.035498318477673, grad_norm: 0.08479968588223485, ic: 0.5165109999557141
train 32, step: 1500, loss: 1.000755793078995, grad_norm: 0.34827113186575753, ic: 0.06300229227745141
train 32, step: 2000, loss: 0.9597907469347625, grad_norm: 0.07225888327371814, ic: 0.5379651052526707
Epoch 32: 2022-04-20 23:50:24.551032: train loss: 1.6221274011789188
Eval step 0: eval loss: 0.8255890503572839
Eval: 2022-04-20 23:50:48.467553: total loss: 1.06605474955614, mse:4.599709467762773, ic :0.18087575319924803, sharpe5:16.068623589277266, irr5:517.2220458984375, ndcg5:0.8369553331127023, pnl5:8.300204277038574 
train 33, step: 0, loss: 1.2759968460335673, grad_norm: 0.37674584677906714, ic: 0.20378073723864615
train 33, step: 500, loss: 0.9890345609124331, grad_norm: 0.029094766331579626, ic: 0.18340169437990694
train 33, step: 1000, loss: 1.0403868909306337, grad_norm: 0.5557662805033549, ic: 0.21546525966931063
train 33, step: 1500, loss: 0.8875641194951068, grad_norm: 0.02704360790372293, ic: 0.5550664762095842
train 33, step: 2000, loss: 0.8124900370505647, grad_norm: 0.02744736454888534, ic: 0.23981840406323168
Epoch 33: 2022-04-20 23:56:46.579112: train loss: 1.6212446160388125
Eval step 0: eval loss: 0.8298208640674394
Eval: 2022-04-20 23:57:11.264180: total loss: 1.0666363494011415, mse:4.599118277151135, ic :0.18471864218600642, sharpe5:15.672131259441375, irr5:511.7886962890625, ndcg5:0.8452086840929126, pnl5:4.515068531036377 
train 34, step: 0, loss: 1.008192180180864, grad_norm: 0.6287795025824643, ic: 0.6016191748677282
train 34, step: 500, loss: 0.821808047979979, grad_norm: 0.21632803193652153, ic: 0.21323195672721107
train 34, step: 1000, loss: 3.2218424479166665, grad_norm: 1.33104119914188, ic: 0.33840082281571715
train 34, step: 1500, loss: 0.805122966561755, grad_norm: 0.3736925087979001, ic: 0.6726766522924925
train 34, step: 2000, loss: 6.949571250484121, grad_norm: 1.3941120342781204, ic: 0.4575779665410816
Epoch 34: 2022-04-21 00:03:21.656144: train loss: 1.6213979141812134
Eval step 0: eval loss: 0.826124667618875
Eval: 2022-04-21 00:03:45.260543: total loss: 1.0674093301401046, mse:4.595727614170955, ic :0.18673039078288453, sharpe5:17.536698403358457, irr5:566.3939208984375, ndcg5:0.8533554215511671, pnl5:5.006045818328857 
train 35, step: 0, loss: 1.225147776884191, grad_norm: 0.6928622472595413, ic: 0.5528581133720811
train 35, step: 500, loss: 1.1917435154014206, grad_norm: 0.46390977486756096, ic: 0.10217130240093458
train 35, step: 1000, loss: 1.9104558535695328, grad_norm: 0.9265437034398627, ic: 0.06354580713137954
train 35, step: 1500, loss: 1.5958552998707707, grad_norm: 0.8242646167194008, ic: 0.10606671530193443
train 35, step: 2000, loss: 0.773055948675635, grad_norm: 0.031150796732593744, ic: 0.5803059103567629
Epoch 35: 2022-04-21 00:09:49.404926: train loss: 1.6215360471805609
Eval step 0: eval loss: 0.829707347680947
Eval: 2022-04-21 00:10:13.742885: total loss: 1.0672924195243298, mse:4.591063111955347, ic :0.18404564967887885, sharpe5:16.643091841936112, irr5:541.9588012695312, ndcg5:0.8454264079447583, pnl5:5.459493637084961 
train 36, step: 0, loss: 1.842922911352041, grad_norm: 0.8490535868673114, ic: 0.09424842378213985
train 36, step: 500, loss: 0.8434926807833433, grad_norm: 0.011907069617118612, ic: 0.11606315372112538
train 36, step: 1000, loss: 1.7742313565340908, grad_norm: 1.4759637064810829, ic: 0.2649378749059267
train 36, step: 1500, loss: 0.7752665717389539, grad_norm: 0.15460444715570829, ic: 0.3721322380184916
train 36, step: 2000, loss: 1.1403660247778493, grad_norm: 1.0970044222898845, ic: 0.7721987980306715
Epoch 36: 2022-04-21 00:16:17.600384: train loss: 1.6214613774923516
Eval step 0: eval loss: 0.8268082099166886
Eval: 2022-04-21 00:16:40.998700: total loss: 1.0693611074459102, mse:4.5971953815252045, ic :0.17884976116559206, sharpe5:16.592252118587492, irr5:534.9009399414062, ndcg5:0.8283186942235629, pnl5:6.095028400421143 
train 37, step: 0, loss: 2.0430267006843414, grad_norm: 0.8262205178946169, ic: 0.16229094740431455
train 37, step: 500, loss: 2.334353572976142, grad_norm: 0.547625900374568, ic: -0.041010564755051944
train 37, step: 1000, loss: 1.0745641513865105, grad_norm: 0.06322741690970876, ic: 0.07981757142210949
train 37, step: 1500, loss: 2.035710261418269, grad_norm: 0.6716297859710351, ic: 0.5974119251331718
train 37, step: 2000, loss: 1.3241064128685631, grad_norm: 0.06414323759869979, ic: 0.17152294080486358
Epoch 37: 2022-04-21 00:22:46.938159: train loss: 1.621645345780276
Eval step 0: eval loss: 0.8288010817307692
Eval: 2022-04-21 00:23:10.905062: total loss: 1.0686381681038182, mse:4.628744115996273, ic :0.1689178089933433, sharpe5:16.151755324602128, irr5:520.4475708007812, ndcg5:0.8475346460132381, pnl5:4.9259209632873535 
train 38, step: 0, loss: 1.3510943156916921, grad_norm: 0.30114519792552286, ic: -0.08212279948509359
train 38, step: 500, loss: 0.9027642144097222, grad_norm: 0.05366678134789297, ic: 0.2644591436431767
train 38, step: 1000, loss: 0.9102845927000988, grad_norm: 0.12620391654847926, ic: 0.052527446560121656
train 38, step: 1500, loss: 0.9524157501660973, grad_norm: 0.017288675781897956, ic: 0.21642989225166906
train 38, step: 2000, loss: 2.318014554026624, grad_norm: 1.4981813256996288, ic: -0.012144501338306118
Epoch 38: 2022-04-21 00:29:19.923610: train loss: 1.621007361683524
Eval step 0: eval loss: 0.8286071069876185
Eval: 2022-04-21 00:29:43.613072: total loss: 1.0657148233860805, mse:4.593419125095485, ic :0.18517936701154977, sharpe5:17.09613539457321, irr5:557.679931640625, ndcg5:0.8448330366195903, pnl5:6.403411865234375 
train 39, step: 0, loss: 0.9701467158232989, grad_norm: 0.004017911284050868, ic: 0.05248052201350761
train 39, step: 500, loss: 0.900276154760761, grad_norm: 0.08541666761686775, ic: 0.24615527485643807
train 39, step: 1000, loss: 0.9552365467916984, grad_norm: 0.24011618652977598, ic: 0.1399193290064944
train 39, step: 1500, loss: 2.108892909320523, grad_norm: 0.1412522364392433, ic: 0.18817565793772678
train 39, step: 2000, loss: 0.618564888952656, grad_norm: 0.028754046477000625, ic: 0.10660146101047596
Epoch 39: 2022-04-21 00:35:53.100741: train loss: 1.6233460155710937
Eval step 0: eval loss: 0.8314389710180123
Eval: 2022-04-21 00:36:17.100753: total loss: 1.0681236704862884, mse:4.616599599676058, ic :0.17715780974728337, sharpe5:16.5868111538887, irr5:546.754150390625, ndcg5:0.8482932222173105, pnl5:5.697273254394531 
train 40, step: 0, loss: 0.8865234375000001, grad_norm: 0.04506463265903256, ic: 0.23803608748553332
train 40, step: 500, loss: 1.081949326221573, grad_norm: 0.038007077371668925, ic: 0.48315574461545324
train 40, step: 1000, loss: 1.2871317049352133, grad_norm: 0.9751030731412773, ic: 0.11434538976106456
train 40, step: 1500, loss: 2.6519023260528214, grad_norm: 1.234794115507179, ic: -0.020712349763123732
train 40, step: 2000, loss: 1.0577081145892655, grad_norm: 0.4871524994140658, ic: 0.06590843986112906
Epoch 40: 2022-04-21 00:42:23.656627: train loss: 1.6208090526403303
Eval step 0: eval loss: 0.831235992142222
Eval: 2022-04-21 00:42:47.107408: total loss: 1.0673423401969757, mse:4.590809449220638, ic :0.1816804033788988, sharpe5:15.660617451667784, irr5:530.34326171875, ndcg5:0.8340280685421946, pnl5:5.392572402954102 
train 41, step: 0, loss: 1.6531839304956897, grad_norm: 0.2632461712972776, ic: 0.41684490969440474
train 41, step: 500, loss: 1.2425992755318664, grad_norm: 0.27328254255567735, ic: 0.2531965322171652
train 41, step: 1000, loss: 1.08314069209208, grad_norm: 0.338501624444111, ic: 0.22554286020453015
train 41, step: 1500, loss: 3.263070164704536, grad_norm: 2.8801413149266057, ic: 0.04058165553696661
train 41, step: 2000, loss: 1.0519764527656015, grad_norm: 0.30808309258084104, ic: 0.17539609482935675
Epoch 41: 2022-04-21 00:48:28.412725: train loss: 1.6207592432624385
Eval step 0: eval loss: 0.8307244930930584
Eval: 2022-04-21 00:48:50.109853: total loss: 1.0663859833290836, mse:4.591691466617004, ic :0.18568926244729703, sharpe5:16.716495677232743, irr5:558.4720458984375, ndcg5:0.8620894753644386, pnl5:8.686502456665039 
train 42, step: 0, loss: 2.0818456657088125, grad_norm: 0.4424327182949037, ic: 0.09723000473462719
train 42, step: 500, loss: 1.4826602801365505, grad_norm: 0.8480318892599481, ic: 0.20636362271576808
train 42, step: 1000, loss: 3.2927371391426905, grad_norm: 5.009545329844803, ic: 0.10193820541184202
train 42, step: 1500, loss: 1.194328049583826, grad_norm: 0.019298021250001206, ic: 0.569307624910053
train 42, step: 2000, loss: 1.1905273437500001, grad_norm: 0.014715295462429376, ic: 0.4615050184937853
Epoch 42: 2022-04-21 00:54:28.869783: train loss: 1.620090150559813
Eval step 0: eval loss: 0.8315522301435722
Eval: 2022-04-21 00:54:50.724319: total loss: 1.0677077577243386, mse:4.5985965446567585, ic :0.18192950386956125, sharpe5:16.526005157232284, irr5:544.3895874023438, ndcg5:0.8469339351209272, pnl5:4.79449987411499 
train 43, step: 0, loss: 0.8361002282251285, grad_norm: 0.22254162524684357, ic: 0.04303967911519186
train 43, step: 500, loss: 0.9400111607142858, grad_norm: 0.1784985083979613, ic: 0.2708611699902674
train 43, step: 1000, loss: 1.6810164463691355, grad_norm: 0.4928115987391769, ic: -0.08865834686713275
train 43, step: 1500, loss: 1.4043733654104078, grad_norm: 0.049130592663306716, ic: 0.10001473219377466
train 43, step: 2000, loss: 1.700072281003937, grad_norm: 0.6652218536217479, ic: -0.08794563428513269
Epoch 43: 2022-04-21 01:00:28.231702: train loss: 1.6205445404600989
Eval step 0: eval loss: 0.8280006143391069
Eval: 2022-04-21 01:00:50.043413: total loss: 1.0657958931145661, mse:4.610664289434477, ic :0.18209313842112404, sharpe5:16.746088017225265, irr5:547.7607421875, ndcg5:0.8447698665545211, pnl5:5.574098110198975 
train 44, step: 0, loss: 1.034784933460076, grad_norm: 0.02837086849866233, ic: 0.05940249800727773
train 44, step: 500, loss: 2.109158668008641, grad_norm: 2.2151657701072462, ic: 0.12409010281744974
train 44, step: 1000, loss: 1.8189470970024497, grad_norm: 0.44062265003230333, ic: 0.1595880138785763
train 44, step: 1500, loss: 1.0288419708861367, grad_norm: 0.0754614458031489, ic: 0.14968262455812625
train 44, step: 2000, loss: 0.9573782113882211, grad_norm: 0.15234855577195533, ic: 0.6914086584163573
Epoch 44: 2022-04-21 01:06:30.643314: train loss: 1.6202707990537304
Eval step 0: eval loss: 0.8265019407764752
Eval: 2022-04-21 01:06:52.046135: total loss: 1.0665395383514344, mse:4.623642613861561, ic :0.17917363086083282, sharpe5:16.93917983293533, irr5:560.3522338867188, ndcg5:0.8462828385399801, pnl5:4.831019401550293 
train 45, step: 0, loss: 1.645668982025376, grad_norm: 0.7240034388360133, ic: 0.0502442741000799
train 45, step: 500, loss: 0.9640219740634006, grad_norm: 0.0848626385370057, ic: 0.4860448760591419
train 45, step: 1000, loss: 1.510943381041997, grad_norm: 0.4429287734818198, ic: 0.9122880836232973
train 45, step: 1500, loss: 1.019856138689442, grad_norm: 0.594163413950622, ic: 0.13957304532798165
train 45, step: 2000, loss: 1.7216913679534314, grad_norm: 0.18386041742930398, ic: 0.4424160490532265
Epoch 45: 2022-04-21 01:12:33.071468: train loss: 1.6199317040592283
Eval step 0: eval loss: 0.8322006563240911
Eval: 2022-04-21 01:12:54.696492: total loss: 1.0721851437517604, mse:4.642492371052833, ic :0.1898560350790477, sharpe5:17.482581993341444, irr5:566.5285034179688, ndcg5:0.8403451999075697, pnl5:4.639895439147949 
train 46, step: 0, loss: 2.1034045690403094, grad_norm: 0.9091429188503997, ic: 0.025987190028394138
train 46, step: 500, loss: 1.9772869791666667, grad_norm: 0.6956554896283322, ic: 0.12736728693831187
train 46, step: 1000, loss: 0.9007014504694614, grad_norm: 0.29537668662058, ic: 0.048181782007255376
train 46, step: 1500, loss: 1.2476877520161291, grad_norm: 0.5131597874285434, ic: 0.9594068480063307
train 46, step: 2000, loss: 2.8840330137218775, grad_norm: 0.7888654178557039, ic: 0.2403895949593719
Epoch 46: 2022-04-21 01:18:38.477236: train loss: 1.62123380320897
Eval step 0: eval loss: 0.8237614686923735
Eval: 2022-04-21 01:19:00.085324: total loss: 1.065265988346296, mse:4.59102479986418, ic :0.1859686778414913, sharpe5:16.605366432666777, irr5:543.3682861328125, ndcg5:0.8383355157903388, pnl5:9.089271545410156 
train 47, step: 0, loss: 1.0786986738235933, grad_norm: 0.03673865674771336, ic: 0.20796443409404367
train 47, step: 500, loss: 1.5222697670269167, grad_norm: 0.4900475317132239, ic: 0.115026960230359
train 47, step: 1000, loss: 2.847474515576588, grad_norm: 2.3774923239633705, ic: 0.522102761069327
train 47, step: 1500, loss: 1.6210064771698742, grad_norm: 0.6551566766758716, ic: -0.05749343572759575
train 47, step: 2000, loss: 1.275592785818641, grad_norm: 0.801029668446399, ic: 0.08742606253661667
Epoch 47: 2022-04-21 01:24:42.233426: train loss: 1.6200110384283721
Eval step 0: eval loss: 0.8255769590934535
Eval: 2022-04-21 01:25:04.047058: total loss: 1.0664140575790964, mse:4.598825871787929, ic :0.18172962555492428, sharpe5:16.86568140506744, irr5:533.4415283203125, ndcg5:0.8534336984718691, pnl5:7.233405590057373 
train 48, step: 0, loss: 1.0914860026041666, grad_norm: 0.33432035898535034, ic: 0.19581338557465547
train 48, step: 500, loss: 1.272455839435905, grad_norm: 0.028627060315533328, ic: 0.176557659200875
train 48, step: 1000, loss: 1.5755851230809326, grad_norm: 0.808306937939079, ic: 0.10555961179138465
train 48, step: 1500, loss: 1.1471876745905993, grad_norm: 0.1077041874356899, ic: 0.5113079480026321
train 48, step: 2000, loss: 2.4140365389430083, grad_norm: 1.5233252577123364, ic: 0.5418249950158474
Epoch 48: 2022-04-21 01:30:47.723203: train loss: 1.6209868795979137
Eval step 0: eval loss: 0.8435425833731229
Eval: 2022-04-21 01:31:09.156728: total loss: 1.0769592189610486, mse:4.624279475245634, ic :0.17847450755924094, sharpe5:16.890143043994904, irr5:559.881591796875, ndcg5:0.8340643882401447, pnl5:4.890486717224121 
train 49, step: 0, loss: 0.9044552209242336, grad_norm: 1.670349732303917, ic: 0.09052866046839289
train 49, step: 500, loss: 1.499496039994266, grad_norm: 0.019473106910863673, ic: 0.05759964394629595
train 49, step: 1000, loss: 1.757994842529297, grad_norm: 0.29724875647661997, ic: 0.12882400228649799
train 49, step: 1500, loss: 1.5969028705693145, grad_norm: 0.15158396185043027, ic: 0.45910163077576494
train 49, step: 2000, loss: 0.9465473763894714, grad_norm: 0.3821725611288723, ic: 0.596732532865851
Epoch 49: 2022-04-21 01:36:46.911990: train loss: 1.6212198680278938
Eval step 0: eval loss: 0.8188409674657534
Eval: 2022-04-21 01:37:08.792567: total loss: 1.066561209572474, mse:4.622079492896324, ic :0.18298939403564118, sharpe5:16.995176743268967, irr5:559.34814453125, ndcg5:0.8511705778918626, pnl5:5.135241508483887 
train 50, step: 0, loss: 1.418722636838207, grad_norm: 1.008500395713219, ic: 0.16538080691994023
train 50, step: 500, loss: 2.8389941792243083, grad_norm: 1.2831368992342649, ic: 0.28334399865707455
train 50, step: 1000, loss: 0.8463476117258738, grad_norm: 0.07649063177585991, ic: 0.18369927262094304
train 50, step: 1500, loss: 1.406052751665945, grad_norm: 0.479575388357297, ic: 0.3841229275091433
train 50, step: 2000, loss: 9.636679626129222, grad_norm: 5.785561932176106, ic: 0.1709556254060415
Epoch 50: 2022-04-21 01:42:47.852749: train loss: 1.620292850356841
Eval step 0: eval loss: 0.8235853735840357
Eval: 2022-04-21 01:43:09.365389: total loss: 1.0686861414786037, mse:4.6329393529097285, ic :0.17695891370847663, sharpe5:16.82303907394409, irr5:552.5720825195312, ndcg5:0.83744785842235, pnl5:5.36616325378418 
train 51, step: 0, loss: 3.3174640583066677, grad_norm: 1.1383815165738835, ic: -0.033660085173477704
train 51, step: 500, loss: 1.4400481597552282, grad_norm: 0.2660464714709108, ic: 0.09342179819615515
train 51, step: 1000, loss: 1.5166991607134015, grad_norm: 0.17238214368620225, ic: 0.9131054177832185
train 51, step: 1500, loss: 1.0182566669022914, grad_norm: 0.07412830063573651, ic: 0.17591320247132763
train 51, step: 2000, loss: 2.3525412911696058, grad_norm: 0.02983559975416674, ic: 0.10879669270349673
Epoch 51: 2022-04-21 01:48:50.916965: train loss: 1.6214540949320653
Eval step 0: eval loss: 0.8219157501317176
Eval: 2022-04-21 01:49:12.468928: total loss: 1.068639329265626, mse:4.64727803325059, ic :0.1770223728143788, sharpe5:16.80471270918846, irr5:545.1007080078125, ndcg5:0.8460129669901486, pnl5:6.064081192016602 
train 52, step: 0, loss: 1.2078836731991525, grad_norm: 0.430505521905234, ic: 0.14129200534154457
train 52, step: 500, loss: 1.6627313945465345, grad_norm: 1.1906376162903267, ic: 0.17359312777159291
train 52, step: 1000, loss: 1.1842555913114454, grad_norm: 0.2902750597529439, ic: 0.5821958618298501
train 52, step: 1500, loss: 1.042202227132099, grad_norm: 0.05146141220614347, ic: -0.07805095302560819
train 52, step: 2000, loss: 1.3810664121865501, grad_norm: 0.49361477629463113, ic: 0.14405905697789012
Epoch 52: 2022-04-21 01:54:52.371405: train loss: 1.6211169068845328
Eval step 0: eval loss: 0.8233191085188356
Eval: 2022-04-21 01:55:13.668036: total loss: 1.0653963480023376, mse:4.598664031513803, ic :0.18396231480262798, sharpe5:16.67551439166069, irr5:541.34912109375, ndcg5:0.8593906298457193, pnl5:4.36807107925415 
train 53, step: 0, loss: 3.0763879067478275, grad_norm: 3.411425187914168, ic: 0.038478556585761346
train 53, step: 500, loss: 1.0647960544861468, grad_norm: 0.04788632768903007, ic: 0.491968751565211
train 53, step: 1000, loss: 1.2382396506197626, grad_norm: 0.024490192654132797, ic: 0.18384453956201535
train 53, step: 1500, loss: 1.3277936108165431, grad_norm: 0.35987955458804355, ic: 0.12172685412621123
train 53, step: 2000, loss: 3.2082279424419746, grad_norm: 1.9915442481307608, ic: 0.18241828779338817
Epoch 53: 2022-04-21 02:00:55.478517: train loss: 1.6201252497687895
Eval step 0: eval loss: 0.8235162347084101
Eval: 2022-04-21 02:01:16.944674: total loss: 1.0688891232158988, mse:4.662830039915652, ic :0.17273265054491754, sharpe5:17.452893168926238, irr5:576.9678955078125, ndcg5:0.854160763780903, pnl5:6.105648040771484 
train 54, step: 0, loss: 2.062421719990079, grad_norm: 0.954744903499053, ic: 0.0366590647646308
train 54, step: 500, loss: 0.8685485659799042, grad_norm: 0.042752838824554024, ic: 0.5356673127652951
train 54, step: 1000, loss: 2.3115432894351056, grad_norm: 0.1418160196349647, ic: 0.09538865102264286
train 54, step: 1500, loss: 1.891872745222309, grad_norm: 1.1287709053914659, ic: 0.18660644451320516
train 54, step: 2000, loss: 2.1764533314278456, grad_norm: 0.7287814609075906, ic: 0.05061527678731027
Epoch 54: 2022-04-21 02:06:53.147695: train loss: 1.6215919169040909
Eval step 0: eval loss: 0.8260896801320469
Eval: 2022-04-21 02:07:14.672516: total loss: 1.0674485603244608, mse:4.611186835237923, ic :0.18095912819602755, sharpe5:17.340023421049118, irr5:551.748291015625, ndcg5:0.8434602633802893, pnl5:5.862023830413818 
train 55, step: 0, loss: 1.7935777601304945, grad_norm: 0.5895986755098556, ic: 0.10555108232867608
train 55, step: 500, loss: 0.8957300610316535, grad_norm: 0.0463046604146643, ic: 0.26913795374188837
train 55, step: 1000, loss: 1.0389118728763385, grad_norm: 0.5486004828710169, ic: 0.08765770988137074
train 55, step: 1500, loss: 1.07797497217252, grad_norm: 0.3353089328143718, ic: 0.577526678373408
train 55, step: 2000, loss: 2.2494805001555322, grad_norm: 0.7122100745560855, ic: 0.027172661520818008
Epoch 55: 2022-04-21 02:12:49.825914: train loss: 1.6188757017036404
Eval step 0: eval loss: 0.830769256495324
Eval: 2022-04-21 02:13:11.275016: total loss: 1.0694901085077937, mse:4.60483221928728, ic :0.18202542649220946, sharpe5:16.615928639173507, irr5:539.3628540039062, ndcg5:0.8411441255693635, pnl5:5.623063564300537 
train 56, step: 0, loss: 1.0068892372112632, grad_norm: 0.008702775943322427, ic: 0.11027830814037579
train 56, step: 500, loss: 0.8975806375151699, grad_norm: 0.09396451740760711, ic: 0.02968127624604511
train 56, step: 1000, loss: 4.686652768140365, grad_norm: 0.6223562930817086, ic: 0.02938469121457302
train 56, step: 1500, loss: 1.1690106035941346, grad_norm: 0.03516490930683937, ic: 0.05604406520981421
train 56, step: 2000, loss: 0.9764783449736947, grad_norm: 0.18769552340198298, ic: 0.4352328653002645
Epoch 56: 2022-04-21 02:18:47.371374: train loss: 1.6194990462884424
Eval step 0: eval loss: 0.8285674888040041
Eval: 2022-04-21 02:19:09.175183: total loss: 1.0675974533339343, mse:4.597100667798052, ic :0.1811870693544806, sharpe5:16.717333767414093, irr5:550.8136596679688, ndcg5:0.8445036902710396, pnl5:4.887845516204834 
train 57, step: 0, loss: 1.0244127069559101, grad_norm: 0.030850035309702848, ic: 0.1220921893293588
train 57, step: 500, loss: 0.8770502390696441, grad_norm: 0.1999122443681804, ic: 0.5831200284554421
train 57, step: 1000, loss: 2.2501987821521094, grad_norm: 1.4800139986951037, ic: 0.12088647137674421
train 57, step: 1500, loss: 1.123681011599235, grad_norm: 0.20477297145439693, ic: 0.14133535294679248
train 57, step: 2000, loss: 1.1098563341590446, grad_norm: 3.2475225509974788, ic: 0.5882155527813835
Epoch 57: 2022-04-21 02:24:43.772623: train loss: 1.6204734791436506
Eval step 0: eval loss: 0.8299212601463711
Eval: 2022-04-21 02:25:05.643901: total loss: 1.0688608748686117, mse:4.648841391681836, ic :0.17345019527073632, sharpe5:16.614163541793822, irr5:549.2631225585938, ndcg5:0.8635363516559091, pnl5:4.944565296173096 
train 58, step: 0, loss: 1.4816914605459572, grad_norm: 0.554340904508694, ic: 0.1698704403213261
train 58, step: 500, loss: 1.5152158994932434, grad_norm: 1.0554822484864501, ic: 0.08922509228397221
train 58, step: 1000, loss: 1.5316594587053571, grad_norm: 0.7557714961810932, ic: 0.07859469418152493
train 58, step: 1500, loss: 2.2640440294358615, grad_norm: 0.6359691259363631, ic: 0.43029464728964284
train 58, step: 2000, loss: 0.9856306056671807, grad_norm: 0.2968682743122253, ic: 0.2530163017171112
Epoch 58: 2022-04-21 02:30:47.690770: train loss: 1.6199563751563426
Eval step 0: eval loss: 0.8299132207422286
Eval: 2022-04-21 02:31:09.248675: total loss: 1.06924417328325, mse:4.614387405761848, ic :0.1743883342361888, sharpe5:16.367392333745954, irr5:531.62060546875, ndcg5:0.8485340147898677, pnl5:4.555922031402588 
train 59, step: 0, loss: 1.1741895726735845, grad_norm: 0.22109172780399372, ic: 0.08460161234484112
train 59, step: 500, loss: 0.7259208086742275, grad_norm: 0.2587768159720395, ic: 0.05964226452304553
train 59, step: 1000, loss: 5.116893294116191, grad_norm: 2.207119989867049, ic: -0.10697227626804098
train 59, step: 1500, loss: 1.3601303952352473, grad_norm: 0.6845125396636386, ic: 0.1652717799241002
train 59, step: 2000, loss: 0.9900737448299631, grad_norm: 0.047768131529045466, ic: 0.04559154248888356
Epoch 59: 2022-04-21 02:36:53.212827: train loss: 1.6210249716780645
Eval step 0: eval loss: 0.8272016261978068
Eval: 2022-04-21 02:37:14.917200: total loss: 1.0695666397159551, mse:4.641180161421953, ic :0.172982397219546, sharpe5:16.44380799651146, irr5:526.5568237304688, ndcg5:0.841803226683354, pnl5:9.600543975830078 

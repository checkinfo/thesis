Namespace(adj_path='./data/concepts_graph_1931_233_3.npy', ann_embed_dim=128, ann_embed_num=89, ann_path=None, batch_size=1, dataset_type='AdjTimeDataset', dout=0.3, epochs=40, gnn_layers=2, gpu=0, hidden_dim=128, input_dim=9, input_graph=True, label_cnt=3, lr=0.001, lstm_layers=3, mask_adj=True, mask_type='soft', model_type='RGCNModel', normalize_adj=True, num_days=1, num_heads=1, print_inteval=500, relation_num=1, seed=10086, shuffle=True, side_info=False, sparse_adj_path=None, stock_num=1931, test_mask_path='./data/test_mask_126_1931.npy', test_path='./data/test_126_1931_12.npy', top_stocks=5, train_mask_path='./data/train_mask_2305_1931.npy', train_path='./data/train_2305_1931_12.npy', use_adj=True)
53027
RGCNModel(
  (fc1): Linear(in_features=9, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
  (fc4): Linear(in_features=128, out_features=1, bias=True)
  (gnns): ModuleList(
    (0): RGCN(
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
    )
    (1): RGCN(
      (lin_rel): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin_root): ModuleList(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
    )
  )
  (dropout): Dropout(p=0.3, inplace=False)
  (relu): LeakyReLU(negative_slope=0.01)
)
train 0, step: 0, loss: 2.0732035881916997, grad_norm: 0.45617140332188777, ic: 0.03285746552009276
train 0, step: 500, loss: 1.3626873719140922, grad_norm: 0.8691883202202608, ic: -0.0587585029817564
train 0, step: 1000, loss: 1.5060713497979747, grad_norm: 0.03259284975223008, ic: 0.2123543538530976
train 0, step: 1500, loss: 1.180090960679285, grad_norm: 0.09326336274234057, ic: 0.026371186728691508
train 0, step: 2000, loss: 1.5641766059689406, grad_norm: 0.05399119751530594, ic: 0.08536544047092247
Epoch 0: 2022-04-04 14:47:38.384851: train loss: 1.6471470912371733
Eval step 0: eval loss: 1.011356588788507
Eval: 2022-04-04 14:47:40.736539: total loss: 1.0919758242449957, mse:4.888100651803991, ic :0.023335837644441335, sharpe5:1.601756937727332, irr5:17.004322052001953, ndcg5:0.8549383876750916, pnl5:1.2413986921310425 
train 1, step: 0, loss: 0.63620659856513, grad_norm: 0.04834164455477925, ic: 0.06508398683690583
train 1, step: 500, loss: 1.2578627680965149, grad_norm: 0.31216069551513903, ic: 0.23295200175108305
train 1, step: 1000, loss: 0.8767079035089236, grad_norm: 0.06267276647922858, ic: 0.0671123261914444
train 1, step: 1500, loss: 1.860568907202744, grad_norm: 0.565199014584406, ic: 0.07599801425772773
train 1, step: 2000, loss: 1.3753215328292496, grad_norm: 0.23758799729823693, ic: 0.15534723935266495
Epoch 1: 2022-04-04 14:48:08.389045: train loss: 1.6456070543561792
Eval step 0: eval loss: 1.0049710065330437
Eval: 2022-04-04 14:48:10.807754: total loss: 1.0888873875516096, mse:4.878899896747224, ic :0.050035788786207396, sharpe5:2.023889411687851, irr5:22.09735870361328, ndcg5:0.8419460621610502, pnl5:1.279313325881958 
train 2, step: 0, loss: 1.326835186853289, grad_norm: 0.5089500853805051, ic: 0.08487568667769374
train 2, step: 500, loss: 0.9551122083649469, grad_norm: 0.2786407563755844, ic: 0.08373987515681836
train 2, step: 1000, loss: 3.052658927842764, grad_norm: 1.166933755860788, ic: 0.1271459413022112
train 2, step: 1500, loss: 2.3161855360329104, grad_norm: 0.9434452377511259, ic: 0.09614582015952607
train 2, step: 2000, loss: 1.4586723620835038, grad_norm: 0.2769082628127225, ic: -0.10590521494329248
Epoch 2: 2022-04-04 14:48:38.557972: train loss: 1.6448262203644628
Eval step 0: eval loss: 0.997806784101007
Eval: 2022-04-04 14:48:40.921635: total loss: 1.0892845024808409, mse:4.881781508900372, ic :0.048795547352607264, sharpe5:3.2266176380217075, irr5:31.845359802246094, ndcg5:0.8495138320119119, pnl5:1.3033870458602905 
train 3, step: 0, loss: 1.8283581197398622, grad_norm: 0.06217924185336982, ic: -0.12742437666345205
train 3, step: 500, loss: 0.7807460849066139, grad_norm: 0.022064924132178376, ic: 0.08119974530302738
train 3, step: 1000, loss: 1.4054048906904013, grad_norm: 0.3796244731108096, ic: 0.2210325630086828
train 3, step: 1500, loss: 2.62819138812355, grad_norm: 0.41560775346637874, ic: -0.06685612317278959
train 3, step: 2000, loss: 1.3559212424538352, grad_norm: 0.16469254478898915, ic: 0.07437368141653379
Epoch 3: 2022-04-04 14:49:08.831761: train loss: 1.6450056623019522
Eval step 0: eval loss: 1.0027635201709781
Eval: 2022-04-04 14:49:11.174763: total loss: 1.0903856052636214, mse:4.878650976242424, ic :0.051788653665689084, sharpe5:2.486601034551859, irr5:26.202978134155273, ndcg5:0.8464061876451691, pnl5:1.2029935121536255 
train 4, step: 0, loss: 1.1625439601764649, grad_norm: 0.14948157019770475, ic: 0.08631114163324902
train 4, step: 500, loss: 0.9879380640750619, grad_norm: 0.008975323531051906, ic: 0.17384713224999943
train 4, step: 1000, loss: 1.3318634615155416, grad_norm: 0.06335994450120669, ic: 0.0764618889185815
train 4, step: 1500, loss: 1.0798803084935897, grad_norm: 0.1063873850679396, ic: 0.1778489761555938
train 4, step: 2000, loss: 4.174605302788159, grad_norm: 0.9480699611282284, ic: -0.008663758424393282
Epoch 4: 2022-04-04 14:49:38.947977: train loss: 1.6445473473895396
Eval step 0: eval loss: 1.006979092100283
Eval: 2022-04-04 14:49:41.258840: total loss: 1.0943558723323756, mse:4.888062501723325, ic :0.04729210595432837, sharpe5:3.250868808478117, irr5:32.385841369628906, ndcg5:0.8441659405040413, pnl5:1.201298475265503 
train 5, step: 0, loss: 1.0079000782440024, grad_norm: 0.254625253211172, ic: -0.11096710564864254
train 5, step: 500, loss: 0.7877559812524684, grad_norm: 0.018132121172408634, ic: 0.15286169796693522
train 5, step: 1000, loss: 1.117539099608138, grad_norm: 0.03879040775338436, ic: -0.12904318484599858
train 5, step: 1500, loss: 1.7935816819105692, grad_norm: 0.5210509425880302, ic: -0.04848686470259801
train 5, step: 2000, loss: 2.179674534486192, grad_norm: 0.8341296551429014, ic: 0.03714662421348572
Epoch 5: 2022-04-04 14:50:09.542792: train loss: 1.6443736995880738
Eval step 0: eval loss: 1.0019499752131056
Eval: 2022-04-04 14:50:11.943337: total loss: 1.0894713187946403, mse:4.879737407065592, ic :0.04689796350452048, sharpe5:5.762099856734276, irr5:127.14703369140625, ndcg5:0.8699981426434839, pnl5:2.358290195465088 
train 6, step: 0, loss: 0.78181439764609, grad_norm: 0.011837338648373075, ic: -0.08532837046856885
train 6, step: 500, loss: 1.4215177123309575, grad_norm: 0.25642123172372405, ic: 0.05230169675074491
train 6, step: 1000, loss: 1.2271028947940836, grad_norm: 0.1878440934815286, ic: 0.19206683413505016
train 6, step: 1500, loss: 1.0732302107900944, grad_norm: 0.3168505410397007, ic: 0.0506670349613665
train 6, step: 2000, loss: 2.2844977495908347, grad_norm: 0.9868314683933289, ic: 0.12313333924938649
Epoch 6: 2022-04-04 14:50:39.646451: train loss: 1.6451805194270572
Eval step 0: eval loss: 0.9991263519656727
Eval: 2022-04-04 14:50:41.992262: total loss: 1.088796882608945, mse:4.8700210139347115, ic :0.06597903616472015, sharpe5:8.145949947237968, irr5:238.3819580078125, ndcg5:0.8487659410313869, pnl5:2.7933995723724365 
train 7, step: 0, loss: 1.4525840294223642, grad_norm: 0.527006940958878, ic: 0.20754722124433764
train 7, step: 500, loss: 1.3206388206388207, grad_norm: 0.023971647120486796, ic: 0.18450382977342988
train 7, step: 1000, loss: 0.6422077120593923, grad_norm: 0.01501114545752669, ic: 0.28395198245541475
train 7, step: 1500, loss: 1.0051355720572717, grad_norm: 0.13034535849718853, ic: 0.09312883758552859
train 7, step: 2000, loss: 1.581726751312401, grad_norm: 0.5613755679237646, ic: 0.4241201696432253
Epoch 7: 2022-04-04 14:51:10.526099: train loss: 1.6414210519913923
Eval step 0: eval loss: 0.9980179483856634
Eval: 2022-04-04 14:51:12.882261: total loss: 1.0845468795650597, mse:4.717725851302095, ic :0.12138697490299416, sharpe5:9.206183214783668, irr5:266.9190979003906, ndcg5:0.8370345598131254, pnl5:3.059683322906494 
train 8, step: 0, loss: 1.20314505578594, grad_norm: 0.08199885883116764, ic: 0.048342654656660114
train 8, step: 500, loss: 5.379266338288597, grad_norm: 4.826163211250121, ic: 0.02853311655741065
train 8, step: 1000, loss: 1.8907511936616261, grad_norm: 0.5876616805481707, ic: 0.12384573596393358
train 8, step: 1500, loss: 1.0820868328842277, grad_norm: 0.3541138365200618, ic: 0.6402127240343679
train 8, step: 2000, loss: 1.1359065129206731, grad_norm: 0.5171992299053532, ic: 0.016362877499983497
Epoch 8: 2022-04-04 14:51:41.052636: train loss: 1.6368562316662287
Eval step 0: eval loss: 1.0031063326915481
Eval: 2022-04-04 14:51:43.393143: total loss: 1.0871915044782987, mse:4.70989043340171, ic :0.13324209314890154, sharpe5:12.175134708881378, irr5:365.849365234375, ndcg5:0.8497570176325496, pnl5:6.175510883331299 
train 9, step: 0, loss: 1.1131544813290717, grad_norm: 0.037239043225116904, ic: 0.4569982677177977
train 9, step: 500, loss: 3.0991690300371, grad_norm: 1.06388562863343, ic: 0.17392806685162582
train 9, step: 1000, loss: 0.8665372867927761, grad_norm: 0.0925712254113203, ic: 0.2169565738831135
train 9, step: 1500, loss: 2.184629665974473, grad_norm: 1.2174284238806592, ic: -0.016054694467246007
train 9, step: 2000, loss: 0.6063859100701957, grad_norm: 0.01862631454002972, ic: 0.06108068959020049
Epoch 9: 2022-04-04 14:52:11.464890: train loss: 1.6325940122512286
Eval step 0: eval loss: 0.9964372696155871
Eval: 2022-04-04 14:52:13.816144: total loss: 1.0862479246751324, mse:4.7499506809868866, ic :0.12273446107178237, sharpe5:9.566511858701706, irr5:280.9813537597656, ndcg5:0.839360972102888, pnl5:3.496830940246582 
train 10, step: 0, loss: 1.2908848865873597, grad_norm: 0.06669368570629446, ic: 0.39719780552379175
train 10, step: 500, loss: 0.8994544132628886, grad_norm: 0.006521237268294781, ic: 0.10257571903226058
train 10, step: 1000, loss: 1.520861521648626, grad_norm: 0.5439215021584572, ic: 0.05198517498904412
train 10, step: 1500, loss: 3.0452672446646343, grad_norm: 1.0792921204775492, ic: 0.10818829448011802
train 10, step: 2000, loss: 1.3743004146680282, grad_norm: 0.1703876976983686, ic: 0.1828269345204798
Epoch 10: 2022-04-04 14:52:41.223737: train loss: 1.63329966876994
Eval step 0: eval loss: 1.0090978701783833
Eval: 2022-04-04 14:52:43.653458: total loss: 1.0845992450044357, mse:4.692601489188012, ic :0.1516227754710448, sharpe5:14.29909265577793, irr5:446.2166442871094, ndcg5:0.8499477805031075, pnl5:5.16499137878418 
train 11, step: 0, loss: 4.740703186082877, grad_norm: 1.197268564951405, ic: 0.4017187541316638
train 11, step: 500, loss: 0.9900954286074308, grad_norm: 0.0602395693491644, ic: 0.03732174981187088
train 11, step: 1000, loss: 1.0384035437821797, grad_norm: 0.3570081412011735, ic: 0.06355492243582962
train 11, step: 1500, loss: 0.6927711528637677, grad_norm: 0.004037630485302553, ic: 0.07898388949342729
train 11, step: 2000, loss: 1.1271034569201868, grad_norm: 0.05422814934143179, ic: -0.17879679676433047
Epoch 11: 2022-04-04 14:53:12.394611: train loss: 1.6297631726243658
Eval step 0: eval loss: 1.0024079799401
Eval: 2022-04-04 14:53:14.716867: total loss: 1.082334637474145, mse:4.699331337843705, ic :0.1534412454963172, sharpe5:15.225981613397597, irr5:491.21820068359375, ndcg5:0.8430475658757665, pnl5:5.714314937591553 
train 12, step: 0, loss: 1.3784138842680607, grad_norm: 0.29332136714362805, ic: 0.17335736455745532
train 12, step: 500, loss: 0.8221583919630525, grad_norm: 0.4653962510545865, ic: 0.009035284556477171
train 12, step: 1000, loss: 1.1795949004885389, grad_norm: 0.3302935377496392, ic: 0.6172321302931245
train 12, step: 1500, loss: 1.0827842035789372, grad_norm: 0.18260265925663122, ic: -0.06989351621991982
train 12, step: 2000, loss: 1.112124418432659, grad_norm: 0.07339047091934052, ic: 0.11318405849353079
Epoch 12: 2022-04-04 14:53:42.711236: train loss: 1.631019777793649
Eval step 0: eval loss: 1.0016270899157451
Eval: 2022-04-04 14:53:44.981749: total loss: 1.0846224711834624, mse:4.702703873085285, ic :0.14788773507597425, sharpe5:13.931630786061286, irr5:430.2239074707031, ndcg5:0.8578805163695439, pnl5:6.8969621658325195 
train 13, step: 0, loss: 1.074884524735455, grad_norm: 0.040793999869251654, ic: 0.43838053616070677
train 13, step: 500, loss: 1.1496142205391222, grad_norm: 0.013804550302342303, ic: -0.1703184591996526
train 13, step: 1000, loss: 1.3745742425685976, grad_norm: 0.6365914366668892, ic: 0.182301789629911
train 13, step: 1500, loss: 0.7757266435086092, grad_norm: 0.008285340544852679, ic: -0.01371951131480683
train 13, step: 2000, loss: 1.03858640703005, grad_norm: 0.02694147766673389, ic: 0.051985850530846055
Epoch 13: 2022-04-04 14:54:12.531912: train loss: 1.6293258513828528
Eval step 0: eval loss: 0.9943063423594655
Eval: 2022-04-04 14:54:14.884176: total loss: 1.0822147337067365, mse:4.7123395921170985, ic :0.15108894282697669, sharpe5:14.403135970830917, irr5:482.17828369140625, ndcg5:0.8545048850461948, pnl5:5.2546491622924805 
train 14, step: 0, loss: 1.756169981875662, grad_norm: 0.6090013958422538, ic: 0.19796870341538383
train 14, step: 500, loss: 1.272509012215283, grad_norm: 0.1985057037493495, ic: 0.24201218711472067
train 14, step: 1000, loss: 1.0623385847107438, grad_norm: 0.1333896355045383, ic: 0.15396676157089093
train 14, step: 1500, loss: 0.9791723050182832, grad_norm: 0.0947430748327973, ic: 0.19702639475870654
train 14, step: 2000, loss: 2.2992799643785684, grad_norm: 0.49840706645496324, ic: -0.06564009495286147
Epoch 14: 2022-04-04 14:54:42.836073: train loss: 1.6288048263702706
Eval step 0: eval loss: 1.0053705794990784
Eval: 2022-04-04 14:54:45.154565: total loss: 1.0888829873758488, mse:4.724068845811895, ic :0.12144546359542768, sharpe5:7.670603831112384, irr5:217.2425079345703, ndcg5:0.8422707685209285, pnl5:3.173321485519409 
train 15, step: 0, loss: 0.9856485060853951, grad_norm: 0.17031755695688905, ic: 0.15441098338858522
train 15, step: 500, loss: 1.2244534532563025, grad_norm: 0.0066754241429056406, ic: 0.059779859461385705
train 15, step: 1000, loss: 1.7666455729166668, grad_norm: 0.06546703767515492, ic: -0.10599350004447593
train 15, step: 1500, loss: 5.4158921385585845, grad_norm: 0.8456031877318262, ic: 0.017483444240125982
train 15, step: 2000, loss: 0.9298887875917081, grad_norm: 0.01614318720617494, ic: 0.00464195278110556
Epoch 15: 2022-04-04 14:55:12.920018: train loss: 1.6351897484661588
Eval step 0: eval loss: 1.007749311418016
Eval: 2022-04-04 14:55:15.275807: total loss: 1.0837714175991005, mse:4.677423646545412, ic :0.1682902595336493, sharpe5:15.377349591851234, irr5:520.2811889648438, ndcg5:0.8423297235206773, pnl5:5.978930950164795 
train 16, step: 0, loss: 6.356421965169003, grad_norm: 2.7258625702844705, ic: 0.17232533836490038
train 16, step: 500, loss: 1.3587853810143848, grad_norm: 0.7198945594727336, ic: -0.012987023850790352
train 16, step: 1000, loss: 0.8374708054240532, grad_norm: 0.21048134511948305, ic: -0.00824434651001157
train 16, step: 1500, loss: 1.2307963878395178, grad_norm: 0.31889720624243084, ic: 0.11195940418384293
train 16, step: 2000, loss: 0.9606447690010651, grad_norm: 0.4659033377498539, ic: 0.5497671447264576
Epoch 16: 2022-04-04 14:55:42.668991: train loss: 1.626272308526373
Eval step 0: eval loss: 0.997902756179239
Eval: 2022-04-04 14:55:45.101048: total loss: 1.0816055557836115, mse:4.711647514817791, ic :0.15969480733020214, sharpe5:15.187951616048812, irr5:501.0091857910156, ndcg5:0.8417453772377698, pnl5:5.455719947814941 
train 17, step: 0, loss: 1.1846841449386503, grad_norm: 0.009367558190304513, ic: 0.114672214714495
train 17, step: 500, loss: 1.0440157070439948, grad_norm: 0.03208708743020759, ic: -0.022075641695015295
train 17, step: 1000, loss: 3.4099580368193068, grad_norm: 2.631690286987448, ic: -0.011862543035181944
train 17, step: 1500, loss: 0.8846953061792071, grad_norm: 0.23149184225145708, ic: 0.09368182714330432
train 17, step: 2000, loss: 1.0064680061084312, grad_norm: 0.6820917377901664, ic: 0.5781816063209826
Epoch 17: 2022-04-04 14:56:12.939915: train loss: 1.627003375742076
Eval step 0: eval loss: 1.006719202540811
Eval: 2022-04-04 14:56:15.290944: total loss: 1.085204045407637, mse:4.713931135635388, ic :0.15731580575400808, sharpe5:15.20084742128849, irr5:506.45855712890625, ndcg5:0.8572830671537448, pnl5:6.418166637420654 
train 18, step: 0, loss: 0.8483277835555333, grad_norm: 0.016919108124416153, ic: 0.052826136352150735
train 18, step: 500, loss: 2.5061261843929743, grad_norm: 1.05991104631574, ic: 0.07881808821264721
train 18, step: 1000, loss: 1.3602908786252248, grad_norm: 0.4361451103525366, ic: 0.5354588472942344
train 18, step: 1500, loss: 1.6772124370360553, grad_norm: 2.0141756615167146, ic: 0.32898210893063123
train 18, step: 2000, loss: 1.2491007275418833, grad_norm: 0.4105892743979417, ic: 0.22143507953491798
Epoch 18: 2022-04-04 14:56:43.016299: train loss: 1.6277061215743927
Eval step 0: eval loss: 0.9961517960727685
Eval: 2022-04-04 14:56:45.367225: total loss: 1.084430198510832, mse:4.717400247122665, ic :0.13508357155865314, sharpe5:10.830896705389023, irr5:328.6297607421875, ndcg5:0.8496156880271092, pnl5:4.298837661743164 
train 19, step: 0, loss: 2.2755154038351186, grad_norm: 0.9597061238368332, ic: 0.19127639177847874
train 19, step: 500, loss: 1.0197646030159884, grad_norm: 0.06583680887632919, ic: 0.06766603169167244
train 19, step: 1000, loss: 0.9824070688447594, grad_norm: 0.5528295505810803, ic: 0.5587238924891994
train 19, step: 1500, loss: 1.575799259138696, grad_norm: 0.13838150461993484, ic: 0.15718148873440202
train 19, step: 2000, loss: 1.7422075146220033, grad_norm: 1.7590679109142808, ic: 0.6358059330081415
Epoch 19: 2022-04-04 14:57:12.870627: train loss: 1.6259712715407426
Eval step 0: eval loss: 0.9990964611308583
Eval: 2022-04-04 14:57:15.204025: total loss: 1.0813923930079001, mse:4.69727426666077, ic :0.15813552207670484, sharpe5:15.182069849967956, irr5:494.6995544433594, ndcg5:0.8573544678943739, pnl5:5.7295074462890625 
train 20, step: 0, loss: 1.2448688611722647, grad_norm: 0.3646741063803706, ic: 0.462038777417142
train 20, step: 500, loss: 1.2092802990676887, grad_norm: 0.4523169289273748, ic: 0.022618416810349564
train 20, step: 1000, loss: 1.5697939758139228, grad_norm: 0.5651577479336991, ic: 0.18551267654115405
train 20, step: 1500, loss: 0.903232503557737, grad_norm: 1.020029795047457, ic: 0.5648018477484206
train 20, step: 2000, loss: 1.3663611323388236, grad_norm: 0.19472633851937016, ic: -0.044295647240258224
Epoch 20: 2022-04-04 14:57:42.631424: train loss: 1.6251423294412946
Eval step 0: eval loss: 1.0007810828684505
Eval: 2022-04-04 14:57:44.971642: total loss: 1.0813543721621446, mse:4.700842540609759, ic :0.16091093492085753, sharpe5:14.872911057472228, irr5:465.2409362792969, ndcg5:0.8356546012455207, pnl5:4.883431911468506 
train 21, step: 0, loss: 1.396128627232143, grad_norm: 0.37149366805479206, ic: 0.2856426141578553
train 21, step: 500, loss: 1.1067327894868975, grad_norm: 0.13565419855248861, ic: 0.04998006450107136
train 21, step: 1000, loss: 0.9037588428255957, grad_norm: 0.18152175299644316, ic: 0.1058102437157296
train 21, step: 1500, loss: 0.7324429756076976, grad_norm: 0.16495252797302373, ic: 0.6314504141605632
train 21, step: 2000, loss: 1.1253046380265692, grad_norm: 0.17290852656780922, ic: 0.29550396655709876
Epoch 21: 2022-04-04 14:58:12.963352: train loss: 1.6250189973525446
Eval step 0: eval loss: 1.0045889180983412
Eval: 2022-04-04 14:58:15.311346: total loss: 1.0820922937080195, mse:4.701416138124284, ic :0.15167421820132684, sharpe5:12.80398139297962, irr5:398.8408203125, ndcg5:0.8508261207579977, pnl5:4.974581241607666 
train 22, step: 0, loss: 1.0436450430817925, grad_norm: 0.4995428882439712, ic: 0.06469517569547714
train 22, step: 500, loss: 1.029121458999754, grad_norm: 0.0014187715876742889, ic: -0.034223161680881686
train 22, step: 1000, loss: 0.9113020484649962, grad_norm: 0.046351757275555246, ic: 0.13126386567895265
train 22, step: 1500, loss: 1.000129105517426, grad_norm: 0.05596312801574417, ic: 0.2693690279863651
train 22, step: 2000, loss: 1.0449779421784158, grad_norm: 0.17849280647433896, ic: 0.13347357789828518
Epoch 22: 2022-04-04 14:58:43.929238: train loss: 1.6246196200251264
Eval step 0: eval loss: 1.0097377268875065
Eval: 2022-04-04 14:58:46.247674: total loss: 1.0816105951022872, mse:4.68126622763326, ic :0.16349634499975071, sharpe5:14.311716980338096, irr5:454.0506286621094, ndcg5:0.8572899309029074, pnl5:5.229385852813721 
train 23, step: 0, loss: 1.2856612033334969, grad_norm: 1.394756756976039, ic: 0.01247686260619637
train 23, step: 500, loss: 0.9056678185096154, grad_norm: 0.16285650241729843, ic: 0.5990402481577782
train 23, step: 1000, loss: 2.271810347229101, grad_norm: 1.1387063645848179, ic: 0.0952007735817342
train 23, step: 1500, loss: 0.7781346572597095, grad_norm: 0.468326547406366, ic: 0.715080745559182
train 23, step: 2000, loss: 1.4650229802207342, grad_norm: 0.43302046185331916, ic: 0.39728813818264397
Epoch 23: 2022-04-04 14:59:13.897671: train loss: 1.6238028181171944
Eval step 0: eval loss: 1.0085707629838072
Eval: 2022-04-04 14:59:16.237474: total loss: 1.088045459168624, mse:4.7059076785563825, ic :0.14439755481101718, sharpe5:13.14906455218792, irr5:400.7586364746094, ndcg5:0.8513760290411184, pnl5:5.35318660736084 
train 24, step: 0, loss: 1.1870650828210383, grad_norm: 0.21069666128603787, ic: 0.3082106881444774
train 24, step: 500, loss: 1.250134547369613, grad_norm: 0.4293708817004871, ic: 0.02293297335883704
train 24, step: 1000, loss: 1.0289804412097465, grad_norm: 0.4549043811279676, ic: 0.10443503369752144
train 24, step: 1500, loss: 1.205626768577756, grad_norm: 0.08188680773181685, ic: 0.04997036960018488
train 24, step: 2000, loss: 1.395284113349131, grad_norm: 0.547793050409433, ic: 0.43920915911206526
Epoch 24: 2022-04-04 14:59:43.918546: train loss: 1.6273202119062327
Eval step 0: eval loss: 1.006248341540778
Eval: 2022-04-04 14:59:46.211543: total loss: 1.0866416815834272, mse:4.722895396943895, ic :0.12602096457336293, sharpe5:9.976016342639923, irr5:290.1297607421875, ndcg5:0.8390813580988007, pnl5:3.5943806171417236 
train 25, step: 0, loss: 1.342764529290194, grad_norm: 0.4624904210379603, ic: 0.20294114632173607
train 25, step: 500, loss: 1.4969477467722707, grad_norm: 0.32286871030304, ic: 0.11556179478445809
train 25, step: 1000, loss: 1.3638102447527314, grad_norm: 0.2521576159291606, ic: 0.27128996655769194
train 25, step: 1500, loss: 2.872590862155047, grad_norm: 1.3150079427267787, ic: 0.23716699948510403
train 25, step: 2000, loss: 1.2007030052474783, grad_norm: 0.1943308502202689, ic: 0.1395329730703324
Epoch 25: 2022-04-04 15:00:14.456925: train loss: 1.6266306965008757
Eval step 0: eval loss: 1.0046147592071484
Eval: 2022-04-04 15:00:16.731476: total loss: 1.08041187185917, mse:4.684392113156598, ic :0.16722301746602264, sharpe5:15.190053462982178, irr5:491.3610534667969, ndcg5:0.8563386606505923, pnl5:5.741873741149902 
train 26, step: 0, loss: 1.608290305397727, grad_norm: 0.29267304273676575, ic: 0.21380860265944526
train 26, step: 500, loss: 1.0170703847190838, grad_norm: 0.24621467261876523, ic: -0.04032119288392234
train 26, step: 1000, loss: 1.8126061127445878, grad_norm: 0.8915937644481344, ic: 0.19541782237190386
train 26, step: 1500, loss: 0.9255345286072939, grad_norm: 0.014820739218073406, ic: -0.06888496219748882
train 26, step: 2000, loss: 0.9925492894931103, grad_norm: 0.17883848585108822, ic: 0.150522062655305
Epoch 26: 2022-04-04 15:00:44.741162: train loss: 1.624894215550041
Eval step 0: eval loss: 0.9962149846547524
Eval: 2022-04-04 15:00:47.086035: total loss: 1.0822544051179697, mse:4.696757321622621, ic :0.15991044434524807, sharpe5:15.137200809717177, irr5:470.5251770019531, ndcg5:0.831785809893056, pnl5:5.2475080490112305 
train 27, step: 0, loss: 1.6222922083843185, grad_norm: 0.33764419789881195, ic: 0.6486776089255487
train 27, step: 500, loss: 1.5158828094624806, grad_norm: 0.6488760206764211, ic: 0.0725664070334808
train 27, step: 1000, loss: 2.5637235485868297, grad_norm: 0.7567708087513939, ic: 0.40179278950564773
train 27, step: 1500, loss: 0.8787220856284698, grad_norm: 0.8624415002636986, ic: 0.5468764253412118
train 27, step: 2000, loss: 1.343239967357911, grad_norm: 1.206240883862357, ic: -0.004867109741360074
Epoch 27: 2022-04-04 15:01:15.222561: train loss: 1.6241339731407034
Eval step 0: eval loss: 1.003245437565824
Eval: 2022-04-04 15:01:17.535616: total loss: 1.0803431362207059, mse:4.69796442361985, ic :0.16794116712045384, sharpe5:15.79964772105217, irr5:509.6968688964844, ndcg5:0.8441976434478751, pnl5:5.303904056549072 
train 28, step: 0, loss: 1.1525032448713552, grad_norm: 0.1668839827469653, ic: 0.12664556969863194
train 28, step: 500, loss: 2.9648578273012767, grad_norm: 1.292098108955423, ic: 0.06732633295904279
train 28, step: 1000, loss: 2.7920305634750195, grad_norm: 3.1085057085151706, ic: -0.03380699127010386
train 28, step: 1500, loss: 1.0243753489670575, grad_norm: 0.004992336003439987, ic: 0.20242667892256822
train 28, step: 2000, loss: 1.7528753945993822, grad_norm: 0.3683791849024755, ic: 0.08240259224938702
Epoch 28: 2022-04-04 15:01:45.896626: train loss: 1.6243687572714165
Eval step 0: eval loss: 1.0068689781217086
Eval: 2022-04-04 15:01:48.218200: total loss: 1.0799075652900958, mse:4.687793726500958, ic :0.168358077636121, sharpe5:15.237714875936508, irr5:500.3719177246094, ndcg5:0.8479607771418983, pnl5:7.991060256958008 
train 29, step: 0, loss: 1.5115229192333206, grad_norm: 0.1185553061720233, ic: 0.08443944803091902
train 29, step: 500, loss: 2.5519571068652183, grad_norm: 1.8746500448249444, ic: -0.10507900077162105
train 29, step: 1000, loss: 1.7004102238321799, grad_norm: 1.7368264905708228, ic: 0.48209542117414117
train 29, step: 1500, loss: 3.949416893115942, grad_norm: 1.4490702010137724, ic: 0.133450915367615
train 29, step: 2000, loss: 0.9211972073538225, grad_norm: 0.29107739413318173, ic: 0.4758806798452829
Epoch 29: 2022-04-04 15:02:16.017835: train loss: 1.624662173739852
Eval step 0: eval loss: 1.0013465660380463
Eval: 2022-04-04 15:02:18.348671: total loss: 1.0809407721847153, mse:4.688238273488248, ic :0.16068688873061088, sharpe5:14.367323223352432, irr5:451.8368835449219, ndcg5:0.8643764228229862, pnl5:5.733344554901123 
train 30, step: 0, loss: 1.2457760530019872, grad_norm: 0.03751186035532146, ic: 0.9891104130461305
train 30, step: 500, loss: 1.9387434947339794, grad_norm: 0.3603097193452128, ic: 0.1708067533745488
train 30, step: 1000, loss: 3.4458462853189027, grad_norm: 1.196843665245353, ic: 0.39881590732170585
train 30, step: 1500, loss: 1.0728281885299726, grad_norm: 0.2826431668378826, ic: 0.1440164417510082
train 30, step: 2000, loss: 1.0874962111198219, grad_norm: 0.081401353438987, ic: 0.4419913985732923
Epoch 30: 2022-04-04 15:02:47.552766: train loss: 1.6246586332122548
Eval step 0: eval loss: 0.9994880632076092
Eval: 2022-04-04 15:02:49.887152: total loss: 1.0798993297949202, mse:4.6827330081377845, ic :0.16895713151262395, sharpe5:15.86249975502491, irr5:520.37939453125, ndcg5:0.8543633253305896, pnl5:5.216014385223389 
train 31, step: 0, loss: 1.1660975949199879, grad_norm: 0.3279759233747688, ic: 0.20239631243554868
train 31, step: 500, loss: 0.8238477594887921, grad_norm: 0.10119838374736304, ic: 0.2177713099329926
train 31, step: 1000, loss: 5.10289548881323, grad_norm: 0.7986997206553061, ic: 0.04344671049544992
train 31, step: 1500, loss: 1.6822439957254636, grad_norm: 0.29013241705319587, ic: 0.27516273607233754
train 31, step: 2000, loss: 0.9687268019636016, grad_norm: 0.36284495783067827, ic: 0.17169581849903148
Epoch 31: 2022-04-04 15:03:17.468073: train loss: 1.6245095618401257
Eval step 0: eval loss: 1.0084220159047523
Eval: 2022-04-04 15:03:19.825032: total loss: 1.0815018256539002, mse:4.6765488729009475, ic :0.16825912861955927, sharpe5:15.162776749134062, irr5:493.9804992675781, ndcg5:0.8549955002360189, pnl5:5.924824237823486 
train 32, step: 0, loss: 0.8842242214153715, grad_norm: 0.48449625272968494, ic: 0.11214119135506952
train 32, step: 500, loss: 1.1100097284084414, grad_norm: 0.327822380017776, ic: 0.17008110914007762
train 32, step: 1000, loss: 1.3778104196559662, grad_norm: 0.05462526687044325, ic: 0.08237744252126426
train 32, step: 1500, loss: 2.068582918621807, grad_norm: 0.42669807676930943, ic: 0.4398379899544568
train 32, step: 2000, loss: 1.0704752604166667, grad_norm: 0.493311876552036, ic: 0.4679389017107594
Epoch 32: 2022-04-04 15:03:47.457741: train loss: 1.6228092953168443
Eval step 0: eval loss: 1.0077551610222484
Eval: 2022-04-04 15:03:49.799726: total loss: 1.0807077554565923, mse:4.673296732257785, ic :0.17250779928261795, sharpe5:16.217020415067672, irr5:530.9249267578125, ndcg5:0.8482931554196801, pnl5:5.194704532623291 
train 33, step: 0, loss: 1.1645734421254297, grad_norm: 0.02276209867150013, ic: 0.03780914995310988
train 33, step: 500, loss: 3.199817748366641, grad_norm: 0.44886470237832443, ic: 0.5135574344074296
train 33, step: 1000, loss: 5.230939249704115, grad_norm: 3.261606070506301, ic: 0.052278145835941495
train 33, step: 1500, loss: 1.2643755656916922, grad_norm: 1.8692818724050497, ic: 0.055002956551198696
train 33, step: 2000, loss: 1.8378828654917636, grad_norm: 0.34772836007468805, ic: 0.0862207024909716
Epoch 33: 2022-04-04 15:04:17.715406: train loss: 1.6248976015424015
Eval step 0: eval loss: 1.0161581496429042
Eval: 2022-04-04 15:04:20.140773: total loss: 1.0851773482952958, mse:4.683081833975151, ic :0.16877774797851466, sharpe5:14.613388770818709, irr5:475.6018371582031, ndcg5:0.8338516395305245, pnl5:5.1075944900512695 
train 34, step: 0, loss: 0.7166303099618662, grad_norm: 0.34561842706144796, ic: 0.1624650191526806
train 34, step: 500, loss: 1.8279723436331339, grad_norm: 0.9272203739640692, ic: 0.7852679222951602
train 34, step: 1000, loss: 0.6909298390355603, grad_norm: 0.11668173444101314, ic: 0.47961547869987275
train 34, step: 1500, loss: 1.6371312850560897, grad_norm: 1.0833211038599921, ic: 0.640644277090748
train 34, step: 2000, loss: 3.00402731479098, grad_norm: 0.4666678678749995, ic: 0.061692806995273165
Epoch 34: 2022-04-04 15:04:48.138900: train loss: 1.6238812494547503
Eval step 0: eval loss: 1.0066247089339784
Eval: 2022-04-04 15:04:50.493674: total loss: 1.0811973712716016, mse:4.687855608685255, ic :0.1648142326446756, sharpe5:15.279862487912178, irr5:503.2549133300781, ndcg5:0.8396479127084021, pnl5:5.4396867752075195 
train 35, step: 0, loss: 1.0506605317321005, grad_norm: 0.7656459037271668, ic: 0.010512129309491192
train 35, step: 500, loss: 3.289425011837121, grad_norm: 1.5848824173587894, ic: -0.07741362706410143
train 35, step: 1000, loss: 1.3379577828051528, grad_norm: 0.08430932046146539, ic: 0.509974851314752
train 35, step: 1500, loss: 1.651375385506245, grad_norm: 0.43345777329776697, ic: 0.04263384210434655
train 35, step: 2000, loss: 1.2943058850858833, grad_norm: 0.06996336612082156, ic: -0.09623154791284128
Epoch 35: 2022-04-04 15:05:18.449961: train loss: 1.6242192294319437
Eval step 0: eval loss: 1.0009916043394549
Eval: 2022-04-04 15:05:20.783573: total loss: 1.0812053954358571, mse:4.684304568763579, ic :0.16193239853633012, sharpe5:13.785269592404365, irr5:438.4263610839844, ndcg5:0.8347947418416332, pnl5:4.674602508544922 
train 36, step: 0, loss: 9.023992452644041, grad_norm: 1.4103841711197285, ic: -0.048104141570853964
train 36, step: 500, loss: 0.8621345652855318, grad_norm: 0.011805080709097655, ic: 0.06646084916362473
train 36, step: 1000, loss: 1.980984487794453, grad_norm: 2.155312918610125, ic: 0.07940669806484016
train 36, step: 1500, loss: 1.0528084941700464, grad_norm: 0.2224053502490806, ic: 0.06170608741209733
train 36, step: 2000, loss: 2.184549332787669, grad_norm: 1.5002138907899925, ic: 0.38828537429885673
Epoch 36: 2022-04-04 15:05:48.630477: train loss: 1.6239286846026242
Eval step 0: eval loss: 1.0140958748848077
Eval: 2022-04-04 15:05:51.064020: total loss: 1.083684162580896, mse:4.682025303349816, ic :0.16630873241319916, sharpe5:14.992939571142196, irr5:493.3466796875, ndcg5:0.8605817800942849, pnl5:5.927913665771484 
train 37, step: 0, loss: 1.1979639287120563, grad_norm: 0.3836002084782251, ic: 0.1684051500771654
train 37, step: 500, loss: 2.342688748054979, grad_norm: 0.04416158244080108, ic: 0.1596433875684275
train 37, step: 1000, loss: 0.7540403629067205, grad_norm: 0.5024633273762078, ic: 0.15920807042392698
train 37, step: 1500, loss: 3.082780092500793, grad_norm: 1.3423256437741506, ic: 0.18839437376259602
train 37, step: 2000, loss: 3.1537432420389733, grad_norm: 2.3009022349693184, ic: -0.0029170744015410664
Epoch 37: 2022-04-04 15:06:19.511256: train loss: 1.6229522555849742
Eval step 0: eval loss: 1.0054491313273433
Eval: 2022-04-04 15:06:21.888653: total loss: 1.0787171120274401, mse:4.670084739089125, ic :0.17549367187112955, sharpe5:16.428680752515792, irr5:542.41064453125, ndcg5:0.8405395795728804, pnl5:4.843396186828613 
train 38, step: 0, loss: 1.349667820785985, grad_norm: 0.3915805832735018, ic: -0.25324544164360685
train 38, step: 500, loss: 1.6944570615310077, grad_norm: 1.106731035320671, ic: 0.24083588902929068
train 38, step: 1000, loss: 1.8230235541044777, grad_norm: 0.6905809541091213, ic: 0.1360411636636363
train 38, step: 1500, loss: 1.0750405744215465, grad_norm: 0.28974771954005485, ic: 0.4834127518520625
train 38, step: 2000, loss: 0.7616562078028549, grad_norm: 0.03050574981448601, ic: 0.5536040647152584
Epoch 38: 2022-04-04 15:06:49.958330: train loss: 1.6222788626734552
Eval step 0: eval loss: 0.9956574080930752
Eval: 2022-04-04 15:06:52.304290: total loss: 1.0789366347185954, mse:4.699375753341711, ic :0.16937177012735274, sharpe5:16.049631292819974, irr5:519.14794921875, ndcg5:0.8372678035581782, pnl5:4.717808723449707 
train 39, step: 0, loss: 0.8683355009009676, grad_norm: 0.03066834906056389, ic: 0.5378708536678453
train 39, step: 500, loss: 1.2510343183014234, grad_norm: 0.5154635171461995, ic: 0.0013374342454263582
train 39, step: 1000, loss: 1.413658650716146, grad_norm: 0.9040159211668541, ic: 0.052728683669273274
train 39, step: 1500, loss: 2.4560230546615447, grad_norm: 0.5800119163821472, ic: -0.0826972253929016
train 39, step: 2000, loss: 2.920711215480616, grad_norm: 1.7349878526597353, ic: 0.22835681345988784
Epoch 39: 2022-04-04 15:07:20.462527: train loss: 1.622431709048824
Eval step 0: eval loss: 1.001983915773927
Eval: 2022-04-04 15:07:22.771152: total loss: 1.0784279482694257, mse:4.67698966421185, ic :0.1721127825608499, sharpe5:15.391076865792273, irr5:519.79345703125, ndcg5:0.8521945557899117, pnl5:3.896538734436035 
